{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8eb59ed-2229-4c67-9b1c-6764a382c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6fc026d-d550-48fc-ad49-0c1f3097e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bd121c8-f468-45fc-9344-a9e47ee3f7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–æ–∫ —Å—Ç–æ–ª–±—Ü–∞ Gender:\n",
      "–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:\n",
      "['Male' 'Female' 'Female' 'Female' 'Female']\n",
      "['Male' 'Male' 'Male' 'Female' 'Male']\n",
      "\n",
      "–¢–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ (–ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏):\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(df[\u001b[33m'\u001b[39m\u001b[33mGender\u001b[39m\u001b[33m'\u001b[39m].head(\u001b[32m5\u001b[39m).values)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m–¢–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ (–ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏):\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mX\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mGender\u001b[39m\u001b[33m'\u001b[39m].head(\u001b[32m5\u001b[39m).values)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m–¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(test_df[\u001b[33m'\u001b[39m\u001b[33mGender\u001b[39m\u001b[33m'\u001b[39m].head(\u001b[32m5\u001b[39m).values)\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/test.csv')\n",
    "print(\"–ü–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–æ–∫ —Å—Ç–æ–ª–±—Ü–∞ Gender:\")\n",
    "print(\"–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:\")\n",
    "print(train_df['Gender'].head(5).values)\n",
    "print(df['Gender'].head(5).values)\n",
    "\n",
    "print(\"\\n–¢–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ (–ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏):\")\n",
    "print(X['Gender'].head(5).values)\n",
    "\n",
    "print(\"\\n–¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ:\")\n",
    "print(test_df['Gender'].head(5).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afa5b37b-d186-4970-9872-c532d0a0d5ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ø—Ä–∏–∑–Ω–∞–∫–∏: (15000, 13)\n",
      "—Ç–∞—Ä–≥–µ—Ç: (15000,)\n",
      "Male ‚Üí 1\n",
      "Female ‚Üí 0\n",
      "   id  CustomerId     Surname  CreditScore Geography  Gender   Age  Tenure  \\\n",
      "0   0  15653521.0  Nkemakonam        667.0   Germany       1  33.0     3.0   \n",
      "1   1  15699005.0   Chiekwugo        614.0    France       0  31.0     2.0   \n",
      "2   2  15656912.0      Chiang        683.0   Germany       0  24.0     6.0   \n",
      "3   3  15700772.0      Ch'ang        678.0    France       0  38.0     9.0   \n",
      "4   4  15583850.0      Chiang        588.0     Spain       0  39.0     3.0   \n",
      "\n",
      "     Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \n",
      "0  131769.04            1.0        1.0             1.0        162719.69  \n",
      "1  110615.47            1.0        1.0             1.0        181879.56  \n",
      "2  115074.02            2.0        1.0             0.0        109688.82  \n",
      "3       0.00            1.0        1.0             0.0        122823.84  \n",
      "4       0.00            2.0        1.0             1.0        136910.18  \n"
     ]
    }
   ],
   "source": [
    "X = train_df.drop('Exited', axis = 1)\n",
    "y = train_df['Exited']\n",
    "\n",
    "print(f\"–ø—Ä–∏–∑–Ω–∞–∫–∏: {X.shape}\")\n",
    "print(f\"—Ç–∞—Ä–≥–µ—Ç: {y.shape}\")\n",
    "\n",
    "le = LabelEncoder()\n",
    "X['Gender'] = le.fit_transform(X['Gender'])\n",
    "test_df['Gender'] = le.transform(test_df['Gender'])\n",
    "\n",
    "print(f\"Male ‚Üí {le.transform(['Male'])[0]}\")\n",
    "print(f\"Female ‚Üí {le.transform(['Female'])[0]}\")\n",
    "\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d23605b-2983-46d5-927a-dd072116efdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15000</td>\n",
       "      <td>15646539.0</td>\n",
       "      <td>Onyemauchechukwu</td>\n",
       "      <td>821.0</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120893.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15001</td>\n",
       "      <td>15628144.0</td>\n",
       "      <td>Chikwado</td>\n",
       "      <td>634.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129299.28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179655.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15002</td>\n",
       "      <td>15687953.0</td>\n",
       "      <td>Ting</td>\n",
       "      <td>713.0</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80552.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15003</td>\n",
       "      <td>15585067.0</td>\n",
       "      <td>Achebe</td>\n",
       "      <td>611.0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>151335.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15004</td>\n",
       "      <td>15746190.0</td>\n",
       "      <td>Chiazagomekpere</td>\n",
       "      <td>724.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88724.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  CustomerId           Surname  CreditScore  Gender   Age  Tenure  \\\n",
       "0  15000  15646539.0  Onyemauchechukwu        821.0       1  32.0     3.0   \n",
       "1  15001  15628144.0          Chikwado        634.0       1  28.0     1.0   \n",
       "2  15002  15687953.0              Ting        713.0       1  42.0     1.0   \n",
       "3  15003  15585067.0            Achebe        611.0       0  38.0     3.0   \n",
       "4  15004  15746190.0   Chiazagomekpere        724.0       1  29.0     9.0   \n",
       "\n",
       "     Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
       "0       0.00            1.0        1.0             1.0        120893.85   \n",
       "1  129299.28            1.0        1.0             0.0        179655.85   \n",
       "2       0.00            2.0        1.0             1.0         80552.12   \n",
       "3       0.00            1.0        0.0             1.0        151335.24   \n",
       "4       0.00            1.0        1.0             1.0         88724.49   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  \n",
       "0                0.0              1.0  \n",
       "1                0.0              0.0  \n",
       "2                0.0              0.0  \n",
       "3                0.0              0.0  \n",
       "4                0.0              0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_cols = ['Geography']\n",
    "\n",
    "'''\n",
    "sparse_output=False –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±—É–¥–µ—Ç –≤–æ–∑–≤—Ä–∞—â–µ–Ω\n",
    "–≤ –≤–∏–¥–µ –æ–±—ã—á–Ω–æ–≥–æ –º–∞—Å—Å–∏–≤–∞ (–∞ –Ω–µ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã).\n",
    "drop='first' –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –¥–∞–º–º–∏-–ª–æ–≤—É—à–∫–∏ \n",
    "(—É–¥–∞–ª—è–µ—Ç—Å—è –ø–µ—Ä–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü –∏–∑ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö). \n",
    "–≠—Ç–æ –∑–Ω–∞—á–∏—Ç, —á—Ç–æ –¥–ª—è N –∫–∞—Ç–µ–≥–æ—Ä–∏–π –º—ã –ø–æ–ª—É—á–∏–º N-1 —Å—Ç–æ–ª–±–µ—Ü.\n",
    "'''\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False, drop='first')\n",
    "X_encoded = ohe.fit_transform(X[cat_cols])\n",
    "test_encoded = ohe.transform(test_df[cat_cols])\n",
    "\n",
    "encoded_cols = ohe.get_feature_names_out(cat_cols)\n",
    "X[encoded_cols] = X_encoded\n",
    "test_df[encoded_cols] = test_encoded\n",
    "\n",
    "X.drop(cat_cols, axis=1, inplace=True)\n",
    "test_df.drop(cat_cols, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "X.head()\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "729996f2-cdf0-4fbc-8db5-c6d2c0b997d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–æ–ª–æ–Ω–∫–∏ –≤ X: ['id', 'CustomerId', 'Surname', 'CreditScore', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Geography_Germany', 'Geography_Spain']\n",
      "–ö–æ–ª–æ–Ω–∫–∏ –≤ test_df: ['id', 'CustomerId', 'Surname', 'CreditScore', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Geography_Germany', 'Geography_Spain']\n"
     ]
    }
   ],
   "source": [
    "print(\"–ö–æ–ª–æ–Ω–∫–∏ –≤ X:\", X.columns.tolist())\n",
    "print(\"–ö–æ–ª–æ–Ω–∫–∏ –≤ test_df:\", test_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e2bd267-a769-4cf7-801e-49335369fe7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–æ–ª–æ–Ω–∫–∏ –≤ X, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ test_df: set()\n",
      "–ö–æ–ª–æ–Ω–∫–∏ –≤ test_df, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ X: set()\n"
     ]
    }
   ],
   "source": [
    "print(\"–ö–æ–ª–æ–Ω–∫–∏ –≤ X, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ test_df:\", set(X.columns) - set(test_df.columns))\n",
    "print(\"–ö–æ–ª–æ–Ω–∫–∏ –≤ test_df, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ X:\", set(test_df.columns) - set(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d98c1422-dc38-4281-b7bd-2d66b64f821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Geography' in test_df.columns:\n",
    "    test_df.drop('Geography', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d9b067a-4885-45d5-a63c-61f3251c6ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'CustomerId', 'Surname', 'CreditScore', 'Gender', 'Age', 'Tenure',\n",
       "       'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember',\n",
       "       'EstimatedSalary', 'Geography_Germany', 'Geography_Spain'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e4da49-508f-4830-86d0-7003e0bb25ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ef51777d-5f8f-46eb-97da-f52e16f070c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–°–æ–∑–¥–∞–µ–º —Ñ–∏—á–∏ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...\n",
      "–°–æ–∑–¥–∞–µ–º —Ñ–∏—á–∏ –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö (—Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –∏–∑ train)...\n",
      "–°–æ–∑–¥–∞–Ω–æ 30 —Ñ–∏—á –≤ train –∏ 30 –≤ test\n"
     ]
    }
   ],
   "source": [
    "def create_advanced_features(df, train_stats=None):\n",
    "    \"\"\"\n",
    "    –°–æ–∑–¥–∞–µ—Ç —Ñ–∏—á–∏, –∏—Å–ø–æ–ª—å–∑—É—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ç–æ–ª—å–∫–æ –∏–∑ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∏—á\n",
    "    train_stats: —Å–ª–æ–≤–∞—Ä—å —Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞–º–∏ –∏–∑ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "                 (–µ—Å–ª–∏ None, –≤—ã—á–∏—Å–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–∑ df)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–∑ train - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö\n",
    "    if train_stats is None:\n",
    "        # –†–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è - –≤—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–∑ –¥–∞–Ω–Ω—ã—Ö\n",
    "        balance_max = df['Balance'].max()\n",
    "        train_stats = {'balance_max': balance_max}\n",
    "    else:\n",
    "        # –†–µ–∂–∏–º –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\n",
    "        balance_max = train_stats['balance_max']\n",
    "    \n",
    "    # ==================== –§–ò–ù–ê–ù–°–û–í–´–ï –ò–ù–î–ò–ö–ê–¢–û–†–´ ====================\n",
    "    \n",
    "    # –û—Ç–Ω–æ—à–µ–Ω–∏–µ –±–∞–ª–∞–Ω—Å–∞ –∫ –∑–∞—Ä–ø–ª–∞—Ç–µ (—Ñ–∏–Ω–∞–Ω—Å–æ–≤–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å)\n",
    "    df['Balance_to_Salary_Ratio'] = df['Balance'] / (df['EstimatedSalary'] + 1)\n",
    "    \n",
    "    # –ö—Ä–µ–¥–∏—Ç–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥ –Ω–∞ –≥–æ–¥ –≤–æ–∑—Ä–∞—Å—Ç–∞\n",
    "    df['CreditScore_per_Age'] = df['CreditScore'] / df['Age']\n",
    "    \n",
    "    # –§–∏–Ω–∞–Ω—Å–æ–≤–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ (–ø—Ä–æ–¥—É–∫—Ç—ã –Ω–∞ –±–∞–ª–∞–Ω—Å)\n",
    "    df['Products_per_Balance'] = df['NumOfProducts'] / (df['Balance'] + 1)\n",
    "    \n",
    "    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º balance_max –∏–∑ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "    df['Financial_Health_Score'] = (\n",
    "        df['CreditScore'] / 850 + \n",
    "        df['Balance'] / balance_max +  # ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º max –∏–∑ train\n",
    "        (1 - df['NumOfProducts'] / 4)\n",
    "    )\n",
    "    \n",
    "    # ==================== –î–ï–ú–û–ì–†–ê–§–ò–ß–ï–°–ö–ò–ï –ì–†–£–ü–ü–´ ====================\n",
    "    \n",
    "    # –í–æ–∑—Ä–∞—Å—Ç–Ω—ã–µ –≥—Ä—É–ø–ø—ã (–±–∏–Ω–∞—Ä–Ω—ã–µ)\n",
    "    df['Is_Young_Client'] = (df['Age'] < 30).astype(int)\n",
    "    df['Is_Middle_Aged_Client'] = ((df['Age'] >= 30) & (df['Age'] <= 50)).astype(int)\n",
    "    df['Is_Senior_Client'] = (df['Age'] > 50).astype(int)\n",
    "    \n",
    "    # –ì—Ä—É–ø–ø—ã –∫—Ä–µ–¥–∏—Ç–Ω–æ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ –∂–µ –±–∏–Ω—ã —á—Ç–æ –∏ –≤ train)\n",
    "    df['CreditScore_Group'] = pd.cut(\n",
    "        df['CreditScore'], \n",
    "        bins=[0, 580, 670, 740, 800, 850],\n",
    "        labels=['Poor', 'Fair', 'Good', 'Very_Good', 'Excellent']\n",
    "    )\n",
    "    \n",
    "    # ==================== –ü–û–í–ï–î–ï–ù–ß–ï–°–ö–ò–ï –ü–ê–¢–¢–ï–†–ù–´ ====================\n",
    "    \n",
    "    # –ü—Ä–æ–¥—É–∫—Ç—ã –≤ –≥–æ–¥ (–∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)\n",
    "    df['Products_per_Year'] = df['NumOfProducts'] / (df['Tenure'] + 1)\n",
    "    \n",
    "    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –º–µ–¥–∏–∞–Ω—É tenure —Ç–æ–∂–µ –Ω—É–∂–Ω–æ –±—Ä–∞—Ç—å –∏–∑ train\n",
    "    if 'tenure_median' in train_stats:\n",
    "        tenure_median = train_stats['tenure_median']\n",
    "    else:\n",
    "        tenure_median = df['Tenure'].median()\n",
    "        train_stats['tenure_median'] = tenure_median\n",
    "    \n",
    "    df['Is_Long_Term_Client'] = (df['Tenure'] > tenure_median).astype(int)\n",
    "    \n",
    "    # –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –¥–ª—è –±–∞–ª–∞–Ω—Å–∞\n",
    "    if 'balance_median' in train_stats:\n",
    "        balance_median = train_stats['balance_median']\n",
    "    else:\n",
    "        balance_median = df['Balance'].median()\n",
    "        train_stats['balance_median'] = balance_median\n",
    "    \n",
    "    df['Is_Active_High_Balance'] = ((df['IsActiveMember'] == 1) & \n",
    "                                   (df['Balance'] > balance_median)).astype(int)\n",
    "    \n",
    "    df['Is_Inactive_Low_Balance'] = ((df['IsActiveMember'] == 0) & \n",
    "                                    (df['Balance'] < balance_median)).astype(int)\n",
    "    \n",
    "    # ==================== –í–ó–ê–ò–ú–û–î–ï–ô–°–¢–í–ò–Ø –ú–ï–ñ–î–£ –ü–†–ò–ó–ù–ê–ö–ê–ú–ò ====================\n",
    "    \n",
    "    df['Age_Balance_Interaction'] = df['Age'] * df['Balance'] / 10000\n",
    "    df['CreditScore_Products_Interaction'] = df['CreditScore'] * df['NumOfProducts']\n",
    "    \n",
    "    # ==================== –†–ò–°–ö–û–í–´–ï –ü–†–û–§–ò–õ–ò ====================\n",
    "    \n",
    "    df['Risk_Score'] = (\n",
    "        (df['Age'] < 25).astype(int) +\n",
    "        (df['NumOfProducts'] > 2).astype(int) +  \n",
    "        (df['Balance'] < 1000).astype(int) +\n",
    "        (df['IsActiveMember'] == 0).astype(int)\n",
    "    )\n",
    "    \n",
    "    df['Customer_Value_Score'] = (\n",
    "        df['Balance'] * 0.4 +\n",
    "        df['Tenure'] * 1000 * 0.3 +\n",
    "        df['CreditScore'] * 0.2 +\n",
    "        df['IsActiveMember'] * 5000 * 0.1\n",
    "    )\n",
    "    \n",
    "    return df, train_stats\n",
    "\n",
    "# –ü–†–ê–í–ò–õ–¨–ù–û–ï –ü–†–ò–ú–ï–ù–ï–ù–ò–ï:\n",
    "print(\"–°–æ–∑–¥–∞–µ–º —Ñ–∏—á–∏ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "X_advanced, train_stats = create_advanced_features(X)\n",
    "\n",
    "print(\"–°–æ–∑–¥–∞–µ–º —Ñ–∏—á–∏ –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö (—Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –∏–∑ train)...\")\n",
    "test_df_advanced, _ = create_advanced_features(test_df, train_stats)\n",
    "\n",
    "print(f\"–°–æ–∑–¥–∞–Ω–æ {X_advanced.shape[1]} —Ñ–∏—á –≤ train –∏ {test_df_advanced.shape[1]} –≤ test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4a88e239-72e3-4901-88ab-944fc1d2005b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –≤ X_advanced:\n",
      "id                                     int64\n",
      "CustomerId                           float64\n",
      "Surname                               object\n",
      "CreditScore                          float64\n",
      "Gender                                 int64\n",
      "Age                                  float64\n",
      "Tenure                               float64\n",
      "Balance                              float64\n",
      "NumOfProducts                        float64\n",
      "HasCrCard                            float64\n",
      "IsActiveMember                       float64\n",
      "EstimatedSalary                      float64\n",
      "Geography_Germany                    float64\n",
      "Geography_Spain                      float64\n",
      "Balance_to_Salary_Ratio              float64\n",
      "CreditScore_per_Age                  float64\n",
      "Products_per_Balance                 float64\n",
      "Financial_Health_Score               float64\n",
      "Is_Young_Client                        int64\n",
      "Is_Middle_Aged_Client                  int64\n",
      "Is_Senior_Client                       int64\n",
      "CreditScore_Group                   category\n",
      "Products_per_Year                    float64\n",
      "Is_Long_Term_Client                    int64\n",
      "Is_Active_High_Balance                 int64\n",
      "Is_Inactive_Low_Balance                int64\n",
      "Age_Balance_Interaction              float64\n",
      "CreditScore_Products_Interaction     float64\n",
      "Risk_Score                             int64\n",
      "Customer_Value_Score                 float64\n",
      "dtype: object\n",
      "\n",
      "–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –≤ test_df_advanced:\n",
      "id                                     int64\n",
      "CustomerId                           float64\n",
      "Surname                               object\n",
      "CreditScore                          float64\n",
      "Gender                                 int64\n",
      "Age                                  float64\n",
      "Tenure                               float64\n",
      "Balance                              float64\n",
      "NumOfProducts                        float64\n",
      "HasCrCard                            float64\n",
      "IsActiveMember                       float64\n",
      "EstimatedSalary                      float64\n",
      "Geography_Germany                    float64\n",
      "Geography_Spain                      float64\n",
      "Balance_to_Salary_Ratio              float64\n",
      "CreditScore_per_Age                  float64\n",
      "Products_per_Balance                 float64\n",
      "Financial_Health_Score               float64\n",
      "Is_Young_Client                        int64\n",
      "Is_Middle_Aged_Client                  int64\n",
      "Is_Senior_Client                       int64\n",
      "CreditScore_Group                   category\n",
      "Products_per_Year                    float64\n",
      "Is_Long_Term_Client                    int64\n",
      "Is_Active_High_Balance                 int64\n",
      "Is_Inactive_Low_Balance                int64\n",
      "Age_Balance_Interaction              float64\n",
      "CreditScore_Products_Interaction     float64\n",
      "Risk_Score                             int64\n",
      "Customer_Value_Score                 float64\n",
      "dtype: object\n",
      "\n",
      "üîç –°—Ç—Ä–æ–∫–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏: ['Surname']\n",
      "\n",
      "Surname: 767 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
      "–ü—Ä–∏–º–µ—Ä—ã: ['Nkemakonam' 'Chiekwugo' 'Chiang' \"Ch'ang\" 'Onwumelu']\n"
     ]
    }
   ],
   "source": [
    "print(\"–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –≤ X_advanced:\")\n",
    "print(X_advanced.dtypes)\n",
    "\n",
    "print(\"\\n–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –≤ test_df_advanced:\")\n",
    "print(test_df_advanced.dtypes)\n",
    "\n",
    "# –ù–∞–π–¥–µ–º —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏\n",
    "string_columns = X_advanced.select_dtypes(include=['object']).columns\n",
    "print(f\"\\nüîç –°—Ç—Ä–æ–∫–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(string_columns)}\")\n",
    "\n",
    "# –ü–æ—Å–º–æ—Ç—Ä–∏–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —ç—Ç–∏—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö\n",
    "for col in string_columns:\n",
    "    print(f\"\\n{col}: {X_advanced[col].nunique()} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\")\n",
    "    print(f\"–ü—Ä–∏–º–µ—Ä—ã: {X_advanced[col].unique()[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "16226343-a569-4d67-85dd-b2006b9af2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–æ–ª–æ–Ω–∫–∏ –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è: ['CreditScore', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Geography_Germany', 'Geography_Spain', 'Balance_to_Salary_Ratio', 'CreditScore_per_Age', 'Products_per_Balance', 'Financial_Health_Score', 'Is_Young_Client', 'Is_Middle_Aged_Client', 'Is_Senior_Client', 'CreditScore_Group', 'Products_per_Year', 'Is_Long_Term_Client', 'Is_Active_High_Balance', 'Is_Inactive_Low_Balance', 'Age_Balance_Interaction', 'CreditScore_Products_Interaction', 'Risk_Score', 'Customer_Value_Score']\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['id', 'CustomerId', 'Surname'] \n",
    "\n",
    "X_advanced_clean = X_advanced.drop(columns=columns_to_drop, errors='ignore')\n",
    "test_df_advanced_clean = test_df_advanced.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "print(f\"–ö–æ–ª–æ–Ω–∫–∏ –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è: {X_advanced_clean.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "df7df241-69ef-42f6-8c3d-2a3d80fece1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_string_cols = X_advanced_clean.select_dtypes(include=['object']).columns\n",
    "if len(remaining_string_cols) > 0:\n",
    "    print(f\"–û—Å—Ç–∞–ª–∏—Å—å —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(remaining_string_cols)}\")\n",
    "    \n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "    for col in remaining_string_cols:\n",
    "        if X_advanced_clean[col].nunique() <= 10:  # –ï—Å–ª–∏ –º–∞–ª–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
    "            # OneHot encoding –¥–ª—è –∫–æ–ª–æ–Ω–æ–∫ —Å –º–∞–ª—ã–º —á–∏—Å–ª–æ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–π\n",
    "            X_advanced_clean = pd.get_dummies(X_advanced_clean, columns=[col], prefix=col)\n",
    "            test_df_advanced_clean = pd.get_dummies(test_df_advanced_clean, columns=[col], prefix=col)\n",
    "        else:\n",
    "            # Label encoding –¥–ª—è –∫–æ–ª–æ–Ω–æ–∫ —Å –±–æ–ª—å—à–∏–º —á–∏—Å–ª–æ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–π\n",
    "            le = LabelEncoder()\n",
    "            X_advanced_clean[col] = le.fit_transform(X_advanced_clean[col].astype(str))\n",
    "            test_df_advanced_clean[col] = le.transform(test_df_advanced_clean[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3c20580a-1376-4eb6-9241-bbb89adb8c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–æ–ª–æ–Ω–∫–∏ –≤ test, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ train: set()\n",
      "–ö–æ–ª–æ–Ω–∫–∏ –≤ train, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ test: set()\n",
      "–§–∏–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã:\n",
      "X_advanced_clean: (15000, 27)\n",
      "test_df_advanced_clean: (10000, 27)\n"
     ]
    }
   ],
   "source": [
    "missing_cols_train = set(test_df_advanced_clean.columns) - set(X_advanced_clean.columns)\n",
    "missing_cols_test = set(X_advanced_clean.columns) - set(test_df_advanced_clean.columns)\n",
    "\n",
    "print(f\"–ö–æ–ª–æ–Ω–∫–∏ –≤ test, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ train: {missing_cols_train}\")\n",
    "print(f\"–ö–æ–ª–æ–Ω–∫–∏ –≤ train, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ test: {missing_cols_test}\")\n",
    "\n",
    "# –î–æ–±–∞–≤–∏–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ (–∑–∞–ø–æ–ª–Ω–∏–º –Ω—É–ª—è–º–∏)\n",
    "for col in missing_cols_test:\n",
    "    test_df_advanced_clean[col] = 0\n",
    "\n",
    "for col in missing_cols_train:\n",
    "    X_advanced_clean[col] = 0\n",
    "\n",
    "# –£–ø–æ—Ä—è–¥–æ—á–∏–º –∫–æ–ª–æ–Ω–∫–∏ –æ–¥–∏–Ω–∞–∫–æ–≤–æ\n",
    "test_df_advanced_clean = test_df_advanced_clean[X_advanced_clean.columns]\n",
    "\n",
    "print(f\"–§–∏–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã:\")\n",
    "print(f\"X_advanced_clean: {X_advanced_clean.shape}\")\n",
    "print(f\"test_df_advanced_clean: {test_df_advanced_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ab5c31b0-7add-427e-bef9-07437147fd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: ['CreditScore_Group']\n",
      "–ö–æ–¥–∏—Ä—É–µ–º –∫–æ–ª–æ–Ω–∫—É: CreditScore_Group\n",
      "–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: ['Fair', 'Good', 'Very_Good', 'Poor', 'Excellent']\n",
      "Categories (5, object): ['Poor' < 'Fair' < 'Good' < 'Very_Good' < 'Excellent']\n",
      "\n",
      "–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è:\n",
      "float64    18\n",
      "int64       9\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "category_columns = X_advanced_clean.select_dtypes(include=['category']).columns\n",
    "print(f\"–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(category_columns)}\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for col in category_columns:\n",
    "    print(f\"–ö–æ–¥–∏—Ä—É–µ–º –∫–æ–ª–æ–Ω–∫—É: {col}\")\n",
    "    print(f\"–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: {X_advanced_clean[col].unique()}\")\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    X_advanced_clean[col] = le.fit_transform(X_advanced_clean[col].astype(str))\n",
    "    test_df_advanced_clean[col] = le.transform(test_df_advanced_clean[col].astype(str))\n",
    "\n",
    "print(f\"\\n–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è:\")\n",
    "print(X_advanced_clean.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dde2b94e-9f4b-4799-917e-9216dabee864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–†–∞–∑–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏:\n",
      "–¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ: (12000, 27)\n",
      "–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ: (3000, 27)\n",
      "\n",
      "–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –≤ X_train:\n",
      "float64    18\n",
      "int64       9\n",
      "Name: count, dtype: int64\n",
      "\n",
      " –û–°–ù–û–í–ù–´–ï –ú–ï–¢–†–ò–ö–ò:\n",
      "Accuracy: 0.8670\n",
      "ROC-AUC: 0.920314\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.89      0.91      2376\n",
      "         1.0       0.65      0.76      0.70       624\n",
      "\n",
      "    accuracy                           0.87      3000\n",
      "   macro avg       0.79      0.83      0.81      3000\n",
      "weighted avg       0.88      0.87      0.87      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "X_final = X_advanced_clean\n",
    "test_final = test_df_advanced_clean\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_final, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"–†–∞–∑–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏:\")\n",
    "print(f\"–¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ: {X_train.shape}\")\n",
    "print(f\"–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ: {X_val.shape}\")\n",
    "\n",
    "print(f\"\\n–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –≤ X_train:\")\n",
    "print(X_train.dtypes.value_counts())\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    max_depth=10,\n",
    "    min_samples_split=5\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = rf.predict(X_val)\n",
    "y_pred_proba = rf.predict_proba(X_val)[:, 1]  \n",
    "\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "\n",
    "print(f\"\\n –û–°–ù–û–í–ù–´–ï –ú–ï–¢–†–ò–ö–ò:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:f}\")\n",
    "\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab712463-f5fd-40de-b2d1-17ce5f7d4a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971044a3-2063-4c98-b10d-b0c0875dca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "–ü–†–ò–ú–ï–ù–Ø–Æ –ú–ï–¢–û–î–´ –î–õ–Ø –†–ê–°–®–ò–†–ï–ù–ù–û–ì–û –ü–†–û–°–¢–†–ê–ù–¢–°–í–ê –§–ò–ß"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c714b2b6-9adf-47e1-a397-6c4198fea4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-optimize --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "082c7455-b97d-4ad7-b1c1-27f703cc5a95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_final shape: (15000, 27)\n",
      "y_final length: 15000\n",
      "–ë—É–¥–µ—Ç –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ 50 –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "–õ—É—á—à–∏–π ROC-AUC: 0.9299\n",
      "–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
      "  colsample_bytree: 0.5438690071815024\n",
      "  gamma: 0.32051609379143403\n",
      "  learning_rate: 0.00560934847477771\n",
      "  max_depth: 3\n",
      "  min_child_weight: 6\n",
      "  n_estimators: 1984\n",
      "  reg_alpha: 0.27341575146016034\n",
      "  reg_lambda: 1.3719835883172633\n",
      "  subsample: 0.805012178084324\n",
      "\n",
      "Bayesian XGBoost –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:\n",
      "ROC-AUC: 0.9368\n",
      "Accuracy: 0.9030\n",
      "\n",
      " –°–†–ê–í–ù–ï–ù–ò–ï –° RANDOM FOREST:\n",
      "Random Forest ROC-AUC: 0.9203\n",
      "Bayesian XGBoost ROC-AUC: 0.9368\n",
      "–£–ª—É—á—à–µ–Ω–∏–µ: 0.0165\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_final = X_advanced_clean\n",
    "y_final = y  \n",
    "\n",
    "print(f\"X_final shape: {X_final.shape}\")\n",
    "print(f\"y_final length: {len(y_final)}\")\n",
    "\n",
    "param_space = {\n",
    "    'n_estimators': Integer(100, 2000),\n",
    "    'max_depth': Integer(3, 12),\n",
    "    'learning_rate': Real(0.001, 0.3, prior='log-uniform'),\n",
    "    'subsample': Real(0.5, 1.0),\n",
    "    'colsample_bytree': Real(0.5, 1.0),\n",
    "    'reg_alpha': Real(0, 2),\n",
    "    'reg_lambda': Real(0, 2),\n",
    "    'gamma': Real(0, 1),\n",
    "    'min_child_weight': Integer(1, 10)\n",
    "}\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å XGBoost\n",
    "xgb = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=xgb,\n",
    "    search_spaces=param_space,\n",
    "    n_iter=50,  \n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='roc_auc',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"–ë—É–¥–µ—Ç –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ {bayes_search.n_iter} –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\")\n",
    "\n",
    "\n",
    "\n",
    "bayes_search.fit(X_final, y_final)\n",
    "\n",
    "# –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "print(f\"–õ—É—á—à–∏–π ROC-AUC: {bayes_search.best_score_:.4f}\")\n",
    "print(f\"–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\")\n",
    "for param, value in bayes_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "best_bayes_model = bayes_search.best_estimator_\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_final, \n",
    "    y_final, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y_final\n",
    ")\n",
    "\n",
    "y_pred_bayes = best_bayes_model.predict(X_val)\n",
    "y_pred_proba_bayes = best_bayes_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "roc_auc_bayes = roc_auc_score(y_val, y_pred_proba_bayes)\n",
    "accuracy_bayes = accuracy_score(y_val, y_pred_bayes)\n",
    "\n",
    "print(f\"\\nBayesian XGBoost –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:\")\n",
    "print(f\"ROC-AUC: {roc_auc_bayes:.4f}\")\n",
    "print(f\"Accuracy: {accuracy_bayes:.4f}\")\n",
    "\n",
    "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å Random Forest\n",
    "print(f\"\\n –°–†–ê–í–ù–ï–ù–ò–ï –° RANDOM FOREST:\")\n",
    "print(f\"Random Forest ROC-AUC: {roc_auc:.4f}\")\n",
    "print(f\"Bayesian XGBoost ROC-AUC: {roc_auc_bayes:.4f}\")\n",
    "print(f\"–£–ª—É—á—à–µ–Ω–∏–µ: {roc_auc_bayes - roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4c0dd124-88af-4fac-8edb-946e5dca68ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " XGBoost –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:\n",
      "ROC-AUC: 0.9254\n",
      "Accuracy: 0.8937\n",
      "–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: 0.27 —Å–µ–∫\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "import time\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "# –û–±—É—á–µ–Ω–∏–µ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
    "start_time = time.time()\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_val)\n",
    "y_pred_proba_xgb = xgb.predict_proba(X_val)[:, 1]\n",
    "xgb_time = time.time() - start_time\n",
    "\n",
    "# –ú–µ—Ç—Ä–∏–∫–∏\n",
    "roc_auc_xgb = roc_auc_score(y_val, y_pred_proba_xgb)\n",
    "accuracy_xgb = accuracy_score(y_val, y_pred_xgb)\n",
    "\n",
    "print(\" XGBoost –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:\")\n",
    "print(f\"ROC-AUC: {roc_auc_xgb:.4f}\")\n",
    "print(f\"Accuracy: {accuracy_xgb:.4f}\")\n",
    "print(f\"–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {xgb_time:.2f} —Å–µ–∫\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f864a84d-30f4-41a1-b63e-a820392d0bdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û–±—É—á–∞–µ–º —Å—É–ø–µ—Ä-–∞–Ω—Å–∞–º–±–ª—å...\n",
      "[LightGBM] [Info] Number of positive: 2494, number of negative: 9506\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2671\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207833 -> initscore=-1.338035\n",
      "[LightGBM] [Info] Start training from score -1.338035\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 2494, number of negative: 9506\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2671\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207833 -> initscore=-1.338035\n",
      "[LightGBM] [Info] Start training from score -1.338035\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1996, number of negative: 7604\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2666\n",
      "[LightGBM] [Info] Number of data points in the train set: 9600, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207917 -> initscore=-1.337529\n",
      "[LightGBM] [Info] Start training from score -1.337529\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1995, number of negative: 7605\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2666\n",
      "[LightGBM] [Info] Number of data points in the train set: 9600, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207813 -> initscore=-1.338162\n",
      "[LightGBM] [Info] Start training from score -1.338162\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1995, number of negative: 7605\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2671\n",
      "[LightGBM] [Info] Number of data points in the train set: 9600, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207813 -> initscore=-1.338162\n",
      "[LightGBM] [Info] Start training from score -1.338162\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1995, number of negative: 7605\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2667\n",
      "[LightGBM] [Info] Number of data points in the train set: 9600, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207813 -> initscore=-1.338162\n",
      "[LightGBM] [Info] Start training from score -1.338162\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1995, number of negative: 7605\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2668\n",
      "[LightGBM] [Info] Number of data points in the train set: 9600, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207813 -> initscore=-1.338162\n",
      "[LightGBM] [Info] Start training from score -1.338162\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1996, number of negative: 7604\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2666\n",
      "[LightGBM] [Info] Number of data points in the train set: 9600, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207917 -> initscore=-1.337529\n",
      "[LightGBM] [Info] Start training from score -1.337529\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1995, number of negative: 7605\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2666\n",
      "[LightGBM] [Info] Number of data points in the train set: 9600, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207813 -> initscore=-1.338162\n",
      "[LightGBM] [Info] Start training from score -1.338162\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1995, number of negative: 7605\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2671\n",
      "[LightGBM] [Info] Number of data points in the train set: 9600, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207813 -> initscore=-1.338162\n",
      "[LightGBM] [Info] Start training from score -1.338162\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1995, number of negative: 7605\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2667\n",
      "[LightGBM] [Info] Number of data points in the train set: 9600, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207813 -> initscore=-1.338162\n",
      "[LightGBM] [Info] Start training from score -1.338162\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1995, number of negative: 7605\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000978 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2668\n",
      "[LightGBM] [Info] Number of data points in the train set: 9600, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207813 -> initscore=-1.338162\n",
      "[LightGBM] [Info] Start training from score -1.338162\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "–°—Ç–µ–∫–∏–Ω–≥ –∞–Ω—Å–∞–º–±–ª—å:\n",
      "ROC-AUC: 0.8277\n",
      "Accuracy: 0.8200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –º–æ—â–Ω—ã–π –∞–Ω—Å–∞–º–±–ª—å –∏–∑ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π\n",
    "models = [\n",
    "    ('xgb1', xgb.XGBClassifier(\n",
    "        n_estimators=500, max_depth=7, learning_rate=0.05, \n",
    "        subsample=0.8, colsample_bytree=0.8, random_state=42\n",
    "    )),\n",
    "    ('xgb2', xgb.XGBClassifier(\n",
    "        n_estimators=300, max_depth=9, learning_rate=0.1,\n",
    "        subsample=0.7, colsample_bytree=0.7, random_state=43\n",
    "    )),\n",
    "    ('lgbm1', lgb.LGBMClassifier(\n",
    "        n_estimators=500, max_depth=6, learning_rate=0.05,\n",
    "        subsample=0.8, colsample_bytree=0.8, random_state=44\n",
    "    )),\n",
    "    ('lgbm2', lgb.LGBMClassifier(\n",
    "        n_estimators=400, max_depth=8, learning_rate=0.08, \n",
    "        subsample=0.75, colsample_bytree=0.75, random_state=45\n",
    "    ))\n",
    "]\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º —Å—Ç–µ–∫–∏–Ω–≥ –∞–Ω—Å–∞–º–±–ª—å\n",
    "stacking_ensemble = StackingClassifier(\n",
    "    estimators=models,\n",
    "    final_estimator=LogisticRegression(C=0.1, random_state=42),\n",
    "    cv=5,\n",
    "    passthrough=True\n",
    ")\n",
    "\n",
    "print(\"–û–±—É—á–∞–µ–º —Å—É–ø–µ—Ä-–∞–Ω—Å–∞–º–±–ª—å...\")\n",
    "stacking_ensemble.fit(X_train, y_train)\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "y_pred_stack = stacking_ensemble.predict(X_val)\n",
    "y_pred_proba_stack = stacking_ensemble.predict_proba(X_val)[:, 1]\n",
    "\n",
    "roc_auc_stack = roc_auc_score(y_val, y_pred_proba_stack)\n",
    "accuracy_stack = accuracy_score(y_val, y_pred_stack)\n",
    "\n",
    "print(f\"–°—Ç–µ–∫–∏–Ω–≥ –∞–Ω—Å–∞–º–±–ª—å:\")\n",
    "print(f\"ROC-AUC: {roc_auc_stack:.4f}\")\n",
    "print(f\"Accuracy: {accuracy_stack:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0bef5775-66a4-44d8-b289-f04c69511916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ –û–±—É—á–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π XGBoost...\n",
      "üéØ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π XGBoost:\n",
      "ROC-AUC: 0.9191\n",
      "Accuracy: 0.8807\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "\n",
    "xgb_optimized = XGBClassifier(\n",
    "    n_estimators=100,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤\n",
    "    max_depth=10,        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≥–ª—É–±–∏–Ω—É\n",
    "    learning_rate=0.01, # –£–º–µ–Ω—å—à–∞–µ–º learning rate –¥–ª—è –ª—É—á—à–µ–π —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,      # L1 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è\n",
    "    reg_lambda=0.1,     # L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "print(\"üéØ –û–±—É—á–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π XGBoost...\")\n",
    "xgb_optimized.fit(X_train, y_train)\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "y_pred_opt = xgb_optimized.predict(X_val)\n",
    "y_pred_proba_opt = xgb_optimized.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# –ú–µ—Ç—Ä–∏–∫–∏\n",
    "roc_auc_opt = roc_auc_score(y_val, y_pred_proba_opt)\n",
    "accuracy_opt = accuracy_score(y_val, y_pred_opt)\n",
    "\n",
    "print(f\"üéØ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π XGBoost:\")\n",
    "print(f\"ROC-AUC: {roc_auc_opt:.4f}\")\n",
    "print(f\"Accuracy: {accuracy_opt:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96cf2dd-6fb4-4002-a49d-2ba4ae653b77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff56a47e-d0b9-4531-bd3b-b8915642e8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ –≠–ª–∏—Ç–Ω—ã–µ —Ñ–∏—á–∏ —Å–æ–∑–¥–∞–Ω—ã: 36 –∫–æ–ª–æ–Ω–æ–∫\n"
     ]
    }
   ],
   "source": [
    "def create_elite_features(df):\n",
    "    \"\"\"\n",
    "    –°–æ–∑–¥–∞–µ–º —ç–ª–∏—Ç–Ω—ã–µ —Ñ–∏—á–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # –£—Å–∏–ª–∏–≤–∞–µ–º —Ç–æ–ø-5 —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö —Ñ–∏—á\n",
    "    # –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å–∞–º—ã—Ö —Å–∏–ª—å–Ω—ã—Ö —Ñ–∏—á\n",
    "    df['Balance_CreditScore_Super'] = df['Balance'] * df['CreditScore'] / 1000\n",
    "    df['Age_Balance_Power'] = (df['Age'] ** 1.5) * (df['Balance'] ** 0.5)\n",
    "    \n",
    "    # –ù–µ–ª–∏–Ω–µ–π–Ω—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ç–æ–ø-—Ñ–∏—á\n",
    "    df['CreditScore_Quantile'] = pd.qcut(df['CreditScore'], q=10, labels=False, duplicates='drop')\n",
    "    df['Balance_Log_Interaction'] = np.log1p(df['Balance']) * df['NumOfProducts']\n",
    "    \n",
    "    # –ö–æ–º–±–∏–Ω–∞—Ü–∏–∏ 3-—Ö —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö —Ñ–∏—á\n",
    "    df['Elite_Financial_Score'] = (\n",
    "        df['CreditScore'] * 0.5 + \n",
    "        df['Balance'] * 0.3 + \n",
    "        df['Age'] * 0.2\n",
    "    )\n",
    "    \n",
    "    # –°–µ–∑–æ–Ω–Ω—ã–µ/–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã (–µ—Å–ª–∏ –µ—Å—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)\n",
    "    if 'Tenure' in df.columns:\n",
    "        df['Tenure_Squared'] = df['Tenure'] ** 2\n",
    "        df['Balance_per_Tenure_Squared'] = df['Balance'] / (df['Tenure'] ** 2 + 1)\n",
    "    \n",
    "    # –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
    "    df['Is_CreditScore_Extreme'] = ((df['CreditScore'] > 800) | (df['CreditScore'] < 500)).astype(int)\n",
    "    df['Is_Balance_Extreme'] = ((df['Balance'] > 150000) | (df['Balance'] < 100)).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω—è–µ–º —ç–ª–∏—Ç–Ω—ã–µ —Ñ–∏—á–∏\n",
    "X_elite = create_elite_features(X_advanced_clean)\n",
    "test_elite = create_elite_features(test_df_advanced_clean)\n",
    "\n",
    "print(f\"üéØ –≠–ª–∏—Ç–Ω—ã–µ —Ñ–∏—á–∏ —Å–æ–∑–¥–∞–Ω—ã: {X_elite.shape[1]} –∫–æ–ª–æ–Ω–æ–∫\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "37c92b68-c34c-4a3f-92f2-24aaf1de26d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ –ó–∞–ø—É—Å–∫–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "üéØ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {'colsample_bytree': np.float64(0.7177795568278342), 'learning_rate': np.float64(0.1255293185805776), 'max_depth': 3, 'n_estimators': 116, 'reg_alpha': np.float64(0.1694927466860925), 'reg_lambda': np.float64(0.5568012624583502), 'subsample': np.float64(0.9744619096643123)}\n",
      "üéØ –õ—É—á—à–∏–π ROC-AUC: 0.9273\n",
      "üéØ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ—Å–ª–µ –ø–æ–¥–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:\n",
      "ROC-AUC: 0.92663\n",
      "Accuracy: 0.8937\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy.stats as stats\n",
    "\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞\n",
    "param_distributions = {\n",
    "    'n_estimators': stats.randint(50,300),\n",
    "    'max_depth': stats.randint(3,25),\n",
    "    'learning_rate': stats.uniform(0.01, 0.3),\n",
    "    'subsample': stats.uniform(0.6, 0.4),\n",
    "    'colsample_bytree': stats.uniform(0.6, 0.4),\n",
    "    'reg_alpha': stats.uniform(0, 1),\n",
    "    'reg_lambda': stats.uniform(0, 1)\n",
    "}\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å\n",
    "xgb_base = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "\n",
    "# Randomized Search\n",
    "random_search = RandomizedSearchCV(\n",
    "    xgb_base,\n",
    "    param_distributions,\n",
    "    n_iter=50,  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
    "    cv=3,       # 3-fold cross-validation\n",
    "    scoring='roc_auc',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ —è–¥—Ä–∞\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"üéØ –ó–∞–ø—É—Å–∫–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...\")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "print(f\"üéØ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {random_search.best_params_}\")\n",
    "print(f\"üéØ –õ—É—á—à–∏–π ROC-AUC: {random_search.best_score_:.4f}\")\n",
    "\n",
    "# –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å\n",
    "best_xgb = random_search.best_estimator_\n",
    "y_pred_best = best_xgb.predict(X_val)\n",
    "y_pred_proba_best = best_xgb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "roc_auc_best = roc_auc_score(y_val, y_pred_proba_best)\n",
    "accuracy_best = accuracy_score(y_val, y_pred_best)\n",
    "\n",
    "print(f\"üéØ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ—Å–ª–µ –ø–æ–¥–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:\")\n",
    "print(f\"ROC-AUC: {roc_auc_best:.5f}\")\n",
    "print(f\"Accuracy: {accuracy_best:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7f9ef0-391d-4abb-ab1e-f77cb8bc5ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "97522896-eb64-45a3-9f13-c4a9aea9eb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω—ã ID –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: 10000 –∑–∞–ø–∏—Å–µ–π\n",
      "üéØ –û–±—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö...\n",
      "üìä –°–æ–∑–¥–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...\n",
      "üìä –†–∞–∑–º–µ—Ä —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–∞–±–º–∏—à–Ω–∞: (10000, 2)\n",
      "üîç –ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ —Å–∞–±–º–∏—à–Ω–∞:\n",
      "      id    Exited\n",
      "0  15000  0.081349\n",
      "1  15001  0.054874\n",
      "2  15002  0.018649\n",
      "3  15003  0.272466\n",
      "4  15004  0.051136\n",
      "‚úÖ submission_final_bayesian_xgb.csv —Å–æ–∑–¥–∞–Ω\n",
      "‚ö†Ô∏è Random Forest –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, —Å–æ–∑–¥–∞–µ–º —Ç–æ–ª—å–∫–æ XGBoost —Å–∞–±–º–∏—à–Ω\n",
      "\n",
      "üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ô:\n",
      "Min: 0.0026\n",
      "Max: 0.9936\n",
      "Mean: 0.2007\n",
      "Std: 0.2850\n",
      "\n",
      "üîç –ü–†–û–í–ï–†–ö–ê –°–ê–ë–ú–ò–®–ù–ê:\n",
      "–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö ID: 10000\n",
      "–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: 0\n",
      "\n",
      "üéâ –§–ò–ù–ê–õ–¨–ù–´–ô –°–ê–ë–ú–ò–®–ù –ì–û–¢–û–í!\n",
      "üìä –†–µ–∫–æ–º–µ–Ω–¥—É—é –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∞ Kaggle:\n",
      "   - submission_final_bayesian_xgb.csv (–æ—Å–Ω–æ–≤–Ω–æ–π)\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è ID\n",
    "test_original = pd.read_csv('data/test.csv')  # —É–∫–∞–∂–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É\n",
    "test_ids = test_original['id']\n",
    "\n",
    "print(f\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω—ã ID –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {len(test_ids)} –∑–∞–ø–∏—Å–µ–π\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å —Å –ª—É—á—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n",
    "final_model = XGBClassifier(\n",
    "    colsample_bytree=0.5438690071815024,\n",
    "    gamma=0.32051609379143403,\n",
    "    learning_rate=0.00560934847477771,\n",
    "    max_depth=3,\n",
    "    min_child_weight=6,\n",
    "    n_estimators=1984,\n",
    "    reg_alpha=0.27341575146016034,\n",
    "    reg_lambda=1.3719835883172633,\n",
    "    subsample=0.805012178084324,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "\n",
    "print(\"üéØ –û–±—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "final_model.fit(X_final, y_final)\n",
    "\n",
    "print(\"üìä –°–æ–∑–¥–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "test_predictions_final = final_model.predict_proba(test_df_advanced_clean)[:, 1]\n",
    "test_predictions_final = np.clip(test_predictions_final, 0.001, 0.999)\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º —Å–∞–±–º–∏—à–Ω —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ ID\n",
    "submission_final = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'Exited': test_predictions_final\n",
    "})\n",
    "\n",
    "print(f\"üìä –†–∞–∑–º–µ—Ä —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–∞–±–º–∏—à–Ω–∞: {submission_final.shape}\")\n",
    "print(\"üîç –ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ —Å–∞–±–º–∏—à–Ω–∞:\")\n",
    "print(submission_final.head())\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∞–±–º–∏—à–Ω\n",
    "submission_final.to_csv('submission_final_bayesian_xgb.csv', index=False)\n",
    "print(\"‚úÖ submission_final_bayesian_xgb.csv —Å–æ–∑–¥–∞–Ω\")\n",
    "\n",
    "# –¢–∞–∫–∂–µ —Å–æ–∑–¥–∞–µ–º –±–ª–µ–Ω–¥–∏–Ω–≥ —Å Random Forest, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ\n",
    "try:\n",
    "    test_predictions_rf = rf_model.predict_proba(test_df_advanced_clean)[:, 1]\n",
    "    test_predictions_blend = (test_predictions_final * 0.7 + test_predictions_rf * 0.3)\n",
    "    test_predictions_blend = np.clip(test_predictions_blend, 0.001, 0.999)\n",
    "    \n",
    "    submission_blend = pd.DataFrame({\n",
    "        'id': test_ids,\n",
    "        'Exited': test_predictions_blend\n",
    "    })\n",
    "    \n",
    "    submission_blend.to_csv('submission_final_blend.csv', index=False)\n",
    "    print(\"‚úÖ submission_final_blend.csv —Å–æ–∑–¥–∞–Ω\")\n",
    "    \n",
    "except NameError:\n",
    "    print(\"‚ö†Ô∏è Random Forest –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, —Å–æ–∑–¥–∞–µ–º —Ç–æ–ª—å–∫–æ XGBoost —Å–∞–±–º–∏—à–Ω\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
    "print(f\"\\nüìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ô:\")\n",
    "print(f\"Min: {test_predictions_final.min():.4f}\")\n",
    "print(f\"Max: {test_predictions_final.max():.4f}\")\n",
    "print(f\"Mean: {test_predictions_final.mean():.4f}\")\n",
    "print(f\"Std: {test_predictions_final.std():.4f}\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ ID –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã\n",
    "print(f\"\\nüîç –ü–†–û–í–ï–†–ö–ê –°–ê–ë–ú–ò–®–ù–ê:\")\n",
    "print(f\"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö ID: {submission_final['id'].nunique()}\")\n",
    "print(f\"–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {submission_final.isnull().sum().sum()}\")\n",
    "\n",
    "print(f\"\\nüéâ –§–ò–ù–ê–õ–¨–ù–´–ô –°–ê–ë–ú–ò–®–ù –ì–û–¢–û–í!\")\n",
    "print(\"üìä –†–µ–∫–æ–º–µ–Ω–¥—É—é –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∞ Kaggle:\")\n",
    "print(\"   - submission_final_bayesian_xgb.csv (–æ—Å–Ω–æ–≤–Ω–æ–π)\")\n",
    "if 'submission_blend' in locals():\n",
    "    print(\"   - submission_final_blend.csv (–±–ª–µ–Ω–¥–∏–Ω–≥ —Å RF)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dbfb9bb7-55d8-48f7-acaa-861c73910aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî¨ –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –Ω–∞ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏...\n",
      "ROC-AUC –Ω–∞ 5-—Ñ–æ–ª–¥ CV: [0.92708051 0.94334508 0.91759284 0.97424776 0.95716996 0.95066414\n",
      " 0.94659799 0.89807536 0.96503117 0.97533207 0.93819463 0.89807536\n",
      " 0.971537   0.86988344 0.95608566 0.95879642 0.92897804 0.94361616\n",
      " 0.86635945 0.92843589 0.94117647 0.93792356 0.8953646  0.91054486\n",
      " 0.94795337 0.92897804 0.96665763 0.90837625 0.90729195 0.94985091\n",
      " 0.94686907 0.93087558 0.93548387 0.94930876 0.9259962  0.94659799\n",
      " 0.88940092 0.92165899 0.9295202  0.94063432 0.91894822 0.8782868\n",
      " 0.97560314 0.84602873 0.88289509 0.93439957 0.91949038 0.93548387\n",
      " 0.95527243 0.91894822 0.87910003 0.95229059 0.93358634 0.92165899\n",
      " 0.90729195 0.91488208 0.91325562 0.93412849 0.93439957 0.91135809\n",
      " 0.94280293 0.93304419 0.94442938 0.90729195 0.96150718 0.90349688\n",
      " 0.92138791 0.92924912 0.94714015 0.92545405 0.93548387 0.93385741\n",
      " 0.94036324 0.9590675  0.93982109 0.93087558 0.92816481 0.92165899\n",
      " 0.96936839 0.9192193  0.97587422 0.88614801 0.93299788 0.97960805\n",
      " 0.94147246 0.93961864 0.91816737 0.94173729 0.86679025 0.93855932\n",
      " 0.87711864 0.92028602 0.95391949 0.9748411  0.91340042 0.95180085\n",
      " 0.94782839 0.93564619 0.90466102 0.9314089 ]\n",
      "–°—Ä–µ–¥–Ω–∏–π ROC-AUC: 0.9302 (+/- 0.0535)\n",
      "üöÄ –û—Ç–ª–∏—á–Ω–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏!\n"
     ]
    }
   ],
   "source": [
    "# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(\"\\nüî¨ –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –Ω–∞ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏...\")\n",
    "cv_scores = cross_val_score(final_model, X_final, y_final, \n",
    "                           cv=100, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "print(f\"ROC-AUC –Ω–∞ 5-—Ñ–æ–ª–¥ CV: {cv_scores}\")\n",
    "print(f\"–°—Ä–µ–¥–Ω–∏–π ROC-AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "if cv_scores.mean() > 0.92:\n",
    "    print(\"üöÄ –û—Ç–ª–∏—á–Ω–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏!\")\n",
    "elif cv_scores.mean() > 0.90:\n",
    "    print(\"‚úÖ –•–æ—Ä–æ—à–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –≤–æ–∑–º–æ–∂–Ω–∞ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6402eafb-27d0-4891-92af-ce9aadaa926b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ –ó–∞–ø—É—Å–∫–∞–µ–º –¢–û–ß–ù–£–Æ Bayesian Optimization...\n",
      "–ë—É–¥–µ—Ç –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ 80 –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
      "–ò—Å–ø–æ–ª—å–∑—É–µ–º 10-—Ñ–æ–ª–¥–æ–≤—É—é CV –¥–ª—è –±–æ–ª—å—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏\n",
      "–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è...\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "\n",
      "üéâ –¢–û–ß–ù–´–ô –ü–û–ò–°–ö –ó–ê–í–ï–†–®–ï–ù!\n",
      "–õ—É—á—à–∏–π ROC-AUC: 0.9303\n",
      "–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
      "  colsample_bytree: 0.52\n",
      "  gamma: 0.35\n",
      "  learning_rate: 0.007\n",
      "  max_depth: 3\n",
      "  min_child_weight: 5\n",
      "  n_estimators: 2100\n",
      "  reg_alpha: 0.25\n",
      "  reg_lambda: 1.3639195910873667\n",
      "  subsample: 0.83\n",
      "\n",
      "üî• Refined XGBoost –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:\n",
      "ROC-AUC: 0.9396\n",
      "Accuracy: 0.9033\n",
      "\n",
      "üìä –°–†–ê–í–ù–ï–ù–ò–ï –° –ü–†–ï–î–´–î–£–©–ï–ô –ú–û–î–ï–õ–¨–Æ:\n",
      "–ü—Ä–µ–¥—ã–¥—É—â–∏–π ROC-AUC: 0.9368\n",
      "Refined ROC-AUC: 0.9396\n",
      "–£–ª—É—á—à–µ–Ω–∏–µ: 0.0029\n",
      "\n",
      "üéØ –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–∞–±–º–∏—à–Ω...\n",
      "‚úÖ submission_refined_xgb.csv —Å–æ–∑–¥–∞–Ω\n",
      "\n",
      "‚úÖ –ù–µ–±–æ–ª—å—à–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ: +0.0029 ROC-AUC\n",
      "\n",
      "üî¨ –ü–†–û–í–ï–†–ö–ê –°–¢–ê–ë–ò–õ–¨–ù–û–°–¢–ò (10-—Ñ–æ–ª–¥ CV):\n",
      "ROC-AUC –Ω–∞ 10-—Ñ–æ–ª–¥ CV: [0.94547284 0.92692122 0.92884507 0.93072552 0.91405508 0.92000669\n",
      " 0.9352904  0.93935077 0.92896378 0.9320475 ]\n",
      "–°—Ä–µ–¥–Ω–∏–π ROC-AUC: 0.9302 (+/- 0.0170)\n",
      "üìà –¶–µ–ª—å –ø–æ–∫–∞ –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞, –Ω–æ –º—ã –±–ª–∏–∑–∫–∏!\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "import numpy as np\n",
    "\n",
    "# –£–∑–∫–∏–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã –≤–æ–∫—Ä—É–≥ –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "refined_param_space = {\n",
    "    'n_estimators': Integer(1900, 2100),  # ¬±100 –≤–æ–∫—Ä—É–≥ 1984\n",
    "    'max_depth': Integer(3, 5),           # 3-5 (–ª—É—á—à–∏–π –±—ã–ª 3)\n",
    "    'learning_rate': Real(0.004, 0.007),  # —É–∑–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω –≤–æ–∫—Ä—É–≥ 0.0056\n",
    "    'subsample': Real(0.78, 0.83),        # ¬±0.025 –≤–æ–∫—Ä—É–≥ 0.805\n",
    "    'colsample_bytree': Real(0.52, 0.57), # ¬±0.015 –≤–æ–∫—Ä—É–≥ 0.544\n",
    "    'reg_alpha': Real(0.25, 0.30),        # ¬±0.025 –≤–æ–∫—Ä—É–≥ 0.273\n",
    "    'reg_lambda': Real(1.3, 1.45),        # ¬±0.05 –≤–æ–∫—Ä—É–≥ 1.372\n",
    "    'gamma': Real(0.30, 0.35),            # ¬±0.02 –≤–æ–∫—Ä—É–≥ 0.321\n",
    "    'min_child_weight': Integer(5, 7)     # 5-7 (–ª—É—á—à–∏–π –±—ã–ª 6)\n",
    "}\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å XGBoost\n",
    "xgb_refined = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º Bayesian Search —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º CV\n",
    "bayes_search_refined = BayesSearchCV(\n",
    "    estimator=xgb_refined,\n",
    "    search_spaces=refined_param_space,\n",
    "    n_iter=80,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π\n",
    "    cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42),  # 10 —Ñ–æ–ª–¥–æ–≤!\n",
    "    scoring='roc_auc',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"üéØ –ó–∞–ø—É—Å–∫–∞–µ–º –¢–û–ß–ù–£–Æ Bayesian Optimization...\")\n",
    "print(f\"–ë—É–¥–µ—Ç –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ {bayes_search_refined.n_iter} –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\")\n",
    "print(\"–ò—Å–ø–æ–ª—å–∑—É–µ–º 10-—Ñ–æ–ª–¥–æ–≤—É—é CV –¥–ª—è –±–æ–ª—å—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏\")\n",
    "print(\"–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è...\")\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–∏—Å–∫ –Ω–∞ –í–°–ï–• –¥–∞–Ω–Ω—ã—Ö\n",
    "bayes_search_refined.fit(X_final, y_final)\n",
    "\n",
    "# –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "print(f\"\\nüéâ –¢–û–ß–ù–´–ô –ü–û–ò–°–ö –ó–ê–í–ï–†–®–ï–ù!\")\n",
    "print(f\"–õ—É—á—à–∏–π ROC-AUC: {bayes_search_refined.best_score_:.4f}\")\n",
    "print(f\"–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\")\n",
    "for param, value in bayes_search_refined.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å\n",
    "best_refined_model = bayes_search_refined.best_estimator_\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∏–º –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_final, \n",
    "    y_final, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y_final\n",
    ")\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è refined –º–æ–¥–µ–ª–∏\n",
    "y_pred_refined = best_refined_model.predict(X_val)\n",
    "y_pred_proba_refined = best_refined_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "roc_auc_refined = roc_auc_score(y_val, y_pred_proba_refined)\n",
    "accuracy_refined = accuracy_score(y_val, y_pred_refined)\n",
    "\n",
    "print(f\"\\nüî• Refined XGBoost –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:\")\n",
    "print(f\"ROC-AUC: {roc_auc_refined:.4f}\")\n",
    "print(f\"Accuracy: {accuracy_refined:.4f}\")\n",
    "\n",
    "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π –ª—É—á—à–µ–π –º–æ–¥–µ–ª—å—é\n",
    "print(f\"\\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –° –ü–†–ï–î–´–î–£–©–ï–ô –ú–û–î–ï–õ–¨–Æ:\")\n",
    "print(f\"–ü—Ä–µ–¥—ã–¥—É—â–∏–π ROC-AUC: {roc_auc_bayes:.4f}\")\n",
    "print(f\"Refined ROC-AUC: {roc_auc_refined:.4f}\")\n",
    "print(f\"–£–ª—É—á—à–µ–Ω–∏–µ: {roc_auc_refined - roc_auc_bayes:.4f}\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–∞–±–º–∏—à–Ω —Å refined –º–æ–¥–µ–ª—å—é\n",
    "print(\"\\nüéØ –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–∞–±–º–∏—à–Ω...\")\n",
    "\n",
    "test_predictions_refined = best_refined_model.predict_proba(test_df_advanced_clean)[:, 1]\n",
    "test_predictions_refined = np.clip(test_predictions_refined, 0.001, 0.999)\n",
    "\n",
    "submission_refined = pd.DataFrame({\n",
    "    'id': range(15000, 15000 + len(test_predictions_refined)),\n",
    "    'Exited': test_predictions_refined\n",
    "})\n",
    "\n",
    "submission_refined.to_csv('submission_refined_xgb.csv', index=False)\n",
    "print(\"‚úÖ submission_refined_xgb.csv —Å–æ–∑–¥–∞–Ω\")\n",
    "\n",
    "# –ê–Ω–∞–ª–∏–∑ —É–ª—É—á—à–µ–Ω–∏—è\n",
    "improvement = roc_auc_refined - roc_auc_bayes\n",
    "if improvement > 0.005:\n",
    "    print(f\"\\nüöÄ –û–¢–õ–ò–ß–ù–û–ï –£–õ–£–ß–®–ï–ù–ò–ï: +{improvement:.4f} ROC-AUC!\")\n",
    "elif improvement > 0:\n",
    "    print(f\"\\n‚úÖ –ù–µ–±–æ–ª—å—à–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ: +{improvement:.4f} ROC-AUC\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  –£—Ö—É–¥—à–µ–Ω–∏–µ: {improvement:.4f} ROC-AUC\")\n",
    "\n",
    "# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏\n",
    "print(f\"\\nüî¨ –ü–†–û–í–ï–†–ö–ê –°–¢–ê–ë–ò–õ–¨–ù–û–°–¢–ò (10-—Ñ–æ–ª–¥ CV):\")\n",
    "cv_scores_refined = cross_val_score(best_refined_model, X_final, y_final, \n",
    "                                  cv=10, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "print(f\"ROC-AUC –Ω–∞ 10-—Ñ–æ–ª–¥ CV: {cv_scores_refined}\")\n",
    "print(f\"–°—Ä–µ–¥–Ω–∏–π ROC-AUC: {cv_scores_refined.mean():.4f} (+/- {cv_scores_refined.std() * 2:.4f})\")\n",
    "\n",
    "if cv_scores_refined.mean() >= 0.939:\n",
    "    print(\"üéØ –¶–ï–õ–¨ –î–û–°–¢–ò–ì–ù–£–¢–ê! ROC-AUC >= 0.939\")\n",
    "else:\n",
    "    print(\"üìà –¶–µ–ª—å –ø–æ–∫–∞ –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞, –Ω–æ –º—ã –±–ª–∏–∑–∫–∏!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0da0eb-81f2-4c96-bb87-a87f1c47caf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7714e75a-ef54-40c9-bda9-e51c028f06ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ X_final_elite shape: (15000, 36)\n",
      "‚úÖ test_df_elite shape: (10000, 36)\n",
      "üéØ –ó–∞–ø—É—Å–∫–∞–µ–º Bayesian Optimization –Ω–∞ —ç–ª–∏—Ç–Ω—ã—Ö —Ñ–∏—á–∞—Ö...\n",
      "–ë—É–¥–µ—Ç –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ 50 –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
      "–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "üéâ –ü–û–ò–°–ö –ù–ê –≠–õ–ò–¢–ù–´–• –§–ò–ß–ê–• –ó–ê–í–ï–†–®–ï–ù!\n",
      "–õ—É—á—à–∏–π ROC-AUC: 0.9302\n",
      "–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
      "  colsample_bytree: 0.5313686494270139\n",
      "  gamma: 0.3\n",
      "  learning_rate: 0.007\n",
      "  max_depth: 3\n",
      "  min_child_weight: 5\n",
      "  n_estimators: 1900\n",
      "  reg_alpha: 0.2981689909158076\n",
      "  reg_lambda: 1.4141827412743657\n",
      "  subsample: 0.78\n",
      "\n",
      "üî• Elite XGBoost –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:\n",
      "ROC-AUC: 0.9388\n",
      "Accuracy: 0.9043\n",
      "\n",
      "üìä –°–†–ê–í–ù–ï–ù–ò–ï –° –ü–†–ï–î–´–î–£–©–ï–ô –õ–£–ß–®–ï–ô –ú–û–î–ï–õ–¨–Æ:\n",
      "–ü—Ä–µ–¥—ã–¥—É—â–∏–π –ª—É—á—à–∏–π ROC-AUC: 0.9396\n",
      "Elite –º–æ–¥–µ–ª—å ROC-AUC: 0.9388\n",
      "–£–ª—É—á—à–µ–Ω–∏–µ: -0.0008\n",
      "\n",
      "üéØ –°–æ–∑–¥–∞–µ–º —Å–∞–±–º–∏—à–Ω —Å —ç–ª–∏—Ç–Ω—ã–º–∏ —Ñ–∏—á–∞–º–∏...\n",
      "‚úÖ submission_elite_features.csv —Å–æ–∑–¥–∞–Ω\n"
     ]
    }
   ],
   "source": [
    "# –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º X_final –∏ test_df —Å —ç–ª–∏—Ç–Ω—ã–º–∏ —Ñ–∏—á–∞–º–∏\n",
    "X_final_elite = X_elite\n",
    "test_df_elite = test_elite\n",
    "\n",
    "print(f\"‚úÖ X_final_elite shape: {X_final_elite.shape}\")\n",
    "print(f\"‚úÖ test_df_elite shape: {test_df_elite.shape}\")\n",
    "\n",
    "# –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ –∂–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, —á—Ç–æ –∏ –≤ refined –ø–æ–∏—Å–∫–µ\n",
    "elite_param_space = {\n",
    "    'n_estimators': Integer(1900, 2100),\n",
    "    'max_depth': Integer(3, 5),\n",
    "    'learning_rate': Real(0.004, 0.007),\n",
    "    'subsample': Real(0.78, 0.83),\n",
    "    'colsample_bytree': Real(0.52, 0.57),\n",
    "    'reg_alpha': Real(0.25, 0.30),\n",
    "    'reg_lambda': Real(1.3, 1.45),\n",
    "    'gamma': Real(0.30, 0.35),\n",
    "    'min_child_weight': Integer(5, 7)\n",
    "}\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å XGBoost\n",
    "xgb_elite = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º Bayesian Search\n",
    "bayes_search_elite = BayesSearchCV(\n",
    "    estimator=xgb_elite,\n",
    "    search_spaces=elite_param_space,\n",
    "    n_iter=50,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='roc_auc',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"üéØ –ó–∞–ø—É—Å–∫–∞–µ–º Bayesian Optimization –Ω–∞ —ç–ª–∏—Ç–Ω—ã—Ö —Ñ–∏—á–∞—Ö...\")\n",
    "print(f\"–ë—É–¥–µ—Ç –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ {bayes_search_elite.n_iter} –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\")\n",
    "print(\"–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç...\")\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–∏—Å–∫ –Ω–∞ —ç–ª–∏—Ç–Ω—ã—Ö —Ñ–∏—á–∞—Ö\n",
    "bayes_search_elite.fit(X_final_elite, y_final)\n",
    "\n",
    "# –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "print(f\"\\nüéâ –ü–û–ò–°–ö –ù–ê –≠–õ–ò–¢–ù–´–• –§–ò–ß–ê–• –ó–ê–í–ï–†–®–ï–ù!\")\n",
    "print(f\"–õ—É—á—à–∏–π ROC-AUC: {bayes_search_elite.best_score_:.4f}\")\n",
    "print(f\"–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\")\n",
    "for param, value in bayes_search_elite.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å\n",
    "best_elite_model = bayes_search_elite.best_estimator_\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∏–º –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "X_train_elite, X_val_elite, y_train_elite, y_val_elite = train_test_split(\n",
    "    X_final_elite, \n",
    "    y_final, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y_final\n",
    ")\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è elite –º–æ–¥–µ–ª–∏\n",
    "y_pred_elite = best_elite_model.predict(X_val_elite)\n",
    "y_pred_proba_elite = best_elite_model.predict_proba(X_val_elite)[:, 1]\n",
    "\n",
    "roc_auc_elite = roc_auc_score(y_val_elite, y_pred_proba_elite)\n",
    "accuracy_elite = accuracy_score(y_val_elite, y_pred_elite)\n",
    "\n",
    "print(f\"\\nüî• Elite XGBoost –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:\")\n",
    "print(f\"ROC-AUC: {roc_auc_elite:.4f}\")\n",
    "print(f\"Accuracy: {accuracy_elite:.4f}\")\n",
    "\n",
    "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π –ª—É—á—à–µ–π –º–æ–¥–µ–ª—å—é\n",
    "print(f\"\\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –° –ü–†–ï–î–´–î–£–©–ï–ô –õ–£–ß–®–ï–ô –ú–û–î–ï–õ–¨–Æ:\")\n",
    "print(f\"–ü—Ä–µ–¥—ã–¥—É—â–∏–π –ª—É—á—à–∏–π ROC-AUC: {roc_auc_refined:.4f}\")\n",
    "print(f\"Elite –º–æ–¥–µ–ª—å ROC-AUC: {roc_auc_elite:.4f}\")\n",
    "print(f\"–£–ª—É—á—à–µ–Ω–∏–µ: {roc_auc_elite - roc_auc_refined:.4f}\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º —Å–∞–±–º–∏—à–Ω —Å elite –º–æ–¥–µ–ª—å—é\n",
    "print(\"\\nüéØ –°–æ–∑–¥–∞–µ–º —Å–∞–±–º–∏—à–Ω —Å —ç–ª–∏—Ç–Ω—ã–º–∏ —Ñ–∏—á–∞–º–∏...\")\n",
    "\n",
    "test_predictions_elite = best_elite_model.predict_proba(test_df_elite)[:, 1]\n",
    "test_predictions_elite = np.clip(test_predictions_elite, 0.001, 0.999)\n",
    "\n",
    "submission_elite = pd.DataFrame({\n",
    "    'id': range(15000, 15000 + len(test_predictions_elite)),\n",
    "    'Exited': test_predictions_elite\n",
    "})\n",
    "\n",
    "submission_elite.to_csv('submission_elite_features.csv', index=False)\n",
    "print(\"‚úÖ submission_elite_features.csv —Å–æ–∑–¥–∞–Ω\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dd3bf7a0-abe3-4e85-a6c7-a391d8beebc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ –°–æ–∑–¥–∞–µ–º –°–£–ü–ï–†-–≠–õ–ò–¢–ù–´–ï —Ñ–∏—á–∏...\n",
      "‚úÖ –°—É–ø–µ—Ä-—ç–ª–∏—Ç–Ω—ã–µ —Ñ–∏—á–∏ —Å–æ–∑–¥–∞–Ω—ã: 42 –∫–æ–ª–æ–Ω–æ–∫\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. –£–õ–£–ß–®–ï–ù–ù–´–ï –≠–õ–ò–¢–ù–´–ï –§–ò–ß–ò\n",
    "def create_super_elite_features(df):\n",
    "    \"\"\"\n",
    "    –°–æ–∑–¥–∞–µ–º —Å—É–ø–µ—Ä-—ç–ª–∏—Ç–Ω—ã–µ —Ñ–∏—á–∏ —Å –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–º–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è–º–∏\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # –°–∏–ª—å–Ω—ã–µ –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è\n",
    "    df['CreditScore_Cube'] = df['CreditScore'] ** 3 / 1000000\n",
    "    df['Balance_Sqrt_Age'] = np.sqrt(df['Balance'] + 1) * df['Age']\n",
    "    df['Age_Exp_Interaction'] = np.exp(df['Age'] * 0.01) * df['CreditScore']\n",
    "    \n",
    "    # –ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Ç–æ–ø-3 —Ñ–∏—á\n",
    "    df['Poly_Financial_Score'] = (\n",
    "        (df['CreditScore'] ** 2) * 0.3 +\n",
    "        (df['Balance'] ** 1.5) * 0.4 +\n",
    "        (df['Age'] ** 2.5) * 0.3\n",
    "    ) / 10000\n",
    "    \n",
    "    # –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è 4-–≥–æ –ø–æ—Ä—è–¥–∫–∞\n",
    "    df['Mega_Interaction'] = (\n",
    "        df['CreditScore'] * df['Balance'] * df['Age'] * df['NumOfProducts']\n",
    "    ) / 10000000\n",
    "    \n",
    "    # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Å –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è–º–∏\n",
    "    df['Log_Balance_Credit_Age'] = (\n",
    "        np.log1p(df['Balance']) * \n",
    "        np.log1p(df['CreditScore']) * \n",
    "        df['Age']\n",
    "    ) / 1000\n",
    "    \n",
    "    # –ö–≤–∞–Ω—Ç–∏–ª—å–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è\n",
    "    df['Balance_Quantile'] = pd.qcut(df['Balance'], q=20, labels=False, duplicates='drop')\n",
    "    df['CreditScore_Quantile_Fine'] = pd.qcut(df['CreditScore'], q=15, labels=False, duplicates='drop')\n",
    "    \n",
    "    # –°–ª–æ–∂–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –∏ –¥–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "    if 'Geography_Germany' in df.columns:\n",
    "        df['Germany_High_Balance'] = df['Geography_Germany'] * (df['Balance'] > 100000)\n",
    "        df['Spain_Young_Active'] = df['Geography_Spain'] * (df['Age'] < 35) * df['IsActiveMember']\n",
    "    \n",
    "    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã (–µ—Å–ª–∏ Tenure –¥–æ—Å—Ç—É–ø–µ–Ω)\n",
    "    if 'Tenure' in df.columns:\n",
    "        df['Tenure_Balance_Ratio'] = df['Balance'] / (df['Tenure'] + 1)\n",
    "        df['Tenure_Age_Product'] = df['Tenure'] * df['Age'] * df['NumOfProducts']\n",
    "    \n",
    "    # –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –±–∏–Ω–∞—Ä–Ω—ã–µ —Ñ–∏—á–∏\n",
    "    df['Is_Very_High_Credit'] = (df['CreditScore'] > 750).astype(int)\n",
    "    df['Is_Very_Low_Balance'] = (df['Balance'] < 50).astype(int)\n",
    "    df['Is_Senior_High_Balance'] = ((df['Age'] > 60) & (df['Balance'] > 100000)).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"üéØ –°–æ–∑–¥–∞–µ–º –°–£–ü–ï–†-–≠–õ–ò–¢–ù–´–ï —Ñ–∏—á–∏...\")\n",
    "X_super_elite = create_super_elite_features(X_advanced_clean)\n",
    "test_super_elite = create_super_elite_features(test_df_advanced_clean)\n",
    "\n",
    "print(f\"‚úÖ –°—É–ø–µ—Ä-—ç–ª–∏—Ç–Ω—ã–µ —Ñ–∏—á–∏ —Å–æ–∑–¥–∞–Ω—ã: {X_super_elite.shape[1]} –∫–æ–ª–æ–Ω–æ–∫\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "43f9cc19-2a7e-4a9a-bb90-8ea5f5935938",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ –ó–∞–ø—É—Å–∫–∞–µ–º –≠–ö–°–¢–†–ï–ú–ê–õ–¨–ù–´–ô Bayesian Optimization...\n",
      "–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É–ø–µ—Ä-—ç–ª–∏—Ç–Ω—ã–µ —Ñ–∏—á–∏ –∏ 10-—Ñ–æ–ª–¥–æ–≤—É—é CV\n",
      "–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è...\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:37:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:38:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:39:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:40:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:41:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:42:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:43:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:44:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:45:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:46:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:47:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:48:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:49:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:50:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:51:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:52:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:53:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:54:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:54:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:54:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:54:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:54:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:54:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:54:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:54:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:54:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [21:54:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéâ –≠–ö–°–¢–†–ï–ú–ê–õ–¨–ù–´–ô –ü–û–ò–°–ö –ó–ê–í–ï–†–®–ï–ù!\n",
      "–õ—É—á—à–∏–π ROC-AUC: 0.9303\n",
      "–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
      "  colsample_bytree: 0.5117444857924075\n",
      "  gamma: 0.3482557867768453\n",
      "  learning_rate: 0.006\n",
      "  max_depth: 3\n",
      "  min_child_weight: 5\n",
      "  n_estimators: 2050\n",
      "  reg_alpha: 0.24182044438461497\n",
      "  reg_lambda: 1.370496433488063\n",
      "  scale_pos_weight: 0.9261068484405822\n",
      "  subsample: 0.82\n"
     ]
    }
   ],
   "source": [
    "# 2. –≠–ö–°–¢–†–ï–ú–ê–õ–¨–ù–ê–Ø OPTIMIZATION –° –£–ó–ö–ò–ú–ò –î–ò–ê–ü–ê–ó–û–ù–ê–ú–ò\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "import numpy as np\n",
    "\n",
    "# –°–£–ü–ï–†-–£–ó–ö–ò–ï –¥–∏–∞–ø–∞–∑–æ–Ω—ã –≤–æ–∫—Ä—É–≥ –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "extreme_param_space = {\n",
    "    'n_estimators': Integer(2050, 2200),\n",
    "    'max_depth': Integer(3, 4),\n",
    "    'learning_rate': Real(0.006, 0.008),\n",
    "    'subsample': Real(0.82, 0.85),\n",
    "    'colsample_bytree': Real(0.51, 0.53),\n",
    "    'reg_alpha': Real(0.24, 0.26),\n",
    "    'reg_lambda': Real(1.35, 1.38),\n",
    "    'gamma': Real(0.34, 0.36),\n",
    "    'min_child_weight': Integer(5, 6),\n",
    "    'scale_pos_weight': Real(0.9, 1.1)\n",
    "}\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n",
    "xgb_extreme = XGBClassifier(\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "# Bayesian Search —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ñ–æ–ª–¥–æ–≤\n",
    "bayes_search_extreme = BayesSearchCV(\n",
    "    estimator=xgb_extreme,\n",
    "    search_spaces=extreme_param_space,\n",
    "    n_iter=80,  # –ë–æ–ª—å—à–µ –∏—Ç–µ—Ä–∞—Ü–∏–π –≤ —É–∑–∫–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ\n",
    "    cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42),  # 10 —Ñ–æ–ª–¥–æ–≤\n",
    "    scoring='roc_auc',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nüéØ –ó–∞–ø—É—Å–∫–∞–µ–º –≠–ö–°–¢–†–ï–ú–ê–õ–¨–ù–´–ô Bayesian Optimization...\")\n",
    "print(\"–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É–ø–µ—Ä-—ç–ª–∏—Ç–Ω—ã–µ —Ñ–∏—á–∏ –∏ 10-—Ñ–æ–ª–¥–æ–≤—É—é CV\")\n",
    "print(\"–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è...\")\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–∏—Å–∫\n",
    "bayes_search_extreme.fit(X_super_elite, y_final)\n",
    "\n",
    "print(f\"\\nüéâ –≠–ö–°–¢–†–ï–ú–ê–õ–¨–ù–´–ô –ü–û–ò–°–ö –ó–ê–í–ï–†–®–ï–ù!\")\n",
    "print(f\"–õ—É—á—à–∏–π ROC-AUC: {bayes_search_extreme.best_score_:.4f}\")\n",
    "print(\"–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\")\n",
    "for param, value in bayes_search_extreme.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "best_extreme_model = bayes_search_extreme.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "970de940-67d0-40e7-896d-46d1e78d4b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " –û–±—É—á–∞–µ–º LightGBM...\n",
      "[LightGBM] [Info] Number of positive: 3118, number of negative: 11882\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4740\n",
      "[LightGBM] [Info] Number of data points in the train set: 15000, number of used features: 41\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207867 -> initscore=-1.337833\n",
      "[LightGBM] [Info] Start training from score -1.337833\n",
      "LightGBM ROC-AUC: 0.9820\n"
     ]
    }
   ],
   "source": [
    "# 3. –î–û–ë–ê–í–õ–Ø–ï–ú LIGHTGBM –í –ê–ù–°–ê–ú–ë–õ–¨\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è LightGBM\n",
    "lgbm_params = {\n",
    "    'n_estimators': 1500,\n",
    "    'max_depth': -1,\n",
    "    'learning_rate': 0.01,\n",
    "    'num_leaves': 31,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "lgbm_model = LGBMClassifier(**lgbm_params)\n",
    "\n",
    "print(\"\\n –û–±—É—á–∞–µ–º LightGBM...\")\n",
    "lgbm_model.fit(X_super_elite, y_final)\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º LightGBM –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "X_train_se, X_val_se, y_train_se, y_val_se = train_test_split(\n",
    "    X_super_elite, y_final, test_size=0.2, random_state=42, stratify=y_final\n",
    ")\n",
    "\n",
    "lgbm_val_pred = lgbm_model.predict_proba(X_val_se)[:, 1]\n",
    "lgbm_roc_auc = roc_auc_score(y_val_se, lgbm_val_pred)\n",
    "print(f\"LightGBM ROC-AUC: {lgbm_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "86da0a30-281b-42f6-920f-f50f0aca21bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ñ–∏—á–µ–π...\n",
      "–°–æ–∑–¥–∞–µ–º —ç–ª–∏—Ç–Ω—ã–µ —Ñ–∏—á–∏ –¥–ª—è elite_model...\n",
      "–°–æ–∑–¥–∞–µ–º —Å—É–ø–µ—Ä-—ç–ª–∏—Ç–Ω—ã–µ —Ñ–∏—á–∏ –¥–ª—è extreme_model –∏ LightGBM...\n",
      "‚úÖ Elite —Ñ–∏—á–∏: 36 –∫–æ–ª–æ–Ω–æ–∫\n",
      "‚úÖ Super Elite —Ñ–∏—á–∏: 42 –∫–æ–ª–æ–Ω–æ–∫\n",
      "\n",
      "üéØ –ü–µ—Ä–µ–æ–±—É—á–∞–µ–º elite_model –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö —Ñ–∏—á–∞—Ö...\n",
      "‚úÖ Elite model ROC-AUC: 0.9396\n"
     ]
    }
   ],
   "source": [
    "print(\"üîÑ –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ñ–∏—á–µ–π...\")\n",
    "\n",
    "# –ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ñ–∏—á–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏\n",
    "print(\"–°–æ–∑–¥–∞–µ–º —ç–ª–∏—Ç–Ω—ã–µ —Ñ–∏—á–∏ –¥–ª—è elite_model...\")\n",
    "X_elite_correct = create_elite_features(X_advanced_clean)\n",
    "test_elite_correct = create_elite_features(test_df_advanced_clean)\n",
    "\n",
    "print(\"–°–æ–∑–¥–∞–µ–º —Å—É–ø–µ—Ä-—ç–ª–∏—Ç–Ω—ã–µ —Ñ–∏—á–∏ –¥–ª—è extreme_model –∏ LightGBM...\")\n",
    "X_super_elite_correct = create_super_elite_features(X_advanced_clean)\n",
    "test_super_elite_correct = create_super_elite_features(test_df_advanced_clean)\n",
    "\n",
    "print(f\"‚úÖ Elite —Ñ–∏—á–∏: {X_elite_correct.shape[1]} –∫–æ–ª–æ–Ω–æ–∫\")\n",
    "print(f\"‚úÖ Super Elite —Ñ–∏—á–∏: {X_super_elite_correct.shape[1]} –∫–æ–ª–æ–Ω–æ–∫\")\n",
    "\n",
    "# –ü–µ—Ä–µ–æ–±—É—á–∞–µ–º elite_model –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö —Ñ–∏—á–∞—Ö (–±—ã—Å—Ç—Ä–æ, —Ç–∞–∫ –∫–∞–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —É–∂–µ –∏–∑–≤–µ—Å—Ç–Ω—ã)\n",
    "print(\"\\nüéØ –ü–µ—Ä–µ–æ–±—É—á–∞–µ–º elite_model –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö —Ñ–∏—á–∞—Ö...\")\n",
    "best_elite_model_correct = XGBClassifier(\n",
    "    colsample_bytree=0.52,\n",
    "    gamma=0.35,\n",
    "    learning_rate=0.007,\n",
    "    max_depth=3,\n",
    "    min_child_weight=5,\n",
    "    n_estimators=2100,\n",
    "    reg_alpha=0.25,\n",
    "    reg_lambda=1.3639195910873667,\n",
    "    subsample=0.83,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "best_elite_model_correct.fit(X_elite_correct, y_final)\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º elite_model –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "X_train_elite, X_val_elite, y_train_elite, y_val_elite = train_test_split(\n",
    "    X_elite_correct, y_final, test_size=0.2, random_state=42, stratify=y_final\n",
    ")\n",
    "\n",
    "elite_val_pred = best_elite_model_correct.predict_proba(X_val_elite)[:, 1]\n",
    "elite_roc_auc = roc_auc_score(y_val_elite, elite_val_pred)\n",
    "print(f\"‚úÖ Elite model ROC-AUC: {elite_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c5be590f-a310-4cd8-8067-fa496ab9e9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ –°–æ–∑–¥–∞–µ–º —Å–∞–±–º–∏—à–Ω—ã —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ —Ñ–∏—á–∞–º–∏...\n",
      "‚úÖ submission_lgbm_champion.csv —Å–æ–∑–¥–∞–Ω\n",
      "‚úÖ submission_extreme_xgb.csv —Å–æ–∑–¥–∞–Ω\n",
      "‚úÖ submission_elite_xgb.csv —Å–æ–∑–¥–∞–Ω\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüöÄ –°–æ–∑–¥–∞–µ–º —Å–∞–±–º–∏—à–Ω—ã —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ —Ñ–∏—á–∞–º–∏...\")\n",
    "\n",
    "# 1. LightGBM –Ω–∞ —Å—É–ø–µ—Ä-—ç–ª–∏—Ç–Ω—ã—Ö —Ñ–∏—á–∞—Ö (–Ω–∞—à —á–µ–º–ø–∏–æ–Ω)\n",
    "test_predictions_lgbm = lgbm_model.predict_proba(test_super_elite_correct)[:, 1]\n",
    "test_predictions_lgbm = np.clip(test_predictions_lgbm, 0.001, 0.999)\n",
    "\n",
    "submission_lgbm = pd.DataFrame({\n",
    "    'id': range(15000, 15000 + len(test_predictions_lgbm)),\n",
    "    'Exited': test_predictions_lgbm\n",
    "})\n",
    "submission_lgbm.to_csv('submission_lgbm_champion.csv', index=False)\n",
    "print(\"‚úÖ submission_lgbm_champion.csv —Å–æ–∑–¥–∞–Ω\")\n",
    "\n",
    "# 2. Extreme XGBoost –Ω–∞ —Å—É–ø–µ—Ä-—ç–ª–∏—Ç–Ω—ã—Ö —Ñ–∏—á–∞—Ö\n",
    "test_predictions_extreme = best_extreme_model.predict_proba(test_super_elite_correct)[:, 1]\n",
    "test_predictions_extreme = np.clip(test_predictions_extreme, 0.001, 0.999)\n",
    "\n",
    "submission_extreme = pd.DataFrame({\n",
    "    'id': range(15000, 15000 + len(test_predictions_extreme)),\n",
    "    'Exited': test_predictions_extreme\n",
    "})\n",
    "submission_extreme.to_csv('submission_extreme_xgb.csv', index=False)\n",
    "print(\"‚úÖ submission_extreme_xgb.csv —Å–æ–∑–¥–∞–Ω\")\n",
    "\n",
    "# 3. Elite XGBoost –Ω–∞ —ç–ª–∏—Ç–Ω—ã—Ö —Ñ–∏—á–∞—Ö\n",
    "test_predictions_elite = best_elite_model_correct.predict_proba(test_elite_correct)[:, 1]\n",
    "test_predictions_elite = np.clip(test_predictions_elite, 0.001, 0.999)\n",
    "\n",
    "submission_elite = pd.DataFrame({\n",
    "    'id': range(15000, 15000 + len(test_predictions_elite)),\n",
    "    'Exited': test_predictions_elite\n",
    "})\n",
    "submission_elite.to_csv('submission_elite_xgb.csv', index=False)\n",
    "print(\"‚úÖ submission_elite_xgb.csv —Å–æ–∑–¥–∞–Ω\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7a1290aa-963e-4285-bba9-0a18ac8b44c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ –°–æ–∑–¥–∞–µ–º –∞–Ω—Å–∞–º–±–ª–∏ –Ω–∞ –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –Ω–∞–±–æ—Ä–∞—Ö —Ñ–∏—á–µ–π...\n",
      "‚úÖ submission_ensemble_super.csv —Å–æ–∑–¥–∞–Ω\n",
      "‚úÖ submission_lgbm_dominant.csv —Å–æ–∑–¥–∞–Ω\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüéØ –°–æ–∑–¥–∞–µ–º –∞–Ω—Å–∞–º–±–ª–∏ –Ω–∞ –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –Ω–∞–±–æ—Ä–∞—Ö —Ñ–∏—á–µ–π...\")\n",
    "\n",
    "# –ê–Ω—Å–∞–º–±–ª—å 1: –¢–æ–ª—å–∫–æ –º–æ–¥–µ–ª–∏ –Ω–∞ —Å—É–ø–µ—Ä-—ç–ª–∏—Ç–Ω—ã—Ö —Ñ–∏—á–∞—Ö (LightGBM + Extreme XGBoost)\n",
    "ensemble_super = (test_predictions_lgbm * 0.7 + test_predictions_extreme * 0.3)\n",
    "ensemble_super = np.clip(ensemble_super, 0.001, 0.999)\n",
    "\n",
    "submission_ensemble_super = pd.DataFrame({\n",
    "    'id': range(15000, 15000 + len(ensemble_super)),\n",
    "    'Exited': ensemble_super\n",
    "})\n",
    "submission_ensemble_super.to_csv('submission_ensemble_super.csv', index=False)\n",
    "print(\"‚úÖ submission_ensemble_super.csv —Å–æ–∑–¥–∞–Ω\")\n",
    "\n",
    "# –ê–Ω—Å–∞–º–±–ª—å 2: LightGBM –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏–π\n",
    "ensemble_lgbm_dominant = (test_predictions_lgbm * 0.9 + test_predictions_extreme * 0.1)\n",
    "ensemble_lgbm_dominant = np.clip(ensemble_lgbm_dominant, 0.001, 0.999)\n",
    "\n",
    "submission_lgbm_dominant = pd.DataFrame({\n",
    "    'id': range(15000, 15000 + len(ensemble_lgbm_dominant)),\n",
    "    'Exited': ensemble_lgbm_dominant\n",
    "})\n",
    "submission_lgbm_dominant.to_csv('submission_lgbm_dominant.csv', index=False)\n",
    "print(\"‚úÖ submission_lgbm_dominant.csv —Å–æ–∑–¥–∞–Ω\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c167af46-82e7-43d5-9241-b8a3c3d88e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä –ü–†–û–í–ï–†–ö–ê –ö–ê–ß–ï–°–¢–í–ê –ù–ê –í–ê–õ–ò–î–ê–¶–ò–ò:\n",
      "LightGBM 0.9 + Extreme 0.1: 0.9800\n",
      "LightGBM 0.8 + Extreme 0.2: 0.9776\n",
      "LightGBM 0.7 + Extreme 0.3: 0.9749\n",
      "LightGBM 1.0 + Extreme 0.0: 0.9820\n",
      "\n",
      "üéØ –õ—É—á—à–∏–π –∞–Ω—Å–∞–º–±–ª—å: LightGBM 1.0 + Extreme 0.0\n",
      "ROC-AUC: 0.9820\n",
      "‚úÖ submission_final_optimized.csv —Å–æ–∑–¥–∞–Ω\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìä –ü–†–û–í–ï–†–ö–ê –ö–ê–ß–ï–°–¢–í–ê –ù–ê –í–ê–õ–ò–î–ê–¶–ò–ò:\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è\n",
    "val_predictions_lgbm = lgbm_model.predict_proba(X_val_se)[:, 1]\n",
    "val_predictions_extreme = best_extreme_model.predict_proba(X_val_se)[:, 1]\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –∞–Ω—Å–∞–º–±–ª—è\n",
    "ensemble_combinations = [\n",
    "    (0.9, 0.1),  # LightGBM 90% + Extreme 10%\n",
    "    (0.8, 0.2),  # LightGBM 80% + Extreme 20%\n",
    "    (0.7, 0.3),  # LightGBM 70% + Extreme 30%\n",
    "    (1.0, 0.0),  # –ß–∏—Å—Ç—ã–π LightGBM\n",
    "]\n",
    "\n",
    "best_ensemble_score = 0\n",
    "best_weights = None\n",
    "\n",
    "for w_lgbm, w_extreme in ensemble_combinations:\n",
    "    ensemble_val = (val_predictions_lgbm * w_lgbm + val_predictions_extreme * w_extreme)\n",
    "    score = roc_auc_score(y_val_se, ensemble_val)\n",
    "    print(f\"LightGBM {w_lgbm:.1f} + Extreme {w_extreme:.1f}: {score:.4f}\")\n",
    "    \n",
    "    if score > best_ensemble_score:\n",
    "        best_ensemble_score = score\n",
    "        best_weights = (w_lgbm, w_extreme)\n",
    "\n",
    "print(f\"\\nüéØ –õ—É—á—à–∏–π –∞–Ω—Å–∞–º–±–ª—å: LightGBM {best_weights[0]:.1f} + Extreme {best_weights[1]:.1f}\")\n",
    "print(f\"ROC-AUC: {best_ensemble_score:.4f}\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω—Å–∞–º–±–ª—å\n",
    "test_final_ensemble = (\n",
    "    test_predictions_lgbm * best_weights[0] + \n",
    "    test_predictions_extreme * best_weights[1]\n",
    ")\n",
    "test_final_ensemble = np.clip(test_final_ensemble, 0.001, 0.999)\n",
    "\n",
    "submission_final_optimized = pd.DataFrame({\n",
    "    'id': range(15000, 15000 + len(test_final_ensemble)),\n",
    "    'Exited': test_final_ensemble\n",
    "})\n",
    "submission_final_optimized.to_csv('submission_final_optimized.csv', index=False)\n",
    "print(\"‚úÖ submission_final_optimized.csv —Å–æ–∑–¥–∞–Ω\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ddaa0870-1ed3-425e-84f2-4085c284bc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéâ –§–ò–ù–ê–õ–¨–ù–´–ï –°–ê–ë–ú–ò–®–ù–´ –°–û–ó–î–ê–ù–´!\n",
      "üìã –†–ï–ö–û–ú–ï–ù–î–£–ï–ú–´–ï (–≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞):\n",
      "1. submission_lgbm_champion.csv - —á–∏—Å—Ç—ã–π LightGBM (0.9820)\n",
      "2. submission_final_optimized.csv - –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω—Å–∞–º–±–ª—å (0.9820)\n",
      "3. submission_lgbm_dominant.csv - LightGBM 90% + Extreme 10%\n",
      "\n",
      "üí° LightGBM –ø–æ–∫–∞–∑–∞–ª –≤—ã–¥–∞—é—â–∏–π—Å—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç: 0.9820\n",
      "   –û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ –ª–∏–¥–µ—Ä–±–æ—Ä–¥–µ: 0.94+ üöÄ\n",
      "   –†–µ–∫–æ–º–µ–Ω–¥—É—é –Ω–∞—á–∞—Ç—å —Å submission_lgbm_champion.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüéâ –§–ò–ù–ê–õ–¨–ù–´–ï –°–ê–ë–ú–ò–®–ù–´ –°–û–ó–î–ê–ù–´!\")\n",
    "print(f\"üìã –†–ï–ö–û–ú–ï–ù–î–£–ï–ú–´–ï (–≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞):\")\n",
    "print(f\"1. submission_lgbm_champion.csv - —á–∏—Å—Ç—ã–π LightGBM (0.9820)\")\n",
    "print(f\"2. submission_final_optimized.csv - –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω—Å–∞–º–±–ª—å ({best_ensemble_score:.4f})\")\n",
    "print(f\"3. submission_lgbm_dominant.csv - LightGBM 90% + Extreme 10%\")\n",
    "\n",
    "print(f\"\\nüí° LightGBM –ø–æ–∫–∞–∑–∞–ª –≤—ã–¥–∞—é—â–∏–π—Å—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç: 0.9820\")\n",
    "print(\"   –û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ –ª–∏–¥–µ—Ä–±–æ—Ä–¥–µ: 0.94+ üöÄ\")\n",
    "print(\"   –†–µ–∫–æ–º–µ–Ω–¥—É—é –Ω–∞—á–∞—Ç—å —Å submission_lgbm_champion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "19bb7d6c-63ec-4785-b0df-ae47189cfef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω–æ–º—É XGBoost —Å —É—Å–∏–ª–µ–Ω–Ω–æ–π —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π...\n",
      "üìä –û–±—É—á–∞–µ–º —Å—É–ø–µ—Ä-—Å—Ç–∞–±–∏–ª—å–Ω—ã–π XGBoost...\n",
      "‚úÖ –°—É–ø–µ—Ä-—Å—Ç–∞–±–∏–ª—å–Ω—ã–π XGBoost ROC-AUC: 0.9389\n",
      "‚úÖ submission_super_stable.csv —Å–æ–∑–¥–∞–Ω\n"
     ]
    }
   ],
   "source": [
    "print(\"üéØ –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω–æ–º—É XGBoost —Å —É—Å–∏–ª–µ–Ω–Ω–æ–π —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π...\")\n",
    "\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –ø–æ–∫–∞–∑–∞–ª–∏ —Ö–æ—Ä–æ—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (0.9396 –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏)\n",
    "# –Ω–æ –¥–æ–±–∞–≤–∏–º –µ—â–µ –±–æ–ª—å—à–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏\n",
    "super_stable_xgb = XGBClassifier(\n",
    "    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "    n_estimators=1800,  # –ù–µ–º–Ω–æ–≥–æ —É–º–µ–Ω—å—à–∏–ª–∏\n",
    "    max_depth=3,        # –û—Å—Ç–∞–≤–ª—è–µ–º –Ω–µ–≥–ª—É–±–æ–∫–∏–µ –¥–µ—Ä–µ–≤—å—è\n",
    "    learning_rate=0.008,\n",
    "    \n",
    "    # –°—É–±—Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –±–æ—Ä—å–±—ã —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º\n",
    "    subsample=0.75,     # –£–≤–µ–ª–∏—á–∏–ª–∏ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é\n",
    "    colsample_bytree=0.6,\n",
    "    \n",
    "    # –°–∏–ª—å–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è\n",
    "    reg_alpha=0.5,      # –£–≤–µ–ª–∏—á–∏–ª–∏ L1 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é\n",
    "    reg_lambda=1.5,     # –£–≤–µ–ª–∏—á–∏–ª–∏ L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é\n",
    "    gamma=0.4,          # –£–≤–µ–ª–∏—á–∏–ª–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π loss reduction\n",
    "    \n",
    "    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å\n",
    "    min_child_weight=8, # –£–≤–µ–ª–∏—á–∏–ª–∏ –¥–ª—è –±–æ–ª—å—à–µ–π —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏\n",
    "    scale_pos_weight=1,\n",
    "    \n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "print(\"üìä –û–±—É—á–∞–µ–º —Å—É–ø–µ—Ä-—Å—Ç–∞–±–∏–ª—å–Ω—ã–π XGBoost...\")\n",
    "super_stable_xgb.fit(X_advanced_clean, y_final)\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "X_train_stable, X_val_stable, y_train_stable, y_val_stable = train_test_split(\n",
    "    X_advanced_clean, y_final, test_size=0.2, random_state=42, stratify=y_final\n",
    ")\n",
    "\n",
    "stable_val_pred = super_stable_xgb.predict_proba(X_val_stable)[:, 1]\n",
    "stable_roc_auc = roc_auc_score(y_val_stable, stable_val_pred)\n",
    "print(f\"‚úÖ –°—É–ø–µ—Ä-—Å—Ç–∞–±–∏–ª—å–Ω—ã–π XGBoost ROC-AUC: {stable_roc_auc:.4f}\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Å–∞–±–º–∏—à–Ω\n",
    "test_predictions_stable = super_stable_xgb.predict_proba(test_df_advanced_clean)[:, 1]\n",
    "test_predictions_stable = np.clip(test_predictions_stable, 0.001, 0.999)\n",
    "\n",
    "submission_super_stable = pd.DataFrame({\n",
    "    'id': range(15000, 15000 + len(test_predictions_stable)),\n",
    "    'Exited': test_predictions_stable\n",
    "})\n",
    "submission_super_stable.to_csv('submission_super_stable.csv', index=False)\n",
    "print(\"‚úÖ submission_super_stable.csv —Å–æ–∑–¥–∞–Ω\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "df984bd4-fc30-4e9f-ac00-7914f81d40b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ –°–æ–∑–¥–∞–µ–º —É–ª—å—Ç—Ä–∞-–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—É—é –º–æ–¥–µ–ª—å...\n",
      "‚úÖ –£–ª—å—Ç—Ä–∞-–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π XGBoost ROC-AUC: 0.9324\n",
      "‚úÖ submission_ultra_conservative.csv —Å–æ–∑–¥–∞–Ω\n"
     ]
    }
   ],
   "source": [
    "# 2. –°–æ–∑–¥–∞–µ–º –£–õ–¨–¢–†–ê-–ö–û–ù–°–ï–†–í–ê–¢–ò–í–ù–£–Æ –≤–µ—Ä—Å–∏—é\n",
    "print(\"\\nüéØ –°–æ–∑–¥–∞–µ–º —É–ª—å—Ç—Ä–∞-–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—É—é –º–æ–¥–µ–ª—å...\")\n",
    "\n",
    "ultra_conservative_xgb = XGBClassifier(\n",
    "    n_estimators=1500,\n",
    "    max_depth=2,        # –ï—â–µ –º–µ–Ω–µ–µ –≥–ª—É–±–æ–∫–∏–µ –¥–µ—Ä–µ–≤—å—è\n",
    "    learning_rate=0.01,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.6,\n",
    "    reg_alpha=1.0,      # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è\n",
    "    reg_lambda=2.0,\n",
    "    gamma=0.5,\n",
    "    min_child_weight=10,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "ultra_conservative_xgb.fit(X_advanced_clean, y_final)\n",
    "\n",
    "ultra_val_pred = ultra_conservative_xgb.predict_proba(X_val_stable)[:, 1]\n",
    "ultra_roc_auc = roc_auc_score(y_val_stable, ultra_val_pred)\n",
    "print(f\"‚úÖ –£–ª—å—Ç—Ä–∞-–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π XGBoost ROC-AUC: {ultra_roc_auc:.4f}\")\n",
    "\n",
    "test_predictions_ultra = ultra_conservative_xgb.predict_proba(test_df_advanced_clean)[:, 1]\n",
    "test_predictions_ultra = np.clip(test_predictions_ultra, 0.001, 0.999)\n",
    "\n",
    "submission_ultra = pd.DataFrame({\n",
    "    'id': range(15000, 15000 + len(test_predictions_ultra)),\n",
    "    'Exited': test_predictions_ultra\n",
    "})\n",
    "submission_ultra.to_csv('submission_ultra_conservative.csv', index=False)\n",
    "print(\"‚úÖ submission_ultra_conservative.csv —Å–æ–∑–¥–∞–Ω\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a22f4134-2e82-4b75-bf53-9c4f096a0562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî® –°–æ–∑–¥–∞–µ–º –∞–Ω—Å–∞–º–±–ª—å –∏–∑ –Ω–∞–¥–µ–∂–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π...\n",
      "‚úÖ submission_ensemble_balanced.csv —Å–æ–∑–¥–∞–Ω\n"
     ]
    }
   ],
   "source": [
    "# 3. –ê–Ω—Å–∞–º–±–ª—å –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π\n",
    "print(\"\\nüî® –°–æ–∑–¥–∞–µ–º –∞–Ω—Å–∞–º–±–ª—å –∏–∑ –Ω–∞–¥–µ–∂–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π...\")\n",
    "\n",
    "# –ù–∞—à–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è refined –º–æ–¥–µ–ª—å (–ø–æ–∫–∞–∑–∞–ª–∞ 0.9396)\n",
    "original_refined = XGBClassifier(\n",
    "    colsample_bytree=0.52,\n",
    "    gamma=0.35,\n",
    "    learning_rate=0.007,\n",
    "    max_depth=3,\n",
    "    min_child_weight=5,\n",
    "    n_estimators=2100,\n",
    "    reg_alpha=0.25,\n",
    "    reg_lambda=1.3639195910873667,\n",
    "    subsample=0.83,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "original_refined.fit(X_advanced_clean, y_final)\n",
    "\n",
    "# –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—Å–µ—Ö —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π\n",
    "test_predictions_original = original_refined.predict_proba(test_df_advanced_clean)[:, 1]\n",
    "\n",
    "# –ê–Ω—Å–∞–º–±–ª—å: 50% —Å—É–ø–µ—Ä-—Å—Ç–∞–±–∏–ª—å–Ω—ã–π + 50% –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π refined\n",
    "ensemble_balanced = (test_predictions_stable * 0.5 + test_predictions_original * 0.5)\n",
    "ensemble_balanced = np.clip(ensemble_balanced, 0.001, 0.999)\n",
    "\n",
    "submission_ensemble_balanced = pd.DataFrame({\n",
    "    'id': range(15000, 15000 + len(ensemble_balanced)),\n",
    "    'Exited': ensemble_balanced\n",
    "})\n",
    "submission_ensemble_balanced.to_csv('submission_ensemble_balanced.csv', index=False)\n",
    "print(\"‚úÖ submission_ensemble_balanced.csv —Å–æ–∑–¥–∞–Ω\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c3edc78c-de5e-4547-a9dc-de56fc3fa549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üõ°Ô∏è –°–æ–∑–¥–∞–µ–º –º–µ–≥–∞-—Å—Ç–∞–±–∏–ª—å–Ω—ã–π –∞–Ω—Å–∞–º–±–ª—å...\n",
      "–û–±—É—á–∞–µ–º 7 —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è...\n",
      "  –ú–æ–¥–µ–ª—å 1: 0.9384\n",
      "  –ú–æ–¥–µ–ª—å 2: 0.9390\n",
      "  –ú–æ–¥–µ–ª—å 3: 0.9394\n",
      "  –ú–æ–¥–µ–ª—å 4: 0.9398\n",
      "  –ú–æ–¥–µ–ª—å 5: 0.9402\n",
      "  –ú–æ–¥–µ–ª—å 6: 0.9407\n",
      "  –ú–æ–¥–µ–ª—å 7: 0.9410\n",
      "‚úÖ submission_mega_stable.csv —Å–æ–∑–¥–∞–Ω\n"
     ]
    }
   ],
   "source": [
    "# 4. –°–ê–ú–´–ô –ö–û–ù–°–ï–†–í–ê–¢–ò–í–ù–´–ô –ü–û–î–•–û–î - —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π\n",
    "print(\"\\nüõ°Ô∏è –°–æ–∑–¥–∞–µ–º –º–µ–≥–∞-—Å—Ç–∞–±–∏–ª—å–Ω—ã–π –∞–Ω—Å–∞–º–±–ª—å...\")\n",
    "\n",
    "def create_mega_stable_ensemble(X_train, y_train, X_test, n_models=7):\n",
    "    \"\"\"–°–æ–∑–¥–∞–µ—Ç –∞–Ω—Å–∞–º–±–ª—å –∏–∑ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π\"\"\"\n",
    "    all_predictions = []\n",
    "    \n",
    "    base_params = {\n",
    "        'max_depth': 3,\n",
    "        'learning_rate': 0.008,\n",
    "        'subsample': 0.75,\n",
    "        'colsample_bytree': 0.6,\n",
    "        'reg_alpha': 0.5,\n",
    "        'reg_lambda': 1.5,\n",
    "        'gamma': 0.4,\n",
    "        'min_child_weight': 8,\n",
    "        'eval_metric': 'logloss'\n",
    "    }\n",
    "    \n",
    "    for i in range(n_models):\n",
    "        # –°–ª–µ–≥–∫–∞ –≤–∞—Ä—å–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è\n",
    "        params = base_params.copy()\n",
    "        params['n_estimators'] = 1700 + i * 100  # –†–∞–∑–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤\n",
    "        params['random_state'] = 42 + i * 10     # –†–∞–∑–Ω—ã–µ random state\n",
    "        params['subsample'] = max(0.7, min(0.8, 0.75 + i * 0.01))  # –†–∞–∑–Ω–æ–µ —Å—É–±—Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "        \n",
    "        model = XGBClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        pred = model.predict_proba(X_test)[:, 1]\n",
    "        all_predictions.append(pred)\n",
    "        \n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "        val_pred = model.predict_proba(X_val_stable)[:, 1]\n",
    "        val_score = roc_auc_score(y_val_stable, val_pred)\n",
    "        print(f\"  –ú–æ–¥–µ–ª—å {i+1}: {val_score:.4f}\")\n",
    "    \n",
    "    return np.mean(all_predictions, axis=0)\n",
    "\n",
    "print(\"–û–±—É—á–∞–µ–º 7 —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è...\")\n",
    "test_predictions_mega_stable = create_mega_stable_ensemble(\n",
    "    X_advanced_clean, y_final, test_df_advanced_clean, n_models=7\n",
    ")\n",
    "test_predictions_mega_stable = np.clip(test_predictions_mega_stable, 0.001, 0.999)\n",
    "\n",
    "submission_mega_stable = pd.DataFrame({\n",
    "    'id': range(15000, 15000 + len(test_predictions_mega_stable)),\n",
    "    'Exited': test_predictions_mega_stable\n",
    "})\n",
    "submission_mega_stable.to_csv('submission_mega_stable.csv', index=False)\n",
    "print(\"‚úÖ submission_mega_stable.csv —Å–æ–∑–¥–∞–Ω\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "756ac4d1-8d0a-445f-8be7-c170b25260c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_final shape: (15000, 27)\n",
      "y_final length: 15000\n",
      "–ë—É–¥–µ—Ç –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ 165 –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:35:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:36:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:37:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:38:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:39:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=0.7640415835413256, colsample_bynode=0.89109029727093, colsample_bytree=0.9731471995391335, gamma=0.6315991869740974, learning_rate=0.021892527128216443, max_delta_step=4, max_depth=8, min_child_weight=11, n_estimators=1261, reg_alpha=1.943374765040633, reg_lambda=1.6498918254293524, scale_pos_weight=0.8507335273583403, subsample=0.7534251755188192; total time=   5.9s\n",
      "[CV] END colsample_bylevel=0.8528382512601542, colsample_bynode=0.6311564916549026, colsample_bytree=0.86673155880575, gamma=1.365494505768866, learning_rate=0.03499245699105878, max_delta_step=0, max_depth=15, min_child_weight=7, n_estimators=511, reg_alpha=2.534576535717491, reg_lambda=2.12775151402026, scale_pos_weight=0.8994639406110219, subsample=0.9116344591059367; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.7095981995133787, colsample_bynode=0.8290116443832669, colsample_bytree=0.7976530235681191, gamma=1.0640769187324983, learning_rate=0.003605364799767672, max_delta_step=2, max_depth=6, min_child_weight=9, n_estimators=2045, reg_alpha=2.8665949197207867, reg_lambda=2.306457129092874, scale_pos_weight=0.8282355592494823, subsample=0.7393948113526363; total time=   7.8s\n",
      "[CV] END colsample_bylevel=0.7095981995133787, colsample_bynode=0.8290116443832669, colsample_bytree=0.7976530235681191, gamma=1.0640769187324983, learning_rate=0.003605364799767672, max_delta_step=2, max_depth=6, min_child_weight=9, n_estimators=2045, reg_alpha=2.8665949197207867, reg_lambda=2.306457129092874, scale_pos_weight=0.8282355592494823, subsample=0.7393948113526363; total time=   4.4s\n",
      "[CV] END colsample_bylevel=0.9349553422213137, colsample_bynode=0.9533261109523449, colsample_bytree=0.7213640439536699, gamma=1.902447813186659, learning_rate=0.05348793493196706, max_delta_step=1, max_depth=6, min_child_weight=6, n_estimators=2089, reg_alpha=2.860440450569381, reg_lambda=1.88970319944357, scale_pos_weight=1.1969175999449346, subsample=0.9300372267817756; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.9349553422213137, colsample_bynode=0.9533261109523449, colsample_bytree=0.7213640439536699, gamma=1.902447813186659, learning_rate=0.05348793493196706, max_delta_step=1, max_depth=6, min_child_weight=6, n_estimators=2089, reg_alpha=2.860440450569381, reg_lambda=1.88970319944357, scale_pos_weight=1.1969175999449346, subsample=0.9300372267817756; total time=   4.7s\n",
      "[CV] END colsample_bylevel=0.7554099400213591, colsample_bynode=0.8429283931898632, colsample_bytree=0.6564111070894564, gamma=0.09563585051707604, learning_rate=0.022558500179106225, max_delta_step=8, max_depth=7, min_child_weight=4, n_estimators=2009, reg_alpha=0.7391073573076685, reg_lambda=1.4271444534371391, scale_pos_weight=1.0069652746394901, subsample=0.8083451713135665; total time=  10.4s\n",
      "[CV] END colsample_bylevel=0.8858602308871624, colsample_bynode=0.6677106398221494, colsample_bytree=0.6813305482440982, gamma=1.1696008736274444, learning_rate=0.009789605136839142, max_delta_step=1, max_depth=5, min_child_weight=10, n_estimators=2507, reg_alpha=1.59336067550892, reg_lambda=0.5219922207239965, scale_pos_weight=0.9345311711605099, subsample=0.8790584028106331; total time=   6.6s\n",
      "[CV] END colsample_bylevel=0.7779330049204607, colsample_bynode=0.9674890086677508, colsample_bytree=0.6419436634210814, gamma=0.8666656037404503, learning_rate=0.0023763498182367165, max_delta_step=5, max_depth=6, min_child_weight=12, n_estimators=1893, reg_alpha=2.9196209330786664, reg_lambda=2.1104025933189123, scale_pos_weight=0.9525892931565766, subsample=0.7593566138329139; total time=   9.5s\n",
      "[CV] END colsample_bylevel=0.8038204453073899, colsample_bynode=0.7781385616731392, colsample_bytree=0.7444561678086361, gamma=1.9938098579429389, learning_rate=0.002885030412141064, max_delta_step=8, max_depth=14, min_child_weight=2, n_estimators=1377, reg_alpha=2.5807623450625163, reg_lambda=1.9755968613209078, scale_pos_weight=1.1401850404430842, subsample=0.7901005123171235; total time=   9.9s\n",
      "[CV] END colsample_bylevel=0.8882629936991471, colsample_bynode=0.8789616849482842, colsample_bytree=0.8933260784439065, gamma=1.1628140265612334, learning_rate=0.009420974429602238, max_delta_step=4, max_depth=9, min_child_weight=8, n_estimators=1922, reg_alpha=0.5031412495239872, reg_lambda=2.0004015079260693, scale_pos_weight=0.9145767613342524, subsample=0.9544589789347462; total time=   6.6s\n",
      "[CV] END colsample_bylevel=0.8882629936991471, colsample_bynode=0.8789616849482842, colsample_bytree=0.8933260784439065, gamma=1.1628140265612334, learning_rate=0.009420974429602238, max_delta_step=4, max_depth=9, min_child_weight=8, n_estimators=1922, reg_alpha=0.5031412495239872, reg_lambda=2.0004015079260693, scale_pos_weight=0.9145767613342524, subsample=0.9544589789347462; total time=   5.6s\n",
      "[CV] END colsample_bylevel=0.9249583953429453, colsample_bynode=0.6687486245586243, colsample_bytree=0.8392188310048512, gamma=1.6055295623126211, learning_rate=0.01111999664226395, max_delta_step=1, max_depth=12, min_child_weight=13, n_estimators=2780, reg_alpha=1.1603857926530512, reg_lambda=1.0247872263079094, scale_pos_weight=1.1350120740405336, subsample=0.8831297285879681; total time=   6.7s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9727891919970675, colsample_bytree=0.6732941062342661, gamma=2.0, learning_rate=0.001, max_delta_step=0, max_depth=9, min_child_weight=2, n_estimators=1203, reg_alpha=2.6074574039519063, reg_lambda=2.54274376282736, scale_pos_weight=1.0273863087030308, subsample=0.7733034128815556; total time=   8.5s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9727891919970675, colsample_bytree=0.6732941062342661, gamma=2.0, learning_rate=0.001, max_delta_step=0, max_depth=9, min_child_weight=2, n_estimators=1203, reg_alpha=2.6074574039519063, reg_lambda=2.54274376282736, scale_pos_weight=1.0273863087030308, subsample=0.7733034128815556; total time=   9.4s\n",
      "[CV] END colsample_bylevel=0.66356001406769, colsample_bynode=0.764706330154597, colsample_bytree=0.8506054103917193, gamma=0.1702307424253167, learning_rate=0.0010092144518871718, max_delta_step=10, max_depth=15, min_child_weight=7, n_estimators=2447, reg_alpha=1.0261507516353077, reg_lambda=1.9435049567823384, scale_pos_weight=0.8112557740864806, subsample=0.8310548413843668; total time=  19.0s\n",
      "[CV] END colsample_bylevel=0.7466137551925102, colsample_bynode=0.8974444134032649, colsample_bytree=0.7548516040655054, gamma=0.43902104288877253, learning_rate=0.0994113015193369, max_delta_step=1, max_depth=14, min_child_weight=14, n_estimators=2017, reg_alpha=0.9715412376355661, reg_lambda=2.914730176276133, scale_pos_weight=1.0126290173347083, subsample=0.7466388846477777; total time=   7.8s\n",
      "[CV] END colsample_bylevel=0.6886827070582457, colsample_bynode=0.7974902178549595, colsample_bytree=0.6176603334641794, gamma=1.4914222819518947, learning_rate=0.02150814856096874, max_delta_step=0, max_depth=9, min_child_weight=4, n_estimators=2405, reg_alpha=0.08545803427150311, reg_lambda=0.0, scale_pos_weight=0.9365930633059527, subsample=0.9726413427108334; total time=   5.7s\n",
      "[CV] END colsample_bylevel=0.7412525382873448, colsample_bynode=0.8664143263426028, colsample_bytree=0.9916051763942715, gamma=1.9472069217216694, learning_rate=0.0010188190400360986, max_delta_step=6, max_depth=6, min_child_weight=13, n_estimators=1158, reg_alpha=0.020491355971932086, reg_lambda=1.1015644869738423, scale_pos_weight=1.1703075458537742, subsample=0.928416009871444; total time=   7.4s\n",
      "[CV] END colsample_bylevel=0.7412525382873448, colsample_bynode=0.8664143263426028, colsample_bytree=0.9916051763942715, gamma=1.9472069217216694, learning_rate=0.0010188190400360986, max_delta_step=6, max_depth=6, min_child_weight=13, n_estimators=1158, reg_alpha=0.020491355971932086, reg_lambda=1.1015644869738423, scale_pos_weight=1.1703075458537742, subsample=0.928416009871444; total time=   5.9s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_delta_step=0, max_depth=15, min_child_weight=15, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=  18.4s\n",
      "[CV] END colsample_bylevel=0.8532729746346017, colsample_bynode=0.9997139531310555, colsample_bytree=0.8621607040266261, gamma=0.5112929578501474, learning_rate=0.014236991825974906, max_delta_step=4, max_depth=9, min_child_weight=8, n_estimators=2801, reg_alpha=2.676687575922181, reg_lambda=0.017699530322734643, scale_pos_weight=1.1031951555001047, subsample=0.9970833908909384; total time=   9.4s[CV] END colsample_bylevel=0.7640415835413256, colsample_bynode=0.89109029727093, colsample_bytree=0.9731471995391335, gamma=0.6315991869740974, learning_rate=0.021892527128216443, max_delta_step=4, max_depth=8, min_child_weight=11, n_estimators=1261, reg_alpha=1.943374765040633, reg_lambda=1.6498918254293524, scale_pos_weight=0.8507335273583403, subsample=0.7534251755188192; total time=   5.8s\n",
      "[CV] END colsample_bylevel=0.8528382512601542, colsample_bynode=0.6311564916549026, colsample_bytree=0.86673155880575, gamma=1.365494505768866, learning_rate=0.03499245699105878, max_delta_step=0, max_depth=15, min_child_weight=7, n_estimators=511, reg_alpha=2.534576535717491, reg_lambda=2.12775151402026, scale_pos_weight=0.8994639406110219, subsample=0.9116344591059367; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.8528382512601542, colsample_bynode=0.6311564916549026, colsample_bytree=0.86673155880575, gamma=1.365494505768866, learning_rate=0.03499245699105878, max_delta_step=0, max_depth=15, min_child_weight=7, n_estimators=511, reg_alpha=2.534576535717491, reg_lambda=2.12775151402026, scale_pos_weight=0.8994639406110219, subsample=0.9116344591059367; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.7095981995133787, colsample_bynode=0.8290116443832669, colsample_bytree=0.7976530235681191, gamma=1.0640769187324983, learning_rate=0.003605364799767672, max_delta_step=2, max_depth=6, min_child_weight=9, n_estimators=2045, reg_alpha=2.8665949197207867, reg_lambda=2.306457129092874, scale_pos_weight=0.8282355592494823, subsample=0.7393948113526363; total time=   7.7s\n",
      "[CV] END colsample_bylevel=0.9349553422213137, colsample_bynode=0.9533261109523449, colsample_bytree=0.7213640439536699, gamma=1.902447813186659, learning_rate=0.05348793493196706, max_delta_step=1, max_depth=6, min_child_weight=6, n_estimators=2089, reg_alpha=2.860440450569381, reg_lambda=1.88970319944357, scale_pos_weight=1.1969175999449346, subsample=0.9300372267817756; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.7554099400213591, colsample_bynode=0.8429283931898632, colsample_bytree=0.6564111070894564, gamma=0.09563585051707604, learning_rate=0.022558500179106225, max_delta_step=8, max_depth=7, min_child_weight=4, n_estimators=2009, reg_alpha=0.7391073573076685, reg_lambda=1.4271444534371391, scale_pos_weight=1.0069652746394901, subsample=0.8083451713135665; total time=  10.4s\n",
      "[CV] END colsample_bylevel=0.8858602308871624, colsample_bynode=0.6677106398221494, colsample_bytree=0.6813305482440982, gamma=1.1696008736274444, learning_rate=0.009789605136839142, max_delta_step=1, max_depth=5, min_child_weight=10, n_estimators=2507, reg_alpha=1.59336067550892, reg_lambda=0.5219922207239965, scale_pos_weight=0.9345311711605099, subsample=0.8790584028106331; total time=   7.4s\n",
      "[CV] END colsample_bylevel=0.8858602308871624, colsample_bynode=0.6677106398221494, colsample_bytree=0.6813305482440982, gamma=1.1696008736274444, learning_rate=0.009789605136839142, max_delta_step=1, max_depth=5, min_child_weight=10, n_estimators=2507, reg_alpha=1.59336067550892, reg_lambda=0.5219922207239965, scale_pos_weight=0.9345311711605099, subsample=0.8790584028106331; total time=   5.9s\n",
      "[CV] END colsample_bylevel=0.7779330049204607, colsample_bynode=0.9674890086677508, colsample_bytree=0.6419436634210814, gamma=0.8666656037404503, learning_rate=0.0023763498182367165, max_delta_step=5, max_depth=6, min_child_weight=12, n_estimators=1893, reg_alpha=2.9196209330786664, reg_lambda=2.1104025933189123, scale_pos_weight=0.9525892931565766, subsample=0.7593566138329139; total time=   9.5s\n",
      "[CV] END colsample_bylevel=0.8038204453073899, colsample_bynode=0.7781385616731392, colsample_bytree=0.7444561678086361, gamma=1.9938098579429389, learning_rate=0.002885030412141064, max_delta_step=8, max_depth=14, min_child_weight=2, n_estimators=1377, reg_alpha=2.5807623450625163, reg_lambda=1.9755968613209078, scale_pos_weight=1.1401850404430842, subsample=0.7901005123171235; total time=  10.0s\n",
      "[CV] END colsample_bylevel=0.8882629936991471, colsample_bynode=0.8789616849482842, colsample_bytree=0.8933260784439065, gamma=1.1628140265612334, learning_rate=0.009420974429602238, max_delta_step=4, max_depth=9, min_child_weight=8, n_estimators=1922, reg_alpha=0.5031412495239872, reg_lambda=2.0004015079260693, scale_pos_weight=0.9145767613342524, subsample=0.9544589789347462; total time=   6.6s\n",
      "[CV] END colsample_bylevel=0.8882629936991471, colsample_bynode=0.8789616849482842, colsample_bytree=0.8933260784439065, gamma=1.1628140265612334, learning_rate=0.009420974429602238, max_delta_step=4, max_depth=9, min_child_weight=8, n_estimators=1922, reg_alpha=0.5031412495239872, reg_lambda=2.0004015079260693, scale_pos_weight=0.9145767613342524, subsample=0.9544589789347462; total time=   5.5s\n",
      "[CV] END colsample_bylevel=0.9249583953429453, colsample_bynode=0.6687486245586243, colsample_bytree=0.8392188310048512, gamma=1.6055295623126211, learning_rate=0.01111999664226395, max_delta_step=1, max_depth=12, min_child_weight=13, n_estimators=2780, reg_alpha=1.1603857926530512, reg_lambda=1.0247872263079094, scale_pos_weight=1.1350120740405336, subsample=0.8831297285879681; total time=   6.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9727891919970675, colsample_bytree=0.6732941062342661, gamma=2.0, learning_rate=0.001, max_delta_step=0, max_depth=9, min_child_weight=2, n_estimators=1203, reg_alpha=2.6074574039519063, reg_lambda=2.54274376282736, scale_pos_weight=1.0273863087030308, subsample=0.7733034128815556; total time=   8.9s\n",
      "[CV] END colsample_bylevel=0.66356001406769, colsample_bynode=0.764706330154597, colsample_bytree=0.8506054103917193, gamma=0.1702307424253167, learning_rate=0.0010092144518871718, max_delta_step=10, max_depth=15, min_child_weight=7, n_estimators=2447, reg_alpha=1.0261507516353077, reg_lambda=1.9435049567823384, scale_pos_weight=0.8112557740864806, subsample=0.8310548413843668; total time=  20.1s\n",
      "[CV] END colsample_bylevel=0.7466137551925102, colsample_bynode=0.8974444134032649, colsample_bytree=0.7548516040655054, gamma=0.43902104288877253, learning_rate=0.0994113015193369, max_delta_step=1, max_depth=14, min_child_weight=14, n_estimators=2017, reg_alpha=0.9715412376355661, reg_lambda=2.914730176276133, scale_pos_weight=1.0126290173347083, subsample=0.7466388846477777; total time=   7.7s\n",
      "[CV] END colsample_bylevel=0.6886827070582457, colsample_bynode=0.7974902178549595, colsample_bytree=0.6176603334641794, gamma=1.4914222819518947, learning_rate=0.02150814856096874, max_delta_step=0, max_depth=9, min_child_weight=4, n_estimators=2405, reg_alpha=0.08545803427150311, reg_lambda=0.0, scale_pos_weight=0.9365930633059527, subsample=0.9726413427108334; total time=   5.0s\n",
      "[CV] END colsample_bylevel=0.6886827070582457, colsample_bynode=0.7974902178549595, colsample_bytree=0.6176603334641794, gamma=1.4914222819518947, learning_rate=0.02150814856096874, max_delta_step=0, max_depth=9, min_child_weight=4, n_estimators=2405, reg_alpha=0.08545803427150311, reg_lambda=0.0, scale_pos_weight=0.9365930633059527, subsample=0.9726413427108334; total time=   6.3s\n",
      "[CV] END colsample_bylevel=0.7412525382873448, colsample_bynode=0.8664143263426028, colsample_bytree=0.9916051763942715, gamma=1.9472069217216694, learning_rate=0.0010188190400360986, max_delta_step=6, max_depth=6, min_child_weight=13, n_estimators=1158, reg_alpha=0.020491355971932086, reg_lambda=1.1015644869738423, scale_pos_weight=1.1703075458537742, subsample=0.928416009871444; total time=   7.1s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_delta_step=0, max_depth=15, min_child_weight=15, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=  18.5s\n",
      "[CV] END colsample_bylevel=0.8532729746346017, colsample_bynode=0.9997139531310555, colsample_bytree=0.8621607040266261, gamma=0.5112929578501474, learning_rate=0.014236991825974906, max_delta_step=4, max_depth=9, min_child_weight=8, n_estimators=2801, reg_alpha=2.676687575922181, reg_lambda=0.017699530322734643, scale_pos_weight=1.1031951555001047, subsample=0.9970833908909384; total time=   9.7s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.5510122035826966, learning_rate=0.001, max_delta_step=0, max_depth=13, min_child_weight=12, n_estimators=2324, reg_alpha=1.324863528038593, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=  10.9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=0.7640415835413256, colsample_bynode=0.89109029727093, colsample_bytree=0.9731471995391335, gamma=0.6315991869740974, learning_rate=0.021892527128216443, max_delta_step=4, max_depth=8, min_child_weight=11, n_estimators=1261, reg_alpha=1.943374765040633, reg_lambda=1.6498918254293524, scale_pos_weight=0.8507335273583403, subsample=0.7534251755188192; total time=   5.8s\n",
      "[CV] END colsample_bylevel=0.8528382512601542, colsample_bynode=0.6311564916549026, colsample_bytree=0.86673155880575, gamma=1.365494505768866, learning_rate=0.03499245699105878, max_delta_step=0, max_depth=15, min_child_weight=7, n_estimators=511, reg_alpha=2.534576535717491, reg_lambda=2.12775151402026, scale_pos_weight=0.8994639406110219, subsample=0.9116344591059367; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.8528382512601542, colsample_bynode=0.6311564916549026, colsample_bytree=0.86673155880575, gamma=1.365494505768866, learning_rate=0.03499245699105878, max_delta_step=0, max_depth=15, min_child_weight=7, n_estimators=511, reg_alpha=2.534576535717491, reg_lambda=2.12775151402026, scale_pos_weight=0.8994639406110219, subsample=0.9116344591059367; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.7095981995133787, colsample_bynode=0.8290116443832669, colsample_bytree=0.7976530235681191, gamma=1.0640769187324983, learning_rate=0.003605364799767672, max_delta_step=2, max_depth=6, min_child_weight=9, n_estimators=2045, reg_alpha=2.8665949197207867, reg_lambda=2.306457129092874, scale_pos_weight=0.8282355592494823, subsample=0.7393948113526363; total time=   7.8s\n",
      "[CV] END colsample_bylevel=0.9349553422213137, colsample_bynode=0.9533261109523449, colsample_bytree=0.7213640439536699, gamma=1.902447813186659, learning_rate=0.05348793493196706, max_delta_step=1, max_depth=6, min_child_weight=6, n_estimators=2089, reg_alpha=2.860440450569381, reg_lambda=1.88970319944357, scale_pos_weight=1.1969175999449346, subsample=0.9300372267817756; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.7554099400213591, colsample_bynode=0.8429283931898632, colsample_bytree=0.6564111070894564, gamma=0.09563585051707604, learning_rate=0.022558500179106225, max_delta_step=8, max_depth=7, min_child_weight=4, n_estimators=2009, reg_alpha=0.7391073573076685, reg_lambda=1.4271444534371391, scale_pos_weight=1.0069652746394901, subsample=0.8083451713135665; total time=  10.6s\n",
      "[CV] END colsample_bylevel=0.8858602308871624, colsample_bynode=0.6677106398221494, colsample_bytree=0.6813305482440982, gamma=1.1696008736274444, learning_rate=0.009789605136839142, max_delta_step=1, max_depth=5, min_child_weight=10, n_estimators=2507, reg_alpha=1.59336067550892, reg_lambda=0.5219922207239965, scale_pos_weight=0.9345311711605099, subsample=0.8790584028106331; total time=   7.4s\n",
      "[CV] END colsample_bylevel=0.8858602308871624, colsample_bynode=0.6677106398221494, colsample_bytree=0.6813305482440982, gamma=1.1696008736274444, learning_rate=0.009789605136839142, max_delta_step=1, max_depth=5, min_child_weight=10, n_estimators=2507, reg_alpha=1.59336067550892, reg_lambda=0.5219922207239965, scale_pos_weight=0.9345311711605099, subsample=0.8790584028106331; total time=   5.8s\n",
      "[CV] END colsample_bylevel=0.7779330049204607, colsample_bynode=0.9674890086677508, colsample_bytree=0.6419436634210814, gamma=0.8666656037404503, learning_rate=0.0023763498182367165, max_delta_step=5, max_depth=6, min_child_weight=12, n_estimators=1893, reg_alpha=2.9196209330786664, reg_lambda=2.1104025933189123, scale_pos_weight=0.9525892931565766, subsample=0.7593566138329139; total time=   9.3s\n",
      "[CV] END colsample_bylevel=0.8038204453073899, colsample_bynode=0.7781385616731392, colsample_bytree=0.7444561678086361, gamma=1.9938098579429389, learning_rate=0.002885030412141064, max_delta_step=8, max_depth=14, min_child_weight=2, n_estimators=1377, reg_alpha=2.5807623450625163, reg_lambda=1.9755968613209078, scale_pos_weight=1.1401850404430842, subsample=0.7901005123171235; total time=  10.0s\n",
      "[CV] END colsample_bylevel=0.8038204453073899, colsample_bynode=0.7781385616731392, colsample_bytree=0.7444561678086361, gamma=1.9938098579429389, learning_rate=0.002885030412141064, max_delta_step=8, max_depth=14, min_child_weight=2, n_estimators=1377, reg_alpha=2.5807623450625163, reg_lambda=1.9755968613209078, scale_pos_weight=1.1401850404430842, subsample=0.7901005123171235; total time=   9.5s\n",
      "[CV] END colsample_bylevel=0.9249583953429453, colsample_bynode=0.6687486245586243, colsample_bytree=0.8392188310048512, gamma=1.6055295623126211, learning_rate=0.01111999664226395, max_delta_step=1, max_depth=12, min_child_weight=13, n_estimators=2780, reg_alpha=1.1603857926530512, reg_lambda=1.0247872263079094, scale_pos_weight=1.1350120740405336, subsample=0.8831297285879681; total time=   6.6s\n",
      "[CV] END colsample_bylevel=0.9249583953429453, colsample_bynode=0.6687486245586243, colsample_bytree=0.8392188310048512, gamma=1.6055295623126211, learning_rate=0.01111999664226395, max_delta_step=1, max_depth=12, min_child_weight=13, n_estimators=2780, reg_alpha=1.1603857926530512, reg_lambda=1.0247872263079094, scale_pos_weight=1.1350120740405336, subsample=0.8831297285879681; total time=   8.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9727891919970675, colsample_bytree=0.6732941062342661, gamma=2.0, learning_rate=0.001, max_delta_step=0, max_depth=9, min_child_weight=2, n_estimators=1203, reg_alpha=2.6074574039519063, reg_lambda=2.54274376282736, scale_pos_weight=1.0273863087030308, subsample=0.7733034128815556; total time=   9.1s\n",
      "[CV] END colsample_bylevel=0.66356001406769, colsample_bynode=0.764706330154597, colsample_bytree=0.8506054103917193, gamma=0.1702307424253167, learning_rate=0.0010092144518871718, max_delta_step=10, max_depth=15, min_child_weight=7, n_estimators=2447, reg_alpha=1.0261507516353077, reg_lambda=1.9435049567823384, scale_pos_weight=0.8112557740864806, subsample=0.8310548413843668; total time=  19.3s\n",
      "[CV] END colsample_bylevel=0.7466137551925102, colsample_bynode=0.8974444134032649, colsample_bytree=0.7548516040655054, gamma=0.43902104288877253, learning_rate=0.0994113015193369, max_delta_step=1, max_depth=14, min_child_weight=14, n_estimators=2017, reg_alpha=0.9715412376355661, reg_lambda=2.914730176276133, scale_pos_weight=1.0126290173347083, subsample=0.7466388846477777; total time=   7.8s\n",
      "[CV] END colsample_bylevel=0.6886827070582457, colsample_bynode=0.7974902178549595, colsample_bytree=0.6176603334641794, gamma=1.4914222819518947, learning_rate=0.02150814856096874, max_delta_step=0, max_depth=9, min_child_weight=4, n_estimators=2405, reg_alpha=0.08545803427150311, reg_lambda=0.0, scale_pos_weight=0.9365930633059527, subsample=0.9726413427108334; total time=   5.0s\n",
      "[CV] END colsample_bylevel=0.6886827070582457, colsample_bynode=0.7974902178549595, colsample_bytree=0.6176603334641794, gamma=1.4914222819518947, learning_rate=0.02150814856096874, max_delta_step=0, max_depth=9, min_child_weight=4, n_estimators=2405, reg_alpha=0.08545803427150311, reg_lambda=0.0, scale_pos_weight=0.9365930633059527, subsample=0.9726413427108334; total time=   6.1s\n",
      "[CV] END colsample_bylevel=0.7412525382873448, colsample_bynode=0.8664143263426028, colsample_bytree=0.9916051763942715, gamma=1.9472069217216694, learning_rate=0.0010188190400360986, max_delta_step=6, max_depth=6, min_child_weight=13, n_estimators=1158, reg_alpha=0.020491355971932086, reg_lambda=1.1015644869738423, scale_pos_weight=1.1703075458537742, subsample=0.928416009871444; total time=   7.0s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_delta_step=0, max_depth=15, min_child_weight=15, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=  18.4s\n",
      "[CV] END colsample_bylevel=0.8532729746346017, colsample_bynode=0.9997139531310555, colsample_bytree=0.8621607040266261, gamma=0.5112929578501474, learning_rate=0.014236991825974906, max_delta_step=4, max_depth=9, min_child_weight=8, n_estimators=2801, reg_alpha=2.676687575922181, reg_lambda=0.017699530322734643, scale_pos_weight=1.1031951555001047, subsample=0.9970833908909384; total time=   9.6s\n",
      "[CV] END colsample_bylevel=0.8532729746346017, colsample_bynode=0.9997139531310555, colsample_bytree=0.8621607040266261, gamma=0.5112929578501474, learning_rate=0.014236991825974906, max_delta_step=4, max_depth=9, min_child_weight=8, n_estimators=2801, reg_alpha=2.676687575922181, reg_lambda=0.017699530322734643, scale_pos_weight=1.1031951555001047, subsample=0.9970833908909384; total time=   8.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=0.7640415835413256, colsample_bynode=0.89109029727093, colsample_bytree=0.9731471995391335, gamma=0.6315991869740974, learning_rate=0.021892527128216443, max_delta_step=4, max_depth=8, min_child_weight=11, n_estimators=1261, reg_alpha=1.943374765040633, reg_lambda=1.6498918254293524, scale_pos_weight=0.8507335273583403, subsample=0.7534251755188192; total time=   5.8s\n",
      "[CV] END colsample_bylevel=0.8528382512601542, colsample_bynode=0.6311564916549026, colsample_bytree=0.86673155880575, gamma=1.365494505768866, learning_rate=0.03499245699105878, max_delta_step=0, max_depth=15, min_child_weight=7, n_estimators=511, reg_alpha=2.534576535717491, reg_lambda=2.12775151402026, scale_pos_weight=0.8994639406110219, subsample=0.9116344591059367; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.8528382512601542, colsample_bynode=0.6311564916549026, colsample_bytree=0.86673155880575, gamma=1.365494505768866, learning_rate=0.03499245699105878, max_delta_step=0, max_depth=15, min_child_weight=7, n_estimators=511, reg_alpha=2.534576535717491, reg_lambda=2.12775151402026, scale_pos_weight=0.8994639406110219, subsample=0.9116344591059367; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.7095981995133787, colsample_bynode=0.8290116443832669, colsample_bytree=0.7976530235681191, gamma=1.0640769187324983, learning_rate=0.003605364799767672, max_delta_step=2, max_depth=6, min_child_weight=9, n_estimators=2045, reg_alpha=2.8665949197207867, reg_lambda=2.306457129092874, scale_pos_weight=0.8282355592494823, subsample=0.7393948113526363; total time=   7.7s\n",
      "[CV] END colsample_bylevel=0.9349553422213137, colsample_bynode=0.9533261109523449, colsample_bytree=0.7213640439536699, gamma=1.902447813186659, learning_rate=0.05348793493196706, max_delta_step=1, max_depth=6, min_child_weight=6, n_estimators=2089, reg_alpha=2.860440450569381, reg_lambda=1.88970319944357, scale_pos_weight=1.1969175999449346, subsample=0.9300372267817756; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.7554099400213591, colsample_bynode=0.8429283931898632, colsample_bytree=0.6564111070894564, gamma=0.09563585051707604, learning_rate=0.022558500179106225, max_delta_step=8, max_depth=7, min_child_weight=4, n_estimators=2009, reg_alpha=0.7391073573076685, reg_lambda=1.4271444534371391, scale_pos_weight=1.0069652746394901, subsample=0.8083451713135665; total time=  10.2s\n",
      "[CV] END colsample_bylevel=0.7554099400213591, colsample_bynode=0.8429283931898632, colsample_bytree=0.6564111070894564, gamma=0.09563585051707604, learning_rate=0.022558500179106225, max_delta_step=8, max_depth=7, min_child_weight=4, n_estimators=2009, reg_alpha=0.7391073573076685, reg_lambda=1.4271444534371391, scale_pos_weight=1.0069652746394901, subsample=0.8083451713135665; total time=   9.5s\n",
      "[CV] END colsample_bylevel=0.7779330049204607, colsample_bynode=0.9674890086677508, colsample_bytree=0.6419436634210814, gamma=0.8666656037404503, learning_rate=0.0023763498182367165, max_delta_step=5, max_depth=6, min_child_weight=12, n_estimators=1893, reg_alpha=2.9196209330786664, reg_lambda=2.1104025933189123, scale_pos_weight=0.9525892931565766, subsample=0.7593566138329139; total time=   9.2s\n",
      "[CV] END colsample_bylevel=0.7779330049204607, colsample_bynode=0.9674890086677508, colsample_bytree=0.6419436634210814, gamma=0.8666656037404503, learning_rate=0.0023763498182367165, max_delta_step=5, max_depth=6, min_child_weight=12, n_estimators=1893, reg_alpha=2.9196209330786664, reg_lambda=2.1104025933189123, scale_pos_weight=0.9525892931565766, subsample=0.7593566138329139; total time=   8.3s\n",
      "[CV] END colsample_bylevel=0.8038204453073899, colsample_bynode=0.7781385616731392, colsample_bytree=0.7444561678086361, gamma=1.9938098579429389, learning_rate=0.002885030412141064, max_delta_step=8, max_depth=14, min_child_weight=2, n_estimators=1377, reg_alpha=2.5807623450625163, reg_lambda=1.9755968613209078, scale_pos_weight=1.1401850404430842, subsample=0.7901005123171235; total time=   9.5s\n",
      "[CV] END colsample_bylevel=0.8882629936991471, colsample_bynode=0.8789616849482842, colsample_bytree=0.8933260784439065, gamma=1.1628140265612334, learning_rate=0.009420974429602238, max_delta_step=4, max_depth=9, min_child_weight=8, n_estimators=1922, reg_alpha=0.5031412495239872, reg_lambda=2.0004015079260693, scale_pos_weight=0.9145767613342524, subsample=0.9544589789347462; total time=   5.0s\n",
      "[CV] END colsample_bylevel=0.9249583953429453, colsample_bynode=0.6687486245586243, colsample_bytree=0.8392188310048512, gamma=1.6055295623126211, learning_rate=0.01111999664226395, max_delta_step=1, max_depth=12, min_child_weight=13, n_estimators=2780, reg_alpha=1.1603857926530512, reg_lambda=1.0247872263079094, scale_pos_weight=1.1350120740405336, subsample=0.8831297285879681; total time=   6.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9727891919970675, colsample_bytree=0.6732941062342661, gamma=2.0, learning_rate=0.001, max_delta_step=0, max_depth=9, min_child_weight=2, n_estimators=1203, reg_alpha=2.6074574039519063, reg_lambda=2.54274376282736, scale_pos_weight=1.0273863087030308, subsample=0.7733034128815556; total time=   8.7s\n",
      "[CV] END colsample_bylevel=0.66356001406769, colsample_bynode=0.764706330154597, colsample_bytree=0.8506054103917193, gamma=0.1702307424253167, learning_rate=0.0010092144518871718, max_delta_step=10, max_depth=15, min_child_weight=7, n_estimators=2447, reg_alpha=1.0261507516353077, reg_lambda=1.9435049567823384, scale_pos_weight=0.8112557740864806, subsample=0.8310548413843668; total time=  19.7s\n",
      "[CV] END colsample_bylevel=0.66356001406769, colsample_bynode=0.764706330154597, colsample_bytree=0.8506054103917193, gamma=0.1702307424253167, learning_rate=0.0010092144518871718, max_delta_step=10, max_depth=15, min_child_weight=7, n_estimators=2447, reg_alpha=1.0261507516353077, reg_lambda=1.9435049567823384, scale_pos_weight=0.8112557740864806, subsample=0.8310548413843668; total time=  12.6s\n",
      "[CV] END colsample_bylevel=0.7466137551925102, colsample_bynode=0.8974444134032649, colsample_bytree=0.7548516040655054, gamma=0.43902104288877253, learning_rate=0.0994113015193369, max_delta_step=1, max_depth=14, min_child_weight=14, n_estimators=2017, reg_alpha=0.9715412376355661, reg_lambda=2.914730176276133, scale_pos_weight=1.0126290173347083, subsample=0.7466388846477777; total time=   7.6s\n",
      "[CV] END colsample_bylevel=0.7466137551925102, colsample_bynode=0.8974444134032649, colsample_bytree=0.7548516040655054, gamma=0.43902104288877253, learning_rate=0.0994113015193369, max_delta_step=1, max_depth=14, min_child_weight=14, n_estimators=2017, reg_alpha=0.9715412376355661, reg_lambda=2.914730176276133, scale_pos_weight=1.0126290173347083, subsample=0.7466388846477777; total time=   9.2s\n",
      "[CV] END colsample_bylevel=0.7412525382873448, colsample_bynode=0.8664143263426028, colsample_bytree=0.9916051763942715, gamma=1.9472069217216694, learning_rate=0.0010188190400360986, max_delta_step=6, max_depth=6, min_child_weight=13, n_estimators=1158, reg_alpha=0.020491355971932086, reg_lambda=1.1015644869738423, scale_pos_weight=1.1703075458537742, subsample=0.928416009871444; total time=   7.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_delta_step=0, max_depth=15, min_child_weight=15, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=  18.1s\n",
      "[CV] END colsample_bylevel=0.8532729746346017, colsample_bynode=0.9997139531310555, colsample_bytree=0.8621607040266261, gamma=0.5112929578501474, learning_rate=0.014236991825974906, max_delta_step=4, max_depth=9, min_child_weight=8, n_estimators=2801, reg_alpha=2.676687575922181, reg_lambda=0.017699530322734643, scale_pos_weight=1.1031951555001047, subsample=0.9970833908909384; total time=   9.4s\n",
      "[CV] END colsample_bylevel=0.8532729746346017, colsample_bynode=0.9997139531310555, colsample_bytree=0.8621607040266261, gamma=0.5112929578501474, learning_rate=0.014236991825974906, max_delta_step=4, max_depth=9, min_child_weight=8, n_estimators=2801, reg_alpha=2.676687575922181, reg_lambda=0.017699530322734643, scale_pos_weight=1.1031951555001047, subsample=0.9970833908909384; total time=   8.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:40:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=0.7640415835413256, colsample_bynode=0.89109029727093, colsample_bytree=0.9731471995391335, gamma=0.6315991869740974, learning_rate=0.021892527128216443, max_delta_step=4, max_depth=8, min_child_weight=11, n_estimators=1261, reg_alpha=1.943374765040633, reg_lambda=1.6498918254293524, scale_pos_weight=0.8507335273583403, subsample=0.7534251755188192; total time=   5.7s\n",
      "[CV] END colsample_bylevel=0.7640415835413256, colsample_bynode=0.89109029727093, colsample_bytree=0.9731471995391335, gamma=0.6315991869740974, learning_rate=0.021892527128216443, max_delta_step=4, max_depth=8, min_child_weight=11, n_estimators=1261, reg_alpha=1.943374765040633, reg_lambda=1.6498918254293524, scale_pos_weight=0.8507335273583403, subsample=0.7534251755188192; total time=   5.2s\n",
      "[CV] END colsample_bylevel=0.7095981995133787, colsample_bynode=0.8290116443832669, colsample_bytree=0.7976530235681191, gamma=1.0640769187324983, learning_rate=0.003605364799767672, max_delta_step=2, max_depth=6, min_child_weight=9, n_estimators=2045, reg_alpha=2.8665949197207867, reg_lambda=2.306457129092874, scale_pos_weight=0.8282355592494823, subsample=0.7393948113526363; total time=   7.0s\n",
      "[CV] END colsample_bylevel=0.9349553422213137, colsample_bynode=0.9533261109523449, colsample_bytree=0.7213640439536699, gamma=1.902447813186659, learning_rate=0.05348793493196706, max_delta_step=1, max_depth=6, min_child_weight=6, n_estimators=2089, reg_alpha=2.860440450569381, reg_lambda=1.88970319944357, scale_pos_weight=1.1969175999449346, subsample=0.9300372267817756; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.7554099400213591, colsample_bynode=0.8429283931898632, colsample_bytree=0.6564111070894564, gamma=0.09563585051707604, learning_rate=0.022558500179106225, max_delta_step=8, max_depth=7, min_child_weight=4, n_estimators=2009, reg_alpha=0.7391073573076685, reg_lambda=1.4271444534371391, scale_pos_weight=1.0069652746394901, subsample=0.8083451713135665; total time=  10.3s\n",
      "[CV] END colsample_bylevel=0.7554099400213591, colsample_bynode=0.8429283931898632, colsample_bytree=0.6564111070894564, gamma=0.09563585051707604, learning_rate=0.022558500179106225, max_delta_step=8, max_depth=7, min_child_weight=4, n_estimators=2009, reg_alpha=0.7391073573076685, reg_lambda=1.4271444534371391, scale_pos_weight=1.0069652746394901, subsample=0.8083451713135665; total time=   9.9s\n",
      "[CV] END colsample_bylevel=0.7779330049204607, colsample_bynode=0.9674890086677508, colsample_bytree=0.6419436634210814, gamma=0.8666656037404503, learning_rate=0.0023763498182367165, max_delta_step=5, max_depth=6, min_child_weight=12, n_estimators=1893, reg_alpha=2.9196209330786664, reg_lambda=2.1104025933189123, scale_pos_weight=0.9525892931565766, subsample=0.7593566138329139; total time=   9.4s\n",
      "[CV] END colsample_bylevel=0.8038204453073899, colsample_bynode=0.7781385616731392, colsample_bytree=0.7444561678086361, gamma=1.9938098579429389, learning_rate=0.002885030412141064, max_delta_step=8, max_depth=14, min_child_weight=2, n_estimators=1377, reg_alpha=2.5807623450625163, reg_lambda=1.9755968613209078, scale_pos_weight=1.1401850404430842, subsample=0.7901005123171235; total time=   9.9s\n",
      "[CV] END colsample_bylevel=0.8038204453073899, colsample_bynode=0.7781385616731392, colsample_bytree=0.7444561678086361, gamma=1.9938098579429389, learning_rate=0.002885030412141064, max_delta_step=8, max_depth=14, min_child_weight=2, n_estimators=1377, reg_alpha=2.5807623450625163, reg_lambda=1.9755968613209078, scale_pos_weight=1.1401850404430842, subsample=0.7901005123171235; total time=   9.5s\n",
      "[CV] END colsample_bylevel=0.9249583953429453, colsample_bynode=0.6687486245586243, colsample_bytree=0.8392188310048512, gamma=1.6055295623126211, learning_rate=0.01111999664226395, max_delta_step=1, max_depth=12, min_child_weight=13, n_estimators=2780, reg_alpha=1.1603857926530512, reg_lambda=1.0247872263079094, scale_pos_weight=1.1350120740405336, subsample=0.8831297285879681; total time=   6.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9727891919970675, colsample_bytree=0.6732941062342661, gamma=2.0, learning_rate=0.001, max_delta_step=0, max_depth=9, min_child_weight=2, n_estimators=1203, reg_alpha=2.6074574039519063, reg_lambda=2.54274376282736, scale_pos_weight=1.0273863087030308, subsample=0.7733034128815556; total time=   8.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9727891919970675, colsample_bytree=0.6732941062342661, gamma=2.0, learning_rate=0.001, max_delta_step=0, max_depth=9, min_child_weight=2, n_estimators=1203, reg_alpha=2.6074574039519063, reg_lambda=2.54274376282736, scale_pos_weight=1.0273863087030308, subsample=0.7733034128815556; total time=   9.4s\n",
      "[CV] END colsample_bylevel=0.66356001406769, colsample_bynode=0.764706330154597, colsample_bytree=0.8506054103917193, gamma=0.1702307424253167, learning_rate=0.0010092144518871718, max_delta_step=10, max_depth=15, min_child_weight=7, n_estimators=2447, reg_alpha=1.0261507516353077, reg_lambda=1.9435049567823384, scale_pos_weight=0.8112557740864806, subsample=0.8310548413843668; total time=  19.1s\n",
      "[CV] END colsample_bylevel=0.7466137551925102, colsample_bynode=0.8974444134032649, colsample_bytree=0.7548516040655054, gamma=0.43902104288877253, learning_rate=0.0994113015193369, max_delta_step=1, max_depth=14, min_child_weight=14, n_estimators=2017, reg_alpha=0.9715412376355661, reg_lambda=2.914730176276133, scale_pos_weight=1.0126290173347083, subsample=0.7466388846477777; total time=   7.8s\n",
      "[CV] END colsample_bylevel=0.6886827070582457, colsample_bynode=0.7974902178549595, colsample_bytree=0.6176603334641794, gamma=1.4914222819518947, learning_rate=0.02150814856096874, max_delta_step=0, max_depth=9, min_child_weight=4, n_estimators=2405, reg_alpha=0.08545803427150311, reg_lambda=0.0, scale_pos_weight=0.9365930633059527, subsample=0.9726413427108334; total time=   5.1s\n",
      "[CV] END colsample_bylevel=0.7412525382873448, colsample_bynode=0.8664143263426028, colsample_bytree=0.9916051763942715, gamma=1.9472069217216694, learning_rate=0.0010188190400360986, max_delta_step=6, max_depth=6, min_child_weight=13, n_estimators=1158, reg_alpha=0.020491355971932086, reg_lambda=1.1015644869738423, scale_pos_weight=1.1703075458537742, subsample=0.928416009871444; total time=   7.5s\n",
      "[CV] END colsample_bylevel=0.7412525382873448, colsample_bynode=0.8664143263426028, colsample_bytree=0.9916051763942715, gamma=1.9472069217216694, learning_rate=0.0010188190400360986, max_delta_step=6, max_depth=6, min_child_weight=13, n_estimators=1158, reg_alpha=0.020491355971932086, reg_lambda=1.1015644869738423, scale_pos_weight=1.1703075458537742, subsample=0.928416009871444; total time=   6.1s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_delta_step=0, max_depth=15, min_child_weight=15, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=  18.4s\n",
      "[CV] END colsample_bylevel=0.8532729746346017, colsample_bynode=0.9997139531310555, colsample_bytree=0.8621607040266261, gamma=0.5112929578501474, learning_rate=0.014236991825974906, max_delta_step=4, max_depth=9, min_child_weight=8, n_estimators=2801, reg_alpha=2.676687575922181, reg_lambda=0.017699530322734643, scale_pos_weight=1.1031951555001047, subsample=0.9970833908909384; total time=   9.7s\n",
      "[CV] END colsample_bylevel=0.8532729746346017, colsample_bynode=0.9997139531310555, colsample_bytree=0.8621607040266261, gamma=0.5112929578501474, learning_rate=0.014236991825974906, max_delta_step=4, max_depth=9, min_child_weight=8, n_estimators=2801, reg_alpha=2.676687575922181, reg_lambda=0.017699530322734643, scale_pos_weight=1.1031951555001047, subsample=0.9970833908909384; total time=   8.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.5510122035826966, learning_rate=0.001, max_delta_step=0, max_depth=13, min_child_weight=12, n_estimators=2324, reg_alpha=1.324863528038593, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=  10.3s\n",
      "[CV] END colsample_bylevel=0.9439267366707895, colsample_bynode=0.6060737761524309, colsample_bytree=0.6182430299570395, gamma=0.008611764773890586, learning_rate=0.0038789044147279376, max_delta_step=9, max_depth=9, min_child_weight=6, n_estimators=2822, reg_alpha=1.0634475128992613, reg_lambda=1.2003201949826288, scale_pos_weight=0.9004198602828055, subsample=0.9527757064782792; total time=  18.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=0.7640415835413256, colsample_bynode=0.89109029727093, colsample_bytree=0.9731471995391335, gamma=0.6315991869740974, learning_rate=0.021892527128216443, max_delta_step=4, max_depth=8, min_child_weight=11, n_estimators=1261, reg_alpha=1.943374765040633, reg_lambda=1.6498918254293524, scale_pos_weight=0.8507335273583403, subsample=0.7534251755188192; total time=   5.8s\n",
      "[CV] END colsample_bylevel=0.8528382512601542, colsample_bynode=0.6311564916549026, colsample_bytree=0.86673155880575, gamma=1.365494505768866, learning_rate=0.03499245699105878, max_delta_step=0, max_depth=15, min_child_weight=7, n_estimators=511, reg_alpha=2.534576535717491, reg_lambda=2.12775151402026, scale_pos_weight=0.8994639406110219, subsample=0.9116344591059367; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.8528382512601542, colsample_bynode=0.6311564916549026, colsample_bytree=0.86673155880575, gamma=1.365494505768866, learning_rate=0.03499245699105878, max_delta_step=0, max_depth=15, min_child_weight=7, n_estimators=511, reg_alpha=2.534576535717491, reg_lambda=2.12775151402026, scale_pos_weight=0.8994639406110219, subsample=0.9116344591059367; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.7095981995133787, colsample_bynode=0.8290116443832669, colsample_bytree=0.7976530235681191, gamma=1.0640769187324983, learning_rate=0.003605364799767672, max_delta_step=2, max_depth=6, min_child_weight=9, n_estimators=2045, reg_alpha=2.8665949197207867, reg_lambda=2.306457129092874, scale_pos_weight=0.8282355592494823, subsample=0.7393948113526363; total time=   7.9s\n",
      "[CV] END colsample_bylevel=0.9349553422213137, colsample_bynode=0.9533261109523449, colsample_bytree=0.7213640439536699, gamma=1.902447813186659, learning_rate=0.05348793493196706, max_delta_step=1, max_depth=6, min_child_weight=6, n_estimators=2089, reg_alpha=2.860440450569381, reg_lambda=1.88970319944357, scale_pos_weight=1.1969175999449346, subsample=0.9300372267817756; total time=   3.4s\n",
      "[CV] END colsample_bylevel=0.7554099400213591, colsample_bynode=0.8429283931898632, colsample_bytree=0.6564111070894564, gamma=0.09563585051707604, learning_rate=0.022558500179106225, max_delta_step=8, max_depth=7, min_child_weight=4, n_estimators=2009, reg_alpha=0.7391073573076685, reg_lambda=1.4271444534371391, scale_pos_weight=1.0069652746394901, subsample=0.8083451713135665; total time=  10.6s\n",
      "[CV] END colsample_bylevel=0.8858602308871624, colsample_bynode=0.6677106398221494, colsample_bytree=0.6813305482440982, gamma=1.1696008736274444, learning_rate=0.009789605136839142, max_delta_step=1, max_depth=5, min_child_weight=10, n_estimators=2507, reg_alpha=1.59336067550892, reg_lambda=0.5219922207239965, scale_pos_weight=0.9345311711605099, subsample=0.8790584028106331; total time=   7.5s\n",
      "[CV] END colsample_bylevel=0.8858602308871624, colsample_bynode=0.6677106398221494, colsample_bytree=0.6813305482440982, gamma=1.1696008736274444, learning_rate=0.009789605136839142, max_delta_step=1, max_depth=5, min_child_weight=10, n_estimators=2507, reg_alpha=1.59336067550892, reg_lambda=0.5219922207239965, scale_pos_weight=0.9345311711605099, subsample=0.8790584028106331; total time=   5.7s\n",
      "[CV] END colsample_bylevel=0.7779330049204607, colsample_bynode=0.9674890086677508, colsample_bytree=0.6419436634210814, gamma=0.8666656037404503, learning_rate=0.0023763498182367165, max_delta_step=5, max_depth=6, min_child_weight=12, n_estimators=1893, reg_alpha=2.9196209330786664, reg_lambda=2.1104025933189123, scale_pos_weight=0.9525892931565766, subsample=0.7593566138329139; total time=   9.1s\n",
      "[CV] END colsample_bylevel=0.7779330049204607, colsample_bynode=0.9674890086677508, colsample_bytree=0.6419436634210814, gamma=0.8666656037404503, learning_rate=0.0023763498182367165, max_delta_step=5, max_depth=6, min_child_weight=12, n_estimators=1893, reg_alpha=2.9196209330786664, reg_lambda=2.1104025933189123, scale_pos_weight=0.9525892931565766, subsample=0.7593566138329139; total time=   8.2s\n",
      "[CV] END colsample_bylevel=0.8038204453073899, colsample_bynode=0.7781385616731392, colsample_bytree=0.7444561678086361, gamma=1.9938098579429389, learning_rate=0.002885030412141064, max_delta_step=8, max_depth=14, min_child_weight=2, n_estimators=1377, reg_alpha=2.5807623450625163, reg_lambda=1.9755968613209078, scale_pos_weight=1.1401850404430842, subsample=0.7901005123171235; total time=   9.8s\n",
      "[CV] END colsample_bylevel=0.8882629936991471, colsample_bynode=0.8789616849482842, colsample_bytree=0.8933260784439065, gamma=1.1628140265612334, learning_rate=0.009420974429602238, max_delta_step=4, max_depth=9, min_child_weight=8, n_estimators=1922, reg_alpha=0.5031412495239872, reg_lambda=2.0004015079260693, scale_pos_weight=0.9145767613342524, subsample=0.9544589789347462; total time=   5.0s\n",
      "[CV] END colsample_bylevel=0.9249583953429453, colsample_bynode=0.6687486245586243, colsample_bytree=0.8392188310048512, gamma=1.6055295623126211, learning_rate=0.01111999664226395, max_delta_step=1, max_depth=12, min_child_weight=13, n_estimators=2780, reg_alpha=1.1603857926530512, reg_lambda=1.0247872263079094, scale_pos_weight=1.1350120740405336, subsample=0.8831297285879681; total time=   6.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9727891919970675, colsample_bytree=0.6732941062342661, gamma=2.0, learning_rate=0.001, max_delta_step=0, max_depth=9, min_child_weight=2, n_estimators=1203, reg_alpha=2.6074574039519063, reg_lambda=2.54274376282736, scale_pos_weight=1.0273863087030308, subsample=0.7733034128815556; total time=   8.7s\n",
      "[CV] END colsample_bylevel=0.66356001406769, colsample_bynode=0.764706330154597, colsample_bytree=0.8506054103917193, gamma=0.1702307424253167, learning_rate=0.0010092144518871718, max_delta_step=10, max_depth=15, min_child_weight=7, n_estimators=2447, reg_alpha=1.0261507516353077, reg_lambda=1.9435049567823384, scale_pos_weight=0.8112557740864806, subsample=0.8310548413843668; total time=  20.4s\n",
      "[CV] END colsample_bylevel=0.7466137551925102, colsample_bynode=0.8974444134032649, colsample_bytree=0.7548516040655054, gamma=0.43902104288877253, learning_rate=0.0994113015193369, max_delta_step=1, max_depth=14, min_child_weight=14, n_estimators=2017, reg_alpha=0.9715412376355661, reg_lambda=2.914730176276133, scale_pos_weight=1.0126290173347083, subsample=0.7466388846477777; total time=   7.7s\n",
      "[CV] END colsample_bylevel=0.6886827070582457, colsample_bynode=0.7974902178549595, colsample_bytree=0.6176603334641794, gamma=1.4914222819518947, learning_rate=0.02150814856096874, max_delta_step=0, max_depth=9, min_child_weight=4, n_estimators=2405, reg_alpha=0.08545803427150311, reg_lambda=0.0, scale_pos_weight=0.9365930633059527, subsample=0.9726413427108334; total time=   5.1s\n",
      "[CV] END colsample_bylevel=0.6886827070582457, colsample_bynode=0.7974902178549595, colsample_bytree=0.6176603334641794, gamma=1.4914222819518947, learning_rate=0.02150814856096874, max_delta_step=0, max_depth=9, min_child_weight=4, n_estimators=2405, reg_alpha=0.08545803427150311, reg_lambda=0.0, scale_pos_weight=0.9365930633059527, subsample=0.9726413427108334; total time=   6.3s\n",
      "[CV] END colsample_bylevel=0.7412525382873448, colsample_bynode=0.8664143263426028, colsample_bytree=0.9916051763942715, gamma=1.9472069217216694, learning_rate=0.0010188190400360986, max_delta_step=6, max_depth=6, min_child_weight=13, n_estimators=1158, reg_alpha=0.020491355971932086, reg_lambda=1.1015644869738423, scale_pos_weight=1.1703075458537742, subsample=0.928416009871444; total time=   7.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_delta_step=0, max_depth=15, min_child_weight=15, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=  18.5s\n",
      "[CV] END colsample_bylevel=0.8532729746346017, colsample_bynode=0.9997139531310555, colsample_bytree=0.8621607040266261, gamma=0.5112929578501474, learning_rate=0.014236991825974906, max_delta_step=4, max_depth=9, min_child_weight=8, n_estimators=2801, reg_alpha=2.676687575922181, reg_lambda=0.017699530322734643, scale_pos_weight=1.1031951555001047, subsample=0.9970833908909384; total time=   9.8s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.5510122035826966, learning_rate=0.001, max_delta_step=0, max_depth=13, min_child_weight=12, n_estimators=2324, reg_alpha=1.324863528038593, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=  10.9s[CV] END colsample_bylevel=0.7640415835413256, colsample_bynode=0.89109029727093, colsample_bytree=0.9731471995391335, gamma=0.6315991869740974, learning_rate=0.021892527128216443, max_delta_step=4, max_depth=8, min_child_weight=11, n_estimators=1261, reg_alpha=1.943374765040633, reg_lambda=1.6498918254293524, scale_pos_weight=0.8507335273583403, subsample=0.7534251755188192; total time=   5.7s\n",
      "[CV] END colsample_bylevel=0.7640415835413256, colsample_bynode=0.89109029727093, colsample_bytree=0.9731471995391335, gamma=0.6315991869740974, learning_rate=0.021892527128216443, max_delta_step=4, max_depth=8, min_child_weight=11, n_estimators=1261, reg_alpha=1.943374765040633, reg_lambda=1.6498918254293524, scale_pos_weight=0.8507335273583403, subsample=0.7534251755188192; total time=   5.1s\n",
      "[CV] END colsample_bylevel=0.7095981995133787, colsample_bynode=0.8290116443832669, colsample_bytree=0.7976530235681191, gamma=1.0640769187324983, learning_rate=0.003605364799767672, max_delta_step=2, max_depth=6, min_child_weight=9, n_estimators=2045, reg_alpha=2.8665949197207867, reg_lambda=2.306457129092874, scale_pos_weight=0.8282355592494823, subsample=0.7393948113526363; total time=   7.1s\n",
      "[CV] END colsample_bylevel=0.9349553422213137, colsample_bynode=0.9533261109523449, colsample_bytree=0.7213640439536699, gamma=1.902447813186659, learning_rate=0.05348793493196706, max_delta_step=1, max_depth=6, min_child_weight=6, n_estimators=2089, reg_alpha=2.860440450569381, reg_lambda=1.88970319944357, scale_pos_weight=1.1969175999449346, subsample=0.9300372267817756; total time=   3.4s\n",
      "[CV] END colsample_bylevel=0.7554099400213591, colsample_bynode=0.8429283931898632, colsample_bytree=0.6564111070894564, gamma=0.09563585051707604, learning_rate=0.022558500179106225, max_delta_step=8, max_depth=7, min_child_weight=4, n_estimators=2009, reg_alpha=0.7391073573076685, reg_lambda=1.4271444534371391, scale_pos_weight=1.0069652746394901, subsample=0.8083451713135665; total time=  10.5s\n",
      "[CV] END colsample_bylevel=0.8858602308871624, colsample_bynode=0.6677106398221494, colsample_bytree=0.6813305482440982, gamma=1.1696008736274444, learning_rate=0.009789605136839142, max_delta_step=1, max_depth=5, min_child_weight=10, n_estimators=2507, reg_alpha=1.59336067550892, reg_lambda=0.5219922207239965, scale_pos_weight=0.9345311711605099, subsample=0.8790584028106331; total time=   7.5s\n",
      "[CV] END colsample_bylevel=0.8858602308871624, colsample_bynode=0.6677106398221494, colsample_bytree=0.6813305482440982, gamma=1.1696008736274444, learning_rate=0.009789605136839142, max_delta_step=1, max_depth=5, min_child_weight=10, n_estimators=2507, reg_alpha=1.59336067550892, reg_lambda=0.5219922207239965, scale_pos_weight=0.9345311711605099, subsample=0.8790584028106331; total time=   5.7s\n",
      "[CV] END colsample_bylevel=0.7779330049204607, colsample_bynode=0.9674890086677508, colsample_bytree=0.6419436634210814, gamma=0.8666656037404503, learning_rate=0.0023763498182367165, max_delta_step=5, max_depth=6, min_child_weight=12, n_estimators=1893, reg_alpha=2.9196209330786664, reg_lambda=2.1104025933189123, scale_pos_weight=0.9525892931565766, subsample=0.7593566138329139; total time=   9.4s\n",
      "[CV] END colsample_bylevel=0.8038204453073899, colsample_bynode=0.7781385616731392, colsample_bytree=0.7444561678086361, gamma=1.9938098579429389, learning_rate=0.002885030412141064, max_delta_step=8, max_depth=14, min_child_weight=2, n_estimators=1377, reg_alpha=2.5807623450625163, reg_lambda=1.9755968613209078, scale_pos_weight=1.1401850404430842, subsample=0.7901005123171235; total time=  10.1s\n",
      "[CV] END colsample_bylevel=0.8882629936991471, colsample_bynode=0.8789616849482842, colsample_bytree=0.8933260784439065, gamma=1.1628140265612334, learning_rate=0.009420974429602238, max_delta_step=4, max_depth=9, min_child_weight=8, n_estimators=1922, reg_alpha=0.5031412495239872, reg_lambda=2.0004015079260693, scale_pos_weight=0.9145767613342524, subsample=0.9544589789347462; total time=   6.5s\n",
      "[CV] END colsample_bylevel=0.8882629936991471, colsample_bynode=0.8789616849482842, colsample_bytree=0.8933260784439065, gamma=1.1628140265612334, learning_rate=0.009420974429602238, max_delta_step=4, max_depth=9, min_child_weight=8, n_estimators=1922, reg_alpha=0.5031412495239872, reg_lambda=2.0004015079260693, scale_pos_weight=0.9145767613342524, subsample=0.9544589789347462; total time=   5.6s\n",
      "[CV] END colsample_bylevel=0.9249583953429453, colsample_bynode=0.6687486245586243, colsample_bytree=0.8392188310048512, gamma=1.6055295623126211, learning_rate=0.01111999664226395, max_delta_step=1, max_depth=12, min_child_weight=13, n_estimators=2780, reg_alpha=1.1603857926530512, reg_lambda=1.0247872263079094, scale_pos_weight=1.1350120740405336, subsample=0.8831297285879681; total time=   6.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9727891919970675, colsample_bytree=0.6732941062342661, gamma=2.0, learning_rate=0.001, max_delta_step=0, max_depth=9, min_child_weight=2, n_estimators=1203, reg_alpha=2.6074574039519063, reg_lambda=2.54274376282736, scale_pos_weight=1.0273863087030308, subsample=0.7733034128815556; total time=   8.6s\n",
      "[CV] END colsample_bylevel=0.66356001406769, colsample_bynode=0.764706330154597, colsample_bytree=0.8506054103917193, gamma=0.1702307424253167, learning_rate=0.0010092144518871718, max_delta_step=10, max_depth=15, min_child_weight=7, n_estimators=2447, reg_alpha=1.0261507516353077, reg_lambda=1.9435049567823384, scale_pos_weight=0.8112557740864806, subsample=0.8310548413843668; total time=  19.8s\n",
      "[CV] END colsample_bylevel=0.66356001406769, colsample_bynode=0.764706330154597, colsample_bytree=0.8506054103917193, gamma=0.1702307424253167, learning_rate=0.0010092144518871718, max_delta_step=10, max_depth=15, min_child_weight=7, n_estimators=2447, reg_alpha=1.0261507516353077, reg_lambda=1.9435049567823384, scale_pos_weight=0.8112557740864806, subsample=0.8310548413843668; total time=  12.6s\n",
      "[CV] END colsample_bylevel=0.7466137551925102, colsample_bynode=0.8974444134032649, colsample_bytree=0.7548516040655054, gamma=0.43902104288877253, learning_rate=0.0994113015193369, max_delta_step=1, max_depth=14, min_child_weight=14, n_estimators=2017, reg_alpha=0.9715412376355661, reg_lambda=2.914730176276133, scale_pos_weight=1.0126290173347083, subsample=0.7466388846477777; total time=   7.7s\n",
      "[CV] END colsample_bylevel=0.6886827070582457, colsample_bynode=0.7974902178549595, colsample_bytree=0.6176603334641794, gamma=1.4914222819518947, learning_rate=0.02150814856096874, max_delta_step=0, max_depth=9, min_child_weight=4, n_estimators=2405, reg_alpha=0.08545803427150311, reg_lambda=0.0, scale_pos_weight=0.9365930633059527, subsample=0.9726413427108334; total time=   5.0s\n",
      "[CV] END colsample_bylevel=0.6886827070582457, colsample_bynode=0.7974902178549595, colsample_bytree=0.6176603334641794, gamma=1.4914222819518947, learning_rate=0.02150814856096874, max_delta_step=0, max_depth=9, min_child_weight=4, n_estimators=2405, reg_alpha=0.08545803427150311, reg_lambda=0.0, scale_pos_weight=0.9365930633059527, subsample=0.9726413427108334; total time=   6.1s\n",
      "[CV] END colsample_bylevel=0.7412525382873448, colsample_bynode=0.8664143263426028, colsample_bytree=0.9916051763942715, gamma=1.9472069217216694, learning_rate=0.0010188190400360986, max_delta_step=6, max_depth=6, min_child_weight=13, n_estimators=1158, reg_alpha=0.020491355971932086, reg_lambda=1.1015644869738423, scale_pos_weight=1.1703075458537742, subsample=0.928416009871444; total time=   7.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_delta_step=0, max_depth=15, min_child_weight=15, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=  18.0s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_delta_step=0, max_depth=15, min_child_weight=15, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=  15.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.5510122035826966, learning_rate=0.001, max_delta_step=0, max_depth=13, min_child_weight=12, n_estimators=2324, reg_alpha=1.324863528038593, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=  11.1sFitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=0.7640415835413256, colsample_bynode=0.89109029727093, colsample_bytree=0.9731471995391335, gamma=0.6315991869740974, learning_rate=0.021892527128216443, max_delta_step=4, max_depth=8, min_child_weight=11, n_estimators=1261, reg_alpha=1.943374765040633, reg_lambda=1.6498918254293524, scale_pos_weight=0.8507335273583403, subsample=0.7534251755188192; total time=   5.8s\n",
      "[CV] END colsample_bylevel=0.8528382512601542, colsample_bynode=0.6311564916549026, colsample_bytree=0.86673155880575, gamma=1.365494505768866, learning_rate=0.03499245699105878, max_delta_step=0, max_depth=15, min_child_weight=7, n_estimators=511, reg_alpha=2.534576535717491, reg_lambda=2.12775151402026, scale_pos_weight=0.8994639406110219, subsample=0.9116344591059367; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.7095981995133787, colsample_bynode=0.8290116443832669, colsample_bytree=0.7976530235681191, gamma=1.0640769187324983, learning_rate=0.003605364799767672, max_delta_step=2, max_depth=6, min_child_weight=9, n_estimators=2045, reg_alpha=2.8665949197207867, reg_lambda=2.306457129092874, scale_pos_weight=0.8282355592494823, subsample=0.7393948113526363; total time=   7.6s\n",
      "[CV] END colsample_bylevel=0.7095981995133787, colsample_bynode=0.8290116443832669, colsample_bytree=0.7976530235681191, gamma=1.0640769187324983, learning_rate=0.003605364799767672, max_delta_step=2, max_depth=6, min_child_weight=9, n_estimators=2045, reg_alpha=2.8665949197207867, reg_lambda=2.306457129092874, scale_pos_weight=0.8282355592494823, subsample=0.7393948113526363; total time=   4.5s\n",
      "[CV] END colsample_bylevel=0.9349553422213137, colsample_bynode=0.9533261109523449, colsample_bytree=0.7213640439536699, gamma=1.902447813186659, learning_rate=0.05348793493196706, max_delta_step=1, max_depth=6, min_child_weight=6, n_estimators=2089, reg_alpha=2.860440450569381, reg_lambda=1.88970319944357, scale_pos_weight=1.1969175999449346, subsample=0.9300372267817756; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.9349553422213137, colsample_bynode=0.9533261109523449, colsample_bytree=0.7213640439536699, gamma=1.902447813186659, learning_rate=0.05348793493196706, max_delta_step=1, max_depth=6, min_child_weight=6, n_estimators=2089, reg_alpha=2.860440450569381, reg_lambda=1.88970319944357, scale_pos_weight=1.1969175999449346, subsample=0.9300372267817756; total time=   4.7s\n",
      "[CV] END colsample_bylevel=0.7554099400213591, colsample_bynode=0.8429283931898632, colsample_bytree=0.6564111070894564, gamma=0.09563585051707604, learning_rate=0.022558500179106225, max_delta_step=8, max_depth=7, min_child_weight=4, n_estimators=2009, reg_alpha=0.7391073573076685, reg_lambda=1.4271444534371391, scale_pos_weight=1.0069652746394901, subsample=0.8083451713135665; total time=  10.4s\n",
      "[CV] END colsample_bylevel=0.8858602308871624, colsample_bynode=0.6677106398221494, colsample_bytree=0.6813305482440982, gamma=1.1696008736274444, learning_rate=0.009789605136839142, max_delta_step=1, max_depth=5, min_child_weight=10, n_estimators=2507, reg_alpha=1.59336067550892, reg_lambda=0.5219922207239965, scale_pos_weight=0.9345311711605099, subsample=0.8790584028106331; total time=   6.6s\n",
      "[CV] END colsample_bylevel=0.7779330049204607, colsample_bynode=0.9674890086677508, colsample_bytree=0.6419436634210814, gamma=0.8666656037404503, learning_rate=0.0023763498182367165, max_delta_step=5, max_depth=6, min_child_weight=12, n_estimators=1893, reg_alpha=2.9196209330786664, reg_lambda=2.1104025933189123, scale_pos_weight=0.9525892931565766, subsample=0.7593566138329139; total time=   9.4s\n",
      "[CV] END colsample_bylevel=0.8038204453073899, colsample_bynode=0.7781385616731392, colsample_bytree=0.7444561678086361, gamma=1.9938098579429389, learning_rate=0.002885030412141064, max_delta_step=8, max_depth=14, min_child_weight=2, n_estimators=1377, reg_alpha=2.5807623450625163, reg_lambda=1.9755968613209078, scale_pos_weight=1.1401850404430842, subsample=0.7901005123171235; total time=   9.9s\n",
      "[CV] END colsample_bylevel=0.8882629936991471, colsample_bynode=0.8789616849482842, colsample_bytree=0.8933260784439065, gamma=1.1628140265612334, learning_rate=0.009420974429602238, max_delta_step=4, max_depth=9, min_child_weight=8, n_estimators=1922, reg_alpha=0.5031412495239872, reg_lambda=2.0004015079260693, scale_pos_weight=0.9145767613342524, subsample=0.9544589789347462; total time=   6.6s\n",
      "[CV] END colsample_bylevel=0.8882629936991471, colsample_bynode=0.8789616849482842, colsample_bytree=0.8933260784439065, gamma=1.1628140265612334, learning_rate=0.009420974429602238, max_delta_step=4, max_depth=9, min_child_weight=8, n_estimators=1922, reg_alpha=0.5031412495239872, reg_lambda=2.0004015079260693, scale_pos_weight=0.9145767613342524, subsample=0.9544589789347462; total time=   5.6s\n",
      "[CV] END colsample_bylevel=0.9249583953429453, colsample_bynode=0.6687486245586243, colsample_bytree=0.8392188310048512, gamma=1.6055295623126211, learning_rate=0.01111999664226395, max_delta_step=1, max_depth=12, min_child_weight=13, n_estimators=2780, reg_alpha=1.1603857926530512, reg_lambda=1.0247872263079094, scale_pos_weight=1.1350120740405336, subsample=0.8831297285879681; total time=   6.6s\n",
      "[CV] END colsample_bylevel=0.9249583953429453, colsample_bynode=0.6687486245586243, colsample_bytree=0.8392188310048512, gamma=1.6055295623126211, learning_rate=0.01111999664226395, max_delta_step=1, max_depth=12, min_child_weight=13, n_estimators=2780, reg_alpha=1.1603857926530512, reg_lambda=1.0247872263079094, scale_pos_weight=1.1350120740405336, subsample=0.8831297285879681; total time=   8.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9727891919970675, colsample_bytree=0.6732941062342661, gamma=2.0, learning_rate=0.001, max_delta_step=0, max_depth=9, min_child_weight=2, n_estimators=1203, reg_alpha=2.6074574039519063, reg_lambda=2.54274376282736, scale_pos_weight=1.0273863087030308, subsample=0.7733034128815556; total time=   9.3s\n",
      "[CV] END colsample_bylevel=0.66356001406769, colsample_bynode=0.764706330154597, colsample_bytree=0.8506054103917193, gamma=0.1702307424253167, learning_rate=0.0010092144518871718, max_delta_step=10, max_depth=15, min_child_weight=7, n_estimators=2447, reg_alpha=1.0261507516353077, reg_lambda=1.9435049567823384, scale_pos_weight=0.8112557740864806, subsample=0.8310548413843668; total time=  19.3s\n",
      "[CV] END colsample_bylevel=0.7466137551925102, colsample_bynode=0.8974444134032649, colsample_bytree=0.7548516040655054, gamma=0.43902104288877253, learning_rate=0.0994113015193369, max_delta_step=1, max_depth=14, min_child_weight=14, n_estimators=2017, reg_alpha=0.9715412376355661, reg_lambda=2.914730176276133, scale_pos_weight=1.0126290173347083, subsample=0.7466388846477777; total time=   7.4s\n",
      "[CV] END colsample_bylevel=0.7466137551925102, colsample_bynode=0.8974444134032649, colsample_bytree=0.7548516040655054, gamma=0.43902104288877253, learning_rate=0.0994113015193369, max_delta_step=1, max_depth=14, min_child_weight=14, n_estimators=2017, reg_alpha=0.9715412376355661, reg_lambda=2.914730176276133, scale_pos_weight=1.0126290173347083, subsample=0.7466388846477777; total time=   9.0s\n",
      "[CV] END colsample_bylevel=0.7412525382873448, colsample_bynode=0.8664143263426028, colsample_bytree=0.9916051763942715, gamma=1.9472069217216694, learning_rate=0.0010188190400360986, max_delta_step=6, max_depth=6, min_child_weight=13, n_estimators=1158, reg_alpha=0.020491355971932086, reg_lambda=1.1015644869738423, scale_pos_weight=1.1703075458537742, subsample=0.928416009871444; total time=   7.4s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_delta_step=0, max_depth=15, min_child_weight=15, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=  18.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=1.0, gamma=0.0, learning_rate=0.001, max_delta_step=0, max_depth=15, min_child_weight=15, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=  15.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.5510122035826966, learning_rate=0.001, max_delta_step=0, max_depth=13, min_child_weight=12, n_estimators=2324, reg_alpha=1.324863528038593, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=  10.7s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:41:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:42:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.5510122035826966, learning_rate=0.001, max_delta_step=0, max_depth=13, min_child_weight=12, n_estimators=2324, reg_alpha=1.324863528038593, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=  10.4s\n",
      "[CV] END colsample_bylevel=0.9439267366707895, colsample_bynode=0.6060737761524309, colsample_bytree=0.6182430299570395, gamma=0.008611764773890586, learning_rate=0.0038789044147279376, max_delta_step=9, max_depth=9, min_child_weight=6, n_estimators=2822, reg_alpha=1.0634475128992613, reg_lambda=1.2003201949826288, scale_pos_weight=0.9004198602828055, subsample=0.9527757064782792; total time=  18.4s\n",
      "[CV] END colsample_bylevel=0.6692299268804345, colsample_bynode=0.616215705508514, colsample_bytree=0.9893936785624549, gamma=1.8989475333021573, learning_rate=0.09584229315414919, max_delta_step=4, max_depth=8, min_child_weight=8, n_estimators=674, reg_alpha=1.7208335823694911, reg_lambda=2.271542660833606, scale_pos_weight=0.841545736296181, subsample=0.7895897843993718; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.6692299268804345, colsample_bynode=0.616215705508514, colsample_bytree=0.9893936785624549, gamma=1.8989475333021573, learning_rate=0.09584229315414919, max_delta_step=4, max_depth=8, min_child_weight=8, n_estimators=674, reg_alpha=1.7208335823694911, reg_lambda=2.271542660833606, scale_pos_weight=0.841545736296181, subsample=0.7895897843993718; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.9855456426695608, colsample_bynode=0.6, colsample_bytree=0.6130474079288737, gamma=0.5783450105047576, learning_rate=0.004135155800711966, max_delta_step=3, max_depth=4, min_child_weight=1, n_estimators=1365, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1952798430153944, subsample=0.7; total time=   4.3s\n",
      "[CV] END colsample_bylevel=0.7402965819445024, colsample_bynode=0.6811016646262777, colsample_bytree=0.7370586987178024, gamma=1.633263339184548, learning_rate=0.013511145030359594, max_delta_step=5, max_depth=5, min_child_weight=13, n_estimators=599, reg_alpha=2.3858601793213974, reg_lambda=0.09259789495853868, scale_pos_weight=1.1510150241526889, subsample=0.9463577974492761; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.6210956286424371, colsample_bynode=0.7114505308672258, colsample_bytree=0.8653294243768137, gamma=0.03333225695723253, learning_rate=0.0010795749185150277, max_delta_step=3, max_depth=4, min_child_weight=2, n_estimators=2445, reg_alpha=2.982709478983814, reg_lambda=2.683349919217637, scale_pos_weight=1.0921605616623704, subsample=0.8601076260992749; total time=   8.2s\n",
      "[CV] END colsample_bylevel=0.6199669415548759, colsample_bynode=0.9684086514687538, colsample_bytree=0.7740202988940662, gamma=1.289224001972352, learning_rate=0.09021612469829324, max_delta_step=8, max_depth=5, min_child_weight=10, n_estimators=2276, reg_alpha=2.9733840568195182, reg_lambda=0.5359728645884603, scale_pos_weight=0.9972558459167127, subsample=0.8179532310154649; total time=   5.6s\n",
      "[CV] END colsample_bylevel=0.6199669415548759, colsample_bynode=0.9684086514687538, colsample_bytree=0.7740202988940662, gamma=1.289224001972352, learning_rate=0.09021612469829324, max_delta_step=8, max_depth=5, min_child_weight=10, n_estimators=2276, reg_alpha=2.9733840568195182, reg_lambda=0.5359728645884603, scale_pos_weight=0.9972558459167127, subsample=0.8179532310154649; total time=   4.6s\n",
      "[CV] END colsample_bylevel=0.7352815407370292, colsample_bynode=0.6200567332915796, colsample_bytree=0.9101335095783277, gamma=1.1329504541128022, learning_rate=0.0010035390508584506, max_delta_step=1, max_depth=14, min_child_weight=15, n_estimators=606, reg_alpha=1.7455352767311612, reg_lambda=1.8976076797949128, scale_pos_weight=1.067678800726689, subsample=0.9696285874682415; total time=   4.0s\n",
      "[CV] END colsample_bylevel=0.7540156032907189, colsample_bynode=0.8268387516223009, colsample_bytree=0.6092865391936877, gamma=1.9997000313859843, learning_rate=0.08766572623579127, max_delta_step=9, max_depth=13, min_child_weight=3, n_estimators=1219, reg_alpha=0.2022600036865369, reg_lambda=1.2626801729424464, scale_pos_weight=0.9610907928432516, subsample=0.9990590346559804; total time=   2.6s\n",
      "[CV] END colsample_bylevel=0.9354582755408554, colsample_bynode=0.6172256516124054, colsample_bytree=0.6017416638155696, gamma=1.753828483520133, learning_rate=0.001936916070194342, max_delta_step=3, max_depth=4, min_child_weight=2, n_estimators=506, reg_alpha=0.6587210463496, reg_lambda=0.6992680181870365, scale_pos_weight=0.9811611420539165, subsample=0.7737143549776055; total time=   1.8s\n",
      "[CV] END colsample_bylevel=0.9354582755408554, colsample_bynode=0.6172256516124054, colsample_bytree=0.6017416638155696, gamma=1.753828483520133, learning_rate=0.001936916070194342, max_delta_step=3, max_depth=4, min_child_weight=2, n_estimators=506, reg_alpha=0.6587210463496, reg_lambda=0.6992680181870365, scale_pos_weight=0.9811611420539165, subsample=0.7737143549776055; total time=   2.1s\n",
      "[CV] END colsample_bylevel=0.6059810064068243, colsample_bynode=0.9063759410470593, colsample_bytree=0.6449423864608045, gamma=1.9991682431731723, learning_rate=0.01624023245298166, max_delta_step=3, max_depth=8, min_child_weight=4, n_estimators=2891, reg_alpha=1.6097393391468522, reg_lambda=1.5886407069973565, scale_pos_weight=0.8683405677207194, subsample=0.818676768055183; total time=   6.5s\n",
      "[CV] END colsample_bylevel=0.6251090767299692, colsample_bynode=0.6296552900287427, colsample_bytree=0.9844432871070234, gamma=0.4456719701029056, learning_rate=0.005107781829880318, max_delta_step=0, max_depth=6, min_child_weight=8, n_estimators=2843, reg_alpha=0.18212059282507315, reg_lambda=0.036452719648428125, scale_pos_weight=0.8111556594359833, subsample=0.8615843085569714; total time=  10.6s\n",
      "[CV] END colsample_bylevel=0.604965750946337, colsample_bynode=0.8645737465518346, colsample_bytree=0.8897714269836252, gamma=0.2850566164722513, learning_rate=0.0021781210030937716, max_delta_step=1, max_depth=11, min_child_weight=4, n_estimators=2255, reg_alpha=2.8727725780999926, reg_lambda=0.4821212107530146, scale_pos_weight=0.8394930224534918, subsample=0.9019929445204036; total time=  21.7s\n",
      "[CV] END colsample_bylevel=0.6259616723886443, colsample_bynode=0.9659928080560519, colsample_bytree=0.7793350917151967, gamma=0.9342906976285583, learning_rate=0.012093591117659853, max_delta_step=8, max_depth=13, min_child_weight=13, n_estimators=950, reg_alpha=2.956179589229266, reg_lambda=0.3347887554162441, scale_pos_weight=1.169588415176817, subsample=0.8451717084841379; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.6259616723886443, colsample_bynode=0.9659928080560519, colsample_bytree=0.7793350917151967, gamma=0.9342906976285583, learning_rate=0.012093591117659853, max_delta_step=8, max_depth=13, min_child_weight=13, n_estimators=950, reg_alpha=2.956179589229266, reg_lambda=0.3347887554162441, scale_pos_weight=1.169588415176817, subsample=0.8451717084841379; total time=   4.6s\n",
      "[CV] END colsample_bylevel=0.8510315935116726, colsample_bynode=0.6, colsample_bytree=0.8898024374477209, gamma=2.0, learning_rate=0.012004608348917287, max_delta_step=4, max_depth=12, min_child_weight=15, n_estimators=709, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bylevel=0.8510315935116726, colsample_bynode=0.6, colsample_bytree=0.8898024374477209, gamma=2.0, learning_rate=0.012004608348917287, max_delta_step=4, max_depth=12, min_child_weight=15, n_estimators=709, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bylevel=0.727120470234154, colsample_bynode=0.6918533566148611, colsample_bytree=0.994871383607197, gamma=1.985334248952408, learning_rate=0.0010647393198241083, max_delta_step=9, max_depth=5, min_child_weight=3, n_estimators=2379, reg_alpha=2.8453423333012204, reg_lambda=0.9071561959039653, scale_pos_weight=0.8403037232263033, subsample=0.7315640134099147; total time=   8.6s\n",
      "[CV] END colsample_bylevel=0.7688323024747616, colsample_bynode=0.7044213593781523, colsample_bytree=0.9877123333531669, gamma=0.0, learning_rate=0.1, max_delta_step=0, max_depth=4, min_child_weight=2, n_estimators=500, reg_alpha=2.279211551803961, reg_lambda=0.0, scale_pos_weight=0.9299951476222413, subsample=0.802873014255309; total time=   1.9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.5510122035826966, learning_rate=0.001, max_delta_step=0, max_depth=13, min_child_weight=12, n_estimators=2324, reg_alpha=1.324863528038593, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   8.7s\n",
      "[CV] END colsample_bylevel=0.9439267366707895, colsample_bynode=0.6060737761524309, colsample_bytree=0.6182430299570395, gamma=0.008611764773890586, learning_rate=0.0038789044147279376, max_delta_step=9, max_depth=9, min_child_weight=6, n_estimators=2822, reg_alpha=1.0634475128992613, reg_lambda=1.2003201949826288, scale_pos_weight=0.9004198602828055, subsample=0.9527757064782792; total time=  18.3s\n",
      "[CV] END colsample_bylevel=0.6692299268804345, colsample_bynode=0.616215705508514, colsample_bytree=0.9893936785624549, gamma=1.8989475333021573, learning_rate=0.09584229315414919, max_delta_step=4, max_depth=8, min_child_weight=8, n_estimators=674, reg_alpha=1.7208335823694911, reg_lambda=2.271542660833606, scale_pos_weight=0.841545736296181, subsample=0.7895897843993718; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.6692299268804345, colsample_bynode=0.616215705508514, colsample_bytree=0.9893936785624549, gamma=1.8989475333021573, learning_rate=0.09584229315414919, max_delta_step=4, max_depth=8, min_child_weight=8, n_estimators=674, reg_alpha=1.7208335823694911, reg_lambda=2.271542660833606, scale_pos_weight=0.841545736296181, subsample=0.7895897843993718; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.9855456426695608, colsample_bynode=0.6, colsample_bytree=0.6130474079288737, gamma=0.5783450105047576, learning_rate=0.004135155800711966, max_delta_step=3, max_depth=4, min_child_weight=1, n_estimators=1365, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1952798430153944, subsample=0.7; total time=   4.2s\n",
      "[CV] END colsample_bylevel=0.9855456426695608, colsample_bynode=0.6, colsample_bytree=0.6130474079288737, gamma=0.5783450105047576, learning_rate=0.004135155800711966, max_delta_step=3, max_depth=4, min_child_weight=1, n_estimators=1365, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1952798430153944, subsample=0.7; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.7402965819445024, colsample_bynode=0.6811016646262777, colsample_bytree=0.7370586987178024, gamma=1.633263339184548, learning_rate=0.013511145030359594, max_delta_step=5, max_depth=5, min_child_weight=13, n_estimators=599, reg_alpha=2.3858601793213974, reg_lambda=0.09259789495853868, scale_pos_weight=1.1510150241526889, subsample=0.9463577974492761; total time=   2.1s\n",
      "[CV] END colsample_bylevel=0.7402965819445024, colsample_bynode=0.6811016646262777, colsample_bytree=0.7370586987178024, gamma=1.633263339184548, learning_rate=0.013511145030359594, max_delta_step=5, max_depth=5, min_child_weight=13, n_estimators=599, reg_alpha=2.3858601793213974, reg_lambda=0.09259789495853868, scale_pos_weight=1.1510150241526889, subsample=0.9463577974492761; total time=   2.4s\n",
      "[CV] END colsample_bylevel=0.6210956286424371, colsample_bynode=0.7114505308672258, colsample_bytree=0.8653294243768137, gamma=0.03333225695723253, learning_rate=0.0010795749185150277, max_delta_step=3, max_depth=4, min_child_weight=2, n_estimators=2445, reg_alpha=2.982709478983814, reg_lambda=2.683349919217637, scale_pos_weight=1.0921605616623704, subsample=0.8601076260992749; total time=   9.1s\n",
      "[CV] END colsample_bylevel=0.6199669415548759, colsample_bynode=0.9684086514687538, colsample_bytree=0.7740202988940662, gamma=1.289224001972352, learning_rate=0.09021612469829324, max_delta_step=8, max_depth=5, min_child_weight=10, n_estimators=2276, reg_alpha=2.9733840568195182, reg_lambda=0.5359728645884603, scale_pos_weight=0.9972558459167127, subsample=0.8179532310154649; total time=   4.3s\n",
      "[CV] END colsample_bylevel=0.7352815407370292, colsample_bynode=0.6200567332915796, colsample_bytree=0.9101335095783277, gamma=1.1329504541128022, learning_rate=0.0010035390508584506, max_delta_step=1, max_depth=14, min_child_weight=15, n_estimators=606, reg_alpha=1.7455352767311612, reg_lambda=1.8976076797949128, scale_pos_weight=1.067678800726689, subsample=0.9696285874682415; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.7540156032907189, colsample_bynode=0.8268387516223009, colsample_bytree=0.6092865391936877, gamma=1.9997000313859843, learning_rate=0.08766572623579127, max_delta_step=9, max_depth=13, min_child_weight=3, n_estimators=1219, reg_alpha=0.2022600036865369, reg_lambda=1.2626801729424464, scale_pos_weight=0.9610907928432516, subsample=0.9990590346559804; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.7540156032907189, colsample_bynode=0.8268387516223009, colsample_bytree=0.6092865391936877, gamma=1.9997000313859843, learning_rate=0.08766572623579127, max_delta_step=9, max_depth=13, min_child_weight=3, n_estimators=1219, reg_alpha=0.2022600036865369, reg_lambda=1.2626801729424464, scale_pos_weight=0.9610907928432516, subsample=0.9990590346559804; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.9354582755408554, colsample_bynode=0.6172256516124054, colsample_bytree=0.6017416638155696, gamma=1.753828483520133, learning_rate=0.001936916070194342, max_delta_step=3, max_depth=4, min_child_weight=2, n_estimators=506, reg_alpha=0.6587210463496, reg_lambda=0.6992680181870365, scale_pos_weight=0.9811611420539165, subsample=0.7737143549776055; total time=   2.1s\n",
      "[CV] END colsample_bylevel=0.6059810064068243, colsample_bynode=0.9063759410470593, colsample_bytree=0.6449423864608045, gamma=1.9991682431731723, learning_rate=0.01624023245298166, max_delta_step=3, max_depth=8, min_child_weight=4, n_estimators=2891, reg_alpha=1.6097393391468522, reg_lambda=1.5886407069973565, scale_pos_weight=0.8683405677207194, subsample=0.818676768055183; total time=   6.6s\n",
      "[CV] END colsample_bylevel=0.6251090767299692, colsample_bynode=0.6296552900287427, colsample_bytree=0.9844432871070234, gamma=0.4456719701029056, learning_rate=0.005107781829880318, max_delta_step=0, max_depth=6, min_child_weight=8, n_estimators=2843, reg_alpha=0.18212059282507315, reg_lambda=0.036452719648428125, scale_pos_weight=0.8111556594359833, subsample=0.8615843085569714; total time=  10.8s\n",
      "[CV] END colsample_bylevel=0.604965750946337, colsample_bynode=0.8645737465518346, colsample_bytree=0.8897714269836252, gamma=0.2850566164722513, learning_rate=0.0021781210030937716, max_delta_step=1, max_depth=11, min_child_weight=4, n_estimators=2255, reg_alpha=2.8727725780999926, reg_lambda=0.4821212107530146, scale_pos_weight=0.8394930224534918, subsample=0.9019929445204036; total time=  21.6s\n",
      "[CV] END colsample_bylevel=0.6259616723886443, colsample_bynode=0.9659928080560519, colsample_bytree=0.7793350917151967, gamma=0.9342906976285583, learning_rate=0.012093591117659853, max_delta_step=8, max_depth=13, min_child_weight=13, n_estimators=950, reg_alpha=2.956179589229266, reg_lambda=0.3347887554162441, scale_pos_weight=1.169588415176817, subsample=0.8451717084841379; total time=   5.1s\n",
      "[CV] END colsample_bylevel=0.9685142659234647, colsample_bynode=0.6801875071811184, colsample_bytree=0.6241634382049382, gamma=1.3582408371508894, learning_rate=0.08900790950386812, max_delta_step=5, max_depth=7, min_child_weight=8, n_estimators=2148, reg_alpha=0.11428010883869802, reg_lambda=2.578254771000493, scale_pos_weight=1.083826796769543, subsample=0.7949844717630685; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.8510315935116726, colsample_bynode=0.6, colsample_bytree=0.8898024374477209, gamma=2.0, learning_rate=0.012004608348917287, max_delta_step=4, max_depth=12, min_child_weight=15, n_estimators=709, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=0.8510315935116726, colsample_bynode=0.6, colsample_bytree=0.8898024374477209, gamma=2.0, learning_rate=0.012004608348917287, max_delta_step=4, max_depth=12, min_child_weight=15, n_estimators=709, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.727120470234154, colsample_bynode=0.6918533566148611, colsample_bytree=0.994871383607197, gamma=1.985334248952408, learning_rate=0.0010647393198241083, max_delta_step=9, max_depth=5, min_child_weight=3, n_estimators=2379, reg_alpha=2.8453423333012204, reg_lambda=0.9071561959039653, scale_pos_weight=0.8403037232263033, subsample=0.7315640134099147; total time=   8.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.5510122035826966, learning_rate=0.001, max_delta_step=0, max_depth=13, min_child_weight=12, n_estimators=2324, reg_alpha=1.324863528038593, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=  10.5s\n",
      "[CV] END colsample_bylevel=0.9439267366707895, colsample_bynode=0.6060737761524309, colsample_bytree=0.6182430299570395, gamma=0.008611764773890586, learning_rate=0.0038789044147279376, max_delta_step=9, max_depth=9, min_child_weight=6, n_estimators=2822, reg_alpha=1.0634475128992613, reg_lambda=1.2003201949826288, scale_pos_weight=0.9004198602828055, subsample=0.9527757064782792; total time=  18.5s\n",
      "[CV] END colsample_bylevel=0.6692299268804345, colsample_bynode=0.616215705508514, colsample_bytree=0.9893936785624549, gamma=1.8989475333021573, learning_rate=0.09584229315414919, max_delta_step=4, max_depth=8, min_child_weight=8, n_estimators=674, reg_alpha=1.7208335823694911, reg_lambda=2.271542660833606, scale_pos_weight=0.841545736296181, subsample=0.7895897843993718; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.9855456426695608, colsample_bynode=0.6, colsample_bytree=0.6130474079288737, gamma=0.5783450105047576, learning_rate=0.004135155800711966, max_delta_step=3, max_depth=4, min_child_weight=1, n_estimators=1365, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1952798430153944, subsample=0.7; total time=   4.2s\n",
      "[CV] END colsample_bylevel=0.9855456426695608, colsample_bynode=0.6, colsample_bytree=0.6130474079288737, gamma=0.5783450105047576, learning_rate=0.004135155800711966, max_delta_step=3, max_depth=4, min_child_weight=1, n_estimators=1365, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1952798430153944, subsample=0.7; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.7402965819445024, colsample_bynode=0.6811016646262777, colsample_bytree=0.7370586987178024, gamma=1.633263339184548, learning_rate=0.013511145030359594, max_delta_step=5, max_depth=5, min_child_weight=13, n_estimators=599, reg_alpha=2.3858601793213974, reg_lambda=0.09259789495853868, scale_pos_weight=1.1510150241526889, subsample=0.9463577974492761; total time=   2.1s\n",
      "[CV] END colsample_bylevel=0.7402965819445024, colsample_bynode=0.6811016646262777, colsample_bytree=0.7370586987178024, gamma=1.633263339184548, learning_rate=0.013511145030359594, max_delta_step=5, max_depth=5, min_child_weight=13, n_estimators=599, reg_alpha=2.3858601793213974, reg_lambda=0.09259789495853868, scale_pos_weight=1.1510150241526889, subsample=0.9463577974492761; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.6210956286424371, colsample_bynode=0.7114505308672258, colsample_bytree=0.8653294243768137, gamma=0.03333225695723253, learning_rate=0.0010795749185150277, max_delta_step=3, max_depth=4, min_child_weight=2, n_estimators=2445, reg_alpha=2.982709478983814, reg_lambda=2.683349919217637, scale_pos_weight=1.0921605616623704, subsample=0.8601076260992749; total time=   9.0s\n",
      "[CV] END colsample_bylevel=0.6199669415548759, colsample_bynode=0.9684086514687538, colsample_bytree=0.7740202988940662, gamma=1.289224001972352, learning_rate=0.09021612469829324, max_delta_step=8, max_depth=5, min_child_weight=10, n_estimators=2276, reg_alpha=2.9733840568195182, reg_lambda=0.5359728645884603, scale_pos_weight=0.9972558459167127, subsample=0.8179532310154649; total time=   4.4s\n",
      "[CV] END colsample_bylevel=0.7352815407370292, colsample_bynode=0.6200567332915796, colsample_bytree=0.9101335095783277, gamma=1.1329504541128022, learning_rate=0.0010035390508584506, max_delta_step=1, max_depth=14, min_child_weight=15, n_estimators=606, reg_alpha=1.7455352767311612, reg_lambda=1.8976076797949128, scale_pos_weight=1.067678800726689, subsample=0.9696285874682415; total time=   3.8s\n",
      "[CV] END colsample_bylevel=0.7352815407370292, colsample_bynode=0.6200567332915796, colsample_bytree=0.9101335095783277, gamma=1.1329504541128022, learning_rate=0.0010035390508584506, max_delta_step=1, max_depth=14, min_child_weight=15, n_estimators=606, reg_alpha=1.7455352767311612, reg_lambda=1.8976076797949128, scale_pos_weight=1.067678800726689, subsample=0.9696285874682415; total time=   3.4s\n",
      "[CV] END colsample_bylevel=0.9354582755408554, colsample_bynode=0.6172256516124054, colsample_bytree=0.6017416638155696, gamma=1.753828483520133, learning_rate=0.001936916070194342, max_delta_step=3, max_depth=4, min_child_weight=2, n_estimators=506, reg_alpha=0.6587210463496, reg_lambda=0.6992680181870365, scale_pos_weight=0.9811611420539165, subsample=0.7737143549776055; total time=   1.7s\n",
      "[CV] END colsample_bylevel=0.9354582755408554, colsample_bynode=0.6172256516124054, colsample_bytree=0.6017416638155696, gamma=1.753828483520133, learning_rate=0.001936916070194342, max_delta_step=3, max_depth=4, min_child_weight=2, n_estimators=506, reg_alpha=0.6587210463496, reg_lambda=0.6992680181870365, scale_pos_weight=0.9811611420539165, subsample=0.7737143549776055; total time=   2.0s\n",
      "[CV] END colsample_bylevel=0.6059810064068243, colsample_bynode=0.9063759410470593, colsample_bytree=0.6449423864608045, gamma=1.9991682431731723, learning_rate=0.01624023245298166, max_delta_step=3, max_depth=8, min_child_weight=4, n_estimators=2891, reg_alpha=1.6097393391468522, reg_lambda=1.5886407069973565, scale_pos_weight=0.8683405677207194, subsample=0.818676768055183; total time=   6.3s\n",
      "[CV] END colsample_bylevel=0.6059810064068243, colsample_bynode=0.9063759410470593, colsample_bytree=0.6449423864608045, gamma=1.9991682431731723, learning_rate=0.01624023245298166, max_delta_step=3, max_depth=8, min_child_weight=4, n_estimators=2891, reg_alpha=1.6097393391468522, reg_lambda=1.5886407069973565, scale_pos_weight=0.8683405677207194, subsample=0.818676768055183; total time=   6.3s\n",
      "[CV] END colsample_bylevel=0.6251090767299692, colsample_bynode=0.6296552900287427, colsample_bytree=0.9844432871070234, gamma=0.4456719701029056, learning_rate=0.005107781829880318, max_delta_step=0, max_depth=6, min_child_weight=8, n_estimators=2843, reg_alpha=0.18212059282507315, reg_lambda=0.036452719648428125, scale_pos_weight=0.8111556594359833, subsample=0.8615843085569714; total time=  12.1s\n",
      "[CV] END colsample_bylevel=0.604965750946337, colsample_bynode=0.8645737465518346, colsample_bytree=0.8897714269836252, gamma=0.2850566164722513, learning_rate=0.0021781210030937716, max_delta_step=1, max_depth=11, min_child_weight=4, n_estimators=2255, reg_alpha=2.8727725780999926, reg_lambda=0.4821212107530146, scale_pos_weight=0.8394930224534918, subsample=0.9019929445204036; total time=  19.8s\n",
      "[CV] END colsample_bylevel=0.6259616723886443, colsample_bynode=0.9659928080560519, colsample_bytree=0.7793350917151967, gamma=0.9342906976285583, learning_rate=0.012093591117659853, max_delta_step=8, max_depth=13, min_child_weight=13, n_estimators=950, reg_alpha=2.956179589229266, reg_lambda=0.3347887554162441, scale_pos_weight=1.169588415176817, subsample=0.8451717084841379; total time=   5.0s\n",
      "[CV] END colsample_bylevel=0.9685142659234647, colsample_bynode=0.6801875071811184, colsample_bytree=0.6241634382049382, gamma=1.3582408371508894, learning_rate=0.08900790950386812, max_delta_step=5, max_depth=7, min_child_weight=8, n_estimators=2148, reg_alpha=0.11428010883869802, reg_lambda=2.578254771000493, scale_pos_weight=1.083826796769543, subsample=0.7949844717630685; total time=   3.6s\n",
      "[CV] END colsample_bylevel=0.9685142659234647, colsample_bynode=0.6801875071811184, colsample_bytree=0.6241634382049382, gamma=1.3582408371508894, learning_rate=0.08900790950386812, max_delta_step=5, max_depth=7, min_child_weight=8, n_estimators=2148, reg_alpha=0.11428010883869802, reg_lambda=2.578254771000493, scale_pos_weight=1.083826796769543, subsample=0.7949844717630685; total time=   4.0s\n",
      "[CV] END colsample_bylevel=0.8510315935116726, colsample_bynode=0.6, colsample_bytree=0.8898024374477209, gamma=2.0, learning_rate=0.012004608348917287, max_delta_step=4, max_depth=12, min_child_weight=15, n_estimators=709, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bylevel=0.727120470234154, colsample_bynode=0.6918533566148611, colsample_bytree=0.994871383607197, gamma=1.985334248952408, learning_rate=0.0010647393198241083, max_delta_step=9, max_depth=5, min_child_weight=3, n_estimators=2379, reg_alpha=2.8453423333012204, reg_lambda=0.9071561959039653, scale_pos_weight=0.8403037232263033, subsample=0.7315640134099147; total time=   8.6sFitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.9439267366707895, colsample_bynode=0.6060737761524309, colsample_bytree=0.6182430299570395, gamma=0.008611764773890586, learning_rate=0.0038789044147279376, max_delta_step=9, max_depth=9, min_child_weight=6, n_estimators=2822, reg_alpha=1.0634475128992613, reg_lambda=1.2003201949826288, scale_pos_weight=0.9004198602828055, subsample=0.9527757064782792; total time=  18.4s\n",
      "[CV] END colsample_bylevel=0.6692299268804345, colsample_bynode=0.616215705508514, colsample_bytree=0.9893936785624549, gamma=1.8989475333021573, learning_rate=0.09584229315414919, max_delta_step=4, max_depth=8, min_child_weight=8, n_estimators=674, reg_alpha=1.7208335823694911, reg_lambda=2.271542660833606, scale_pos_weight=0.841545736296181, subsample=0.7895897843993718; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.6692299268804345, colsample_bynode=0.616215705508514, colsample_bytree=0.9893936785624549, gamma=1.8989475333021573, learning_rate=0.09584229315414919, max_delta_step=4, max_depth=8, min_child_weight=8, n_estimators=674, reg_alpha=1.7208335823694911, reg_lambda=2.271542660833606, scale_pos_weight=0.841545736296181, subsample=0.7895897843993718; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.9855456426695608, colsample_bynode=0.6, colsample_bytree=0.6130474079288737, gamma=0.5783450105047576, learning_rate=0.004135155800711966, max_delta_step=3, max_depth=4, min_child_weight=1, n_estimators=1365, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1952798430153944, subsample=0.7; total time=   4.2s\n",
      "[CV] END colsample_bylevel=0.9855456426695608, colsample_bynode=0.6, colsample_bytree=0.6130474079288737, gamma=0.5783450105047576, learning_rate=0.004135155800711966, max_delta_step=3, max_depth=4, min_child_weight=1, n_estimators=1365, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1952798430153944, subsample=0.7; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.7402965819445024, colsample_bynode=0.6811016646262777, colsample_bytree=0.7370586987178024, gamma=1.633263339184548, learning_rate=0.013511145030359594, max_delta_step=5, max_depth=5, min_child_weight=13, n_estimators=599, reg_alpha=2.3858601793213974, reg_lambda=0.09259789495853868, scale_pos_weight=1.1510150241526889, subsample=0.9463577974492761; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.6210956286424371, colsample_bynode=0.7114505308672258, colsample_bytree=0.8653294243768137, gamma=0.03333225695723253, learning_rate=0.0010795749185150277, max_delta_step=3, max_depth=4, min_child_weight=2, n_estimators=2445, reg_alpha=2.982709478983814, reg_lambda=2.683349919217637, scale_pos_weight=1.0921605616623704, subsample=0.8601076260992749; total time=   7.9s\n",
      "[CV] END colsample_bylevel=0.6210956286424371, colsample_bynode=0.7114505308672258, colsample_bytree=0.8653294243768137, gamma=0.03333225695723253, learning_rate=0.0010795749185150277, max_delta_step=3, max_depth=4, min_child_weight=2, n_estimators=2445, reg_alpha=2.982709478983814, reg_lambda=2.683349919217637, scale_pos_weight=1.0921605616623704, subsample=0.8601076260992749; total time=   9.1s\n",
      "[CV] END colsample_bylevel=0.7352815407370292, colsample_bynode=0.6200567332915796, colsample_bytree=0.9101335095783277, gamma=1.1329504541128022, learning_rate=0.0010035390508584506, max_delta_step=1, max_depth=14, min_child_weight=15, n_estimators=606, reg_alpha=1.7455352767311612, reg_lambda=1.8976076797949128, scale_pos_weight=1.067678800726689, subsample=0.9696285874682415; total time=   3.9s\n",
      "[CV] END colsample_bylevel=0.7540156032907189, colsample_bynode=0.8268387516223009, colsample_bytree=0.6092865391936877, gamma=1.9997000313859843, learning_rate=0.08766572623579127, max_delta_step=9, max_depth=13, min_child_weight=3, n_estimators=1219, reg_alpha=0.2022600036865369, reg_lambda=1.2626801729424464, scale_pos_weight=0.9610907928432516, subsample=0.9990590346559804; total time=   2.5s\n",
      "[CV] END colsample_bylevel=0.7540156032907189, colsample_bynode=0.8268387516223009, colsample_bytree=0.6092865391936877, gamma=1.9997000313859843, learning_rate=0.08766572623579127, max_delta_step=9, max_depth=13, min_child_weight=3, n_estimators=1219, reg_alpha=0.2022600036865369, reg_lambda=1.2626801729424464, scale_pos_weight=0.9610907928432516, subsample=0.9990590346559804; total time=   2.5s\n",
      "[CV] END colsample_bylevel=0.6059810064068243, colsample_bynode=0.9063759410470593, colsample_bytree=0.6449423864608045, gamma=1.9991682431731723, learning_rate=0.01624023245298166, max_delta_step=3, max_depth=8, min_child_weight=4, n_estimators=2891, reg_alpha=1.6097393391468522, reg_lambda=1.5886407069973565, scale_pos_weight=0.8683405677207194, subsample=0.818676768055183; total time=   6.5s\n",
      "[CV] END colsample_bylevel=0.6059810064068243, colsample_bynode=0.9063759410470593, colsample_bytree=0.6449423864608045, gamma=1.9991682431731723, learning_rate=0.01624023245298166, max_delta_step=3, max_depth=8, min_child_weight=4, n_estimators=2891, reg_alpha=1.6097393391468522, reg_lambda=1.5886407069973565, scale_pos_weight=0.8683405677207194, subsample=0.818676768055183; total time=   5.9s\n",
      "[CV] END colsample_bylevel=0.6251090767299692, colsample_bynode=0.6296552900287427, colsample_bytree=0.9844432871070234, gamma=0.4456719701029056, learning_rate=0.005107781829880318, max_delta_step=0, max_depth=6, min_child_weight=8, n_estimators=2843, reg_alpha=0.18212059282507315, reg_lambda=0.036452719648428125, scale_pos_weight=0.8111556594359833, subsample=0.8615843085569714; total time=  12.2s\n",
      "[CV] END colsample_bylevel=0.604965750946337, colsample_bynode=0.8645737465518346, colsample_bytree=0.8897714269836252, gamma=0.2850566164722513, learning_rate=0.0021781210030937716, max_delta_step=1, max_depth=11, min_child_weight=4, n_estimators=2255, reg_alpha=2.8727725780999926, reg_lambda=0.4821212107530146, scale_pos_weight=0.8394930224534918, subsample=0.9019929445204036; total time=  19.5s\n",
      "[CV] END colsample_bylevel=0.6259616723886443, colsample_bynode=0.9659928080560519, colsample_bytree=0.7793350917151967, gamma=0.9342906976285583, learning_rate=0.012093591117659853, max_delta_step=8, max_depth=13, min_child_weight=13, n_estimators=950, reg_alpha=2.956179589229266, reg_lambda=0.3347887554162441, scale_pos_weight=1.169588415176817, subsample=0.8451717084841379; total time=   5.0s\n",
      "[CV] END colsample_bylevel=0.9685142659234647, colsample_bynode=0.6801875071811184, colsample_bytree=0.6241634382049382, gamma=1.3582408371508894, learning_rate=0.08900790950386812, max_delta_step=5, max_depth=7, min_child_weight=8, n_estimators=2148, reg_alpha=0.11428010883869802, reg_lambda=2.578254771000493, scale_pos_weight=1.083826796769543, subsample=0.7949844717630685; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.9685142659234647, colsample_bynode=0.6801875071811184, colsample_bytree=0.6241634382049382, gamma=1.3582408371508894, learning_rate=0.08900790950386812, max_delta_step=5, max_depth=7, min_child_weight=8, n_estimators=2148, reg_alpha=0.11428010883869802, reg_lambda=2.578254771000493, scale_pos_weight=1.083826796769543, subsample=0.7949844717630685; total time=   4.0s\n",
      "[CV] END colsample_bylevel=0.727120470234154, colsample_bynode=0.6918533566148611, colsample_bytree=0.994871383607197, gamma=1.985334248952408, learning_rate=0.0010647393198241083, max_delta_step=9, max_depth=5, min_child_weight=3, n_estimators=2379, reg_alpha=2.8453423333012204, reg_lambda=0.9071561959039653, scale_pos_weight=0.8403037232263033, subsample=0.7315640134099147; total time=   8.7s\n",
      "[CV] END colsample_bylevel=0.7688323024747616, colsample_bynode=0.7044213593781523, colsample_bytree=0.9877123333531669, gamma=0.0, learning_rate=0.1, max_delta_step=0, max_depth=4, min_child_weight=2, n_estimators=500, reg_alpha=2.279211551803961, reg_lambda=0.0, scale_pos_weight=0.9299951476222413, subsample=0.802873014255309; total time=   2.1s\n",
      "[CV] END colsample_bylevel=0.9875692583845788, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0070596311324909195, max_delta_step=5, max_depth=4, min_child_weight=1, n_estimators=1862, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1808664507413735, subsample=0.8407554031198103; total time=   5.4s\n",
      "[CV] END colsample_bylevel=0.9875692583845788, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0070596311324909195, max_delta_step=5, max_depth=4, min_child_weight=1, n_estimators=1862, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1808664507413735, subsample=0.8407554031198103; total time=   4.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:43:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.6692299268804345, colsample_bynode=0.616215705508514, colsample_bytree=0.9893936785624549, gamma=1.8989475333021573, learning_rate=0.09584229315414919, max_delta_step=4, max_depth=8, min_child_weight=8, n_estimators=674, reg_alpha=1.7208335823694911, reg_lambda=2.271542660833606, scale_pos_weight=0.841545736296181, subsample=0.7895897843993718; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.9855456426695608, colsample_bynode=0.6, colsample_bytree=0.6130474079288737, gamma=0.5783450105047576, learning_rate=0.004135155800711966, max_delta_step=3, max_depth=4, min_child_weight=1, n_estimators=1365, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1952798430153944, subsample=0.7; total time=   4.2s\n",
      "[CV] END colsample_bylevel=0.9855456426695608, colsample_bynode=0.6, colsample_bytree=0.6130474079288737, gamma=0.5783450105047576, learning_rate=0.004135155800711966, max_delta_step=3, max_depth=4, min_child_weight=1, n_estimators=1365, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1952798430153944, subsample=0.7; total time=   3.6s\n",
      "[CV] END colsample_bylevel=0.7402965819445024, colsample_bynode=0.6811016646262777, colsample_bytree=0.7370586987178024, gamma=1.633263339184548, learning_rate=0.013511145030359594, max_delta_step=5, max_depth=5, min_child_weight=13, n_estimators=599, reg_alpha=2.3858601793213974, reg_lambda=0.09259789495853868, scale_pos_weight=1.1510150241526889, subsample=0.9463577974492761; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.6210956286424371, colsample_bynode=0.7114505308672258, colsample_bytree=0.8653294243768137, gamma=0.03333225695723253, learning_rate=0.0010795749185150277, max_delta_step=3, max_depth=4, min_child_weight=2, n_estimators=2445, reg_alpha=2.982709478983814, reg_lambda=2.683349919217637, scale_pos_weight=1.0921605616623704, subsample=0.8601076260992749; total time=   8.1s\n",
      "[CV] END colsample_bylevel=0.6199669415548759, colsample_bynode=0.9684086514687538, colsample_bytree=0.7740202988940662, gamma=1.289224001972352, learning_rate=0.09021612469829324, max_delta_step=8, max_depth=5, min_child_weight=10, n_estimators=2276, reg_alpha=2.9733840568195182, reg_lambda=0.5359728645884603, scale_pos_weight=0.9972558459167127, subsample=0.8179532310154649; total time=   5.5s\n",
      "[CV] END colsample_bylevel=0.6199669415548759, colsample_bynode=0.9684086514687538, colsample_bytree=0.7740202988940662, gamma=1.289224001972352, learning_rate=0.09021612469829324, max_delta_step=8, max_depth=5, min_child_weight=10, n_estimators=2276, reg_alpha=2.9733840568195182, reg_lambda=0.5359728645884603, scale_pos_weight=0.9972558459167127, subsample=0.8179532310154649; total time=   4.6s\n",
      "[CV] END colsample_bylevel=0.7352815407370292, colsample_bynode=0.6200567332915796, colsample_bytree=0.9101335095783277, gamma=1.1329504541128022, learning_rate=0.0010035390508584506, max_delta_step=1, max_depth=14, min_child_weight=15, n_estimators=606, reg_alpha=1.7455352767311612, reg_lambda=1.8976076797949128, scale_pos_weight=1.067678800726689, subsample=0.9696285874682415; total time=   3.9s\n",
      "[CV] END colsample_bylevel=0.7540156032907189, colsample_bynode=0.8268387516223009, colsample_bytree=0.6092865391936877, gamma=1.9997000313859843, learning_rate=0.08766572623579127, max_delta_step=9, max_depth=13, min_child_weight=3, n_estimators=1219, reg_alpha=0.2022600036865369, reg_lambda=1.2626801729424464, scale_pos_weight=0.9610907928432516, subsample=0.9990590346559804; total time=   2.6s\n",
      "[CV] END colsample_bylevel=0.9354582755408554, colsample_bynode=0.6172256516124054, colsample_bytree=0.6017416638155696, gamma=1.753828483520133, learning_rate=0.001936916070194342, max_delta_step=3, max_depth=4, min_child_weight=2, n_estimators=506, reg_alpha=0.6587210463496, reg_lambda=0.6992680181870365, scale_pos_weight=0.9811611420539165, subsample=0.7737143549776055; total time=   1.7s\n",
      "[CV] END colsample_bylevel=0.9354582755408554, colsample_bynode=0.6172256516124054, colsample_bytree=0.6017416638155696, gamma=1.753828483520133, learning_rate=0.001936916070194342, max_delta_step=3, max_depth=4, min_child_weight=2, n_estimators=506, reg_alpha=0.6587210463496, reg_lambda=0.6992680181870365, scale_pos_weight=0.9811611420539165, subsample=0.7737143549776055; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.6059810064068243, colsample_bynode=0.9063759410470593, colsample_bytree=0.6449423864608045, gamma=1.9991682431731723, learning_rate=0.01624023245298166, max_delta_step=3, max_depth=8, min_child_weight=4, n_estimators=2891, reg_alpha=1.6097393391468522, reg_lambda=1.5886407069973565, scale_pos_weight=0.8683405677207194, subsample=0.818676768055183; total time=   6.6s\n",
      "[CV] END colsample_bylevel=0.6251090767299692, colsample_bynode=0.6296552900287427, colsample_bytree=0.9844432871070234, gamma=0.4456719701029056, learning_rate=0.005107781829880318, max_delta_step=0, max_depth=6, min_child_weight=8, n_estimators=2843, reg_alpha=0.18212059282507315, reg_lambda=0.036452719648428125, scale_pos_weight=0.8111556594359833, subsample=0.8615843085569714; total time=  10.5s\n",
      "[CV] END colsample_bylevel=0.6251090767299692, colsample_bynode=0.6296552900287427, colsample_bytree=0.9844432871070234, gamma=0.4456719701029056, learning_rate=0.005107781829880318, max_delta_step=0, max_depth=6, min_child_weight=8, n_estimators=2843, reg_alpha=0.18212059282507315, reg_lambda=0.036452719648428125, scale_pos_weight=0.8111556594359833, subsample=0.8615843085569714; total time=  12.8s\n",
      "[CV] END colsample_bylevel=0.604965750946337, colsample_bynode=0.8645737465518346, colsample_bytree=0.8897714269836252, gamma=0.2850566164722513, learning_rate=0.0021781210030937716, max_delta_step=1, max_depth=11, min_child_weight=4, n_estimators=2255, reg_alpha=2.8727725780999926, reg_lambda=0.4821212107530146, scale_pos_weight=0.8394930224534918, subsample=0.9019929445204036; total time=  17.4s\n",
      "[CV] END colsample_bylevel=0.6259616723886443, colsample_bynode=0.9659928080560519, colsample_bytree=0.7793350917151967, gamma=0.9342906976285583, learning_rate=0.012093591117659853, max_delta_step=8, max_depth=13, min_child_weight=13, n_estimators=950, reg_alpha=2.956179589229266, reg_lambda=0.3347887554162441, scale_pos_weight=1.169588415176817, subsample=0.8451717084841379; total time=   5.0s\n",
      "[CV] END colsample_bylevel=0.9685142659234647, colsample_bynode=0.6801875071811184, colsample_bytree=0.6241634382049382, gamma=1.3582408371508894, learning_rate=0.08900790950386812, max_delta_step=5, max_depth=7, min_child_weight=8, n_estimators=2148, reg_alpha=0.11428010883869802, reg_lambda=2.578254771000493, scale_pos_weight=1.083826796769543, subsample=0.7949844717630685; total time=   3.6s\n",
      "[CV] END colsample_bylevel=0.9685142659234647, colsample_bynode=0.6801875071811184, colsample_bytree=0.6241634382049382, gamma=1.3582408371508894, learning_rate=0.08900790950386812, max_delta_step=5, max_depth=7, min_child_weight=8, n_estimators=2148, reg_alpha=0.11428010883869802, reg_lambda=2.578254771000493, scale_pos_weight=1.083826796769543, subsample=0.7949844717630685; total time=   3.9s\n",
      "[CV] END colsample_bylevel=0.8510315935116726, colsample_bynode=0.6, colsample_bytree=0.8898024374477209, gamma=2.0, learning_rate=0.012004608348917287, max_delta_step=4, max_depth=12, min_child_weight=15, n_estimators=709, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bylevel=0.727120470234154, colsample_bynode=0.6918533566148611, colsample_bytree=0.994871383607197, gamma=1.985334248952408, learning_rate=0.0010647393198241083, max_delta_step=9, max_depth=5, min_child_weight=3, n_estimators=2379, reg_alpha=2.8453423333012204, reg_lambda=0.9071561959039653, scale_pos_weight=0.8403037232263033, subsample=0.7315640134099147; total time=   8.6s\n",
      "[CV] END colsample_bylevel=0.7688323024747616, colsample_bynode=0.7044213593781523, colsample_bytree=0.9877123333531669, gamma=0.0, learning_rate=0.1, max_delta_step=0, max_depth=4, min_child_weight=2, n_estimators=500, reg_alpha=2.279211551803961, reg_lambda=0.0, scale_pos_weight=0.9299951476222413, subsample=0.802873014255309; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.9875692583845788, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0070596311324909195, max_delta_step=5, max_depth=4, min_child_weight=1, n_estimators=1862, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1808664507413735, subsample=0.8407554031198103; total time=   5.2s\n",
      "[CV] END colsample_bylevel=0.8532729746346017, colsample_bynode=0.9997139531310555, colsample_bytree=0.8621607040266261, gamma=0.5112929578501474, learning_rate=0.014236991825974906, max_delta_step=4, max_depth=9, min_child_weight=8, n_estimators=2801, reg_alpha=2.676687575922181, reg_lambda=0.017699530322734643, scale_pos_weight=1.1031951555001047, subsample=0.9970833908909384; total time=   8.6s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.5510122035826966, learning_rate=0.001, max_delta_step=0, max_depth=13, min_child_weight=12, n_estimators=2324, reg_alpha=1.324863528038593, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=  10.6s\n",
      "[CV] END colsample_bylevel=0.9439267366707895, colsample_bynode=0.6060737761524309, colsample_bytree=0.6182430299570395, gamma=0.008611764773890586, learning_rate=0.0038789044147279376, max_delta_step=9, max_depth=9, min_child_weight=6, n_estimators=2822, reg_alpha=1.0634475128992613, reg_lambda=1.2003201949826288, scale_pos_weight=0.9004198602828055, subsample=0.9527757064782792; total time=  18.3s\n",
      "[CV] END colsample_bylevel=0.6692299268804345, colsample_bynode=0.616215705508514, colsample_bytree=0.9893936785624549, gamma=1.8989475333021573, learning_rate=0.09584229315414919, max_delta_step=4, max_depth=8, min_child_weight=8, n_estimators=674, reg_alpha=1.7208335823694911, reg_lambda=2.271542660833606, scale_pos_weight=0.841545736296181, subsample=0.7895897843993718; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.6692299268804345, colsample_bynode=0.616215705508514, colsample_bytree=0.9893936785624549, gamma=1.8989475333021573, learning_rate=0.09584229315414919, max_delta_step=4, max_depth=8, min_child_weight=8, n_estimators=674, reg_alpha=1.7208335823694911, reg_lambda=2.271542660833606, scale_pos_weight=0.841545736296181, subsample=0.7895897843993718; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.9855456426695608, colsample_bynode=0.6, colsample_bytree=0.6130474079288737, gamma=0.5783450105047576, learning_rate=0.004135155800711966, max_delta_step=3, max_depth=4, min_child_weight=1, n_estimators=1365, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1952798430153944, subsample=0.7; total time=   4.3s\n",
      "[CV] END colsample_bylevel=0.7402965819445024, colsample_bynode=0.6811016646262777, colsample_bytree=0.7370586987178024, gamma=1.633263339184548, learning_rate=0.013511145030359594, max_delta_step=5, max_depth=5, min_child_weight=13, n_estimators=599, reg_alpha=2.3858601793213974, reg_lambda=0.09259789495853868, scale_pos_weight=1.1510150241526889, subsample=0.9463577974492761; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.6210956286424371, colsample_bynode=0.7114505308672258, colsample_bytree=0.8653294243768137, gamma=0.03333225695723253, learning_rate=0.0010795749185150277, max_delta_step=3, max_depth=4, min_child_weight=2, n_estimators=2445, reg_alpha=2.982709478983814, reg_lambda=2.683349919217637, scale_pos_weight=1.0921605616623704, subsample=0.8601076260992749; total time=   8.0s\n",
      "[CV] END colsample_bylevel=0.6199669415548759, colsample_bynode=0.9684086514687538, colsample_bytree=0.7740202988940662, gamma=1.289224001972352, learning_rate=0.09021612469829324, max_delta_step=8, max_depth=5, min_child_weight=10, n_estimators=2276, reg_alpha=2.9733840568195182, reg_lambda=0.5359728645884603, scale_pos_weight=0.9972558459167127, subsample=0.8179532310154649; total time=   5.7s\n",
      "[CV] END colsample_bylevel=0.6199669415548759, colsample_bynode=0.9684086514687538, colsample_bytree=0.7740202988940662, gamma=1.289224001972352, learning_rate=0.09021612469829324, max_delta_step=8, max_depth=5, min_child_weight=10, n_estimators=2276, reg_alpha=2.9733840568195182, reg_lambda=0.5359728645884603, scale_pos_weight=0.9972558459167127, subsample=0.8179532310154649; total time=   4.7s\n",
      "[CV] END colsample_bylevel=0.7352815407370292, colsample_bynode=0.6200567332915796, colsample_bytree=0.9101335095783277, gamma=1.1329504541128022, learning_rate=0.0010035390508584506, max_delta_step=1, max_depth=14, min_child_weight=15, n_estimators=606, reg_alpha=1.7455352767311612, reg_lambda=1.8976076797949128, scale_pos_weight=1.067678800726689, subsample=0.9696285874682415; total time=   3.8s\n",
      "[CV] END colsample_bylevel=0.7352815407370292, colsample_bynode=0.6200567332915796, colsample_bytree=0.9101335095783277, gamma=1.1329504541128022, learning_rate=0.0010035390508584506, max_delta_step=1, max_depth=14, min_child_weight=15, n_estimators=606, reg_alpha=1.7455352767311612, reg_lambda=1.8976076797949128, scale_pos_weight=1.067678800726689, subsample=0.9696285874682415; total time=   3.5s\n",
      "[CV] END colsample_bylevel=0.9354582755408554, colsample_bynode=0.6172256516124054, colsample_bytree=0.6017416638155696, gamma=1.753828483520133, learning_rate=0.001936916070194342, max_delta_step=3, max_depth=4, min_child_weight=2, n_estimators=506, reg_alpha=0.6587210463496, reg_lambda=0.6992680181870365, scale_pos_weight=0.9811611420539165, subsample=0.7737143549776055; total time=   1.7s\n",
      "[CV] END colsample_bylevel=0.6059810064068243, colsample_bynode=0.9063759410470593, colsample_bytree=0.6449423864608045, gamma=1.9991682431731723, learning_rate=0.01624023245298166, max_delta_step=3, max_depth=8, min_child_weight=4, n_estimators=2891, reg_alpha=1.6097393391468522, reg_lambda=1.5886407069973565, scale_pos_weight=0.8683405677207194, subsample=0.818676768055183; total time=   6.7s\n",
      "[CV] END colsample_bylevel=0.6251090767299692, colsample_bynode=0.6296552900287427, colsample_bytree=0.9844432871070234, gamma=0.4456719701029056, learning_rate=0.005107781829880318, max_delta_step=0, max_depth=6, min_child_weight=8, n_estimators=2843, reg_alpha=0.18212059282507315, reg_lambda=0.036452719648428125, scale_pos_weight=0.8111556594359833, subsample=0.8615843085569714; total time=  10.7s\n",
      "[CV] END colsample_bylevel=0.604965750946337, colsample_bynode=0.8645737465518346, colsample_bytree=0.8897714269836252, gamma=0.2850566164722513, learning_rate=0.0021781210030937716, max_delta_step=1, max_depth=11, min_child_weight=4, n_estimators=2255, reg_alpha=2.8727725780999926, reg_lambda=0.4821212107530146, scale_pos_weight=0.8394930224534918, subsample=0.9019929445204036; total time=  21.4s\n",
      "[CV] END colsample_bylevel=0.604965750946337, colsample_bynode=0.8645737465518346, colsample_bytree=0.8897714269836252, gamma=0.2850566164722513, learning_rate=0.0021781210030937716, max_delta_step=1, max_depth=11, min_child_weight=4, n_estimators=2255, reg_alpha=2.8727725780999926, reg_lambda=0.4821212107530146, scale_pos_weight=0.8394930224534918, subsample=0.9019929445204036; total time=  12.0s\n",
      "[CV] END colsample_bylevel=0.6259616723886443, colsample_bynode=0.9659928080560519, colsample_bytree=0.7793350917151967, gamma=0.9342906976285583, learning_rate=0.012093591117659853, max_delta_step=8, max_depth=13, min_child_weight=13, n_estimators=950, reg_alpha=2.956179589229266, reg_lambda=0.3347887554162441, scale_pos_weight=1.169588415176817, subsample=0.8451717084841379; total time=   5.2s\n",
      "[CV] END colsample_bylevel=0.9685142659234647, colsample_bynode=0.6801875071811184, colsample_bytree=0.6241634382049382, gamma=1.3582408371508894, learning_rate=0.08900790950386812, max_delta_step=5, max_depth=7, min_child_weight=8, n_estimators=2148, reg_alpha=0.11428010883869802, reg_lambda=2.578254771000493, scale_pos_weight=1.083826796769543, subsample=0.7949844717630685; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.8510315935116726, colsample_bynode=0.6, colsample_bytree=0.8898024374477209, gamma=2.0, learning_rate=0.012004608348917287, max_delta_step=4, max_depth=12, min_child_weight=15, n_estimators=709, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=0.8510315935116726, colsample_bynode=0.6, colsample_bytree=0.8898024374477209, gamma=2.0, learning_rate=0.012004608348917287, max_delta_step=4, max_depth=12, min_child_weight=15, n_estimators=709, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.727120470234154, colsample_bynode=0.6918533566148611, colsample_bytree=0.994871383607197, gamma=1.985334248952408, learning_rate=0.0010647393198241083, max_delta_step=9, max_depth=5, min_child_weight=3, n_estimators=2379, reg_alpha=2.8453423333012204, reg_lambda=0.9071561959039653, scale_pos_weight=0.8403037232263033, subsample=0.7315640134099147; total time=   8.4s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.5510122035826966, learning_rate=0.001, max_delta_step=0, max_depth=13, min_child_weight=12, n_estimators=2324, reg_alpha=1.324863528038593, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   8.7s\n",
      "[CV] END colsample_bylevel=0.9439267366707895, colsample_bynode=0.6060737761524309, colsample_bytree=0.6182430299570395, gamma=0.008611764773890586, learning_rate=0.0038789044147279376, max_delta_step=9, max_depth=9, min_child_weight=6, n_estimators=2822, reg_alpha=1.0634475128992613, reg_lambda=1.2003201949826288, scale_pos_weight=0.9004198602828055, subsample=0.9527757064782792; total time=  18.1s\n",
      "[CV] END colsample_bylevel=0.9439267366707895, colsample_bynode=0.6060737761524309, colsample_bytree=0.6182430299570395, gamma=0.008611764773890586, learning_rate=0.0038789044147279376, max_delta_step=9, max_depth=9, min_child_weight=6, n_estimators=2822, reg_alpha=1.0634475128992613, reg_lambda=1.2003201949826288, scale_pos_weight=0.9004198602828055, subsample=0.9527757064782792; total time=  12.2s\n",
      "[CV] END colsample_bylevel=0.7402965819445024, colsample_bynode=0.6811016646262777, colsample_bytree=0.7370586987178024, gamma=1.633263339184548, learning_rate=0.013511145030359594, max_delta_step=5, max_depth=5, min_child_weight=13, n_estimators=599, reg_alpha=2.3858601793213974, reg_lambda=0.09259789495853868, scale_pos_weight=1.1510150241526889, subsample=0.9463577974492761; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.6210956286424371, colsample_bynode=0.7114505308672258, colsample_bytree=0.8653294243768137, gamma=0.03333225695723253, learning_rate=0.0010795749185150277, max_delta_step=3, max_depth=4, min_child_weight=2, n_estimators=2445, reg_alpha=2.982709478983814, reg_lambda=2.683349919217637, scale_pos_weight=1.0921605616623704, subsample=0.8601076260992749; total time=   7.7s\n",
      "[CV] END colsample_bylevel=0.6210956286424371, colsample_bynode=0.7114505308672258, colsample_bytree=0.8653294243768137, gamma=0.03333225695723253, learning_rate=0.0010795749185150277, max_delta_step=3, max_depth=4, min_child_weight=2, n_estimators=2445, reg_alpha=2.982709478983814, reg_lambda=2.683349919217637, scale_pos_weight=1.0921605616623704, subsample=0.8601076260992749; total time=   9.0s\n",
      "[CV] END colsample_bylevel=0.7352815407370292, colsample_bynode=0.6200567332915796, colsample_bytree=0.9101335095783277, gamma=1.1329504541128022, learning_rate=0.0010035390508584506, max_delta_step=1, max_depth=14, min_child_weight=15, n_estimators=606, reg_alpha=1.7455352767311612, reg_lambda=1.8976076797949128, scale_pos_weight=1.067678800726689, subsample=0.9696285874682415; total time=   3.8s\n",
      "[CV] END colsample_bylevel=0.7540156032907189, colsample_bynode=0.8268387516223009, colsample_bytree=0.6092865391936877, gamma=1.9997000313859843, learning_rate=0.08766572623579127, max_delta_step=9, max_depth=13, min_child_weight=3, n_estimators=1219, reg_alpha=0.2022600036865369, reg_lambda=1.2626801729424464, scale_pos_weight=0.9610907928432516, subsample=0.9990590346559804; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.7540156032907189, colsample_bynode=0.8268387516223009, colsample_bytree=0.6092865391936877, gamma=1.9997000313859843, learning_rate=0.08766572623579127, max_delta_step=9, max_depth=13, min_child_weight=3, n_estimators=1219, reg_alpha=0.2022600036865369, reg_lambda=1.2626801729424464, scale_pos_weight=0.9610907928432516, subsample=0.9990590346559804; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.9354582755408554, colsample_bynode=0.6172256516124054, colsample_bytree=0.6017416638155696, gamma=1.753828483520133, learning_rate=0.001936916070194342, max_delta_step=3, max_depth=4, min_child_weight=2, n_estimators=506, reg_alpha=0.6587210463496, reg_lambda=0.6992680181870365, scale_pos_weight=0.9811611420539165, subsample=0.7737143549776055; total time=   2.1s\n",
      "[CV] END colsample_bylevel=0.6059810064068243, colsample_bynode=0.9063759410470593, colsample_bytree=0.6449423864608045, gamma=1.9991682431731723, learning_rate=0.01624023245298166, max_delta_step=3, max_depth=8, min_child_weight=4, n_estimators=2891, reg_alpha=1.6097393391468522, reg_lambda=1.5886407069973565, scale_pos_weight=0.8683405677207194, subsample=0.818676768055183; total time=   6.5s\n",
      "[CV] END colsample_bylevel=0.6251090767299692, colsample_bynode=0.6296552900287427, colsample_bytree=0.9844432871070234, gamma=0.4456719701029056, learning_rate=0.005107781829880318, max_delta_step=0, max_depth=6, min_child_weight=8, n_estimators=2843, reg_alpha=0.18212059282507315, reg_lambda=0.036452719648428125, scale_pos_weight=0.8111556594359833, subsample=0.8615843085569714; total time=  10.7s\n",
      "[CV] END colsample_bylevel=0.604965750946337, colsample_bynode=0.8645737465518346, colsample_bytree=0.8897714269836252, gamma=0.2850566164722513, learning_rate=0.0021781210030937716, max_delta_step=1, max_depth=11, min_child_weight=4, n_estimators=2255, reg_alpha=2.8727725780999926, reg_lambda=0.4821212107530146, scale_pos_weight=0.8394930224534918, subsample=0.9019929445204036; total time=  21.6s\n",
      "[CV] END colsample_bylevel=0.604965750946337, colsample_bynode=0.8645737465518346, colsample_bytree=0.8897714269836252, gamma=0.2850566164722513, learning_rate=0.0021781210030937716, max_delta_step=1, max_depth=11, min_child_weight=4, n_estimators=2255, reg_alpha=2.8727725780999926, reg_lambda=0.4821212107530146, scale_pos_weight=0.8394930224534918, subsample=0.9019929445204036; total time=  12.0s\n",
      "[CV] END colsample_bylevel=0.6259616723886443, colsample_bynode=0.9659928080560519, colsample_bytree=0.7793350917151967, gamma=0.9342906976285583, learning_rate=0.012093591117659853, max_delta_step=8, max_depth=13, min_child_weight=13, n_estimators=950, reg_alpha=2.956179589229266, reg_lambda=0.3347887554162441, scale_pos_weight=1.169588415176817, subsample=0.8451717084841379; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.6259616723886443, colsample_bynode=0.9659928080560519, colsample_bytree=0.7793350917151967, gamma=0.9342906976285583, learning_rate=0.012093591117659853, max_delta_step=8, max_depth=13, min_child_weight=13, n_estimators=950, reg_alpha=2.956179589229266, reg_lambda=0.3347887554162441, scale_pos_weight=1.169588415176817, subsample=0.8451717084841379; total time=   4.7s\n",
      "[CV] END colsample_bylevel=0.8510315935116726, colsample_bynode=0.6, colsample_bytree=0.8898024374477209, gamma=2.0, learning_rate=0.012004608348917287, max_delta_step=4, max_depth=12, min_child_weight=15, n_estimators=709, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bylevel=0.8510315935116726, colsample_bynode=0.6, colsample_bytree=0.8898024374477209, gamma=2.0, learning_rate=0.012004608348917287, max_delta_step=4, max_depth=12, min_child_weight=15, n_estimators=709, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bylevel=0.727120470234154, colsample_bynode=0.6918533566148611, colsample_bytree=0.994871383607197, gamma=1.985334248952408, learning_rate=0.0010647393198241083, max_delta_step=9, max_depth=5, min_child_weight=3, n_estimators=2379, reg_alpha=2.8453423333012204, reg_lambda=0.9071561959039653, scale_pos_weight=0.8403037232263033, subsample=0.7315640134099147; total time=   8.6s\n",
      "[CV] END colsample_bylevel=0.7688323024747616, colsample_bynode=0.7044213593781523, colsample_bytree=0.9877123333531669, gamma=0.0, learning_rate=0.1, max_delta_step=0, max_depth=4, min_child_weight=2, n_estimators=500, reg_alpha=2.279211551803961, reg_lambda=0.0, scale_pos_weight=0.9299951476222413, subsample=0.802873014255309; total time=   2.0s\n",
      "[CV] END colsample_bylevel=0.7688323024747616, colsample_bynode=0.7044213593781523, colsample_bytree=0.9877123333531669, gamma=0.0, learning_rate=0.1, max_delta_step=0, max_depth=4, min_child_weight=2, n_estimators=500, reg_alpha=2.279211551803961, reg_lambda=0.0, scale_pos_weight=0.9299951476222413, subsample=0.802873014255309; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.9875692583845788, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0070596311324909195, max_delta_step=5, max_depth=4, min_child_weight=1, n_estimators=1862, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1808664507413735, subsample=0.8407554031198103; total time=   5.8s\n",
      "[CV] END colsample_bylevel=0.9439267366707895, colsample_bynode=0.6060737761524309, colsample_bytree=0.6182430299570395, gamma=0.008611764773890586, learning_rate=0.0038789044147279376, max_delta_step=9, max_depth=9, min_child_weight=6, n_estimators=2822, reg_alpha=1.0634475128992613, reg_lambda=1.2003201949826288, scale_pos_weight=0.9004198602828055, subsample=0.9527757064782792; total time=  18.2s\n",
      "[CV] END colsample_bylevel=0.9439267366707895, colsample_bynode=0.6060737761524309, colsample_bytree=0.6182430299570395, gamma=0.008611764773890586, learning_rate=0.0038789044147279376, max_delta_step=9, max_depth=9, min_child_weight=6, n_estimators=2822, reg_alpha=1.0634475128992613, reg_lambda=1.2003201949826288, scale_pos_weight=0.9004198602828055, subsample=0.9527757064782792; total time=  12.3s\n",
      "[CV] END colsample_bylevel=0.7402965819445024, colsample_bynode=0.6811016646262777, colsample_bytree=0.7370586987178024, gamma=1.633263339184548, learning_rate=0.013511145030359594, max_delta_step=5, max_depth=5, min_child_weight=13, n_estimators=599, reg_alpha=2.3858601793213974, reg_lambda=0.09259789495853868, scale_pos_weight=1.1510150241526889, subsample=0.9463577974492761; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.6210956286424371, colsample_bynode=0.7114505308672258, colsample_bytree=0.8653294243768137, gamma=0.03333225695723253, learning_rate=0.0010795749185150277, max_delta_step=3, max_depth=4, min_child_weight=2, n_estimators=2445, reg_alpha=2.982709478983814, reg_lambda=2.683349919217637, scale_pos_weight=1.0921605616623704, subsample=0.8601076260992749; total time=   8.2s\n",
      "[CV] END colsample_bylevel=0.6199669415548759, colsample_bynode=0.9684086514687538, colsample_bytree=0.7740202988940662, gamma=1.289224001972352, learning_rate=0.09021612469829324, max_delta_step=8, max_depth=5, min_child_weight=10, n_estimators=2276, reg_alpha=2.9733840568195182, reg_lambda=0.5359728645884603, scale_pos_weight=0.9972558459167127, subsample=0.8179532310154649; total time=   5.6s\n",
      "[CV] END colsample_bylevel=0.6199669415548759, colsample_bynode=0.9684086514687538, colsample_bytree=0.7740202988940662, gamma=1.289224001972352, learning_rate=0.09021612469829324, max_delta_step=8, max_depth=5, min_child_weight=10, n_estimators=2276, reg_alpha=2.9733840568195182, reg_lambda=0.5359728645884603, scale_pos_weight=0.9972558459167127, subsample=0.8179532310154649; total time=   4.7s\n",
      "[CV] END colsample_bylevel=0.7352815407370292, colsample_bynode=0.6200567332915796, colsample_bytree=0.9101335095783277, gamma=1.1329504541128022, learning_rate=0.0010035390508584506, max_delta_step=1, max_depth=14, min_child_weight=15, n_estimators=606, reg_alpha=1.7455352767311612, reg_lambda=1.8976076797949128, scale_pos_weight=1.067678800726689, subsample=0.9696285874682415; total time=   3.8s\n",
      "[CV] END colsample_bylevel=0.7540156032907189, colsample_bynode=0.8268387516223009, colsample_bytree=0.6092865391936877, gamma=1.9997000313859843, learning_rate=0.08766572623579127, max_delta_step=9, max_depth=13, min_child_weight=3, n_estimators=1219, reg_alpha=0.2022600036865369, reg_lambda=1.2626801729424464, scale_pos_weight=0.9610907928432516, subsample=0.9990590346559804; total time=   2.5s\n",
      "[CV] END colsample_bylevel=0.7540156032907189, colsample_bynode=0.8268387516223009, colsample_bytree=0.6092865391936877, gamma=1.9997000313859843, learning_rate=0.08766572623579127, max_delta_step=9, max_depth=13, min_child_weight=3, n_estimators=1219, reg_alpha=0.2022600036865369, reg_lambda=1.2626801729424464, scale_pos_weight=0.9610907928432516, subsample=0.9990590346559804; total time=   2.4s\n",
      "[CV] END colsample_bylevel=0.9354582755408554, colsample_bynode=0.6172256516124054, colsample_bytree=0.6017416638155696, gamma=1.753828483520133, learning_rate=0.001936916070194342, max_delta_step=3, max_depth=4, min_child_weight=2, n_estimators=506, reg_alpha=0.6587210463496, reg_lambda=0.6992680181870365, scale_pos_weight=0.9811611420539165, subsample=0.7737143549776055; total time=   2.1s\n",
      "[CV] END colsample_bylevel=0.6059810064068243, colsample_bynode=0.9063759410470593, colsample_bytree=0.6449423864608045, gamma=1.9991682431731723, learning_rate=0.01624023245298166, max_delta_step=3, max_depth=8, min_child_weight=4, n_estimators=2891, reg_alpha=1.6097393391468522, reg_lambda=1.5886407069973565, scale_pos_weight=0.8683405677207194, subsample=0.818676768055183; total time=   6.5s\n",
      "[CV] END colsample_bylevel=0.6251090767299692, colsample_bynode=0.6296552900287427, colsample_bytree=0.9844432871070234, gamma=0.4456719701029056, learning_rate=0.005107781829880318, max_delta_step=0, max_depth=6, min_child_weight=8, n_estimators=2843, reg_alpha=0.18212059282507315, reg_lambda=0.036452719648428125, scale_pos_weight=0.8111556594359833, subsample=0.8615843085569714; total time=  10.4s\n",
      "[CV] END colsample_bylevel=0.6251090767299692, colsample_bynode=0.6296552900287427, colsample_bytree=0.9844432871070234, gamma=0.4456719701029056, learning_rate=0.005107781829880318, max_delta_step=0, max_depth=6, min_child_weight=8, n_estimators=2843, reg_alpha=0.18212059282507315, reg_lambda=0.036452719648428125, scale_pos_weight=0.8111556594359833, subsample=0.8615843085569714; total time=  12.6s\n",
      "[CV] END colsample_bylevel=0.604965750946337, colsample_bynode=0.8645737465518346, colsample_bytree=0.8897714269836252, gamma=0.2850566164722513, learning_rate=0.0021781210030937716, max_delta_step=1, max_depth=11, min_child_weight=4, n_estimators=2255, reg_alpha=2.8727725780999926, reg_lambda=0.4821212107530146, scale_pos_weight=0.8394930224534918, subsample=0.9019929445204036; total time=  17.2s\n",
      "[CV] END colsample_bylevel=0.6259616723886443, colsample_bynode=0.9659928080560519, colsample_bytree=0.7793350917151967, gamma=0.9342906976285583, learning_rate=0.012093591117659853, max_delta_step=8, max_depth=13, min_child_weight=13, n_estimators=950, reg_alpha=2.956179589229266, reg_lambda=0.3347887554162441, scale_pos_weight=1.169588415176817, subsample=0.8451717084841379; total time=   5.0s\n",
      "[CV] END colsample_bylevel=0.9685142659234647, colsample_bynode=0.6801875071811184, colsample_bytree=0.6241634382049382, gamma=1.3582408371508894, learning_rate=0.08900790950386812, max_delta_step=5, max_depth=7, min_child_weight=8, n_estimators=2148, reg_alpha=0.11428010883869802, reg_lambda=2.578254771000493, scale_pos_weight=1.083826796769543, subsample=0.7949844717630685; total time=   3.6s\n",
      "[CV] END colsample_bylevel=0.9685142659234647, colsample_bynode=0.6801875071811184, colsample_bytree=0.6241634382049382, gamma=1.3582408371508894, learning_rate=0.08900790950386812, max_delta_step=5, max_depth=7, min_child_weight=8, n_estimators=2148, reg_alpha=0.11428010883869802, reg_lambda=2.578254771000493, scale_pos_weight=1.083826796769543, subsample=0.7949844717630685; total time=   4.0s\n",
      "[CV] END colsample_bylevel=0.727120470234154, colsample_bynode=0.6918533566148611, colsample_bytree=0.994871383607197, gamma=1.985334248952408, learning_rate=0.0010647393198241083, max_delta_step=9, max_depth=5, min_child_weight=3, n_estimators=2379, reg_alpha=2.8453423333012204, reg_lambda=0.9071561959039653, scale_pos_weight=0.8403037232263033, subsample=0.7315640134099147; total time=   8.5s\n",
      "[CV] END colsample_bylevel=0.727120470234154, colsample_bynode=0.6918533566148611, colsample_bytree=0.994871383607197, gamma=1.985334248952408, learning_rate=0.0010647393198241083, max_delta_step=9, max_depth=5, min_child_weight=3, n_estimators=2379, reg_alpha=2.8453423333012204, reg_lambda=0.9071561959039653, scale_pos_weight=0.8403037232263033, subsample=0.7315640134099147; total time=   9.7s\n",
      "[CV] END colsample_bylevel=0.6902898083369154, colsample_bynode=0.729265210094319, colsample_bytree=0.7520589940405396, gamma=0.057693116738353215, learning_rate=0.0019491998224497483, max_delta_step=9, max_depth=4, min_child_weight=8, n_estimators=507, reg_alpha=0.12101589767581447, reg_lambda=0.32356660413121574, scale_pos_weight=1.0312234538742902, subsample=0.8940031771439871; total time=   1.6s\n",
      "[CV] END colsample_bylevel=0.7319515960353224, colsample_bynode=0.6625473183333549, colsample_bytree=0.6362277318874227, gamma=1.9866279796621586, learning_rate=0.09829981379832747, max_delta_step=5, max_depth=6, min_child_weight=7, n_estimators=2764, reg_alpha=2.038371516863884, reg_lambda=0.5508685552930112, scale_pos_weight=0.9938876860145709, subsample=0.7293317260844863; total time=   4.3sFitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:44:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.7688323024747616, colsample_bynode=0.7044213593781523, colsample_bytree=0.9877123333531669, gamma=0.0, learning_rate=0.1, max_delta_step=0, max_depth=4, min_child_weight=2, n_estimators=500, reg_alpha=2.279211551803961, reg_lambda=0.0, scale_pos_weight=0.9299951476222413, subsample=0.802873014255309; total time=   1.8s\n",
      "[CV] END colsample_bylevel=0.7688323024747616, colsample_bynode=0.7044213593781523, colsample_bytree=0.9877123333531669, gamma=0.0, learning_rate=0.1, max_delta_step=0, max_depth=4, min_child_weight=2, n_estimators=500, reg_alpha=2.279211551803961, reg_lambda=0.0, scale_pos_weight=0.9299951476222413, subsample=0.802873014255309; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.9875692583845788, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0070596311324909195, max_delta_step=5, max_depth=4, min_child_weight=1, n_estimators=1862, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1808664507413735, subsample=0.8407554031198103; total time=   5.5s\n",
      "[CV] END colsample_bylevel=0.9875692583845788, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0070596311324909195, max_delta_step=5, max_depth=4, min_child_weight=1, n_estimators=1862, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1808664507413735, subsample=0.8407554031198103; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.6902898083369154, colsample_bynode=0.729265210094319, colsample_bytree=0.7520589940405396, gamma=0.057693116738353215, learning_rate=0.0019491998224497483, max_delta_step=9, max_depth=4, min_child_weight=8, n_estimators=507, reg_alpha=0.12101589767581447, reg_lambda=0.32356660413121574, scale_pos_weight=1.0312234538742902, subsample=0.8940031771439871; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.7319515960353224, colsample_bynode=0.6625473183333549, colsample_bytree=0.6362277318874227, gamma=1.9866279796621586, learning_rate=0.09829981379832747, max_delta_step=5, max_depth=6, min_child_weight=7, n_estimators=2764, reg_alpha=2.038371516863884, reg_lambda=0.5508685552930112, scale_pos_weight=0.9938876860145709, subsample=0.7293317260844863; total time=   4.2s\n",
      "[CV] END colsample_bylevel=0.6186887914374329, colsample_bynode=0.7533148766236588, colsample_bytree=0.6515169309055433, gamma=0.8791551284920724, learning_rate=0.0011042545532556646, max_delta_step=9, max_depth=14, min_child_weight=10, n_estimators=1862, reg_alpha=0.04635411825257786, reg_lambda=2.795201006186862, scale_pos_weight=0.847722709525919, subsample=0.8402636137328704; total time=  12.5s\n",
      "[CV] END colsample_bylevel=0.6186887914374329, colsample_bynode=0.7533148766236588, colsample_bytree=0.6515169309055433, gamma=0.8791551284920724, learning_rate=0.0011042545532556646, max_delta_step=9, max_depth=14, min_child_weight=10, n_estimators=1862, reg_alpha=0.04635411825257786, reg_lambda=2.795201006186862, scale_pos_weight=0.847722709525919, subsample=0.8402636137328704; total time=   7.1s\n",
      "[CV] END colsample_bylevel=0.6017591329617606, colsample_bynode=0.7672631586545967, colsample_bytree=0.7153324488442117, gamma=2.0, learning_rate=0.07468234718805346, max_delta_step=7, max_depth=4, min_child_weight=8, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1982298283970803, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.9675487442905569, colsample_bynode=0.7693814808848571, colsample_bytree=0.7532743293813426, gamma=1.8856526378594152, learning_rate=0.0012093050824436432, max_delta_step=4, max_depth=12, min_child_weight=8, n_estimators=2974, reg_alpha=0.13310605867754902, reg_lambda=2.8105841083595537, scale_pos_weight=0.8533054181899051, subsample=0.924635338150894; total time=  20.1s\n",
      "[CV] END colsample_bylevel=0.9505969574942382, colsample_bynode=0.9587464723597442, colsample_bytree=0.880875957371215, gamma=1.9458965961674273, learning_rate=0.005033199385464154, max_delta_step=2, max_depth=5, min_child_weight=11, n_estimators=2997, reg_alpha=2.5550149072314206, reg_lambda=0.44078685040565513, scale_pos_weight=1.0532802330741007, subsample=0.7526382551315829; total time=   8.5s\n",
      "[CV] END colsample_bylevel=0.9505969574942382, colsample_bynode=0.9587464723597442, colsample_bytree=0.880875957371215, gamma=1.9458965961674273, learning_rate=0.005033199385464154, max_delta_step=2, max_depth=5, min_child_weight=11, n_estimators=2997, reg_alpha=2.5550149072314206, reg_lambda=0.44078685040565513, scale_pos_weight=1.0532802330741007, subsample=0.7526382551315829; total time=   6.6s\n",
      "[CV] END colsample_bylevel=0.6130539491520861, colsample_bynode=0.9645489429145693, colsample_bytree=0.6, gamma=2.0, learning_rate=0.03447950110717634, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=1459, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8811708257770303, subsample=0.7802689654202507; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.7555843933600613, colsample_bynode=0.7342154562757516, colsample_bytree=0.9047825703255421, gamma=0.013681776200661803, learning_rate=0.008755728060749667, max_delta_step=4, max_depth=15, min_child_weight=13, n_estimators=501, reg_alpha=2.2239046320579727, reg_lambda=0.930573361352659, scale_pos_weight=1.1285336100225523, subsample=0.7618162689626533; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.7555843933600613, colsample_bynode=0.7342154562757516, colsample_bytree=0.9047825703255421, gamma=0.013681776200661803, learning_rate=0.008755728060749667, max_delta_step=4, max_depth=15, min_child_weight=13, n_estimators=501, reg_alpha=2.2239046320579727, reg_lambda=0.930573361352659, scale_pos_weight=1.1285336100225523, subsample=0.7618162689626533; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.7102614217088588, colsample_bynode=0.9956795189168736, colsample_bytree=0.6537916954991997, gamma=1.964369355334033, learning_rate=0.008137780029892924, max_delta_step=2, max_depth=12, min_child_weight=4, n_estimators=546, reg_alpha=2.9315412297117462, reg_lambda=2.944549430761168, scale_pos_weight=0.98498844302692, subsample=0.9949321459308116; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.7102614217088588, colsample_bynode=0.9956795189168736, colsample_bytree=0.6537916954991997, gamma=1.964369355334033, learning_rate=0.008137780029892924, max_delta_step=2, max_depth=12, min_child_weight=4, n_estimators=546, reg_alpha=2.9315412297117462, reg_lambda=2.944549430761168, scale_pos_weight=0.98498844302692, subsample=0.9949321459308116; total time=   2.7s\n",
      "[CV] END colsample_bylevel=0.6258186176996943, colsample_bynode=0.9885918494307244, colsample_bytree=0.7563962882534245, gamma=0.3738707392539005, learning_rate=0.0014795665023032603, max_delta_step=6, max_depth=6, min_child_weight=5, n_estimators=2993, reg_alpha=2.6023844313955387, reg_lambda=1.0437712697024757, scale_pos_weight=1.0425088112500578, subsample=0.9492511474544013; total time=  12.8s\n",
      "[CV] END colsample_bylevel=0.7740314658519427, colsample_bynode=0.6581940659487177, colsample_bytree=0.6693600355026151, gamma=1.9824750542860747, learning_rate=0.03183166349644174, max_delta_step=7, max_depth=5, min_child_weight=13, n_estimators=567, reg_alpha=0.16866898402802072, reg_lambda=0.3884287930980391, scale_pos_weight=0.9056142305680899, subsample=0.7280512134652743; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.7854431694681967, colsample_bynode=0.9736044600545583, colsample_bytree=0.944187882111511, gamma=0.06062978622707839, learning_rate=0.09309099791530866, max_delta_step=7, max_depth=6, min_child_weight=15, n_estimators=2982, reg_alpha=0.8366401454176351, reg_lambda=0.6470422147781214, scale_pos_weight=1.1474553292519365, subsample=0.7594834090117789; total time=   9.2s\n",
      "[CV] END colsample_bylevel=0.9337266847296054, colsample_bynode=0.9433517756785279, colsample_bytree=0.816473185297633, gamma=0.009388091233385023, learning_rate=0.0010252776418486456, max_delta_step=9, max_depth=11, min_child_weight=12, n_estimators=1353, reg_alpha=1.3579239173247923, reg_lambda=0.3588301087189326, scale_pos_weight=0.8739226153440494, subsample=0.7705695010541683; total time=  10.2s\n",
      "[CV] END colsample_bylevel=0.9337266847296054, colsample_bynode=0.9433517756785279, colsample_bytree=0.816473185297633, gamma=0.009388091233385023, learning_rate=0.0010252776418486456, max_delta_step=9, max_depth=11, min_child_weight=12, n_estimators=1353, reg_alpha=1.3579239173247923, reg_lambda=0.3588301087189326, scale_pos_weight=0.8739226153440494, subsample=0.7705695010541683; total time=   6.0s\n",
      "[CV] END colsample_bylevel=0.7688323024747616, colsample_bynode=0.7044213593781523, colsample_bytree=0.9877123333531669, gamma=0.0, learning_rate=0.1, max_delta_step=0, max_depth=4, min_child_weight=2, n_estimators=500, reg_alpha=2.279211551803961, reg_lambda=0.0, scale_pos_weight=0.9299951476222413, subsample=0.802873014255309; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.9875692583845788, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0070596311324909195, max_delta_step=5, max_depth=4, min_child_weight=1, n_estimators=1862, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1808664507413735, subsample=0.8407554031198103; total time=   5.5s\n",
      "[CV] END colsample_bylevel=0.9875692583845788, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0070596311324909195, max_delta_step=5, max_depth=4, min_child_weight=1, n_estimators=1862, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1808664507413735, subsample=0.8407554031198103; total time=   3.6s\n",
      "[CV] END colsample_bylevel=0.6902898083369154, colsample_bynode=0.729265210094319, colsample_bytree=0.7520589940405396, gamma=0.057693116738353215, learning_rate=0.0019491998224497483, max_delta_step=9, max_depth=4, min_child_weight=8, n_estimators=507, reg_alpha=0.12101589767581447, reg_lambda=0.32356660413121574, scale_pos_weight=1.0312234538742902, subsample=0.8940031771439871; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.6902898083369154, colsample_bynode=0.729265210094319, colsample_bytree=0.7520589940405396, gamma=0.057693116738353215, learning_rate=0.0019491998224497483, max_delta_step=9, max_depth=4, min_child_weight=8, n_estimators=507, reg_alpha=0.12101589767581447, reg_lambda=0.32356660413121574, scale_pos_weight=1.0312234538742902, subsample=0.8940031771439871; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.7319515960353224, colsample_bynode=0.6625473183333549, colsample_bytree=0.6362277318874227, gamma=1.9866279796621586, learning_rate=0.09829981379832747, max_delta_step=5, max_depth=6, min_child_weight=7, n_estimators=2764, reg_alpha=2.038371516863884, reg_lambda=0.5508685552930112, scale_pos_weight=0.9938876860145709, subsample=0.7293317260844863; total time=   4.7s\n",
      "[CV] END colsample_bylevel=0.6186887914374329, colsample_bynode=0.7533148766236588, colsample_bytree=0.6515169309055433, gamma=0.8791551284920724, learning_rate=0.0011042545532556646, max_delta_step=9, max_depth=14, min_child_weight=10, n_estimators=1862, reg_alpha=0.04635411825257786, reg_lambda=2.795201006186862, scale_pos_weight=0.847722709525919, subsample=0.8402636137328704; total time=  12.6s\n",
      "[CV] END colsample_bylevel=0.6017591329617606, colsample_bynode=0.7672631586545967, colsample_bytree=0.7153324488442117, gamma=2.0, learning_rate=0.07468234718805346, max_delta_step=7, max_depth=4, min_child_weight=8, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1982298283970803, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.9675487442905569, colsample_bynode=0.7693814808848571, colsample_bytree=0.7532743293813426, gamma=1.8856526378594152, learning_rate=0.0012093050824436432, max_delta_step=4, max_depth=12, min_child_weight=8, n_estimators=2974, reg_alpha=0.13310605867754902, reg_lambda=2.8105841083595537, scale_pos_weight=0.8533054181899051, subsample=0.924635338150894; total time=  19.6s\n",
      "[CV] END colsample_bylevel=0.9675487442905569, colsample_bynode=0.7693814808848571, colsample_bytree=0.7532743293813426, gamma=1.8856526378594152, learning_rate=0.0012093050824436432, max_delta_step=4, max_depth=12, min_child_weight=8, n_estimators=2974, reg_alpha=0.13310605867754902, reg_lambda=2.8105841083595537, scale_pos_weight=0.8533054181899051, subsample=0.924635338150894; total time=  13.9s\n",
      "[CV] END colsample_bylevel=0.6130539491520861, colsample_bynode=0.9645489429145693, colsample_bytree=0.6, gamma=2.0, learning_rate=0.03447950110717634, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=1459, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8811708257770303, subsample=0.7802689654202507; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.7555843933600613, colsample_bynode=0.7342154562757516, colsample_bytree=0.9047825703255421, gamma=0.013681776200661803, learning_rate=0.008755728060749667, max_delta_step=4, max_depth=15, min_child_weight=13, n_estimators=501, reg_alpha=2.2239046320579727, reg_lambda=0.930573361352659, scale_pos_weight=1.1285336100225523, subsample=0.7618162689626533; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.8811634816903577, colsample_bynode=0.6509540354183844, colsample_bytree=0.8096424268380363, gamma=0.34573822186685704, learning_rate=0.011736893245850376, max_delta_step=8, max_depth=5, min_child_weight=12, n_estimators=576, reg_alpha=2.6717603172436704, reg_lambda=2.786726000127308, scale_pos_weight=1.1105571215385763, subsample=0.8963730577891755; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.8811634816903577, colsample_bynode=0.6509540354183844, colsample_bytree=0.8096424268380363, gamma=0.34573822186685704, learning_rate=0.011736893245850376, max_delta_step=8, max_depth=5, min_child_weight=12, n_estimators=576, reg_alpha=2.6717603172436704, reg_lambda=2.786726000127308, scale_pos_weight=1.1105571215385763, subsample=0.8963730577891755; total time=   1.6s\n",
      "[CV] END colsample_bylevel=0.7102614217088588, colsample_bynode=0.9956795189168736, colsample_bytree=0.6537916954991997, gamma=1.964369355334033, learning_rate=0.008137780029892924, max_delta_step=2, max_depth=12, min_child_weight=4, n_estimators=546, reg_alpha=2.9315412297117462, reg_lambda=2.944549430761168, scale_pos_weight=0.98498844302692, subsample=0.9949321459308116; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.6258186176996943, colsample_bynode=0.9885918494307244, colsample_bytree=0.7563962882534245, gamma=0.3738707392539005, learning_rate=0.0014795665023032603, max_delta_step=6, max_depth=6, min_child_weight=5, n_estimators=2993, reg_alpha=2.6023844313955387, reg_lambda=1.0437712697024757, scale_pos_weight=1.0425088112500578, subsample=0.9492511474544013; total time=  12.9s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.04289287583626258, max_delta_step=10, max_depth=15, min_child_weight=3, n_estimators=500, reg_alpha=2.810983959382777, reg_lambda=2.758260997912067, scale_pos_weight=0.8883883882578147, subsample=0.9287026492378757; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.04289287583626258, max_delta_step=10, max_depth=15, min_child_weight=3, n_estimators=500, reg_alpha=2.810983959382777, reg_lambda=2.758260997912067, scale_pos_weight=0.8883883882578147, subsample=0.9287026492378757; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.04289287583626258, max_delta_step=10, max_depth=15, min_child_weight=3, n_estimators=500, reg_alpha=2.810983959382777, reg_lambda=2.758260997912067, scale_pos_weight=0.8883883882578147, subsample=0.9287026492378757; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.7740314658519427, colsample_bynode=0.6581940659487177, colsample_bytree=0.6693600355026151, gamma=1.9824750542860747, learning_rate=0.03183166349644174, max_delta_step=7, max_depth=5, min_child_weight=13, n_estimators=567, reg_alpha=0.16866898402802072, reg_lambda=0.3884287930980391, scale_pos_weight=0.9056142305680899, subsample=0.7280512134652743; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.7740314658519427, colsample_bynode=0.6581940659487177, colsample_bytree=0.6693600355026151, gamma=1.9824750542860747, learning_rate=0.03183166349644174, max_delta_step=7, max_depth=5, min_child_weight=13, n_estimators=567, reg_alpha=0.16866898402802072, reg_lambda=0.3884287930980391, scale_pos_weight=0.9056142305680899, subsample=0.7280512134652743; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.7854431694681967, colsample_bynode=0.9736044600545583, colsample_bytree=0.944187882111511, gamma=0.06062978622707839, learning_rate=0.09309099791530866, max_delta_step=7, max_depth=6, min_child_weight=15, n_estimators=2982, reg_alpha=0.8366401454176351, reg_lambda=0.6470422147781214, scale_pos_weight=1.1474553292519365, subsample=0.7594834090117789; total time=   9.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:45:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.7688323024747616, colsample_bynode=0.7044213593781523, colsample_bytree=0.9877123333531669, gamma=0.0, learning_rate=0.1, max_delta_step=0, max_depth=4, min_child_weight=2, n_estimators=500, reg_alpha=2.279211551803961, reg_lambda=0.0, scale_pos_weight=0.9299951476222413, subsample=0.802873014255309; total time=   2.0s\n",
      "[CV] END colsample_bylevel=0.7688323024747616, colsample_bynode=0.7044213593781523, colsample_bytree=0.9877123333531669, gamma=0.0, learning_rate=0.1, max_delta_step=0, max_depth=4, min_child_weight=2, n_estimators=500, reg_alpha=2.279211551803961, reg_lambda=0.0, scale_pos_weight=0.9299951476222413, subsample=0.802873014255309; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.9875692583845788, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0070596311324909195, max_delta_step=5, max_depth=4, min_child_weight=1, n_estimators=1862, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1808664507413735, subsample=0.8407554031198103; total time=   5.5s\n",
      "[CV] END colsample_bylevel=0.6902898083369154, colsample_bynode=0.729265210094319, colsample_bytree=0.7520589940405396, gamma=0.057693116738353215, learning_rate=0.0019491998224497483, max_delta_step=9, max_depth=4, min_child_weight=8, n_estimators=507, reg_alpha=0.12101589767581447, reg_lambda=0.32356660413121574, scale_pos_weight=1.0312234538742902, subsample=0.8940031771439871; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.6902898083369154, colsample_bynode=0.729265210094319, colsample_bytree=0.7520589940405396, gamma=0.057693116738353215, learning_rate=0.0019491998224497483, max_delta_step=9, max_depth=4, min_child_weight=8, n_estimators=507, reg_alpha=0.12101589767581447, reg_lambda=0.32356660413121574, scale_pos_weight=1.0312234538742902, subsample=0.8940031771439871; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.7319515960353224, colsample_bynode=0.6625473183333549, colsample_bytree=0.6362277318874227, gamma=1.9866279796621586, learning_rate=0.09829981379832747, max_delta_step=5, max_depth=6, min_child_weight=7, n_estimators=2764, reg_alpha=2.038371516863884, reg_lambda=0.5508685552930112, scale_pos_weight=0.9938876860145709, subsample=0.7293317260844863; total time=   5.1s\n",
      "[CV] END colsample_bylevel=0.6186887914374329, colsample_bynode=0.7533148766236588, colsample_bytree=0.6515169309055433, gamma=0.8791551284920724, learning_rate=0.0011042545532556646, max_delta_step=9, max_depth=14, min_child_weight=10, n_estimators=1862, reg_alpha=0.04635411825257786, reg_lambda=2.795201006186862, scale_pos_weight=0.847722709525919, subsample=0.8402636137328704; total time=  12.5s\n",
      "[CV] END colsample_bylevel=0.6017591329617606, colsample_bynode=0.7672631586545967, colsample_bytree=0.7153324488442117, gamma=2.0, learning_rate=0.07468234718805346, max_delta_step=7, max_depth=4, min_child_weight=8, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1982298283970803, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.9675487442905569, colsample_bynode=0.7693814808848571, colsample_bytree=0.7532743293813426, gamma=1.8856526378594152, learning_rate=0.0012093050824436432, max_delta_step=4, max_depth=12, min_child_weight=8, n_estimators=2974, reg_alpha=0.13310605867754902, reg_lambda=2.8105841083595537, scale_pos_weight=0.8533054181899051, subsample=0.924635338150894; total time=  20.2s\n",
      "[CV] END colsample_bylevel=0.9505969574942382, colsample_bynode=0.9587464723597442, colsample_bytree=0.880875957371215, gamma=1.9458965961674273, learning_rate=0.005033199385464154, max_delta_step=2, max_depth=5, min_child_weight=11, n_estimators=2997, reg_alpha=2.5550149072314206, reg_lambda=0.44078685040565513, scale_pos_weight=1.0532802330741007, subsample=0.7526382551315829; total time=   8.5s\n",
      "[CV] END colsample_bylevel=0.9505969574942382, colsample_bynode=0.9587464723597442, colsample_bytree=0.880875957371215, gamma=1.9458965961674273, learning_rate=0.005033199385464154, max_delta_step=2, max_depth=5, min_child_weight=11, n_estimators=2997, reg_alpha=2.5550149072314206, reg_lambda=0.44078685040565513, scale_pos_weight=1.0532802330741007, subsample=0.7526382551315829; total time=   6.5s\n",
      "[CV] END colsample_bylevel=0.6130539491520861, colsample_bynode=0.9645489429145693, colsample_bytree=0.6, gamma=2.0, learning_rate=0.03447950110717634, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=1459, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8811708257770303, subsample=0.7802689654202507; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.7555843933600613, colsample_bynode=0.7342154562757516, colsample_bytree=0.9047825703255421, gamma=0.013681776200661803, learning_rate=0.008755728060749667, max_delta_step=4, max_depth=15, min_child_weight=13, n_estimators=501, reg_alpha=2.2239046320579727, reg_lambda=0.930573361352659, scale_pos_weight=1.1285336100225523, subsample=0.7618162689626533; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.8811634816903577, colsample_bynode=0.6509540354183844, colsample_bytree=0.8096424268380363, gamma=0.34573822186685704, learning_rate=0.011736893245850376, max_delta_step=8, max_depth=5, min_child_weight=12, n_estimators=576, reg_alpha=2.6717603172436704, reg_lambda=2.786726000127308, scale_pos_weight=1.1105571215385763, subsample=0.8963730577891755; total time=   1.8s\n",
      "[CV] END colsample_bylevel=0.8811634816903577, colsample_bynode=0.6509540354183844, colsample_bytree=0.8096424268380363, gamma=0.34573822186685704, learning_rate=0.011736893245850376, max_delta_step=8, max_depth=5, min_child_weight=12, n_estimators=576, reg_alpha=2.6717603172436704, reg_lambda=2.786726000127308, scale_pos_weight=1.1105571215385763, subsample=0.8963730577891755; total time=   1.6s\n",
      "[CV] END colsample_bylevel=0.7102614217088588, colsample_bynode=0.9956795189168736, colsample_bytree=0.6537916954991997, gamma=1.964369355334033, learning_rate=0.008137780029892924, max_delta_step=2, max_depth=12, min_child_weight=4, n_estimators=546, reg_alpha=2.9315412297117462, reg_lambda=2.944549430761168, scale_pos_weight=0.98498844302692, subsample=0.9949321459308116; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.6258186176996943, colsample_bynode=0.9885918494307244, colsample_bytree=0.7563962882534245, gamma=0.3738707392539005, learning_rate=0.0014795665023032603, max_delta_step=6, max_depth=6, min_child_weight=5, n_estimators=2993, reg_alpha=2.6023844313955387, reg_lambda=1.0437712697024757, scale_pos_weight=1.0425088112500578, subsample=0.9492511474544013; total time=  12.7s\n",
      "[CV] END colsample_bylevel=0.6258186176996943, colsample_bynode=0.9885918494307244, colsample_bytree=0.7563962882534245, gamma=0.3738707392539005, learning_rate=0.0014795665023032603, max_delta_step=6, max_depth=6, min_child_weight=5, n_estimators=2993, reg_alpha=2.6023844313955387, reg_lambda=1.0437712697024757, scale_pos_weight=1.0425088112500578, subsample=0.9492511474544013; total time=   6.6s\n",
      "[CV] END colsample_bylevel=0.7740314658519427, colsample_bynode=0.6581940659487177, colsample_bytree=0.6693600355026151, gamma=1.9824750542860747, learning_rate=0.03183166349644174, max_delta_step=7, max_depth=5, min_child_weight=13, n_estimators=567, reg_alpha=0.16866898402802072, reg_lambda=0.3884287930980391, scale_pos_weight=0.9056142305680899, subsample=0.7280512134652743; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.7854431694681967, colsample_bynode=0.9736044600545583, colsample_bytree=0.944187882111511, gamma=0.06062978622707839, learning_rate=0.09309099791530866, max_delta_step=7, max_depth=6, min_child_weight=15, n_estimators=2982, reg_alpha=0.8366401454176351, reg_lambda=0.6470422147781214, scale_pos_weight=1.1474553292519365, subsample=0.7594834090117789; total time=   9.2s\n",
      "[CV] END colsample_bylevel=0.9337266847296054, colsample_bynode=0.9433517756785279, colsample_bytree=0.816473185297633, gamma=0.009388091233385023, learning_rate=0.0010252776418486456, max_delta_step=9, max_depth=11, min_child_weight=12, n_estimators=1353, reg_alpha=1.3579239173247923, reg_lambda=0.3588301087189326, scale_pos_weight=0.8739226153440494, subsample=0.7705695010541683; total time=  10.4s\n",
      "[CV] END colsample_bylevel=0.9337266847296054, colsample_bynode=0.9433517756785279, colsample_bytree=0.816473185297633, gamma=0.009388091233385023, learning_rate=0.0010252776418486456, max_delta_step=9, max_depth=11, min_child_weight=12, n_estimators=1353, reg_alpha=1.3579239173247923, reg_lambda=0.3588301087189326, scale_pos_weight=0.8739226153440494, subsample=0.7705695010541683; total time=   6.1sFitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.9875692583845788, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0070596311324909195, max_delta_step=5, max_depth=4, min_child_weight=1, n_estimators=1862, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1808664507413735, subsample=0.8407554031198103; total time=   4.6s\n",
      "[CV] END colsample_bylevel=0.6902898083369154, colsample_bynode=0.729265210094319, colsample_bytree=0.7520589940405396, gamma=0.057693116738353215, learning_rate=0.0019491998224497483, max_delta_step=9, max_depth=4, min_child_weight=8, n_estimators=507, reg_alpha=0.12101589767581447, reg_lambda=0.32356660413121574, scale_pos_weight=1.0312234538742902, subsample=0.8940031771439871; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.7319515960353224, colsample_bynode=0.6625473183333549, colsample_bytree=0.6362277318874227, gamma=1.9866279796621586, learning_rate=0.09829981379832747, max_delta_step=5, max_depth=6, min_child_weight=7, n_estimators=2764, reg_alpha=2.038371516863884, reg_lambda=0.5508685552930112, scale_pos_weight=0.9938876860145709, subsample=0.7293317260844863; total time=   4.4s\n",
      "[CV] END colsample_bylevel=0.6186887914374329, colsample_bynode=0.7533148766236588, colsample_bytree=0.6515169309055433, gamma=0.8791551284920724, learning_rate=0.0011042545532556646, max_delta_step=9, max_depth=14, min_child_weight=10, n_estimators=1862, reg_alpha=0.04635411825257786, reg_lambda=2.795201006186862, scale_pos_weight=0.847722709525919, subsample=0.8402636137328704; total time=  12.6s\n",
      "[CV] END colsample_bylevel=0.6017591329617606, colsample_bynode=0.7672631586545967, colsample_bytree=0.7153324488442117, gamma=2.0, learning_rate=0.07468234718805346, max_delta_step=7, max_depth=4, min_child_weight=8, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1982298283970803, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bylevel=0.6017591329617606, colsample_bynode=0.7672631586545967, colsample_bytree=0.7153324488442117, gamma=2.0, learning_rate=0.07468234718805346, max_delta_step=7, max_depth=4, min_child_weight=8, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1982298283970803, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.9675487442905569, colsample_bynode=0.7693814808848571, colsample_bytree=0.7532743293813426, gamma=1.8856526378594152, learning_rate=0.0012093050824436432, max_delta_step=4, max_depth=12, min_child_weight=8, n_estimators=2974, reg_alpha=0.13310605867754902, reg_lambda=2.8105841083595537, scale_pos_weight=0.8533054181899051, subsample=0.924635338150894; total time=  19.9s\n",
      "[CV] END colsample_bylevel=0.9505969574942382, colsample_bynode=0.9587464723597442, colsample_bytree=0.880875957371215, gamma=1.9458965961674273, learning_rate=0.005033199385464154, max_delta_step=2, max_depth=5, min_child_weight=11, n_estimators=2997, reg_alpha=2.5550149072314206, reg_lambda=0.44078685040565513, scale_pos_weight=1.0532802330741007, subsample=0.7526382551315829; total time=   8.4s\n",
      "[CV] END colsample_bylevel=0.6130539491520861, colsample_bynode=0.9645489429145693, colsample_bytree=0.6, gamma=2.0, learning_rate=0.03447950110717634, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=1459, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8811708257770303, subsample=0.7802689654202507; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.6130539491520861, colsample_bynode=0.9645489429145693, colsample_bytree=0.6, gamma=2.0, learning_rate=0.03447950110717634, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=1459, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8811708257770303, subsample=0.7802689654202507; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.7555843933600613, colsample_bynode=0.7342154562757516, colsample_bytree=0.9047825703255421, gamma=0.013681776200661803, learning_rate=0.008755728060749667, max_delta_step=4, max_depth=15, min_child_weight=13, n_estimators=501, reg_alpha=2.2239046320579727, reg_lambda=0.930573361352659, scale_pos_weight=1.1285336100225523, subsample=0.7618162689626533; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.8811634816903577, colsample_bynode=0.6509540354183844, colsample_bytree=0.8096424268380363, gamma=0.34573822186685704, learning_rate=0.011736893245850376, max_delta_step=8, max_depth=5, min_child_weight=12, n_estimators=576, reg_alpha=2.6717603172436704, reg_lambda=2.786726000127308, scale_pos_weight=1.1105571215385763, subsample=0.8963730577891755; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.7102614217088588, colsample_bynode=0.9956795189168736, colsample_bytree=0.6537916954991997, gamma=1.964369355334033, learning_rate=0.008137780029892924, max_delta_step=2, max_depth=12, min_child_weight=4, n_estimators=546, reg_alpha=2.9315412297117462, reg_lambda=2.944549430761168, scale_pos_weight=0.98498844302692, subsample=0.9949321459308116; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.7102614217088588, colsample_bynode=0.9956795189168736, colsample_bytree=0.6537916954991997, gamma=1.964369355334033, learning_rate=0.008137780029892924, max_delta_step=2, max_depth=12, min_child_weight=4, n_estimators=546, reg_alpha=2.9315412297117462, reg_lambda=2.944549430761168, scale_pos_weight=0.98498844302692, subsample=0.9949321459308116; total time=   2.7s\n",
      "[CV] END colsample_bylevel=0.6258186176996943, colsample_bynode=0.9885918494307244, colsample_bytree=0.7563962882534245, gamma=0.3738707392539005, learning_rate=0.0014795665023032603, max_delta_step=6, max_depth=6, min_child_weight=5, n_estimators=2993, reg_alpha=2.6023844313955387, reg_lambda=1.0437712697024757, scale_pos_weight=1.0425088112500578, subsample=0.9492511474544013; total time=  12.7s\n",
      "[CV] END colsample_bylevel=0.7740314658519427, colsample_bynode=0.6581940659487177, colsample_bytree=0.6693600355026151, gamma=1.9824750542860747, learning_rate=0.03183166349644174, max_delta_step=7, max_depth=5, min_child_weight=13, n_estimators=567, reg_alpha=0.16866898402802072, reg_lambda=0.3884287930980391, scale_pos_weight=0.9056142305680899, subsample=0.7280512134652743; total time=   0.9s\n",
      "[CV] END colsample_bylevel=0.7740314658519427, colsample_bynode=0.6581940659487177, colsample_bytree=0.6693600355026151, gamma=1.9824750542860747, learning_rate=0.03183166349644174, max_delta_step=7, max_depth=5, min_child_weight=13, n_estimators=567, reg_alpha=0.16866898402802072, reg_lambda=0.3884287930980391, scale_pos_weight=0.9056142305680899, subsample=0.7280512134652743; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.7854431694681967, colsample_bynode=0.9736044600545583, colsample_bytree=0.944187882111511, gamma=0.06062978622707839, learning_rate=0.09309099791530866, max_delta_step=7, max_depth=6, min_child_weight=15, n_estimators=2982, reg_alpha=0.8366401454176351, reg_lambda=0.6470422147781214, scale_pos_weight=1.1474553292519365, subsample=0.7594834090117789; total time=   9.2s\n",
      "[CV] END colsample_bylevel=0.9337266847296054, colsample_bynode=0.9433517756785279, colsample_bytree=0.816473185297633, gamma=0.009388091233385023, learning_rate=0.0010252776418486456, max_delta_step=9, max_depth=11, min_child_weight=12, n_estimators=1353, reg_alpha=1.3579239173247923, reg_lambda=0.3588301087189326, scale_pos_weight=0.8739226153440494, subsample=0.7705695010541683; total time=  10.0s\n",
      "[CV] END colsample_bylevel=0.7884597892949705, colsample_bynode=0.6214273757694567, colsample_bytree=0.7804797273252069, gamma=0.7419509008911594, learning_rate=0.027611597981324038, max_delta_step=8, max_depth=9, min_child_weight=1, n_estimators=2992, reg_alpha=2.9338857324999905, reg_lambda=2.537948678088542, scale_pos_weight=1.0314161190837028, subsample=0.7982981895304777; total time=   8.4s\n",
      "[CV] END colsample_bylevel=0.7884597892949705, colsample_bynode=0.6214273757694567, colsample_bytree=0.7804797273252069, gamma=0.7419509008911594, learning_rate=0.027611597981324038, max_delta_step=8, max_depth=9, min_child_weight=1, n_estimators=2992, reg_alpha=2.9338857324999905, reg_lambda=2.537948678088542, scale_pos_weight=1.0314161190837028, subsample=0.7982981895304777; total time=   8.6s\n",
      "[CV] END colsample_bylevel=0.6846421906217146, colsample_bynode=0.9624681118750951, colsample_bytree=0.7217919670811719, gamma=1.2347986229390675, learning_rate=0.0011955602126583968, max_delta_step=6, max_depth=13, min_child_weight=4, n_estimators=2980, reg_alpha=0.1158804762712852, reg_lambda=1.3266228743756976, scale_pos_weight=1.0104191220430034, subsample=0.872409731165494; total time=  25.9s\n",
      "[CV] END colsample_bylevel=0.6902898083369154, colsample_bynode=0.729265210094319, colsample_bytree=0.7520589940405396, gamma=0.057693116738353215, learning_rate=0.0019491998224497483, max_delta_step=9, max_depth=4, min_child_weight=8, n_estimators=507, reg_alpha=0.12101589767581447, reg_lambda=0.32356660413121574, scale_pos_weight=1.0312234538742902, subsample=0.8940031771439871; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.7319515960353224, colsample_bynode=0.6625473183333549, colsample_bytree=0.6362277318874227, gamma=1.9866279796621586, learning_rate=0.09829981379832747, max_delta_step=5, max_depth=6, min_child_weight=7, n_estimators=2764, reg_alpha=2.038371516863884, reg_lambda=0.5508685552930112, scale_pos_weight=0.9938876860145709, subsample=0.7293317260844863; total time=   4.3s\n",
      "[CV] END colsample_bylevel=0.6186887914374329, colsample_bynode=0.7533148766236588, colsample_bytree=0.6515169309055433, gamma=0.8791551284920724, learning_rate=0.0011042545532556646, max_delta_step=9, max_depth=14, min_child_weight=10, n_estimators=1862, reg_alpha=0.04635411825257786, reg_lambda=2.795201006186862, scale_pos_weight=0.847722709525919, subsample=0.8402636137328704; total time=  13.0s\n",
      "[CV] END colsample_bylevel=0.6017591329617606, colsample_bynode=0.7672631586545967, colsample_bytree=0.7153324488442117, gamma=2.0, learning_rate=0.07468234718805346, max_delta_step=7, max_depth=4, min_child_weight=8, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1982298283970803, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bylevel=0.9675487442905569, colsample_bynode=0.7693814808848571, colsample_bytree=0.7532743293813426, gamma=1.8856526378594152, learning_rate=0.0012093050824436432, max_delta_step=4, max_depth=12, min_child_weight=8, n_estimators=2974, reg_alpha=0.13310605867754902, reg_lambda=2.8105841083595537, scale_pos_weight=0.8533054181899051, subsample=0.924635338150894; total time=  19.6s\n",
      "[CV] END colsample_bylevel=0.9675487442905569, colsample_bynode=0.7693814808848571, colsample_bytree=0.7532743293813426, gamma=1.8856526378594152, learning_rate=0.0012093050824436432, max_delta_step=4, max_depth=12, min_child_weight=8, n_estimators=2974, reg_alpha=0.13310605867754902, reg_lambda=2.8105841083595537, scale_pos_weight=0.8533054181899051, subsample=0.924635338150894; total time=  14.0s\n",
      "[CV] END colsample_bylevel=0.6130539491520861, colsample_bynode=0.9645489429145693, colsample_bytree=0.6, gamma=2.0, learning_rate=0.03447950110717634, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=1459, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8811708257770303, subsample=0.7802689654202507; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.6130539491520861, colsample_bynode=0.9645489429145693, colsample_bytree=0.6, gamma=2.0, learning_rate=0.03447950110717634, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=1459, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8811708257770303, subsample=0.7802689654202507; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.7555843933600613, colsample_bynode=0.7342154562757516, colsample_bytree=0.9047825703255421, gamma=0.013681776200661803, learning_rate=0.008755728060749667, max_delta_step=4, max_depth=15, min_child_weight=13, n_estimators=501, reg_alpha=2.2239046320579727, reg_lambda=0.930573361352659, scale_pos_weight=1.1285336100225523, subsample=0.7618162689626533; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.8811634816903577, colsample_bynode=0.6509540354183844, colsample_bytree=0.8096424268380363, gamma=0.34573822186685704, learning_rate=0.011736893245850376, max_delta_step=8, max_depth=5, min_child_weight=12, n_estimators=576, reg_alpha=2.6717603172436704, reg_lambda=2.786726000127308, scale_pos_weight=1.1105571215385763, subsample=0.8963730577891755; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.7102614217088588, colsample_bynode=0.9956795189168736, colsample_bytree=0.6537916954991997, gamma=1.964369355334033, learning_rate=0.008137780029892924, max_delta_step=2, max_depth=12, min_child_weight=4, n_estimators=546, reg_alpha=2.9315412297117462, reg_lambda=2.944549430761168, scale_pos_weight=0.98498844302692, subsample=0.9949321459308116; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.6258186176996943, colsample_bynode=0.9885918494307244, colsample_bytree=0.7563962882534245, gamma=0.3738707392539005, learning_rate=0.0014795665023032603, max_delta_step=6, max_depth=6, min_child_weight=5, n_estimators=2993, reg_alpha=2.6023844313955387, reg_lambda=1.0437712697024757, scale_pos_weight=1.0425088112500578, subsample=0.9492511474544013; total time=  13.1s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.04289287583626258, max_delta_step=10, max_depth=15, min_child_weight=3, n_estimators=500, reg_alpha=2.810983959382777, reg_lambda=2.758260997912067, scale_pos_weight=0.8883883882578147, subsample=0.9287026492378757; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.04289287583626258, max_delta_step=10, max_depth=15, min_child_weight=3, n_estimators=500, reg_alpha=2.810983959382777, reg_lambda=2.758260997912067, scale_pos_weight=0.8883883882578147, subsample=0.9287026492378757; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.7740314658519427, colsample_bynode=0.6581940659487177, colsample_bytree=0.6693600355026151, gamma=1.9824750542860747, learning_rate=0.03183166349644174, max_delta_step=7, max_depth=5, min_child_weight=13, n_estimators=567, reg_alpha=0.16866898402802072, reg_lambda=0.3884287930980391, scale_pos_weight=0.9056142305680899, subsample=0.7280512134652743; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.7854431694681967, colsample_bynode=0.9736044600545583, colsample_bytree=0.944187882111511, gamma=0.06062978622707839, learning_rate=0.09309099791530866, max_delta_step=7, max_depth=6, min_child_weight=15, n_estimators=2982, reg_alpha=0.8366401454176351, reg_lambda=0.6470422147781214, scale_pos_weight=1.1474553292519365, subsample=0.7594834090117789; total time=   9.3s\n",
      "[CV] END colsample_bylevel=0.9337266847296054, colsample_bynode=0.9433517756785279, colsample_bytree=0.816473185297633, gamma=0.009388091233385023, learning_rate=0.0010252776418486456, max_delta_step=9, max_depth=11, min_child_weight=12, n_estimators=1353, reg_alpha=1.3579239173247923, reg_lambda=0.3588301087189326, scale_pos_weight=0.8739226153440494, subsample=0.7705695010541683; total time=  10.5s\n",
      "[CV] END colsample_bylevel=0.9337266847296054, colsample_bynode=0.9433517756785279, colsample_bytree=0.816473185297633, gamma=0.009388091233385023, learning_rate=0.0010252776418486456, max_delta_step=9, max_depth=11, min_child_weight=12, n_estimators=1353, reg_alpha=1.3579239173247923, reg_lambda=0.3588301087189326, scale_pos_weight=0.8739226153440494, subsample=0.7705695010541683; total time=   6.0s\n",
      "[CV] END colsample_bylevel=0.7884597892949705, colsample_bynode=0.6214273757694567, colsample_bytree=0.7804797273252069, gamma=0.7419509008911594, learning_rate=0.027611597981324038, max_delta_step=8, max_depth=9, min_child_weight=1, n_estimators=2992, reg_alpha=2.9338857324999905, reg_lambda=2.537948678088542, scale_pos_weight=1.0314161190837028, subsample=0.7982981895304777; total time=   8.7s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=1.3780854786729064, learning_rate=0.008564259804121236, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=0.9783088249460782; total time=   5.6s\n",
      "[CV] END colsample_bylevel=0.6846421906217146, colsample_bynode=0.9624681118750951, colsample_bytree=0.7217919670811719, gamma=1.2347986229390675, learning_rate=0.0011955602126583968, max_delta_step=6, max_depth=13, min_child_weight=4, n_estimators=2980, reg_alpha=0.1158804762712852, reg_lambda=1.3266228743756976, scale_pos_weight=1.0104191220430034, subsample=0.872409731165494; total time=  24.7s\n",
      "[CV] END colsample_bylevel=0.6846421906217146, colsample_bynode=0.9624681118750951, colsample_bytree=0.7217919670811719, gamma=1.2347986229390675, learning_rate=0.0011955602126583968, max_delta_step=6, max_depth=13, min_child_weight=4, n_estimators=2980, reg_alpha=0.1158804762712852, reg_lambda=1.3266228743756976, scale_pos_weight=1.0104191220430034, subsample=0.872409731165494; total time=  13.5s\n",
      "[CV] END colsample_bylevel=0.6902898083369154, colsample_bynode=0.729265210094319, colsample_bytree=0.7520589940405396, gamma=0.057693116738353215, learning_rate=0.0019491998224497483, max_delta_step=9, max_depth=4, min_child_weight=8, n_estimators=507, reg_alpha=0.12101589767581447, reg_lambda=0.32356660413121574, scale_pos_weight=1.0312234538742902, subsample=0.8940031771439871; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.7319515960353224, colsample_bynode=0.6625473183333549, colsample_bytree=0.6362277318874227, gamma=1.9866279796621586, learning_rate=0.09829981379832747, max_delta_step=5, max_depth=6, min_child_weight=7, n_estimators=2764, reg_alpha=2.038371516863884, reg_lambda=0.5508685552930112, scale_pos_weight=0.9938876860145709, subsample=0.7293317260844863; total time=   4.2s\n",
      "[CV] END colsample_bylevel=0.7319515960353224, colsample_bynode=0.6625473183333549, colsample_bytree=0.6362277318874227, gamma=1.9866279796621586, learning_rate=0.09829981379832747, max_delta_step=5, max_depth=6, min_child_weight=7, n_estimators=2764, reg_alpha=2.038371516863884, reg_lambda=0.5508685552930112, scale_pos_weight=0.9938876860145709, subsample=0.7293317260844863; total time=   6.8s\n",
      "[CV] END colsample_bylevel=0.6186887914374329, colsample_bynode=0.7533148766236588, colsample_bytree=0.6515169309055433, gamma=0.8791551284920724, learning_rate=0.0011042545532556646, max_delta_step=9, max_depth=14, min_child_weight=10, n_estimators=1862, reg_alpha=0.04635411825257786, reg_lambda=2.795201006186862, scale_pos_weight=0.847722709525919, subsample=0.8402636137328704; total time=   9.9s\n",
      "[CV] END colsample_bylevel=0.6017591329617606, colsample_bynode=0.7672631586545967, colsample_bytree=0.7153324488442117, gamma=2.0, learning_rate=0.07468234718805346, max_delta_step=7, max_depth=4, min_child_weight=8, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1982298283970803, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bylevel=0.9675487442905569, colsample_bynode=0.7693814808848571, colsample_bytree=0.7532743293813426, gamma=1.8856526378594152, learning_rate=0.0012093050824436432, max_delta_step=4, max_depth=12, min_child_weight=8, n_estimators=2974, reg_alpha=0.13310605867754902, reg_lambda=2.8105841083595537, scale_pos_weight=0.8533054181899051, subsample=0.924635338150894; total time=  19.8s\n",
      "[CV] END colsample_bylevel=0.9505969574942382, colsample_bynode=0.9587464723597442, colsample_bytree=0.880875957371215, gamma=1.9458965961674273, learning_rate=0.005033199385464154, max_delta_step=2, max_depth=5, min_child_weight=11, n_estimators=2997, reg_alpha=2.5550149072314206, reg_lambda=0.44078685040565513, scale_pos_weight=1.0532802330741007, subsample=0.7526382551315829; total time=   8.6s\n",
      "[CV] END colsample_bylevel=0.9505969574942382, colsample_bynode=0.9587464723597442, colsample_bytree=0.880875957371215, gamma=1.9458965961674273, learning_rate=0.005033199385464154, max_delta_step=2, max_depth=5, min_child_weight=11, n_estimators=2997, reg_alpha=2.5550149072314206, reg_lambda=0.44078685040565513, scale_pos_weight=1.0532802330741007, subsample=0.7526382551315829; total time=   6.7s\n",
      "[CV] END colsample_bylevel=0.6130539491520861, colsample_bynode=0.9645489429145693, colsample_bytree=0.6, gamma=2.0, learning_rate=0.03447950110717634, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=1459, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8811708257770303, subsample=0.7802689654202507; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.7555843933600613, colsample_bynode=0.7342154562757516, colsample_bytree=0.9047825703255421, gamma=0.013681776200661803, learning_rate=0.008755728060749667, max_delta_step=4, max_depth=15, min_child_weight=13, n_estimators=501, reg_alpha=2.2239046320579727, reg_lambda=0.930573361352659, scale_pos_weight=1.1285336100225523, subsample=0.7618162689626533; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.8811634816903577, colsample_bynode=0.6509540354183844, colsample_bytree=0.8096424268380363, gamma=0.34573822186685704, learning_rate=0.011736893245850376, max_delta_step=8, max_depth=5, min_child_weight=12, n_estimators=576, reg_alpha=2.6717603172436704, reg_lambda=2.786726000127308, scale_pos_weight=1.1105571215385763, subsample=0.8963730577891755; total time=   1.8s\n",
      "[CV] END colsample_bylevel=0.8811634816903577, colsample_bynode=0.6509540354183844, colsample_bytree=0.8096424268380363, gamma=0.34573822186685704, learning_rate=0.011736893245850376, max_delta_step=8, max_depth=5, min_child_weight=12, n_estimators=576, reg_alpha=2.6717603172436704, reg_lambda=2.786726000127308, scale_pos_weight=1.1105571215385763, subsample=0.8963730577891755; total time=   1.6s\n",
      "[CV] END colsample_bylevel=0.7102614217088588, colsample_bynode=0.9956795189168736, colsample_bytree=0.6537916954991997, gamma=1.964369355334033, learning_rate=0.008137780029892924, max_delta_step=2, max_depth=12, min_child_weight=4, n_estimators=546, reg_alpha=2.9315412297117462, reg_lambda=2.944549430761168, scale_pos_weight=0.98498844302692, subsample=0.9949321459308116; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.6258186176996943, colsample_bynode=0.9885918494307244, colsample_bytree=0.7563962882534245, gamma=0.3738707392539005, learning_rate=0.0014795665023032603, max_delta_step=6, max_depth=6, min_child_weight=5, n_estimators=2993, reg_alpha=2.6023844313955387, reg_lambda=1.0437712697024757, scale_pos_weight=1.0425088112500578, subsample=0.9492511474544013; total time=  12.8s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.04289287583626258, max_delta_step=10, max_depth=15, min_child_weight=3, n_estimators=500, reg_alpha=2.810983959382777, reg_lambda=2.758260997912067, scale_pos_weight=0.8883883882578147, subsample=0.9287026492378757; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.04289287583626258, max_delta_step=10, max_depth=15, min_child_weight=3, n_estimators=500, reg_alpha=2.810983959382777, reg_lambda=2.758260997912067, scale_pos_weight=0.8883883882578147, subsample=0.9287026492378757; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.04289287583626258, max_delta_step=10, max_depth=15, min_child_weight=3, n_estimators=500, reg_alpha=2.810983959382777, reg_lambda=2.758260997912067, scale_pos_weight=0.8883883882578147, subsample=0.9287026492378757; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.7740314658519427, colsample_bynode=0.6581940659487177, colsample_bytree=0.6693600355026151, gamma=1.9824750542860747, learning_rate=0.03183166349644174, max_delta_step=7, max_depth=5, min_child_weight=13, n_estimators=567, reg_alpha=0.16866898402802072, reg_lambda=0.3884287930980391, scale_pos_weight=0.9056142305680899, subsample=0.7280512134652743; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.7854431694681967, colsample_bynode=0.9736044600545583, colsample_bytree=0.944187882111511, gamma=0.06062978622707839, learning_rate=0.09309099791530866, max_delta_step=7, max_depth=6, min_child_weight=15, n_estimators=2982, reg_alpha=0.8366401454176351, reg_lambda=0.6470422147781214, scale_pos_weight=1.1474553292519365, subsample=0.7594834090117789; total time=   9.1s\n",
      "[CV] END colsample_bylevel=0.7854431694681967, colsample_bynode=0.9736044600545583, colsample_bytree=0.944187882111511, gamma=0.06062978622707839, learning_rate=0.09309099791530866, max_delta_step=7, max_depth=6, min_child_weight=15, n_estimators=2982, reg_alpha=0.8366401454176351, reg_lambda=0.6470422147781214, scale_pos_weight=1.1474553292519365, subsample=0.7594834090117789; total time=  11.2s\n",
      "[CV] END colsample_bylevel=0.7884597892949705, colsample_bynode=0.6214273757694567, colsample_bytree=0.7804797273252069, gamma=0.7419509008911594, learning_rate=0.027611597981324038, max_delta_step=8, max_depth=9, min_child_weight=1, n_estimators=2992, reg_alpha=2.9338857324999905, reg_lambda=2.537948678088542, scale_pos_weight=1.0314161190837028, subsample=0.7982981895304777; total time=   8.4s\n",
      "[CV] END colsample_bylevel=0.7884597892949705, colsample_bynode=0.6214273757694567, colsample_bytree=0.7804797273252069, gamma=0.7419509008911594, learning_rate=0.027611597981324038, max_delta_step=8, max_depth=9, min_child_weight=1, n_estimators=2992, reg_alpha=2.9338857324999905, reg_lambda=2.537948678088542, scale_pos_weight=1.0314161190837028, subsample=0.7982981895304777; total time=   8.6sFitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.727120470234154, colsample_bynode=0.6918533566148611, colsample_bytree=0.994871383607197, gamma=1.985334248952408, learning_rate=0.0010647393198241083, max_delta_step=9, max_depth=5, min_child_weight=3, n_estimators=2379, reg_alpha=2.8453423333012204, reg_lambda=0.9071561959039653, scale_pos_weight=0.8403037232263033, subsample=0.7315640134099147; total time=   9.8s\n",
      "[CV] END colsample_bylevel=0.6902898083369154, colsample_bynode=0.729265210094319, colsample_bytree=0.7520589940405396, gamma=0.057693116738353215, learning_rate=0.0019491998224497483, max_delta_step=9, max_depth=4, min_child_weight=8, n_estimators=507, reg_alpha=0.12101589767581447, reg_lambda=0.32356660413121574, scale_pos_weight=1.0312234538742902, subsample=0.8940031771439871; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.7319515960353224, colsample_bynode=0.6625473183333549, colsample_bytree=0.6362277318874227, gamma=1.9866279796621586, learning_rate=0.09829981379832747, max_delta_step=5, max_depth=6, min_child_weight=7, n_estimators=2764, reg_alpha=2.038371516863884, reg_lambda=0.5508685552930112, scale_pos_weight=0.9938876860145709, subsample=0.7293317260844863; total time=   4.2s\n",
      "[CV] END colsample_bylevel=0.7319515960353224, colsample_bynode=0.6625473183333549, colsample_bytree=0.6362277318874227, gamma=1.9866279796621586, learning_rate=0.09829981379832747, max_delta_step=5, max_depth=6, min_child_weight=7, n_estimators=2764, reg_alpha=2.038371516863884, reg_lambda=0.5508685552930112, scale_pos_weight=0.9938876860145709, subsample=0.7293317260844863; total time=   6.7s\n",
      "[CV] END colsample_bylevel=0.6186887914374329, colsample_bynode=0.7533148766236588, colsample_bytree=0.6515169309055433, gamma=0.8791551284920724, learning_rate=0.0011042545532556646, max_delta_step=9, max_depth=14, min_child_weight=10, n_estimators=1862, reg_alpha=0.04635411825257786, reg_lambda=2.795201006186862, scale_pos_weight=0.847722709525919, subsample=0.8402636137328704; total time=  10.0s\n",
      "[CV] END colsample_bylevel=0.6017591329617606, colsample_bynode=0.7672631586545967, colsample_bytree=0.7153324488442117, gamma=2.0, learning_rate=0.07468234718805346, max_delta_step=7, max_depth=4, min_child_weight=8, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1982298283970803, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.6017591329617606, colsample_bynode=0.7672631586545967, colsample_bytree=0.7153324488442117, gamma=2.0, learning_rate=0.07468234718805346, max_delta_step=7, max_depth=4, min_child_weight=8, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1982298283970803, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.9675487442905569, colsample_bynode=0.7693814808848571, colsample_bytree=0.7532743293813426, gamma=1.8856526378594152, learning_rate=0.0012093050824436432, max_delta_step=4, max_depth=12, min_child_weight=8, n_estimators=2974, reg_alpha=0.13310605867754902, reg_lambda=2.8105841083595537, scale_pos_weight=0.8533054181899051, subsample=0.924635338150894; total time=  19.7s\n",
      "[CV] END colsample_bylevel=0.9505969574942382, colsample_bynode=0.9587464723597442, colsample_bytree=0.880875957371215, gamma=1.9458965961674273, learning_rate=0.005033199385464154, max_delta_step=2, max_depth=5, min_child_weight=11, n_estimators=2997, reg_alpha=2.5550149072314206, reg_lambda=0.44078685040565513, scale_pos_weight=1.0532802330741007, subsample=0.7526382551315829; total time=   8.3s\n",
      "[CV] END colsample_bylevel=0.6130539491520861, colsample_bynode=0.9645489429145693, colsample_bytree=0.6, gamma=2.0, learning_rate=0.03447950110717634, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=1459, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8811708257770303, subsample=0.7802689654202507; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.7555843933600613, colsample_bynode=0.7342154562757516, colsample_bytree=0.9047825703255421, gamma=0.013681776200661803, learning_rate=0.008755728060749667, max_delta_step=4, max_depth=15, min_child_weight=13, n_estimators=501, reg_alpha=2.2239046320579727, reg_lambda=0.930573361352659, scale_pos_weight=1.1285336100225523, subsample=0.7618162689626533; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.7555843933600613, colsample_bynode=0.7342154562757516, colsample_bytree=0.9047825703255421, gamma=0.013681776200661803, learning_rate=0.008755728060749667, max_delta_step=4, max_depth=15, min_child_weight=13, n_estimators=501, reg_alpha=2.2239046320579727, reg_lambda=0.930573361352659, scale_pos_weight=1.1285336100225523, subsample=0.7618162689626533; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.7102614217088588, colsample_bynode=0.9956795189168736, colsample_bytree=0.6537916954991997, gamma=1.964369355334033, learning_rate=0.008137780029892924, max_delta_step=2, max_depth=12, min_child_weight=4, n_estimators=546, reg_alpha=2.9315412297117462, reg_lambda=2.944549430761168, scale_pos_weight=0.98498844302692, subsample=0.9949321459308116; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.6258186176996943, colsample_bynode=0.9885918494307244, colsample_bytree=0.7563962882534245, gamma=0.3738707392539005, learning_rate=0.0014795665023032603, max_delta_step=6, max_depth=6, min_child_weight=5, n_estimators=2993, reg_alpha=2.6023844313955387, reg_lambda=1.0437712697024757, scale_pos_weight=1.0425088112500578, subsample=0.9492511474544013; total time=  12.7s\n",
      "[CV] END colsample_bylevel=0.6258186176996943, colsample_bynode=0.9885918494307244, colsample_bytree=0.7563962882534245, gamma=0.3738707392539005, learning_rate=0.0014795665023032603, max_delta_step=6, max_depth=6, min_child_weight=5, n_estimators=2993, reg_alpha=2.6023844313955387, reg_lambda=1.0437712697024757, scale_pos_weight=1.0425088112500578, subsample=0.9492511474544013; total time=   6.7s\n",
      "[CV] END colsample_bylevel=0.7740314658519427, colsample_bynode=0.6581940659487177, colsample_bytree=0.6693600355026151, gamma=1.9824750542860747, learning_rate=0.03183166349644174, max_delta_step=7, max_depth=5, min_child_weight=13, n_estimators=567, reg_alpha=0.16866898402802072, reg_lambda=0.3884287930980391, scale_pos_weight=0.9056142305680899, subsample=0.7280512134652743; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.7854431694681967, colsample_bynode=0.9736044600545583, colsample_bytree=0.944187882111511, gamma=0.06062978622707839, learning_rate=0.09309099791530866, max_delta_step=7, max_depth=6, min_child_weight=15, n_estimators=2982, reg_alpha=0.8366401454176351, reg_lambda=0.6470422147781214, scale_pos_weight=1.1474553292519365, subsample=0.7594834090117789; total time=   9.1s\n",
      "[CV] END colsample_bylevel=0.7854431694681967, colsample_bynode=0.9736044600545583, colsample_bytree=0.944187882111511, gamma=0.06062978622707839, learning_rate=0.09309099791530866, max_delta_step=7, max_depth=6, min_child_weight=15, n_estimators=2982, reg_alpha=0.8366401454176351, reg_lambda=0.6470422147781214, scale_pos_weight=1.1474553292519365, subsample=0.7594834090117789; total time=  11.2s\n",
      "[CV] END colsample_bylevel=0.7884597892949705, colsample_bynode=0.6214273757694567, colsample_bytree=0.7804797273252069, gamma=0.7419509008911594, learning_rate=0.027611597981324038, max_delta_step=8, max_depth=9, min_child_weight=1, n_estimators=2992, reg_alpha=2.9338857324999905, reg_lambda=2.537948678088542, scale_pos_weight=1.0314161190837028, subsample=0.7982981895304777; total time=   8.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=1.3780854786729064, learning_rate=0.008564259804121236, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=0.9783088249460782; total time=   5.7s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=1.3780854786729064, learning_rate=0.008564259804121236, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=0.9783088249460782; total time=   5.5s\n",
      "[CV] END colsample_bylevel=0.6846421906217146, colsample_bynode=0.9624681118750951, colsample_bytree=0.7217919670811719, gamma=1.2347986229390675, learning_rate=0.0011955602126583968, max_delta_step=6, max_depth=13, min_child_weight=4, n_estimators=2980, reg_alpha=0.1158804762712852, reg_lambda=1.3266228743756976, scale_pos_weight=1.0104191220430034, subsample=0.872409731165494; total time=  25.4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.6186887914374329, colsample_bynode=0.7533148766236588, colsample_bytree=0.6515169309055433, gamma=0.8791551284920724, learning_rate=0.0011042545532556646, max_delta_step=9, max_depth=14, min_child_weight=10, n_estimators=1862, reg_alpha=0.04635411825257786, reg_lambda=2.795201006186862, scale_pos_weight=0.847722709525919, subsample=0.8402636137328704; total time=  12.5s\n",
      "[CV] END colsample_bylevel=0.6186887914374329, colsample_bynode=0.7533148766236588, colsample_bytree=0.6515169309055433, gamma=0.8791551284920724, learning_rate=0.0011042545532556646, max_delta_step=9, max_depth=14, min_child_weight=10, n_estimators=1862, reg_alpha=0.04635411825257786, reg_lambda=2.795201006186862, scale_pos_weight=0.847722709525919, subsample=0.8402636137328704; total time=   6.9s\n",
      "[CV] END colsample_bylevel=0.6017591329617606, colsample_bynode=0.7672631586545967, colsample_bytree=0.7153324488442117, gamma=2.0, learning_rate=0.07468234718805346, max_delta_step=7, max_depth=4, min_child_weight=8, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1982298283970803, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.9675487442905569, colsample_bynode=0.7693814808848571, colsample_bytree=0.7532743293813426, gamma=1.8856526378594152, learning_rate=0.0012093050824436432, max_delta_step=4, max_depth=12, min_child_weight=8, n_estimators=2974, reg_alpha=0.13310605867754902, reg_lambda=2.8105841083595537, scale_pos_weight=0.8533054181899051, subsample=0.924635338150894; total time=  20.0s\n",
      "[CV] END colsample_bylevel=0.9505969574942382, colsample_bynode=0.9587464723597442, colsample_bytree=0.880875957371215, gamma=1.9458965961674273, learning_rate=0.005033199385464154, max_delta_step=2, max_depth=5, min_child_weight=11, n_estimators=2997, reg_alpha=2.5550149072314206, reg_lambda=0.44078685040565513, scale_pos_weight=1.0532802330741007, subsample=0.7526382551315829; total time=   8.4s\n",
      "[CV] END colsample_bylevel=0.9505969574942382, colsample_bynode=0.9587464723597442, colsample_bytree=0.880875957371215, gamma=1.9458965961674273, learning_rate=0.005033199385464154, max_delta_step=2, max_depth=5, min_child_weight=11, n_estimators=2997, reg_alpha=2.5550149072314206, reg_lambda=0.44078685040565513, scale_pos_weight=1.0532802330741007, subsample=0.7526382551315829; total time=   6.7s\n",
      "[CV] END colsample_bylevel=0.6130539491520861, colsample_bynode=0.9645489429145693, colsample_bytree=0.6, gamma=2.0, learning_rate=0.03447950110717634, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=1459, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8811708257770303, subsample=0.7802689654202507; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.7555843933600613, colsample_bynode=0.7342154562757516, colsample_bytree=0.9047825703255421, gamma=0.013681776200661803, learning_rate=0.008755728060749667, max_delta_step=4, max_depth=15, min_child_weight=13, n_estimators=501, reg_alpha=2.2239046320579727, reg_lambda=0.930573361352659, scale_pos_weight=1.1285336100225523, subsample=0.7618162689626533; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.8811634816903577, colsample_bynode=0.6509540354183844, colsample_bytree=0.8096424268380363, gamma=0.34573822186685704, learning_rate=0.011736893245850376, max_delta_step=8, max_depth=5, min_child_weight=12, n_estimators=576, reg_alpha=2.6717603172436704, reg_lambda=2.786726000127308, scale_pos_weight=1.1105571215385763, subsample=0.8963730577891755; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.8811634816903577, colsample_bynode=0.6509540354183844, colsample_bytree=0.8096424268380363, gamma=0.34573822186685704, learning_rate=0.011736893245850376, max_delta_step=8, max_depth=5, min_child_weight=12, n_estimators=576, reg_alpha=2.6717603172436704, reg_lambda=2.786726000127308, scale_pos_weight=1.1105571215385763, subsample=0.8963730577891755; total time=   1.6s\n",
      "[CV] END colsample_bylevel=0.7102614217088588, colsample_bynode=0.9956795189168736, colsample_bytree=0.6537916954991997, gamma=1.964369355334033, learning_rate=0.008137780029892924, max_delta_step=2, max_depth=12, min_child_weight=4, n_estimators=546, reg_alpha=2.9315412297117462, reg_lambda=2.944549430761168, scale_pos_weight=0.98498844302692, subsample=0.9949321459308116; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.6258186176996943, colsample_bynode=0.9885918494307244, colsample_bytree=0.7563962882534245, gamma=0.3738707392539005, learning_rate=0.0014795665023032603, max_delta_step=6, max_depth=6, min_child_weight=5, n_estimators=2993, reg_alpha=2.6023844313955387, reg_lambda=1.0437712697024757, scale_pos_weight=1.0425088112500578, subsample=0.9492511474544013; total time=  13.0s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.04289287583626258, max_delta_step=10, max_depth=15, min_child_weight=3, n_estimators=500, reg_alpha=2.810983959382777, reg_lambda=2.758260997912067, scale_pos_weight=0.8883883882578147, subsample=0.9287026492378757; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.04289287583626258, max_delta_step=10, max_depth=15, min_child_weight=3, n_estimators=500, reg_alpha=2.810983959382777, reg_lambda=2.758260997912067, scale_pos_weight=0.8883883882578147, subsample=0.9287026492378757; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.7740314658519427, colsample_bynode=0.6581940659487177, colsample_bytree=0.6693600355026151, gamma=1.9824750542860747, learning_rate=0.03183166349644174, max_delta_step=7, max_depth=5, min_child_weight=13, n_estimators=567, reg_alpha=0.16866898402802072, reg_lambda=0.3884287930980391, scale_pos_weight=0.9056142305680899, subsample=0.7280512134652743; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.7854431694681967, colsample_bynode=0.9736044600545583, colsample_bytree=0.944187882111511, gamma=0.06062978622707839, learning_rate=0.09309099791530866, max_delta_step=7, max_depth=6, min_child_weight=15, n_estimators=2982, reg_alpha=0.8366401454176351, reg_lambda=0.6470422147781214, scale_pos_weight=1.1474553292519365, subsample=0.7594834090117789; total time=   9.2s\n",
      "[CV] END colsample_bylevel=0.9337266847296054, colsample_bynode=0.9433517756785279, colsample_bytree=0.816473185297633, gamma=0.009388091233385023, learning_rate=0.0010252776418486456, max_delta_step=9, max_depth=11, min_child_weight=12, n_estimators=1353, reg_alpha=1.3579239173247923, reg_lambda=0.3588301087189326, scale_pos_weight=0.8739226153440494, subsample=0.7705695010541683; total time=  10.1s\n",
      "[CV] END colsample_bylevel=0.9337266847296054, colsample_bynode=0.9433517756785279, colsample_bytree=0.816473185297633, gamma=0.009388091233385023, learning_rate=0.0010252776418486456, max_delta_step=9, max_depth=11, min_child_weight=12, n_estimators=1353, reg_alpha=1.3579239173247923, reg_lambda=0.3588301087189326, scale_pos_weight=0.8739226153440494, subsample=0.7705695010541683; total time=   6.3s\n",
      "[CV] END colsample_bylevel=0.7884597892949705, colsample_bynode=0.6214273757694567, colsample_bytree=0.7804797273252069, gamma=0.7419509008911594, learning_rate=0.027611597981324038, max_delta_step=8, max_depth=9, min_child_weight=1, n_estimators=2992, reg_alpha=2.9338857324999905, reg_lambda=2.537948678088542, scale_pos_weight=1.0314161190837028, subsample=0.7982981895304777; total time=   8.7s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=1.3780854786729064, learning_rate=0.008564259804121236, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=0.9783088249460782; total time=   5.6s\n",
      "[CV] END colsample_bylevel=0.6846421906217146, colsample_bynode=0.9624681118750951, colsample_bytree=0.7217919670811719, gamma=1.2347986229390675, learning_rate=0.0011955602126583968, max_delta_step=6, max_depth=13, min_child_weight=4, n_estimators=2980, reg_alpha=0.1158804762712852, reg_lambda=1.3266228743756976, scale_pos_weight=1.0104191220430034, subsample=0.872409731165494; total time=  24.9s\n",
      "[CV] END colsample_bylevel=0.6846421906217146, colsample_bynode=0.9624681118750951, colsample_bytree=0.7217919670811719, gamma=1.2347986229390675, learning_rate=0.0011955602126583968, max_delta_step=6, max_depth=13, min_child_weight=4, n_estimators=2980, reg_alpha=0.1158804762712852, reg_lambda=1.3266228743756976, scale_pos_weight=1.0104191220430034, subsample=0.872409731165494; total time=  13.4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:47:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:48:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.9337266847296054, colsample_bynode=0.9433517756785279, colsample_bytree=0.816473185297633, gamma=0.009388091233385023, learning_rate=0.0010252776418486456, max_delta_step=9, max_depth=11, min_child_weight=12, n_estimators=1353, reg_alpha=1.3579239173247923, reg_lambda=0.3588301087189326, scale_pos_weight=0.8739226153440494, subsample=0.7705695010541683; total time=   9.9s\n",
      "[CV] END colsample_bylevel=0.7884597892949705, colsample_bynode=0.6214273757694567, colsample_bytree=0.7804797273252069, gamma=0.7419509008911594, learning_rate=0.027611597981324038, max_delta_step=8, max_depth=9, min_child_weight=1, n_estimators=2992, reg_alpha=2.9338857324999905, reg_lambda=2.537948678088542, scale_pos_weight=1.0314161190837028, subsample=0.7982981895304777; total time=   8.4s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=1.3780854786729064, learning_rate=0.008564259804121236, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=0.9783088249460782; total time=   5.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=1.3780854786729064, learning_rate=0.008564259804121236, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=0.9783088249460782; total time=   5.4s\n",
      "[CV] END colsample_bylevel=0.6846421906217146, colsample_bynode=0.9624681118750951, colsample_bytree=0.7217919670811719, gamma=1.2347986229390675, learning_rate=0.0011955602126583968, max_delta_step=6, max_depth=13, min_child_weight=4, n_estimators=2980, reg_alpha=0.1158804762712852, reg_lambda=1.3266228743756976, scale_pos_weight=1.0104191220430034, subsample=0.872409731165494; total time=  25.2s\n",
      "[CV] END colsample_bylevel=0.9929161003416886, colsample_bynode=0.9563083820831286, colsample_bytree=0.97095963574126, gamma=0.8486635975289332, learning_rate=0.0014053216772569321, max_delta_step=1, max_depth=7, min_child_weight=8, n_estimators=2538, reg_alpha=2.8562402781254503, reg_lambda=1.199533112609045, scale_pos_weight=1.0969551354560385, subsample=0.7833638143554537; total time=  14.1s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.7432915889875962, colsample_bytree=0.6, gamma=2.0, learning_rate=0.03586847235253286, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.2, subsample=0.9800612206903186; total time=   0.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.7432915889875962, colsample_bytree=0.6, gamma=2.0, learning_rate=0.03586847235253286, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.2, subsample=0.9800612206903186; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.9991578316721332, colsample_bynode=0.6886601198061583, colsample_bytree=0.6178614903891883, gamma=1.6190271338740558, learning_rate=0.0010427228624761875, max_delta_step=4, max_depth=7, min_child_weight=12, n_estimators=2099, reg_alpha=0.21559731543388355, reg_lambda=0.9281713371511084, scale_pos_weight=1.013569337983841, subsample=0.7312578190162871; total time=   9.1s\n",
      "[CV] END colsample_bylevel=0.9991578316721332, colsample_bynode=0.6886601198061583, colsample_bytree=0.6178614903891883, gamma=1.6190271338740558, learning_rate=0.0010427228624761875, max_delta_step=4, max_depth=7, min_child_weight=12, n_estimators=2099, reg_alpha=0.21559731543388355, reg_lambda=0.9281713371511084, scale_pos_weight=1.013569337983841, subsample=0.7312578190162871; total time=   6.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=2.0, learning_rate=0.013187427963062425, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=2275, reg_alpha=3.0, reg_lambda=2.258100681982806, scale_pos_weight=1.2, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=2.0, learning_rate=0.013187427963062425, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=2275, reg_alpha=3.0, reg_lambda=2.258100681982806, scale_pos_weight=1.2, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bylevel=0.6832028574542088, colsample_bynode=0.7390955454389112, colsample_bytree=0.8316786544535053, gamma=1.9198419701603529, learning_rate=0.006195707130341904, max_delta_step=9, max_depth=4, min_child_weight=3, n_estimators=2457, reg_alpha=0.1051275288904833, reg_lambda=0.22055708814092428, scale_pos_weight=1.0816347854389956, subsample=0.8550757167960481; total time=   5.2s\n",
      "[CV] END colsample_bylevel=0.9815081044348658, colsample_bynode=0.9413921152529386, colsample_bytree=0.7237157629479105, gamma=1.0314241963941422, learning_rate=0.01197378995159849, max_delta_step=0, max_depth=12, min_child_weight=2, n_estimators=516, reg_alpha=0.11102729786737667, reg_lambda=2.853546658918587, scale_pos_weight=1.1499276917846268, subsample=0.89654777691648; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.6620484731382483, colsample_bynode=0.7424052032088251, colsample_bytree=0.6846985149753861, gamma=0.7748640645993101, learning_rate=0.0841332749600658, max_delta_step=2, max_depth=9, min_child_weight=13, n_estimators=584, reg_alpha=2.9551880501801713, reg_lambda=0.16230920085216466, scale_pos_weight=0.8392934261090509, subsample=0.915892679744317; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.6557657381440714, colsample_bynode=0.6296904116131872, colsample_bytree=0.6345251746968908, gamma=1.1147243735515961, learning_rate=0.08111857802579646, max_delta_step=4, max_depth=4, min_child_weight=9, n_estimators=527, reg_alpha=0.22409122779401808, reg_lambda=0.6688044489366509, scale_pos_weight=0.9923166554304077, subsample=0.7581370286561188; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.9166913208302345, colsample_bynode=0.6875663622267032, colsample_bytree=0.7116455082724042, gamma=0.10305079267391906, learning_rate=0.0011236151733937773, max_delta_step=1, max_depth=12, min_child_weight=12, n_estimators=523, reg_alpha=2.8480491900363614, reg_lambda=0.17969135495851923, scale_pos_weight=0.9248569769405225, subsample=0.9209094803579234; total time=   2.4s\n",
      "[CV] END colsample_bylevel=0.9166913208302345, colsample_bynode=0.6875663622267032, colsample_bytree=0.7116455082724042, gamma=0.10305079267391906, learning_rate=0.0011236151733937773, max_delta_step=1, max_depth=12, min_child_weight=12, n_estimators=523, reg_alpha=2.8480491900363614, reg_lambda=0.17969135495851923, scale_pos_weight=0.9248569769405225, subsample=0.9209094803579234; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.891858086682517, colsample_bytree=0.6, gamma=1.425451915766663, learning_rate=0.03656543972257821, max_delta_step=4, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1284056101359625, subsample=0.7136158970305119; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.014492457739839008, max_delta_step=0, max_depth=4, min_child_weight=5, n_estimators=1789, reg_alpha=0.0, reg_lambda=3.0, scale_pos_weight=1.0353197010516506, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.9605179097569689, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0032658837517848256, max_delta_step=6, max_depth=4, min_child_weight=1, n_estimators=1939, reg_alpha=0.0, reg_lambda=1.0940963595871933, scale_pos_weight=1.2, subsample=1.0; total time=   5.2s\n",
      "[CV] END colsample_bylevel=0.8029283259305771, colsample_bynode=0.9936221654794641, colsample_bytree=0.6790811358619492, gamma=0.0637635869291764, learning_rate=0.007675271828094204, max_delta_step=2, max_depth=4, min_child_weight=6, n_estimators=744, reg_alpha=2.7887697815570136, reg_lambda=0.9104251335644562, scale_pos_weight=1.110364074810476, subsample=0.7475003063795894; total time=   2.4s\n",
      "[CV] END colsample_bylevel=0.6229462387272339, colsample_bynode=0.9601058664657138, colsample_bytree=0.6498199391116954, gamma=0.00782673946834689, learning_rate=0.025202260542171437, max_delta_step=3, max_depth=13, min_child_weight=12, n_estimators=605, reg_alpha=0.38465180101943897, reg_lambda=0.638556323670433, scale_pos_weight=1.111888815683276, subsample=0.9563046911335706; total time=   3.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.7884597892949705, colsample_bynode=0.6214273757694567, colsample_bytree=0.7804797273252069, gamma=0.7419509008911594, learning_rate=0.027611597981324038, max_delta_step=8, max_depth=9, min_child_weight=1, n_estimators=2992, reg_alpha=2.9338857324999905, reg_lambda=2.537948678088542, scale_pos_weight=1.0314161190837028, subsample=0.7982981895304777; total time=   8.6s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=1.3780854786729064, learning_rate=0.008564259804121236, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=0.9783088249460782; total time=   5.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=1.3780854786729064, learning_rate=0.008564259804121236, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=0.9783088249460782; total time=   5.4s\n",
      "[CV] END colsample_bylevel=0.6846421906217146, colsample_bynode=0.9624681118750951, colsample_bytree=0.7217919670811719, gamma=1.2347986229390675, learning_rate=0.0011955602126583968, max_delta_step=6, max_depth=13, min_child_weight=4, n_estimators=2980, reg_alpha=0.1158804762712852, reg_lambda=1.3266228743756976, scale_pos_weight=1.0104191220430034, subsample=0.872409731165494; total time=  25.4s\n",
      "[CV] END colsample_bylevel=0.9929161003416886, colsample_bynode=0.9563083820831286, colsample_bytree=0.97095963574126, gamma=0.8486635975289332, learning_rate=0.0014053216772569321, max_delta_step=1, max_depth=7, min_child_weight=8, n_estimators=2538, reg_alpha=2.8562402781254503, reg_lambda=1.199533112609045, scale_pos_weight=1.0969551354560385, subsample=0.7833638143554537; total time=  14.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.7432915889875962, colsample_bytree=0.6, gamma=2.0, learning_rate=0.03586847235253286, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.2, subsample=0.9800612206903186; total time=   0.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.7432915889875962, colsample_bytree=0.6, gamma=2.0, learning_rate=0.03586847235253286, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.2, subsample=0.9800612206903186; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.9991578316721332, colsample_bynode=0.6886601198061583, colsample_bytree=0.6178614903891883, gamma=1.6190271338740558, learning_rate=0.0010427228624761875, max_delta_step=4, max_depth=7, min_child_weight=12, n_estimators=2099, reg_alpha=0.21559731543388355, reg_lambda=0.9281713371511084, scale_pos_weight=1.013569337983841, subsample=0.7312578190162871; total time=   9.2s\n",
      "[CV] END colsample_bylevel=0.9991578316721332, colsample_bynode=0.6886601198061583, colsample_bytree=0.6178614903891883, gamma=1.6190271338740558, learning_rate=0.0010427228624761875, max_delta_step=4, max_depth=7, min_child_weight=12, n_estimators=2099, reg_alpha=0.21559731543388355, reg_lambda=0.9281713371511084, scale_pos_weight=1.013569337983841, subsample=0.7312578190162871; total time=   6.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=2.0, learning_rate=0.013187427963062425, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=2275, reg_alpha=3.0, reg_lambda=2.258100681982806, scale_pos_weight=1.2, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bylevel=0.6832028574542088, colsample_bynode=0.7390955454389112, colsample_bytree=0.8316786544535053, gamma=1.9198419701603529, learning_rate=0.006195707130341904, max_delta_step=9, max_depth=4, min_child_weight=3, n_estimators=2457, reg_alpha=0.1051275288904833, reg_lambda=0.22055708814092428, scale_pos_weight=1.0816347854389956, subsample=0.8550757167960481; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.9815081044348658, colsample_bynode=0.9413921152529386, colsample_bytree=0.7237157629479105, gamma=1.0314241963941422, learning_rate=0.01197378995159849, max_delta_step=0, max_depth=12, min_child_weight=2, n_estimators=516, reg_alpha=0.11102729786737667, reg_lambda=2.853546658918587, scale_pos_weight=1.1499276917846268, subsample=0.89654777691648; total time=   5.0s\n",
      "[CV] END colsample_bylevel=0.9815081044348658, colsample_bynode=0.9413921152529386, colsample_bytree=0.7237157629479105, gamma=1.0314241963941422, learning_rate=0.01197378995159849, max_delta_step=0, max_depth=12, min_child_weight=2, n_estimators=516, reg_alpha=0.11102729786737667, reg_lambda=2.853546658918587, scale_pos_weight=1.1499276917846268, subsample=0.89654777691648; total time=   4.2s\n",
      "[CV] END colsample_bylevel=0.6620484731382483, colsample_bynode=0.7424052032088251, colsample_bytree=0.6846985149753861, gamma=0.7748640645993101, learning_rate=0.0841332749600658, max_delta_step=2, max_depth=9, min_child_weight=13, n_estimators=584, reg_alpha=2.9551880501801713, reg_lambda=0.16230920085216466, scale_pos_weight=0.8392934261090509, subsample=0.915892679744317; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.6557657381440714, colsample_bynode=0.6296904116131872, colsample_bytree=0.6345251746968908, gamma=1.1147243735515961, learning_rate=0.08111857802579646, max_delta_step=4, max_depth=4, min_child_weight=9, n_estimators=527, reg_alpha=0.22409122779401808, reg_lambda=0.6688044489366509, scale_pos_weight=0.9923166554304077, subsample=0.7581370286561188; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.9166913208302345, colsample_bynode=0.6875663622267032, colsample_bytree=0.7116455082724042, gamma=0.10305079267391906, learning_rate=0.0011236151733937773, max_delta_step=1, max_depth=12, min_child_weight=12, n_estimators=523, reg_alpha=2.8480491900363614, reg_lambda=0.17969135495851923, scale_pos_weight=0.9248569769405225, subsample=0.9209094803579234; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.9166913208302345, colsample_bynode=0.6875663622267032, colsample_bytree=0.7116455082724042, gamma=0.10305079267391906, learning_rate=0.0011236151733937773, max_delta_step=1, max_depth=12, min_child_weight=12, n_estimators=523, reg_alpha=2.8480491900363614, reg_lambda=0.17969135495851923, scale_pos_weight=0.9248569769405225, subsample=0.9209094803579234; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.891858086682517, colsample_bytree=0.6, gamma=1.425451915766663, learning_rate=0.03656543972257821, max_delta_step=4, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1284056101359625, subsample=0.7136158970305119; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.014492457739839008, max_delta_step=0, max_depth=4, min_child_weight=5, n_estimators=1789, reg_alpha=0.0, reg_lambda=3.0, scale_pos_weight=1.0353197010516506, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.9605179097569689, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0032658837517848256, max_delta_step=6, max_depth=4, min_child_weight=1, n_estimators=1939, reg_alpha=0.0, reg_lambda=1.0940963595871933, scale_pos_weight=1.2, subsample=1.0; total time=   5.0s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.9605179097569689, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0032658837517848256, max_delta_step=6, max_depth=4, min_child_weight=1, n_estimators=1939, reg_alpha=0.0, reg_lambda=1.0940963595871933, scale_pos_weight=1.2, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.8029283259305771, colsample_bynode=0.9936221654794641, colsample_bytree=0.6790811358619492, gamma=0.0637635869291764, learning_rate=0.007675271828094204, max_delta_step=2, max_depth=4, min_child_weight=6, n_estimators=744, reg_alpha=2.7887697815570136, reg_lambda=0.9104251335644562, scale_pos_weight=1.110364074810476, subsample=0.7475003063795894; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.6229462387272339, colsample_bynode=0.9601058664657138, colsample_bytree=0.6498199391116954, gamma=0.00782673946834689, learning_rate=0.025202260542171437, max_delta_step=3, max_depth=13, min_child_weight=12, n_estimators=605, reg_alpha=0.38465180101943897, reg_lambda=0.638556323670433, scale_pos_weight=1.111888815683276, subsample=0.9563046911335706; total time=   3.7s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.7884597892949705, colsample_bynode=0.6214273757694567, colsample_bytree=0.7804797273252069, gamma=0.7419509008911594, learning_rate=0.027611597981324038, max_delta_step=8, max_depth=9, min_child_weight=1, n_estimators=2992, reg_alpha=2.9338857324999905, reg_lambda=2.537948678088542, scale_pos_weight=1.0314161190837028, subsample=0.7982981895304777; total time=   8.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=1.3780854786729064, learning_rate=0.008564259804121236, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=0.9783088249460782; total time=   5.6s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=1.3780854786729064, learning_rate=0.008564259804121236, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=0.9783088249460782; total time=   5.4s\n",
      "[CV] END colsample_bylevel=0.6846421906217146, colsample_bynode=0.9624681118750951, colsample_bytree=0.7217919670811719, gamma=1.2347986229390675, learning_rate=0.0011955602126583968, max_delta_step=6, max_depth=13, min_child_weight=4, n_estimators=2980, reg_alpha=0.1158804762712852, reg_lambda=1.3266228743756976, scale_pos_weight=1.0104191220430034, subsample=0.872409731165494; total time=  25.5s\n",
      "[CV] END colsample_bylevel=0.9929161003416886, colsample_bynode=0.9563083820831286, colsample_bytree=0.97095963574126, gamma=0.8486635975289332, learning_rate=0.0014053216772569321, max_delta_step=1, max_depth=7, min_child_weight=8, n_estimators=2538, reg_alpha=2.8562402781254503, reg_lambda=1.199533112609045, scale_pos_weight=1.0969551354560385, subsample=0.7833638143554537; total time=  14.1s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.7432915889875962, colsample_bytree=0.6, gamma=2.0, learning_rate=0.03586847235253286, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.2, subsample=0.9800612206903186; total time=   0.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.7432915889875962, colsample_bytree=0.6, gamma=2.0, learning_rate=0.03586847235253286, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.2, subsample=0.9800612206903186; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.9991578316721332, colsample_bynode=0.6886601198061583, colsample_bytree=0.6178614903891883, gamma=1.6190271338740558, learning_rate=0.0010427228624761875, max_delta_step=4, max_depth=7, min_child_weight=12, n_estimators=2099, reg_alpha=0.21559731543388355, reg_lambda=0.9281713371511084, scale_pos_weight=1.013569337983841, subsample=0.7312578190162871; total time=   9.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=2.0, learning_rate=0.013187427963062425, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=2275, reg_alpha=3.0, reg_lambda=2.258100681982806, scale_pos_weight=1.2, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=2.0, learning_rate=0.013187427963062425, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=2275, reg_alpha=3.0, reg_lambda=2.258100681982806, scale_pos_weight=1.2, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.6832028574542088, colsample_bynode=0.7390955454389112, colsample_bytree=0.8316786544535053, gamma=1.9198419701603529, learning_rate=0.006195707130341904, max_delta_step=9, max_depth=4, min_child_weight=3, n_estimators=2457, reg_alpha=0.1051275288904833, reg_lambda=0.22055708814092428, scale_pos_weight=1.0816347854389956, subsample=0.8550757167960481; total time=   5.2s\n",
      "[CV] END colsample_bylevel=0.9815081044348658, colsample_bynode=0.9413921152529386, colsample_bytree=0.7237157629479105, gamma=1.0314241963941422, learning_rate=0.01197378995159849, max_delta_step=0, max_depth=12, min_child_weight=2, n_estimators=516, reg_alpha=0.11102729786737667, reg_lambda=2.853546658918587, scale_pos_weight=1.1499276917846268, subsample=0.89654777691648; total time=   4.8s\n",
      "[CV] END colsample_bylevel=0.6620484731382483, colsample_bynode=0.7424052032088251, colsample_bytree=0.6846985149753861, gamma=0.7748640645993101, learning_rate=0.0841332749600658, max_delta_step=2, max_depth=9, min_child_weight=13, n_estimators=584, reg_alpha=2.9551880501801713, reg_lambda=0.16230920085216466, scale_pos_weight=0.8392934261090509, subsample=0.915892679744317; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.6557657381440714, colsample_bynode=0.6296904116131872, colsample_bytree=0.6345251746968908, gamma=1.1147243735515961, learning_rate=0.08111857802579646, max_delta_step=4, max_depth=4, min_child_weight=9, n_estimators=527, reg_alpha=0.22409122779401808, reg_lambda=0.6688044489366509, scale_pos_weight=0.9923166554304077, subsample=0.7581370286561188; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.9166913208302345, colsample_bynode=0.6875663622267032, colsample_bytree=0.7116455082724042, gamma=0.10305079267391906, learning_rate=0.0011236151733937773, max_delta_step=1, max_depth=12, min_child_weight=12, n_estimators=523, reg_alpha=2.8480491900363614, reg_lambda=0.17969135495851923, scale_pos_weight=0.9248569769405225, subsample=0.9209094803579234; total time=   2.4s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.891858086682517, colsample_bytree=0.6, gamma=1.425451915766663, learning_rate=0.03656543972257821, max_delta_step=4, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1284056101359625, subsample=0.7136158970305119; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.891858086682517, colsample_bytree=0.6, gamma=1.425451915766663, learning_rate=0.03656543972257821, max_delta_step=4, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1284056101359625, subsample=0.7136158970305119; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.014492457739839008, max_delta_step=0, max_depth=4, min_child_weight=5, n_estimators=1789, reg_alpha=0.0, reg_lambda=3.0, scale_pos_weight=1.0353197010516506, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.9605179097569689, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0032658837517848256, max_delta_step=6, max_depth=4, min_child_weight=1, n_estimators=1939, reg_alpha=0.0, reg_lambda=1.0940963595871933, scale_pos_weight=1.2, subsample=1.0; total time=   4.8s\n",
      "[CV] END colsample_bylevel=0.8029283259305771, colsample_bynode=0.9936221654794641, colsample_bytree=0.6790811358619492, gamma=0.0637635869291764, learning_rate=0.007675271828094204, max_delta_step=2, max_depth=4, min_child_weight=6, n_estimators=744, reg_alpha=2.7887697815570136, reg_lambda=0.9104251335644562, scale_pos_weight=1.110364074810476, subsample=0.7475003063795894; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.6229462387272339, colsample_bynode=0.9601058664657138, colsample_bytree=0.6498199391116954, gamma=0.00782673946834689, learning_rate=0.025202260542171437, max_delta_step=3, max_depth=13, min_child_weight=12, n_estimators=605, reg_alpha=0.38465180101943897, reg_lambda=0.638556323670433, scale_pos_weight=1.111888815683276, subsample=0.9563046911335706; total time=   3.6s\n",
      "[CV] END colsample_bylevel=0.8256287992875267, colsample_bynode=0.9654727869366945, colsample_bytree=0.6192082065967969, gamma=0.019538019563527523, learning_rate=0.00509161588310719, max_delta_step=5, max_depth=12, min_child_weight=5, n_estimators=1540, reg_alpha=1.9945551129532708, reg_lambda=2.77230005126179, scale_pos_weight=1.1658504448215, subsample=0.9970470474080131; total time=  16.0s\n",
      "[CV] END colsample_bylevel=0.8256287992875267, colsample_bynode=0.9654727869366945, colsample_bytree=0.6192082065967969, gamma=0.019538019563527523, learning_rate=0.00509161588310719, max_delta_step=5, max_depth=12, min_child_weight=5, n_estimators=1540, reg_alpha=1.9945551129532708, reg_lambda=2.77230005126179, scale_pos_weight=1.1658504448215, subsample=0.9970470474080131; total time=   7.4sFitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.6846421906217146, colsample_bynode=0.9624681118750951, colsample_bytree=0.7217919670811719, gamma=1.2347986229390675, learning_rate=0.0011955602126583968, max_delta_step=6, max_depth=13, min_child_weight=4, n_estimators=2980, reg_alpha=0.1158804762712852, reg_lambda=1.3266228743756976, scale_pos_weight=1.0104191220430034, subsample=0.872409731165494; total time=  25.7s\n",
      "[CV] END colsample_bylevel=0.9929161003416886, colsample_bynode=0.9563083820831286, colsample_bytree=0.97095963574126, gamma=0.8486635975289332, learning_rate=0.0014053216772569321, max_delta_step=1, max_depth=7, min_child_weight=8, n_estimators=2538, reg_alpha=2.8562402781254503, reg_lambda=1.199533112609045, scale_pos_weight=1.0969551354560385, subsample=0.7833638143554537; total time=  14.1s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.7432915889875962, colsample_bytree=0.6, gamma=2.0, learning_rate=0.03586847235253286, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.2, subsample=0.9800612206903186; total time=   0.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.7432915889875962, colsample_bytree=0.6, gamma=2.0, learning_rate=0.03586847235253286, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.2, subsample=0.9800612206903186; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.9991578316721332, colsample_bynode=0.6886601198061583, colsample_bytree=0.6178614903891883, gamma=1.6190271338740558, learning_rate=0.0010427228624761875, max_delta_step=4, max_depth=7, min_child_weight=12, n_estimators=2099, reg_alpha=0.21559731543388355, reg_lambda=0.9281713371511084, scale_pos_weight=1.013569337983841, subsample=0.7312578190162871; total time=   9.4s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=2.0, learning_rate=0.013187427963062425, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=2275, reg_alpha=3.0, reg_lambda=2.258100681982806, scale_pos_weight=1.2, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bylevel=0.6832028574542088, colsample_bynode=0.7390955454389112, colsample_bytree=0.8316786544535053, gamma=1.9198419701603529, learning_rate=0.006195707130341904, max_delta_step=9, max_depth=4, min_child_weight=3, n_estimators=2457, reg_alpha=0.1051275288904833, reg_lambda=0.22055708814092428, scale_pos_weight=1.0816347854389956, subsample=0.8550757167960481; total time=   4.8s\n",
      "[CV] END colsample_bylevel=0.6832028574542088, colsample_bynode=0.7390955454389112, colsample_bytree=0.8316786544535053, gamma=1.9198419701603529, learning_rate=0.006195707130341904, max_delta_step=9, max_depth=4, min_child_weight=3, n_estimators=2457, reg_alpha=0.1051275288904833, reg_lambda=0.22055708814092428, scale_pos_weight=1.0816347854389956, subsample=0.8550757167960481; total time=   5.5s\n",
      "[CV] END colsample_bylevel=0.6620484731382483, colsample_bynode=0.7424052032088251, colsample_bytree=0.6846985149753861, gamma=0.7748640645993101, learning_rate=0.0841332749600658, max_delta_step=2, max_depth=9, min_child_weight=13, n_estimators=584, reg_alpha=2.9551880501801713, reg_lambda=0.16230920085216466, scale_pos_weight=0.8392934261090509, subsample=0.915892679744317; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.6620484731382483, colsample_bynode=0.7424052032088251, colsample_bytree=0.6846985149753861, gamma=0.7748640645993101, learning_rate=0.0841332749600658, max_delta_step=2, max_depth=9, min_child_weight=13, n_estimators=584, reg_alpha=2.9551880501801713, reg_lambda=0.16230920085216466, scale_pos_weight=0.8392934261090509, subsample=0.915892679744317; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.6557657381440714, colsample_bynode=0.6296904116131872, colsample_bytree=0.6345251746968908, gamma=1.1147243735515961, learning_rate=0.08111857802579646, max_delta_step=4, max_depth=4, min_child_weight=9, n_estimators=527, reg_alpha=0.22409122779401808, reg_lambda=0.6688044489366509, scale_pos_weight=0.9923166554304077, subsample=0.7581370286561188; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.9166913208302345, colsample_bynode=0.6875663622267032, colsample_bytree=0.7116455082724042, gamma=0.10305079267391906, learning_rate=0.0011236151733937773, max_delta_step=1, max_depth=12, min_child_weight=12, n_estimators=523, reg_alpha=2.8480491900363614, reg_lambda=0.17969135495851923, scale_pos_weight=0.9248569769405225, subsample=0.9209094803579234; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.891858086682517, colsample_bytree=0.6, gamma=1.425451915766663, learning_rate=0.03656543972257821, max_delta_step=4, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1284056101359625, subsample=0.7136158970305119; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.014492457739839008, max_delta_step=0, max_depth=4, min_child_weight=5, n_estimators=1789, reg_alpha=0.0, reg_lambda=3.0, scale_pos_weight=1.0353197010516506, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.9605179097569689, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0032658837517848256, max_delta_step=6, max_depth=4, min_child_weight=1, n_estimators=1939, reg_alpha=0.0, reg_lambda=1.0940963595871933, scale_pos_weight=1.2, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bylevel=0.8029283259305771, colsample_bynode=0.9936221654794641, colsample_bytree=0.6790811358619492, gamma=0.0637635869291764, learning_rate=0.007675271828094204, max_delta_step=2, max_depth=4, min_child_weight=6, n_estimators=744, reg_alpha=2.7887697815570136, reg_lambda=0.9104251335644562, scale_pos_weight=1.110364074810476, subsample=0.7475003063795894; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.8029283259305771, colsample_bynode=0.9936221654794641, colsample_bytree=0.6790811358619492, gamma=0.0637635869291764, learning_rate=0.007675271828094204, max_delta_step=2, max_depth=4, min_child_weight=6, n_estimators=744, reg_alpha=2.7887697815570136, reg_lambda=0.9104251335644562, scale_pos_weight=1.110364074810476, subsample=0.7475003063795894; total time=   2.6s\n",
      "[CV] END colsample_bylevel=0.6229462387272339, colsample_bynode=0.9601058664657138, colsample_bytree=0.6498199391116954, gamma=0.00782673946834689, learning_rate=0.025202260542171437, max_delta_step=3, max_depth=13, min_child_weight=12, n_estimators=605, reg_alpha=0.38465180101943897, reg_lambda=0.638556323670433, scale_pos_weight=1.111888815683276, subsample=0.9563046911335706; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.8256287992875267, colsample_bynode=0.9654727869366945, colsample_bytree=0.6192082065967969, gamma=0.019538019563527523, learning_rate=0.00509161588310719, max_delta_step=5, max_depth=12, min_child_weight=5, n_estimators=1540, reg_alpha=1.9945551129532708, reg_lambda=2.77230005126179, scale_pos_weight=1.1658504448215, subsample=0.9970470474080131; total time=  15.8s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.8250732258254885, colsample_bytree=0.6, gamma=2.0, learning_rate=0.017997938375945485, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bylevel=0.6338004436618527, colsample_bynode=0.8358391687795322, colsample_bytree=0.8509651570552472, gamma=1.774596698647124, learning_rate=0.0012642284200513525, max_delta_step=5, max_depth=15, min_child_weight=2, n_estimators=2612, reg_alpha=2.9830239320387877, reg_lambda=0.0438300116240138, scale_pos_weight=1.1967450001905853, subsample=0.9782547396414123; total time=  27.1s\n",
      "[CV] END colsample_bylevel=0.7318589818233534, colsample_bynode=0.752794124091841, colsample_bytree=0.6064557946069994, gamma=1.9617988064780607, learning_rate=0.004664068954879086, max_delta_step=9, max_depth=15, min_child_weight=13, n_estimators=2321, reg_alpha=0.06227389191807976, reg_lambda=1.1230720828040295, scale_pos_weight=0.8726451378579114, subsample=0.7407539227770299; total time=   7.9s\n",
      "[CV] END colsample_bylevel=0.7318589818233534, colsample_bynode=0.752794124091841, colsample_bytree=0.6064557946069994, gamma=1.9617988064780607, learning_rate=0.004664068954879086, max_delta_step=9, max_depth=15, min_child_weight=13, n_estimators=2321, reg_alpha=0.06227389191807976, reg_lambda=1.1230720828040295, scale_pos_weight=0.8726451378579114, subsample=0.7407539227770299; total time=   7.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:49:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.9929161003416886, colsample_bynode=0.9563083820831286, colsample_bytree=0.97095963574126, gamma=0.8486635975289332, learning_rate=0.0014053216772569321, max_delta_step=1, max_depth=7, min_child_weight=8, n_estimators=2538, reg_alpha=2.8562402781254503, reg_lambda=1.199533112609045, scale_pos_weight=1.0969551354560385, subsample=0.7833638143554537; total time=  14.1s\n",
      "[CV] END colsample_bylevel=0.9929161003416886, colsample_bynode=0.9563083820831286, colsample_bytree=0.97095963574126, gamma=0.8486635975289332, learning_rate=0.0014053216772569321, max_delta_step=1, max_depth=7, min_child_weight=8, n_estimators=2538, reg_alpha=2.8562402781254503, reg_lambda=1.199533112609045, scale_pos_weight=1.0969551354560385, subsample=0.7833638143554537; total time=  14.8s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=2.0, learning_rate=0.013187427963062425, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=2275, reg_alpha=3.0, reg_lambda=2.258100681982806, scale_pos_weight=1.2, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.6832028574542088, colsample_bynode=0.7390955454389112, colsample_bytree=0.8316786544535053, gamma=1.9198419701603529, learning_rate=0.006195707130341904, max_delta_step=9, max_depth=4, min_child_weight=3, n_estimators=2457, reg_alpha=0.1051275288904833, reg_lambda=0.22055708814092428, scale_pos_weight=1.0816347854389956, subsample=0.8550757167960481; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.9815081044348658, colsample_bynode=0.9413921152529386, colsample_bytree=0.7237157629479105, gamma=1.0314241963941422, learning_rate=0.01197378995159849, max_delta_step=0, max_depth=12, min_child_weight=2, n_estimators=516, reg_alpha=0.11102729786737667, reg_lambda=2.853546658918587, scale_pos_weight=1.1499276917846268, subsample=0.89654777691648; total time=   5.2s\n",
      "[CV] END colsample_bylevel=0.9815081044348658, colsample_bynode=0.9413921152529386, colsample_bytree=0.7237157629479105, gamma=1.0314241963941422, learning_rate=0.01197378995159849, max_delta_step=0, max_depth=12, min_child_weight=2, n_estimators=516, reg_alpha=0.11102729786737667, reg_lambda=2.853546658918587, scale_pos_weight=1.1499276917846268, subsample=0.89654777691648; total time=   4.2s\n",
      "[CV] END colsample_bylevel=0.6620484731382483, colsample_bynode=0.7424052032088251, colsample_bytree=0.6846985149753861, gamma=0.7748640645993101, learning_rate=0.0841332749600658, max_delta_step=2, max_depth=9, min_child_weight=13, n_estimators=584, reg_alpha=2.9551880501801713, reg_lambda=0.16230920085216466, scale_pos_weight=0.8392934261090509, subsample=0.915892679744317; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.6620484731382483, colsample_bynode=0.7424052032088251, colsample_bytree=0.6846985149753861, gamma=0.7748640645993101, learning_rate=0.0841332749600658, max_delta_step=2, max_depth=9, min_child_weight=13, n_estimators=584, reg_alpha=2.9551880501801713, reg_lambda=0.16230920085216466, scale_pos_weight=0.8392934261090509, subsample=0.915892679744317; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.9166913208302345, colsample_bynode=0.6875663622267032, colsample_bytree=0.7116455082724042, gamma=0.10305079267391906, learning_rate=0.0011236151733937773, max_delta_step=1, max_depth=12, min_child_weight=12, n_estimators=523, reg_alpha=2.8480491900363614, reg_lambda=0.17969135495851923, scale_pos_weight=0.9248569769405225, subsample=0.9209094803579234; total time=   2.4s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.891858086682517, colsample_bytree=0.6, gamma=1.425451915766663, learning_rate=0.03656543972257821, max_delta_step=4, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1284056101359625, subsample=0.7136158970305119; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.014492457739839008, max_delta_step=0, max_depth=4, min_child_weight=5, n_estimators=1789, reg_alpha=0.0, reg_lambda=3.0, scale_pos_weight=1.0353197010516506, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.014492457739839008, max_delta_step=0, max_depth=4, min_child_weight=5, n_estimators=1789, reg_alpha=0.0, reg_lambda=3.0, scale_pos_weight=1.0353197010516506, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.9605179097569689, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0032658837517848256, max_delta_step=6, max_depth=4, min_child_weight=1, n_estimators=1939, reg_alpha=0.0, reg_lambda=1.0940963595871933, scale_pos_weight=1.2, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bylevel=0.8029283259305771, colsample_bynode=0.9936221654794641, colsample_bytree=0.6790811358619492, gamma=0.0637635869291764, learning_rate=0.007675271828094204, max_delta_step=2, max_depth=4, min_child_weight=6, n_estimators=744, reg_alpha=2.7887697815570136, reg_lambda=0.9104251335644562, scale_pos_weight=1.110364074810476, subsample=0.7475003063795894; total time=   2.1s\n",
      "[CV] END colsample_bylevel=0.8029283259305771, colsample_bynode=0.9936221654794641, colsample_bytree=0.6790811358619492, gamma=0.0637635869291764, learning_rate=0.007675271828094204, max_delta_step=2, max_depth=4, min_child_weight=6, n_estimators=744, reg_alpha=2.7887697815570136, reg_lambda=0.9104251335644562, scale_pos_weight=1.110364074810476, subsample=0.7475003063795894; total time=   2.6s\n",
      "[CV] END colsample_bylevel=0.6229462387272339, colsample_bynode=0.9601058664657138, colsample_bytree=0.6498199391116954, gamma=0.00782673946834689, learning_rate=0.025202260542171437, max_delta_step=3, max_depth=13, min_child_weight=12, n_estimators=605, reg_alpha=0.38465180101943897, reg_lambda=0.638556323670433, scale_pos_weight=1.111888815683276, subsample=0.9563046911335706; total time=   3.9s\n",
      "[CV] END colsample_bylevel=0.8256287992875267, colsample_bynode=0.9654727869366945, colsample_bytree=0.6192082065967969, gamma=0.019538019563527523, learning_rate=0.00509161588310719, max_delta_step=5, max_depth=12, min_child_weight=5, n_estimators=1540, reg_alpha=1.9945551129532708, reg_lambda=2.77230005126179, scale_pos_weight=1.1658504448215, subsample=0.9970470474080131; total time=  15.9s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.8250732258254885, colsample_bytree=0.6, gamma=2.0, learning_rate=0.017997938375945485, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bylevel=0.6338004436618527, colsample_bynode=0.8358391687795322, colsample_bytree=0.8509651570552472, gamma=1.774596698647124, learning_rate=0.0012642284200513525, max_delta_step=5, max_depth=15, min_child_weight=2, n_estimators=2612, reg_alpha=2.9830239320387877, reg_lambda=0.0438300116240138, scale_pos_weight=1.1967450001905853, subsample=0.9782547396414123; total time=  26.6s\n",
      "[CV] END colsample_bylevel=0.6338004436618527, colsample_bynode=0.8358391687795322, colsample_bytree=0.8509651570552472, gamma=1.774596698647124, learning_rate=0.0012642284200513525, max_delta_step=5, max_depth=15, min_child_weight=2, n_estimators=2612, reg_alpha=2.9830239320387877, reg_lambda=0.0438300116240138, scale_pos_weight=1.1967450001905853, subsample=0.9782547396414123; total time=  18.4s\n",
      "[CV] END colsample_bylevel=0.6010300856271814, colsample_bynode=0.8965573748092919, colsample_bytree=0.9154200469404541, gamma=0.12112769121585235, learning_rate=0.0010271523932214696, max_delta_step=7, max_depth=7, min_child_weight=2, n_estimators=2976, reg_alpha=0.40395565723104887, reg_lambda=0.643016424477618, scale_pos_weight=1.181343972105119, subsample=0.8730904028252356; total time=  21.9s\n",
      "[CV] END colsample_bylevel=0.7517728220468336, colsample_bynode=0.866464167707957, colsample_bytree=0.9421523683349787, gamma=0.1429115552841931, learning_rate=0.0018550652218404372, max_delta_step=4, max_depth=4, min_child_weight=14, n_estimators=1985, reg_alpha=0.029722034054998965, reg_lambda=0.6248411296721061, scale_pos_weight=0.8270823971921468, subsample=0.9005085239982015; total time=   6.9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.9929161003416886, colsample_bynode=0.9563083820831286, colsample_bytree=0.97095963574126, gamma=0.8486635975289332, learning_rate=0.0014053216772569321, max_delta_step=1, max_depth=7, min_child_weight=8, n_estimators=2538, reg_alpha=2.8562402781254503, reg_lambda=1.199533112609045, scale_pos_weight=1.0969551354560385, subsample=0.7833638143554537; total time=  14.1s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.7432915889875962, colsample_bytree=0.6, gamma=2.0, learning_rate=0.03586847235253286, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.2, subsample=0.9800612206903186; total time=   0.9s\n",
      "[CV] END colsample_bylevel=0.9991578316721332, colsample_bynode=0.6886601198061583, colsample_bytree=0.6178614903891883, gamma=1.6190271338740558, learning_rate=0.0010427228624761875, max_delta_step=4, max_depth=7, min_child_weight=12, n_estimators=2099, reg_alpha=0.21559731543388355, reg_lambda=0.9281713371511084, scale_pos_weight=1.013569337983841, subsample=0.7312578190162871; total time=   9.3s\n",
      "[CV] END colsample_bylevel=0.9991578316721332, colsample_bynode=0.6886601198061583, colsample_bytree=0.6178614903891883, gamma=1.6190271338740558, learning_rate=0.0010427228624761875, max_delta_step=4, max_depth=7, min_child_weight=12, n_estimators=2099, reg_alpha=0.21559731543388355, reg_lambda=0.9281713371511084, scale_pos_weight=1.013569337983841, subsample=0.7312578190162871; total time=   7.1s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=2.0, learning_rate=0.013187427963062425, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=2275, reg_alpha=3.0, reg_lambda=2.258100681982806, scale_pos_weight=1.2, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bylevel=0.6832028574542088, colsample_bynode=0.7390955454389112, colsample_bytree=0.8316786544535053, gamma=1.9198419701603529, learning_rate=0.006195707130341904, max_delta_step=9, max_depth=4, min_child_weight=3, n_estimators=2457, reg_alpha=0.1051275288904833, reg_lambda=0.22055708814092428, scale_pos_weight=1.0816347854389956, subsample=0.8550757167960481; total time=   5.0s\n",
      "[CV] END colsample_bylevel=0.9815081044348658, colsample_bynode=0.9413921152529386, colsample_bytree=0.7237157629479105, gamma=1.0314241963941422, learning_rate=0.01197378995159849, max_delta_step=0, max_depth=12, min_child_weight=2, n_estimators=516, reg_alpha=0.11102729786737667, reg_lambda=2.853546658918587, scale_pos_weight=1.1499276917846268, subsample=0.89654777691648; total time=   5.1s\n",
      "[CV] END colsample_bylevel=0.9815081044348658, colsample_bynode=0.9413921152529386, colsample_bytree=0.7237157629479105, gamma=1.0314241963941422, learning_rate=0.01197378995159849, max_delta_step=0, max_depth=12, min_child_weight=2, n_estimators=516, reg_alpha=0.11102729786737667, reg_lambda=2.853546658918587, scale_pos_weight=1.1499276917846268, subsample=0.89654777691648; total time=   4.2s\n",
      "[CV] END colsample_bylevel=0.6620484731382483, colsample_bynode=0.7424052032088251, colsample_bytree=0.6846985149753861, gamma=0.7748640645993101, learning_rate=0.0841332749600658, max_delta_step=2, max_depth=9, min_child_weight=13, n_estimators=584, reg_alpha=2.9551880501801713, reg_lambda=0.16230920085216466, scale_pos_weight=0.8392934261090509, subsample=0.915892679744317; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.6557657381440714, colsample_bynode=0.6296904116131872, colsample_bytree=0.6345251746968908, gamma=1.1147243735515961, learning_rate=0.08111857802579646, max_delta_step=4, max_depth=4, min_child_weight=9, n_estimators=527, reg_alpha=0.22409122779401808, reg_lambda=0.6688044489366509, scale_pos_weight=0.9923166554304077, subsample=0.7581370286561188; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.6557657381440714, colsample_bynode=0.6296904116131872, colsample_bytree=0.6345251746968908, gamma=1.1147243735515961, learning_rate=0.08111857802579646, max_delta_step=4, max_depth=4, min_child_weight=9, n_estimators=527, reg_alpha=0.22409122779401808, reg_lambda=0.6688044489366509, scale_pos_weight=0.9923166554304077, subsample=0.7581370286561188; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.9166913208302345, colsample_bynode=0.6875663622267032, colsample_bytree=0.7116455082724042, gamma=0.10305079267391906, learning_rate=0.0011236151733937773, max_delta_step=1, max_depth=12, min_child_weight=12, n_estimators=523, reg_alpha=2.8480491900363614, reg_lambda=0.17969135495851923, scale_pos_weight=0.9248569769405225, subsample=0.9209094803579234; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.891858086682517, colsample_bytree=0.6, gamma=1.425451915766663, learning_rate=0.03656543972257821, max_delta_step=4, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1284056101359625, subsample=0.7136158970305119; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.891858086682517, colsample_bytree=0.6, gamma=1.425451915766663, learning_rate=0.03656543972257821, max_delta_step=4, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1284056101359625, subsample=0.7136158970305119; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.014492457739839008, max_delta_step=0, max_depth=4, min_child_weight=5, n_estimators=1789, reg_alpha=0.0, reg_lambda=3.0, scale_pos_weight=1.0353197010516506, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.9605179097569689, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0032658837517848256, max_delta_step=6, max_depth=4, min_child_weight=1, n_estimators=1939, reg_alpha=0.0, reg_lambda=1.0940963595871933, scale_pos_weight=1.2, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.8029283259305771, colsample_bynode=0.9936221654794641, colsample_bytree=0.6790811358619492, gamma=0.0637635869291764, learning_rate=0.007675271828094204, max_delta_step=2, max_depth=4, min_child_weight=6, n_estimators=744, reg_alpha=2.7887697815570136, reg_lambda=0.9104251335644562, scale_pos_weight=1.110364074810476, subsample=0.7475003063795894; total time=   2.1s\n",
      "[CV] END colsample_bylevel=0.6229462387272339, colsample_bynode=0.9601058664657138, colsample_bytree=0.6498199391116954, gamma=0.00782673946834689, learning_rate=0.025202260542171437, max_delta_step=3, max_depth=13, min_child_weight=12, n_estimators=605, reg_alpha=0.38465180101943897, reg_lambda=0.638556323670433, scale_pos_weight=1.111888815683276, subsample=0.9563046911335706; total time=   3.8s\n",
      "[CV] END colsample_bylevel=0.8256287992875267, colsample_bynode=0.9654727869366945, colsample_bytree=0.6192082065967969, gamma=0.019538019563527523, learning_rate=0.00509161588310719, max_delta_step=5, max_depth=12, min_child_weight=5, n_estimators=1540, reg_alpha=1.9945551129532708, reg_lambda=2.77230005126179, scale_pos_weight=1.1658504448215, subsample=0.9970470474080131; total time=  16.1s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.8250732258254885, colsample_bytree=0.6, gamma=2.0, learning_rate=0.017997938375945485, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.8250732258254885, colsample_bytree=0.6, gamma=2.0, learning_rate=0.017997938375945485, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bylevel=0.6338004436618527, colsample_bynode=0.8358391687795322, colsample_bytree=0.8509651570552472, gamma=1.774596698647124, learning_rate=0.0012642284200513525, max_delta_step=5, max_depth=15, min_child_weight=2, n_estimators=2612, reg_alpha=2.9830239320387877, reg_lambda=0.0438300116240138, scale_pos_weight=1.1967450001905853, subsample=0.9782547396414123; total time=  26.8s\n",
      "[CV] END colsample_bylevel=0.7318589818233534, colsample_bynode=0.752794124091841, colsample_bytree=0.6064557946069994, gamma=1.9617988064780607, learning_rate=0.004664068954879086, max_delta_step=9, max_depth=15, min_child_weight=13, n_estimators=2321, reg_alpha=0.06227389191807976, reg_lambda=1.1230720828040295, scale_pos_weight=0.8726451378579114, subsample=0.7407539227770299; total time=   7.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.9929161003416886, colsample_bynode=0.9563083820831286, colsample_bytree=0.97095963574126, gamma=0.8486635975289332, learning_rate=0.0014053216772569321, max_delta_step=1, max_depth=7, min_child_weight=8, n_estimators=2538, reg_alpha=2.8562402781254503, reg_lambda=1.199533112609045, scale_pos_weight=1.0969551354560385, subsample=0.7833638143554537; total time=  14.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.7432915889875962, colsample_bytree=0.6, gamma=2.0, learning_rate=0.03586847235253286, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.2, subsample=0.9800612206903186; total time=   0.9s\n",
      "[CV] END colsample_bylevel=0.9991578316721332, colsample_bynode=0.6886601198061583, colsample_bytree=0.6178614903891883, gamma=1.6190271338740558, learning_rate=0.0010427228624761875, max_delta_step=4, max_depth=7, min_child_weight=12, n_estimators=2099, reg_alpha=0.21559731543388355, reg_lambda=0.9281713371511084, scale_pos_weight=1.013569337983841, subsample=0.7312578190162871; total time=   9.2s\n",
      "[CV] END colsample_bylevel=0.9991578316721332, colsample_bynode=0.6886601198061583, colsample_bytree=0.6178614903891883, gamma=1.6190271338740558, learning_rate=0.0010427228624761875, max_delta_step=4, max_depth=7, min_child_weight=12, n_estimators=2099, reg_alpha=0.21559731543388355, reg_lambda=0.9281713371511084, scale_pos_weight=1.013569337983841, subsample=0.7312578190162871; total time=   7.1s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=2.0, learning_rate=0.013187427963062425, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=2275, reg_alpha=3.0, reg_lambda=2.258100681982806, scale_pos_weight=1.2, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bylevel=0.6832028574542088, colsample_bynode=0.7390955454389112, colsample_bytree=0.8316786544535053, gamma=1.9198419701603529, learning_rate=0.006195707130341904, max_delta_step=9, max_depth=4, min_child_weight=3, n_estimators=2457, reg_alpha=0.1051275288904833, reg_lambda=0.22055708814092428, scale_pos_weight=1.0816347854389956, subsample=0.8550757167960481; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.6832028574542088, colsample_bynode=0.7390955454389112, colsample_bytree=0.8316786544535053, gamma=1.9198419701603529, learning_rate=0.006195707130341904, max_delta_step=9, max_depth=4, min_child_weight=3, n_estimators=2457, reg_alpha=0.1051275288904833, reg_lambda=0.22055708814092428, scale_pos_weight=1.0816347854389956, subsample=0.8550757167960481; total time=   5.6s\n",
      "[CV] END colsample_bylevel=0.6620484731382483, colsample_bynode=0.7424052032088251, colsample_bytree=0.6846985149753861, gamma=0.7748640645993101, learning_rate=0.0841332749600658, max_delta_step=2, max_depth=9, min_child_weight=13, n_estimators=584, reg_alpha=2.9551880501801713, reg_lambda=0.16230920085216466, scale_pos_weight=0.8392934261090509, subsample=0.915892679744317; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.6557657381440714, colsample_bynode=0.6296904116131872, colsample_bytree=0.6345251746968908, gamma=1.1147243735515961, learning_rate=0.08111857802579646, max_delta_step=4, max_depth=4, min_child_weight=9, n_estimators=527, reg_alpha=0.22409122779401808, reg_lambda=0.6688044489366509, scale_pos_weight=0.9923166554304077, subsample=0.7581370286561188; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.6557657381440714, colsample_bynode=0.6296904116131872, colsample_bytree=0.6345251746968908, gamma=1.1147243735515961, learning_rate=0.08111857802579646, max_delta_step=4, max_depth=4, min_child_weight=9, n_estimators=527, reg_alpha=0.22409122779401808, reg_lambda=0.6688044489366509, scale_pos_weight=0.9923166554304077, subsample=0.7581370286561188; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.9166913208302345, colsample_bynode=0.6875663622267032, colsample_bytree=0.7116455082724042, gamma=0.10305079267391906, learning_rate=0.0011236151733937773, max_delta_step=1, max_depth=12, min_child_weight=12, n_estimators=523, reg_alpha=2.8480491900363614, reg_lambda=0.17969135495851923, scale_pos_weight=0.9248569769405225, subsample=0.9209094803579234; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.891858086682517, colsample_bytree=0.6, gamma=1.425451915766663, learning_rate=0.03656543972257821, max_delta_step=4, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1284056101359625, subsample=0.7136158970305119; total time=   1.6s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.014492457739839008, max_delta_step=0, max_depth=4, min_child_weight=5, n_estimators=1789, reg_alpha=0.0, reg_lambda=3.0, scale_pos_weight=1.0353197010516506, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.9605179097569689, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0032658837517848256, max_delta_step=6, max_depth=4, min_child_weight=1, n_estimators=1939, reg_alpha=0.0, reg_lambda=1.0940963595871933, scale_pos_weight=1.2, subsample=1.0; total time=   5.0s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.9605179097569689, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0032658837517848256, max_delta_step=6, max_depth=4, min_child_weight=1, n_estimators=1939, reg_alpha=0.0, reg_lambda=1.0940963595871933, scale_pos_weight=1.2, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.8029283259305771, colsample_bynode=0.9936221654794641, colsample_bytree=0.6790811358619492, gamma=0.0637635869291764, learning_rate=0.007675271828094204, max_delta_step=2, max_depth=4, min_child_weight=6, n_estimators=744, reg_alpha=2.7887697815570136, reg_lambda=0.9104251335644562, scale_pos_weight=1.110364074810476, subsample=0.7475003063795894; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.6229462387272339, colsample_bynode=0.9601058664657138, colsample_bytree=0.6498199391116954, gamma=0.00782673946834689, learning_rate=0.025202260542171437, max_delta_step=3, max_depth=13, min_child_weight=12, n_estimators=605, reg_alpha=0.38465180101943897, reg_lambda=0.638556323670433, scale_pos_weight=1.111888815683276, subsample=0.9563046911335706; total time=   3.6s\n",
      "[CV] END colsample_bylevel=0.6229462387272339, colsample_bynode=0.9601058664657138, colsample_bytree=0.6498199391116954, gamma=0.00782673946834689, learning_rate=0.025202260542171437, max_delta_step=3, max_depth=13, min_child_weight=12, n_estimators=605, reg_alpha=0.38465180101943897, reg_lambda=0.638556323670433, scale_pos_weight=1.111888815683276, subsample=0.9563046911335706; total time=   3.9s\n",
      "[CV] END colsample_bylevel=0.8256287992875267, colsample_bynode=0.9654727869366945, colsample_bytree=0.6192082065967969, gamma=0.019538019563527523, learning_rate=0.00509161588310719, max_delta_step=5, max_depth=12, min_child_weight=5, n_estimators=1540, reg_alpha=1.9945551129532708, reg_lambda=2.77230005126179, scale_pos_weight=1.1658504448215, subsample=0.9970470474080131; total time=  15.0s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.8250732258254885, colsample_bytree=0.6, gamma=2.0, learning_rate=0.017997938375945485, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bylevel=0.6338004436618527, colsample_bynode=0.8358391687795322, colsample_bytree=0.8509651570552472, gamma=1.774596698647124, learning_rate=0.0012642284200513525, max_delta_step=5, max_depth=15, min_child_weight=2, n_estimators=2612, reg_alpha=2.9830239320387877, reg_lambda=0.0438300116240138, scale_pos_weight=1.1967450001905853, subsample=0.9782547396414123; total time=  26.9s\n",
      "[CV] END colsample_bylevel=0.7318589818233534, colsample_bynode=0.752794124091841, colsample_bytree=0.6064557946069994, gamma=1.9617988064780607, learning_rate=0.004664068954879086, max_delta_step=9, max_depth=15, min_child_weight=13, n_estimators=2321, reg_alpha=0.06227389191807976, reg_lambda=1.1230720828040295, scale_pos_weight=0.8726451378579114, subsample=0.7407539227770299; total time=   7.9s\n",
      "[CV] END colsample_bylevel=0.7318589818233534, colsample_bynode=0.752794124091841, colsample_bytree=0.6064557946069994, gamma=1.9617988064780607, learning_rate=0.004664068954879086, max_delta_step=9, max_depth=15, min_child_weight=13, n_estimators=2321, reg_alpha=0.06227389191807976, reg_lambda=1.1230720828040295, scale_pos_weight=0.8726451378579114, subsample=0.7407539227770299; total time=   7.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.9929161003416886, colsample_bynode=0.9563083820831286, colsample_bytree=0.97095963574126, gamma=0.8486635975289332, learning_rate=0.0014053216772569321, max_delta_step=1, max_depth=7, min_child_weight=8, n_estimators=2538, reg_alpha=2.8562402781254503, reg_lambda=1.199533112609045, scale_pos_weight=1.0969551354560385, subsample=0.7833638143554537; total time=  14.0s\n",
      "[CV] END colsample_bylevel=0.9929161003416886, colsample_bynode=0.9563083820831286, colsample_bytree=0.97095963574126, gamma=0.8486635975289332, learning_rate=0.0014053216772569321, max_delta_step=1, max_depth=7, min_child_weight=8, n_estimators=2538, reg_alpha=2.8562402781254503, reg_lambda=1.199533112609045, scale_pos_weight=1.0969551354560385, subsample=0.7833638143554537; total time=  14.9s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=2.0, learning_rate=0.013187427963062425, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=2275, reg_alpha=3.0, reg_lambda=2.258100681982806, scale_pos_weight=1.2, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bylevel=0.6832028574542088, colsample_bynode=0.7390955454389112, colsample_bytree=0.8316786544535053, gamma=1.9198419701603529, learning_rate=0.006195707130341904, max_delta_step=9, max_depth=4, min_child_weight=3, n_estimators=2457, reg_alpha=0.1051275288904833, reg_lambda=0.22055708814092428, scale_pos_weight=1.0816347854389956, subsample=0.8550757167960481; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.9815081044348658, colsample_bynode=0.9413921152529386, colsample_bytree=0.7237157629479105, gamma=1.0314241963941422, learning_rate=0.01197378995159849, max_delta_step=0, max_depth=12, min_child_weight=2, n_estimators=516, reg_alpha=0.11102729786737667, reg_lambda=2.853546658918587, scale_pos_weight=1.1499276917846268, subsample=0.89654777691648; total time=   5.0s\n",
      "[CV] END colsample_bylevel=0.9815081044348658, colsample_bynode=0.9413921152529386, colsample_bytree=0.7237157629479105, gamma=1.0314241963941422, learning_rate=0.01197378995159849, max_delta_step=0, max_depth=12, min_child_weight=2, n_estimators=516, reg_alpha=0.11102729786737667, reg_lambda=2.853546658918587, scale_pos_weight=1.1499276917846268, subsample=0.89654777691648; total time=   4.3s\n",
      "[CV] END colsample_bylevel=0.6620484731382483, colsample_bynode=0.7424052032088251, colsample_bytree=0.6846985149753861, gamma=0.7748640645993101, learning_rate=0.0841332749600658, max_delta_step=2, max_depth=9, min_child_weight=13, n_estimators=584, reg_alpha=2.9551880501801713, reg_lambda=0.16230920085216466, scale_pos_weight=0.8392934261090509, subsample=0.915892679744317; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.6557657381440714, colsample_bynode=0.6296904116131872, colsample_bytree=0.6345251746968908, gamma=1.1147243735515961, learning_rate=0.08111857802579646, max_delta_step=4, max_depth=4, min_child_weight=9, n_estimators=527, reg_alpha=0.22409122779401808, reg_lambda=0.6688044489366509, scale_pos_weight=0.9923166554304077, subsample=0.7581370286561188; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.6557657381440714, colsample_bynode=0.6296904116131872, colsample_bytree=0.6345251746968908, gamma=1.1147243735515961, learning_rate=0.08111857802579646, max_delta_step=4, max_depth=4, min_child_weight=9, n_estimators=527, reg_alpha=0.22409122779401808, reg_lambda=0.6688044489366509, scale_pos_weight=0.9923166554304077, subsample=0.7581370286561188; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.9166913208302345, colsample_bynode=0.6875663622267032, colsample_bytree=0.7116455082724042, gamma=0.10305079267391906, learning_rate=0.0011236151733937773, max_delta_step=1, max_depth=12, min_child_weight=12, n_estimators=523, reg_alpha=2.8480491900363614, reg_lambda=0.17969135495851923, scale_pos_weight=0.9248569769405225, subsample=0.9209094803579234; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.891858086682517, colsample_bytree=0.6, gamma=1.425451915766663, learning_rate=0.03656543972257821, max_delta_step=4, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1284056101359625, subsample=0.7136158970305119; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.014492457739839008, max_delta_step=0, max_depth=4, min_child_weight=5, n_estimators=1789, reg_alpha=0.0, reg_lambda=3.0, scale_pos_weight=1.0353197010516506, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.014492457739839008, max_delta_step=0, max_depth=4, min_child_weight=5, n_estimators=1789, reg_alpha=0.0, reg_lambda=3.0, scale_pos_weight=1.0353197010516506, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.9605179097569689, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0032658837517848256, max_delta_step=6, max_depth=4, min_child_weight=1, n_estimators=1939, reg_alpha=0.0, reg_lambda=1.0940963595871933, scale_pos_weight=1.2, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bylevel=0.8029283259305771, colsample_bynode=0.9936221654794641, colsample_bytree=0.6790811358619492, gamma=0.0637635869291764, learning_rate=0.007675271828094204, max_delta_step=2, max_depth=4, min_child_weight=6, n_estimators=744, reg_alpha=2.7887697815570136, reg_lambda=0.9104251335644562, scale_pos_weight=1.110364074810476, subsample=0.7475003063795894; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.6229462387272339, colsample_bynode=0.9601058664657138, colsample_bytree=0.6498199391116954, gamma=0.00782673946834689, learning_rate=0.025202260542171437, max_delta_step=3, max_depth=13, min_child_weight=12, n_estimators=605, reg_alpha=0.38465180101943897, reg_lambda=0.638556323670433, scale_pos_weight=1.111888815683276, subsample=0.9563046911335706; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.6229462387272339, colsample_bynode=0.9601058664657138, colsample_bytree=0.6498199391116954, gamma=0.00782673946834689, learning_rate=0.025202260542171437, max_delta_step=3, max_depth=13, min_child_weight=12, n_estimators=605, reg_alpha=0.38465180101943897, reg_lambda=0.638556323670433, scale_pos_weight=1.111888815683276, subsample=0.9563046911335706; total time=   3.9s\n",
      "[CV] END colsample_bylevel=0.8256287992875267, colsample_bynode=0.9654727869366945, colsample_bytree=0.6192082065967969, gamma=0.019538019563527523, learning_rate=0.00509161588310719, max_delta_step=5, max_depth=12, min_child_weight=5, n_estimators=1540, reg_alpha=1.9945551129532708, reg_lambda=2.77230005126179, scale_pos_weight=1.1658504448215, subsample=0.9970470474080131; total time=  15.1s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.8250732258254885, colsample_bytree=0.6, gamma=2.0, learning_rate=0.017997938375945485, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bylevel=0.6338004436618527, colsample_bynode=0.8358391687795322, colsample_bytree=0.8509651570552472, gamma=1.774596698647124, learning_rate=0.0012642284200513525, max_delta_step=5, max_depth=15, min_child_weight=2, n_estimators=2612, reg_alpha=2.9830239320387877, reg_lambda=0.0438300116240138, scale_pos_weight=1.1967450001905853, subsample=0.9782547396414123; total time=  26.8s\n",
      "[CV] END colsample_bylevel=0.6338004436618527, colsample_bynode=0.8358391687795322, colsample_bytree=0.8509651570552472, gamma=1.774596698647124, learning_rate=0.0012642284200513525, max_delta_step=5, max_depth=15, min_child_weight=2, n_estimators=2612, reg_alpha=2.9830239320387877, reg_lambda=0.0438300116240138, scale_pos_weight=1.1967450001905853, subsample=0.9782547396414123; total time=  18.5s\n",
      "[CV] END colsample_bylevel=0.6010300856271814, colsample_bynode=0.8965573748092919, colsample_bytree=0.9154200469404541, gamma=0.12112769121585235, learning_rate=0.0010271523932214696, max_delta_step=7, max_depth=7, min_child_weight=2, n_estimators=2976, reg_alpha=0.40395565723104887, reg_lambda=0.643016424477618, scale_pos_weight=1.181343972105119, subsample=0.8730904028252356; total time=  21.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:50:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:51:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.8256287992875267, colsample_bynode=0.9654727869366945, colsample_bytree=0.6192082065967969, gamma=0.019538019563527523, learning_rate=0.00509161588310719, max_delta_step=5, max_depth=12, min_child_weight=5, n_estimators=1540, reg_alpha=1.9945551129532708, reg_lambda=2.77230005126179, scale_pos_weight=1.1658504448215, subsample=0.9970470474080131; total time=  15.8s\n",
      "[CV] END colsample_bylevel=0.8256287992875267, colsample_bynode=0.9654727869366945, colsample_bytree=0.6192082065967969, gamma=0.019538019563527523, learning_rate=0.00509161588310719, max_delta_step=5, max_depth=12, min_child_weight=5, n_estimators=1540, reg_alpha=1.9945551129532708, reg_lambda=2.77230005126179, scale_pos_weight=1.1658504448215, subsample=0.9970470474080131; total time=   7.6s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.8250732258254885, colsample_bytree=0.6, gamma=2.0, learning_rate=0.017997938375945485, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=1.0; total time=   4.1s\n",
      "[CV] END colsample_bylevel=0.6338004436618527, colsample_bynode=0.8358391687795322, colsample_bytree=0.8509651570552472, gamma=1.774596698647124, learning_rate=0.0012642284200513525, max_delta_step=5, max_depth=15, min_child_weight=2, n_estimators=2612, reg_alpha=2.9830239320387877, reg_lambda=0.0438300116240138, scale_pos_weight=1.1967450001905853, subsample=0.9782547396414123; total time=  26.7s\n",
      "[CV] END colsample_bylevel=0.7318589818233534, colsample_bynode=0.752794124091841, colsample_bytree=0.6064557946069994, gamma=1.9617988064780607, learning_rate=0.004664068954879086, max_delta_step=9, max_depth=15, min_child_weight=13, n_estimators=2321, reg_alpha=0.06227389191807976, reg_lambda=1.1230720828040295, scale_pos_weight=0.8726451378579114, subsample=0.7407539227770299; total time=   8.1s\n",
      "[CV] END colsample_bylevel=0.7318589818233534, colsample_bynode=0.752794124091841, colsample_bytree=0.6064557946069994, gamma=1.9617988064780607, learning_rate=0.004664068954879086, max_delta_step=9, max_depth=15, min_child_weight=13, n_estimators=2321, reg_alpha=0.06227389191807976, reg_lambda=1.1230720828040295, scale_pos_weight=0.8726451378579114, subsample=0.7407539227770299; total time=   7.2s\n",
      "[CV] END colsample_bylevel=0.6010300856271814, colsample_bynode=0.8965573748092919, colsample_bytree=0.9154200469404541, gamma=0.12112769121585235, learning_rate=0.0010271523932214696, max_delta_step=7, max_depth=7, min_child_weight=2, n_estimators=2976, reg_alpha=0.40395565723104887, reg_lambda=0.643016424477618, scale_pos_weight=1.181343972105119, subsample=0.8730904028252356; total time=  22.0s\n",
      "[CV] END colsample_bylevel=0.7517728220468336, colsample_bynode=0.866464167707957, colsample_bytree=0.9421523683349787, gamma=0.1429115552841931, learning_rate=0.0018550652218404372, max_delta_step=4, max_depth=4, min_child_weight=14, n_estimators=1985, reg_alpha=0.029722034054998965, reg_lambda=0.6248411296721061, scale_pos_weight=0.8270823971921468, subsample=0.9005085239982015; total time=   6.8s\n",
      "[CV] END colsample_bylevel=0.7517728220468336, colsample_bynode=0.866464167707957, colsample_bytree=0.9421523683349787, gamma=0.1429115552841931, learning_rate=0.0018550652218404372, max_delta_step=4, max_depth=4, min_child_weight=14, n_estimators=1985, reg_alpha=0.029722034054998965, reg_lambda=0.6248411296721061, scale_pos_weight=0.8270823971921468, subsample=0.9005085239982015; total time=   6.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.0, learning_rate=0.001, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=0.7; total time=   9.0s\n",
      "[CV] END colsample_bylevel=0.6249101981366861, colsample_bynode=0.6417499979095366, colsample_bytree=0.9905276020613366, gamma=1.9677435539271961, learning_rate=0.035638260559013986, max_delta_step=1, max_depth=15, min_child_weight=1, n_estimators=2945, reg_alpha=0.021985432949321544, reg_lambda=1.761672643769806, scale_pos_weight=1.04381040288482, subsample=0.8388302343627552; total time=   6.4s\n",
      "[CV] END colsample_bylevel=0.6249101981366861, colsample_bynode=0.6417499979095366, colsample_bytree=0.9905276020613366, gamma=1.9677435539271961, learning_rate=0.035638260559013986, max_delta_step=1, max_depth=15, min_child_weight=1, n_estimators=2945, reg_alpha=0.021985432949321544, reg_lambda=1.761672643769806, scale_pos_weight=1.04381040288482, subsample=0.8388302343627552; total time=   4.5s\n",
      "[CV] END colsample_bylevel=0.9602838031640679, colsample_bynode=0.7394758886143243, colsample_bytree=0.7813523799480191, gamma=1.8332809334917124, learning_rate=0.09433159317817344, max_delta_step=4, max_depth=15, min_child_weight=10, n_estimators=2672, reg_alpha=2.6938234418268565, reg_lambda=1.9784042824977464, scale_pos_weight=1.0756371423363167, subsample=0.9713700153976069; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.00394789976347214, max_delta_step=6, max_depth=4, min_child_weight=9, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.2516616629187012, scale_pos_weight=0.8, subsample=1.0; total time=   5.8s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.9614612931359314, colsample_bytree=0.6, gamma=0.9204768055736312, learning_rate=0.004030678769699066, max_delta_step=10, max_depth=4, min_child_weight=8, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   6.4s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.9614612931359314, colsample_bytree=0.6, gamma=0.9204768055736312, learning_rate=0.004030678769699066, max_delta_step=10, max_depth=4, min_child_weight=8, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   7.5s\n",
      "[CV] END colsample_bylevel=0.6901971182437642, colsample_bynode=0.824853365329119, colsample_bytree=0.7391895749087618, gamma=1.9667205660355251, learning_rate=0.0010176050220125474, max_delta_step=8, max_depth=15, min_child_weight=8, n_estimators=1476, reg_alpha=0.17272008389022558, reg_lambda=2.7884529304862076, scale_pos_weight=1.110766797966305, subsample=0.8535943916445419; total time=   8.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7050182232229448, colsample_bytree=0.6, gamma=2.0, learning_rate=0.009686747314976062, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=1354, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.0183581848280083, subsample=0.7; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.6068361029872763, colsample_bynode=0.8198508237347564, colsample_bytree=0.9554580396281735, gamma=0.03851030135886125, learning_rate=0.006668339641989962, max_delta_step=1, max_depth=4, min_child_weight=15, n_estimators=2820, reg_alpha=2.6082480057681563, reg_lambda=0.6985656288359039, scale_pos_weight=1.178337224596226, subsample=0.7082207942075341; total time=   6.8s\n",
      "[CV] END colsample_bylevel=0.7076754763140614, colsample_bynode=0.8868433174003499, colsample_bytree=0.9941587532954389, gamma=1.866879730280912, learning_rate=0.029597300454890195, max_delta_step=4, max_depth=15, min_child_weight=14, n_estimators=1965, reg_alpha=2.857977428294917, reg_lambda=1.4237062587232279, scale_pos_weight=0.9308546516702704, subsample=0.8935365269250675; total time=   3.9s\n",
      "[CV] END colsample_bylevel=0.7076754763140614, colsample_bynode=0.8868433174003499, colsample_bytree=0.9941587532954389, gamma=1.866879730280912, learning_rate=0.029597300454890195, max_delta_step=4, max_depth=15, min_child_weight=14, n_estimators=1965, reg_alpha=2.857977428294917, reg_lambda=1.4237062587232279, scale_pos_weight=0.9308546516702704, subsample=0.8935365269250675; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.78607317324341, colsample_bynode=0.9119086035548003, colsample_bytree=0.611745424403072, gamma=0.7428288265747619, learning_rate=0.0034038781147346536, max_delta_step=3, max_depth=15, min_child_weight=12, n_estimators=680, reg_alpha=2.875051550347724, reg_lambda=1.1212600237731027, scale_pos_weight=0.8009300345203847, subsample=0.7187348425454448; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.8256287992875267, colsample_bynode=0.9654727869366945, colsample_bytree=0.6192082065967969, gamma=0.019538019563527523, learning_rate=0.00509161588310719, max_delta_step=5, max_depth=12, min_child_weight=5, n_estimators=1540, reg_alpha=1.9945551129532708, reg_lambda=2.77230005126179, scale_pos_weight=1.1658504448215, subsample=0.9970470474080131; total time=  16.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.8250732258254885, colsample_bytree=0.6, gamma=2.0, learning_rate=0.017997938375945485, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.8250732258254885, colsample_bytree=0.6, gamma=2.0, learning_rate=0.017997938375945485, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.6338004436618527, colsample_bynode=0.8358391687795322, colsample_bytree=0.8509651570552472, gamma=1.774596698647124, learning_rate=0.0012642284200513525, max_delta_step=5, max_depth=15, min_child_weight=2, n_estimators=2612, reg_alpha=2.9830239320387877, reg_lambda=0.0438300116240138, scale_pos_weight=1.1967450001905853, subsample=0.9782547396414123; total time=  26.7s\n",
      "[CV] END colsample_bylevel=0.7318589818233534, colsample_bynode=0.752794124091841, colsample_bytree=0.6064557946069994, gamma=1.9617988064780607, learning_rate=0.004664068954879086, max_delta_step=9, max_depth=15, min_child_weight=13, n_estimators=2321, reg_alpha=0.06227389191807976, reg_lambda=1.1230720828040295, scale_pos_weight=0.8726451378579114, subsample=0.7407539227770299; total time=   7.7s\n",
      "[CV] END colsample_bylevel=0.6010300856271814, colsample_bynode=0.8965573748092919, colsample_bytree=0.9154200469404541, gamma=0.12112769121585235, learning_rate=0.0010271523932214696, max_delta_step=7, max_depth=7, min_child_weight=2, n_estimators=2976, reg_alpha=0.40395565723104887, reg_lambda=0.643016424477618, scale_pos_weight=1.181343972105119, subsample=0.8730904028252356; total time=  21.9s\n",
      "[CV] END colsample_bylevel=0.7517728220468336, colsample_bynode=0.866464167707957, colsample_bytree=0.9421523683349787, gamma=0.1429115552841931, learning_rate=0.0018550652218404372, max_delta_step=4, max_depth=4, min_child_weight=14, n_estimators=1985, reg_alpha=0.029722034054998965, reg_lambda=0.6248411296721061, scale_pos_weight=0.8270823971921468, subsample=0.9005085239982015; total time=   6.7s\n",
      "[CV] END colsample_bylevel=0.7517728220468336, colsample_bynode=0.866464167707957, colsample_bytree=0.9421523683349787, gamma=0.1429115552841931, learning_rate=0.0018550652218404372, max_delta_step=4, max_depth=4, min_child_weight=14, n_estimators=1985, reg_alpha=0.029722034054998965, reg_lambda=0.6248411296721061, scale_pos_weight=0.8270823971921468, subsample=0.9005085239982015; total time=   6.7s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.0, learning_rate=0.001, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=0.7; total time=   9.0s\n",
      "[CV] END colsample_bylevel=0.6249101981366861, colsample_bynode=0.6417499979095366, colsample_bytree=0.9905276020613366, gamma=1.9677435539271961, learning_rate=0.035638260559013986, max_delta_step=1, max_depth=15, min_child_weight=1, n_estimators=2945, reg_alpha=0.021985432949321544, reg_lambda=1.761672643769806, scale_pos_weight=1.04381040288482, subsample=0.8388302343627552; total time=   6.7s\n",
      "[CV] END colsample_bylevel=0.8661310939812046, colsample_bynode=0.9248374424121059, colsample_bytree=0.6182014385847379, gamma=1.9761719269657005, learning_rate=0.09411510087112965, max_delta_step=1, max_depth=14, min_child_weight=12, n_estimators=1771, reg_alpha=2.895638504394922, reg_lambda=2.9811972953745274, scale_pos_weight=0.842780107626605, subsample=0.9474509448587037; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.9602838031640679, colsample_bynode=0.7394758886143243, colsample_bytree=0.7813523799480191, gamma=1.8332809334917124, learning_rate=0.09433159317817344, max_delta_step=4, max_depth=15, min_child_weight=10, n_estimators=2672, reg_alpha=2.6938234418268565, reg_lambda=1.9784042824977464, scale_pos_weight=1.0756371423363167, subsample=0.9713700153976069; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.9602838031640679, colsample_bynode=0.7394758886143243, colsample_bytree=0.7813523799480191, gamma=1.8332809334917124, learning_rate=0.09433159317817344, max_delta_step=4, max_depth=15, min_child_weight=10, n_estimators=2672, reg_alpha=2.6938234418268565, reg_lambda=1.9784042824977464, scale_pos_weight=1.0756371423363167, subsample=0.9713700153976069; total time=   2.6s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.00394789976347214, max_delta_step=6, max_depth=4, min_child_weight=9, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.2516616629187012, scale_pos_weight=0.8, subsample=1.0; total time=   5.7s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.00394789976347214, max_delta_step=6, max_depth=4, min_child_weight=9, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.2516616629187012, scale_pos_weight=0.8, subsample=1.0; total time=   5.6s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.9614612931359314, colsample_bytree=0.6, gamma=0.9204768055736312, learning_rate=0.004030678769699066, max_delta_step=10, max_depth=4, min_child_weight=8, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   7.4s\n",
      "[CV] END colsample_bylevel=0.6901971182437642, colsample_bynode=0.824853365329119, colsample_bytree=0.7391895749087618, gamma=1.9667205660355251, learning_rate=0.0010176050220125474, max_delta_step=8, max_depth=15, min_child_weight=8, n_estimators=1476, reg_alpha=0.17272008389022558, reg_lambda=2.7884529304862076, scale_pos_weight=1.110766797966305, subsample=0.8535943916445419; total time=   8.4s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7050182232229448, colsample_bytree=0.6, gamma=2.0, learning_rate=0.009686747314976062, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=1354, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.0183581848280083, subsample=0.7; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.6068361029872763, colsample_bynode=0.8198508237347564, colsample_bytree=0.9554580396281735, gamma=0.03851030135886125, learning_rate=0.006668339641989962, max_delta_step=1, max_depth=4, min_child_weight=15, n_estimators=2820, reg_alpha=2.6082480057681563, reg_lambda=0.6985656288359039, scale_pos_weight=1.178337224596226, subsample=0.7082207942075341; total time=   6.7s\n",
      "[CV] END colsample_bylevel=0.7076754763140614, colsample_bynode=0.8868433174003499, colsample_bytree=0.9941587532954389, gamma=1.866879730280912, learning_rate=0.029597300454890195, max_delta_step=4, max_depth=15, min_child_weight=14, n_estimators=1965, reg_alpha=2.857977428294917, reg_lambda=1.4237062587232279, scale_pos_weight=0.9308546516702704, subsample=0.8935365269250675; total time=   4.0s\n",
      "[CV] END colsample_bylevel=0.7076754763140614, colsample_bynode=0.8868433174003499, colsample_bytree=0.9941587532954389, gamma=1.866879730280912, learning_rate=0.029597300454890195, max_delta_step=4, max_depth=15, min_child_weight=14, n_estimators=1965, reg_alpha=2.857977428294917, reg_lambda=1.4237062587232279, scale_pos_weight=0.9308546516702704, subsample=0.8935365269250675; total time=   3.8s\n",
      "[CV] END colsample_bylevel=0.78607317324341, colsample_bynode=0.9119086035548003, colsample_bytree=0.611745424403072, gamma=0.7428288265747619, learning_rate=0.0034038781147346536, max_delta_step=3, max_depth=15, min_child_weight=12, n_estimators=680, reg_alpha=2.875051550347724, reg_lambda=1.1212600237731027, scale_pos_weight=0.8009300345203847, subsample=0.7187348425454448; total time=   3.4s\n",
      "[CV] END colsample_bylevel=0.6675000313433527, colsample_bynode=0.9008421695284963, colsample_bytree=0.60561552067792, gamma=0.15802806306265296, learning_rate=0.03656649954192327, max_delta_step=4, max_depth=4, min_child_weight=6, n_estimators=564, reg_alpha=2.9784841695406126, reg_lambda=2.2523170716204346, scale_pos_weight=1.1550409969712567, subsample=0.8225880058928153; total time=   1.3sFitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:52:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.8250732258254885, colsample_bytree=0.6, gamma=2.0, learning_rate=0.017997938375945485, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bylevel=0.6338004436618527, colsample_bynode=0.8358391687795322, colsample_bytree=0.8509651570552472, gamma=1.774596698647124, learning_rate=0.0012642284200513525, max_delta_step=5, max_depth=15, min_child_weight=2, n_estimators=2612, reg_alpha=2.9830239320387877, reg_lambda=0.0438300116240138, scale_pos_weight=1.1967450001905853, subsample=0.9782547396414123; total time=  27.0s\n",
      "[CV] END colsample_bylevel=0.7318589818233534, colsample_bynode=0.752794124091841, colsample_bytree=0.6064557946069994, gamma=1.9617988064780607, learning_rate=0.004664068954879086, max_delta_step=9, max_depth=15, min_child_weight=13, n_estimators=2321, reg_alpha=0.06227389191807976, reg_lambda=1.1230720828040295, scale_pos_weight=0.8726451378579114, subsample=0.7407539227770299; total time=   7.8s\n",
      "[CV] END colsample_bylevel=0.7318589818233534, colsample_bynode=0.752794124091841, colsample_bytree=0.6064557946069994, gamma=1.9617988064780607, learning_rate=0.004664068954879086, max_delta_step=9, max_depth=15, min_child_weight=13, n_estimators=2321, reg_alpha=0.06227389191807976, reg_lambda=1.1230720828040295, scale_pos_weight=0.8726451378579114, subsample=0.7407539227770299; total time=   7.2s\n",
      "[CV] END colsample_bylevel=0.6010300856271814, colsample_bynode=0.8965573748092919, colsample_bytree=0.9154200469404541, gamma=0.12112769121585235, learning_rate=0.0010271523932214696, max_delta_step=7, max_depth=7, min_child_weight=2, n_estimators=2976, reg_alpha=0.40395565723104887, reg_lambda=0.643016424477618, scale_pos_weight=1.181343972105119, subsample=0.8730904028252356; total time=  21.9s\n",
      "[CV] END colsample_bylevel=0.7517728220468336, colsample_bynode=0.866464167707957, colsample_bytree=0.9421523683349787, gamma=0.1429115552841931, learning_rate=0.0018550652218404372, max_delta_step=4, max_depth=4, min_child_weight=14, n_estimators=1985, reg_alpha=0.029722034054998965, reg_lambda=0.6248411296721061, scale_pos_weight=0.8270823971921468, subsample=0.9005085239982015; total time=   6.7s\n",
      "[CV] END colsample_bylevel=0.7517728220468336, colsample_bynode=0.866464167707957, colsample_bytree=0.9421523683349787, gamma=0.1429115552841931, learning_rate=0.0018550652218404372, max_delta_step=4, max_depth=4, min_child_weight=14, n_estimators=1985, reg_alpha=0.029722034054998965, reg_lambda=0.6248411296721061, scale_pos_weight=0.8270823971921468, subsample=0.9005085239982015; total time=   6.6s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.0, learning_rate=0.001, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=0.7; total time=   9.0s\n",
      "[CV] END colsample_bylevel=0.6249101981366861, colsample_bynode=0.6417499979095366, colsample_bytree=0.9905276020613366, gamma=1.9677435539271961, learning_rate=0.035638260559013986, max_delta_step=1, max_depth=15, min_child_weight=1, n_estimators=2945, reg_alpha=0.021985432949321544, reg_lambda=1.761672643769806, scale_pos_weight=1.04381040288482, subsample=0.8388302343627552; total time=   6.7s\n",
      "[CV] END colsample_bylevel=0.8661310939812046, colsample_bynode=0.9248374424121059, colsample_bytree=0.6182014385847379, gamma=1.9761719269657005, learning_rate=0.09411510087112965, max_delta_step=1, max_depth=14, min_child_weight=12, n_estimators=1771, reg_alpha=2.895638504394922, reg_lambda=2.9811972953745274, scale_pos_weight=0.842780107626605, subsample=0.9474509448587037; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.8661310939812046, colsample_bynode=0.9248374424121059, colsample_bytree=0.6182014385847379, gamma=1.9761719269657005, learning_rate=0.09411510087112965, max_delta_step=1, max_depth=14, min_child_weight=12, n_estimators=1771, reg_alpha=2.895638504394922, reg_lambda=2.9811972953745274, scale_pos_weight=0.842780107626605, subsample=0.9474509448587037; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.9602838031640679, colsample_bynode=0.7394758886143243, colsample_bytree=0.7813523799480191, gamma=1.8332809334917124, learning_rate=0.09433159317817344, max_delta_step=4, max_depth=15, min_child_weight=10, n_estimators=2672, reg_alpha=2.6938234418268565, reg_lambda=1.9784042824977464, scale_pos_weight=1.0756371423363167, subsample=0.9713700153976069; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.00394789976347214, max_delta_step=6, max_depth=4, min_child_weight=9, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.2516616629187012, scale_pos_weight=0.8, subsample=1.0; total time=   5.8s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.9614612931359314, colsample_bytree=0.6, gamma=0.9204768055736312, learning_rate=0.004030678769699066, max_delta_step=10, max_depth=4, min_child_weight=8, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   6.4s\n",
      "[CV] END colsample_bylevel=0.6901971182437642, colsample_bynode=0.824853365329119, colsample_bytree=0.7391895749087618, gamma=1.9667205660355251, learning_rate=0.0010176050220125474, max_delta_step=8, max_depth=15, min_child_weight=8, n_estimators=1476, reg_alpha=0.17272008389022558, reg_lambda=2.7884529304862076, scale_pos_weight=1.110766797966305, subsample=0.8535943916445419; total time=   8.2s\n",
      "[CV] END colsample_bylevel=0.6901971182437642, colsample_bynode=0.824853365329119, colsample_bytree=0.7391895749087618, gamma=1.9667205660355251, learning_rate=0.0010176050220125474, max_delta_step=8, max_depth=15, min_child_weight=8, n_estimators=1476, reg_alpha=0.17272008389022558, reg_lambda=2.7884529304862076, scale_pos_weight=1.110766797966305, subsample=0.8535943916445419; total time=   8.0s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7050182232229448, colsample_bytree=0.6, gamma=2.0, learning_rate=0.009686747314976062, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=1354, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.0183581848280083, subsample=0.7; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.6068361029872763, colsample_bynode=0.8198508237347564, colsample_bytree=0.9554580396281735, gamma=0.03851030135886125, learning_rate=0.006668339641989962, max_delta_step=1, max_depth=4, min_child_weight=15, n_estimators=2820, reg_alpha=2.6082480057681563, reg_lambda=0.6985656288359039, scale_pos_weight=1.178337224596226, subsample=0.7082207942075341; total time=   6.6s\n",
      "[CV] END colsample_bylevel=0.6068361029872763, colsample_bynode=0.8198508237347564, colsample_bytree=0.9554580396281735, gamma=0.03851030135886125, learning_rate=0.006668339641989962, max_delta_step=1, max_depth=4, min_child_weight=15, n_estimators=2820, reg_alpha=2.6082480057681563, reg_lambda=0.6985656288359039, scale_pos_weight=1.178337224596226, subsample=0.7082207942075341; total time=   7.6s\n",
      "[CV] END colsample_bylevel=0.78607317324341, colsample_bynode=0.9119086035548003, colsample_bytree=0.611745424403072, gamma=0.7428288265747619, learning_rate=0.0034038781147346536, max_delta_step=3, max_depth=15, min_child_weight=12, n_estimators=680, reg_alpha=2.875051550347724, reg_lambda=1.1212600237731027, scale_pos_weight=0.8009300345203847, subsample=0.7187348425454448; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.78607317324341, colsample_bynode=0.9119086035548003, colsample_bytree=0.611745424403072, gamma=0.7428288265747619, learning_rate=0.0034038781147346536, max_delta_step=3, max_depth=15, min_child_weight=12, n_estimators=680, reg_alpha=2.875051550347724, reg_lambda=1.1212600237731027, scale_pos_weight=0.8009300345203847, subsample=0.7187348425454448; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.7281538580252533, colsample_bynode=0.6805558296769407, colsample_bytree=0.9353515839436878, gamma=1.1136248221318752, learning_rate=0.005817697013060812, max_delta_step=10, max_depth=6, min_child_weight=12, n_estimators=522, reg_alpha=2.8053757478891264, reg_lambda=1.211241563805959, scale_pos_weight=1.051817148643392, subsample=0.7567233571429313; total time=   2.7s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.7517728220468336, colsample_bynode=0.866464167707957, colsample_bytree=0.9421523683349787, gamma=0.1429115552841931, learning_rate=0.0018550652218404372, max_delta_step=4, max_depth=4, min_child_weight=14, n_estimators=1985, reg_alpha=0.029722034054998965, reg_lambda=0.6248411296721061, scale_pos_weight=0.8270823971921468, subsample=0.9005085239982015; total time=   6.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.0, learning_rate=0.001, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=0.7; total time=   9.0s\n",
      "[CV] END colsample_bylevel=0.6249101981366861, colsample_bynode=0.6417499979095366, colsample_bytree=0.9905276020613366, gamma=1.9677435539271961, learning_rate=0.035638260559013986, max_delta_step=1, max_depth=15, min_child_weight=1, n_estimators=2945, reg_alpha=0.021985432949321544, reg_lambda=1.761672643769806, scale_pos_weight=1.04381040288482, subsample=0.8388302343627552; total time=   6.7s\n",
      "[CV] END colsample_bylevel=0.8661310939812046, colsample_bynode=0.9248374424121059, colsample_bytree=0.6182014385847379, gamma=1.9761719269657005, learning_rate=0.09411510087112965, max_delta_step=1, max_depth=14, min_child_weight=12, n_estimators=1771, reg_alpha=2.895638504394922, reg_lambda=2.9811972953745274, scale_pos_weight=0.842780107626605, subsample=0.9474509448587037; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.9602838031640679, colsample_bynode=0.7394758886143243, colsample_bytree=0.7813523799480191, gamma=1.8332809334917124, learning_rate=0.09433159317817344, max_delta_step=4, max_depth=15, min_child_weight=10, n_estimators=2672, reg_alpha=2.6938234418268565, reg_lambda=1.9784042824977464, scale_pos_weight=1.0756371423363167, subsample=0.9713700153976069; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.9602838031640679, colsample_bynode=0.7394758886143243, colsample_bytree=0.7813523799480191, gamma=1.8332809334917124, learning_rate=0.09433159317817344, max_delta_step=4, max_depth=15, min_child_weight=10, n_estimators=2672, reg_alpha=2.6938234418268565, reg_lambda=1.9784042824977464, scale_pos_weight=1.0756371423363167, subsample=0.9713700153976069; total time=   2.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.00394789976347214, max_delta_step=6, max_depth=4, min_child_weight=9, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.2516616629187012, scale_pos_weight=0.8, subsample=1.0; total time=   5.7s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.00394789976347214, max_delta_step=6, max_depth=4, min_child_weight=9, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.2516616629187012, scale_pos_weight=0.8, subsample=1.0; total time=   5.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.9614612931359314, colsample_bytree=0.6, gamma=0.9204768055736312, learning_rate=0.004030678769699066, max_delta_step=10, max_depth=4, min_child_weight=8, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   7.5s\n",
      "[CV] END colsample_bylevel=0.6901971182437642, colsample_bynode=0.824853365329119, colsample_bytree=0.7391895749087618, gamma=1.9667205660355251, learning_rate=0.0010176050220125474, max_delta_step=8, max_depth=15, min_child_weight=8, n_estimators=1476, reg_alpha=0.17272008389022558, reg_lambda=2.7884529304862076, scale_pos_weight=1.110766797966305, subsample=0.8535943916445419; total time=   8.4s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7050182232229448, colsample_bytree=0.6, gamma=2.0, learning_rate=0.009686747314976062, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=1354, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.0183581848280083, subsample=0.7; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.6068361029872763, colsample_bynode=0.8198508237347564, colsample_bytree=0.9554580396281735, gamma=0.03851030135886125, learning_rate=0.006668339641989962, max_delta_step=1, max_depth=4, min_child_weight=15, n_estimators=2820, reg_alpha=2.6082480057681563, reg_lambda=0.6985656288359039, scale_pos_weight=1.178337224596226, subsample=0.7082207942075341; total time=   6.8s\n",
      "[CV] END colsample_bylevel=0.7076754763140614, colsample_bynode=0.8868433174003499, colsample_bytree=0.9941587532954389, gamma=1.866879730280912, learning_rate=0.029597300454890195, max_delta_step=4, max_depth=15, min_child_weight=14, n_estimators=1965, reg_alpha=2.857977428294917, reg_lambda=1.4237062587232279, scale_pos_weight=0.9308546516702704, subsample=0.8935365269250675; total time=   4.0s\n",
      "[CV] END colsample_bylevel=0.7076754763140614, colsample_bynode=0.8868433174003499, colsample_bytree=0.9941587532954389, gamma=1.866879730280912, learning_rate=0.029597300454890195, max_delta_step=4, max_depth=15, min_child_weight=14, n_estimators=1965, reg_alpha=2.857977428294917, reg_lambda=1.4237062587232279, scale_pos_weight=0.9308546516702704, subsample=0.8935365269250675; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.78607317324341, colsample_bynode=0.9119086035548003, colsample_bytree=0.611745424403072, gamma=0.7428288265747619, learning_rate=0.0034038781147346536, max_delta_step=3, max_depth=15, min_child_weight=12, n_estimators=680, reg_alpha=2.875051550347724, reg_lambda=1.1212600237731027, scale_pos_weight=0.8009300345203847, subsample=0.7187348425454448; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.6675000313433527, colsample_bynode=0.9008421695284963, colsample_bytree=0.60561552067792, gamma=0.15802806306265296, learning_rate=0.03656649954192327, max_delta_step=4, max_depth=4, min_child_weight=6, n_estimators=564, reg_alpha=2.9784841695406126, reg_lambda=2.2523170716204346, scale_pos_weight=1.1550409969712567, subsample=0.8225880058928153; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.6675000313433527, colsample_bynode=0.9008421695284963, colsample_bytree=0.60561552067792, gamma=0.15802806306265296, learning_rate=0.03656649954192327, max_delta_step=4, max_depth=4, min_child_weight=6, n_estimators=564, reg_alpha=2.9784841695406126, reg_lambda=2.2523170716204346, scale_pos_weight=1.1550409969712567, subsample=0.8225880058928153; total time=   1.6s\n",
      "[CV] END colsample_bylevel=0.7281538580252533, colsample_bynode=0.6805558296769407, colsample_bytree=0.9353515839436878, gamma=1.1136248221318752, learning_rate=0.005817697013060812, max_delta_step=10, max_depth=6, min_child_weight=12, n_estimators=522, reg_alpha=2.8053757478891264, reg_lambda=1.211241563805959, scale_pos_weight=1.051817148643392, subsample=0.7567233571429313; total time=   2.6s\n",
      "[CV] END colsample_bylevel=0.8396228324365845, colsample_bynode=0.6388173948126993, colsample_bytree=0.7081449018709958, gamma=1.98381584140394, learning_rate=0.006658985448726347, max_delta_step=2, max_depth=14, min_child_weight=12, n_estimators=682, reg_alpha=0.02804951915936727, reg_lambda=2.4167686314224746, scale_pos_weight=0.8101078196910982, subsample=0.8905399700512685; total time=   2.6s\n",
      "[CV] END colsample_bylevel=0.8396228324365845, colsample_bynode=0.6388173948126993, colsample_bytree=0.7081449018709958, gamma=1.98381584140394, learning_rate=0.006658985448726347, max_delta_step=2, max_depth=14, min_child_weight=12, n_estimators=682, reg_alpha=0.02804951915936727, reg_lambda=2.4167686314224746, scale_pos_weight=0.8101078196910982, subsample=0.8905399700512685; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.7603737077398374, colsample_bynode=1.0, colsample_bytree=0.6, gamma=1.713397583364906, learning_rate=0.02045131518705028, max_delta_step=2, max_depth=4, min_child_weight=9, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   5.7s\n",
      "[CV] END colsample_bylevel=0.9131257619095126, colsample_bynode=0.6341249216690007, colsample_bytree=0.9936675155445983, gamma=0.0857942676485748, learning_rate=0.09481663486224755, max_delta_step=7, max_depth=15, min_child_weight=3, n_estimators=548, reg_alpha=2.4610959455164734, reg_lambda=2.6124094668159477, scale_pos_weight=1.0940675942646385, subsample=0.8595823133915781; total time=   3.9s\n",
      "[CV] END colsample_bylevel=0.9496495710520071, colsample_bynode=0.7297548347921033, colsample_bytree=0.6729551572186834, gamma=0.35894132306677556, learning_rate=0.008217533888141244, max_delta_step=7, max_depth=15, min_child_weight=9, n_estimators=2956, reg_alpha=2.9634734275917465, reg_lambda=0.9536283864182313, scale_pos_weight=0.8133759404527321, subsample=0.7208362598703725; total time=  14.7sFitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.6010300856271814, colsample_bynode=0.8965573748092919, colsample_bytree=0.9154200469404541, gamma=0.12112769121585235, learning_rate=0.0010271523932214696, max_delta_step=7, max_depth=7, min_child_weight=2, n_estimators=2976, reg_alpha=0.40395565723104887, reg_lambda=0.643016424477618, scale_pos_weight=1.181343972105119, subsample=0.8730904028252356; total time=  22.4s\n",
      "[CV] END colsample_bylevel=0.7517728220468336, colsample_bynode=0.866464167707957, colsample_bytree=0.9421523683349787, gamma=0.1429115552841931, learning_rate=0.0018550652218404372, max_delta_step=4, max_depth=4, min_child_weight=14, n_estimators=1985, reg_alpha=0.029722034054998965, reg_lambda=0.6248411296721061, scale_pos_weight=0.8270823971921468, subsample=0.9005085239982015; total time=   6.9s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.0, learning_rate=0.001, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=0.7; total time=   8.7s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.0, learning_rate=0.001, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=0.7; total time=   8.0s\n",
      "[CV] END colsample_bylevel=0.6249101981366861, colsample_bynode=0.6417499979095366, colsample_bytree=0.9905276020613366, gamma=1.9677435539271961, learning_rate=0.035638260559013986, max_delta_step=1, max_depth=15, min_child_weight=1, n_estimators=2945, reg_alpha=0.021985432949321544, reg_lambda=1.761672643769806, scale_pos_weight=1.04381040288482, subsample=0.8388302343627552; total time=   6.5s\n",
      "[CV] END colsample_bylevel=0.6249101981366861, colsample_bynode=0.6417499979095366, colsample_bytree=0.9905276020613366, gamma=1.9677435539271961, learning_rate=0.035638260559013986, max_delta_step=1, max_depth=15, min_child_weight=1, n_estimators=2945, reg_alpha=0.021985432949321544, reg_lambda=1.761672643769806, scale_pos_weight=1.04381040288482, subsample=0.8388302343627552; total time=   4.4s\n",
      "[CV] END colsample_bylevel=0.9602838031640679, colsample_bynode=0.7394758886143243, colsample_bytree=0.7813523799480191, gamma=1.8332809334917124, learning_rate=0.09433159317817344, max_delta_step=4, max_depth=15, min_child_weight=10, n_estimators=2672, reg_alpha=2.6938234418268565, reg_lambda=1.9784042824977464, scale_pos_weight=1.0756371423363167, subsample=0.9713700153976069; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.00394789976347214, max_delta_step=6, max_depth=4, min_child_weight=9, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.2516616629187012, scale_pos_weight=0.8, subsample=1.0; total time=   5.9s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.9614612931359314, colsample_bytree=0.6, gamma=0.9204768055736312, learning_rate=0.004030678769699066, max_delta_step=10, max_depth=4, min_child_weight=8, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   6.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.9614612931359314, colsample_bytree=0.6, gamma=0.9204768055736312, learning_rate=0.004030678769699066, max_delta_step=10, max_depth=4, min_child_weight=8, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   7.7s\n",
      "[CV] END colsample_bylevel=0.6901971182437642, colsample_bynode=0.824853365329119, colsample_bytree=0.7391895749087618, gamma=1.9667205660355251, learning_rate=0.0010176050220125474, max_delta_step=8, max_depth=15, min_child_weight=8, n_estimators=1476, reg_alpha=0.17272008389022558, reg_lambda=2.7884529304862076, scale_pos_weight=1.110766797966305, subsample=0.8535943916445419; total time=   8.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7050182232229448, colsample_bytree=0.6, gamma=2.0, learning_rate=0.009686747314976062, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=1354, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.0183581848280083, subsample=0.7; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.6068361029872763, colsample_bynode=0.8198508237347564, colsample_bytree=0.9554580396281735, gamma=0.03851030135886125, learning_rate=0.006668339641989962, max_delta_step=1, max_depth=4, min_child_weight=15, n_estimators=2820, reg_alpha=2.6082480057681563, reg_lambda=0.6985656288359039, scale_pos_weight=1.178337224596226, subsample=0.7082207942075341; total time=   6.6s\n",
      "[CV] END colsample_bylevel=0.6068361029872763, colsample_bynode=0.8198508237347564, colsample_bytree=0.9554580396281735, gamma=0.03851030135886125, learning_rate=0.006668339641989962, max_delta_step=1, max_depth=4, min_child_weight=15, n_estimators=2820, reg_alpha=2.6082480057681563, reg_lambda=0.6985656288359039, scale_pos_weight=1.178337224596226, subsample=0.7082207942075341; total time=   7.8s\n",
      "[CV] END colsample_bylevel=0.78607317324341, colsample_bynode=0.9119086035548003, colsample_bytree=0.611745424403072, gamma=0.7428288265747619, learning_rate=0.0034038781147346536, max_delta_step=3, max_depth=15, min_child_weight=12, n_estimators=680, reg_alpha=2.875051550347724, reg_lambda=1.1212600237731027, scale_pos_weight=0.8009300345203847, subsample=0.7187348425454448; total time=   3.4s\n",
      "[CV] END colsample_bylevel=0.6675000313433527, colsample_bynode=0.9008421695284963, colsample_bytree=0.60561552067792, gamma=0.15802806306265296, learning_rate=0.03656649954192327, max_delta_step=4, max_depth=4, min_child_weight=6, n_estimators=564, reg_alpha=2.9784841695406126, reg_lambda=2.2523170716204346, scale_pos_weight=1.1550409969712567, subsample=0.8225880058928153; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.6675000313433527, colsample_bynode=0.9008421695284963, colsample_bytree=0.60561552067792, gamma=0.15802806306265296, learning_rate=0.03656649954192327, max_delta_step=4, max_depth=4, min_child_weight=6, n_estimators=564, reg_alpha=2.9784841695406126, reg_lambda=2.2523170716204346, scale_pos_weight=1.1550409969712567, subsample=0.8225880058928153; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.7281538580252533, colsample_bynode=0.6805558296769407, colsample_bytree=0.9353515839436878, gamma=1.1136248221318752, learning_rate=0.005817697013060812, max_delta_step=10, max_depth=6, min_child_weight=12, n_estimators=522, reg_alpha=2.8053757478891264, reg_lambda=1.211241563805959, scale_pos_weight=1.051817148643392, subsample=0.7567233571429313; total time=   2.7s\n",
      "[CV] END colsample_bylevel=0.8396228324365845, colsample_bynode=0.6388173948126993, colsample_bytree=0.7081449018709958, gamma=1.98381584140394, learning_rate=0.006658985448726347, max_delta_step=2, max_depth=14, min_child_weight=12, n_estimators=682, reg_alpha=0.02804951915936727, reg_lambda=2.4167686314224746, scale_pos_weight=0.8101078196910982, subsample=0.8905399700512685; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.7603737077398374, colsample_bynode=1.0, colsample_bytree=0.6, gamma=1.713397583364906, learning_rate=0.02045131518705028, max_delta_step=2, max_depth=4, min_child_weight=9, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bylevel=0.9131257619095126, colsample_bynode=0.6341249216690007, colsample_bytree=0.9936675155445983, gamma=0.0857942676485748, learning_rate=0.09481663486224755, max_delta_step=7, max_depth=15, min_child_weight=3, n_estimators=548, reg_alpha=2.4610959455164734, reg_lambda=2.6124094668159477, scale_pos_weight=1.0940675942646385, subsample=0.8595823133915781; total time=   5.7s\n",
      "[CV] END colsample_bylevel=0.9496495710520071, colsample_bynode=0.7297548347921033, colsample_bytree=0.6729551572186834, gamma=0.35894132306677556, learning_rate=0.008217533888141244, max_delta_step=7, max_depth=15, min_child_weight=9, n_estimators=2956, reg_alpha=2.9634734275917465, reg_lambda=0.9536283864182313, scale_pos_weight=0.8133759404527321, subsample=0.7208362598703725; total time=  14.6s\n",
      "[CV] END colsample_bylevel=0.9496495710520071, colsample_bynode=0.7297548347921033, colsample_bytree=0.6729551572186834, gamma=0.35894132306677556, learning_rate=0.008217533888141244, max_delta_step=7, max_depth=15, min_child_weight=9, n_estimators=2956, reg_alpha=2.9634734275917465, reg_lambda=0.9536283864182313, scale_pos_weight=0.8133759404527321, subsample=0.7208362598703725; total time=  16.1s\n",
      "[CV] END colsample_bylevel=0.6010300856271814, colsample_bynode=0.8965573748092919, colsample_bytree=0.9154200469404541, gamma=0.12112769121585235, learning_rate=0.0010271523932214696, max_delta_step=7, max_depth=7, min_child_weight=2, n_estimators=2976, reg_alpha=0.40395565723104887, reg_lambda=0.643016424477618, scale_pos_weight=1.181343972105119, subsample=0.8730904028252356; total time=  22.1s\n",
      "[CV] END colsample_bylevel=0.7517728220468336, colsample_bynode=0.866464167707957, colsample_bytree=0.9421523683349787, gamma=0.1429115552841931, learning_rate=0.0018550652218404372, max_delta_step=4, max_depth=4, min_child_weight=14, n_estimators=1985, reg_alpha=0.029722034054998965, reg_lambda=0.6248411296721061, scale_pos_weight=0.8270823971921468, subsample=0.9005085239982015; total time=   6.8s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.0, learning_rate=0.001, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=0.7; total time=   9.0s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.0, learning_rate=0.001, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=0.7; total time=   8.0s\n",
      "[CV] END colsample_bylevel=0.6249101981366861, colsample_bynode=0.6417499979095366, colsample_bytree=0.9905276020613366, gamma=1.9677435539271961, learning_rate=0.035638260559013986, max_delta_step=1, max_depth=15, min_child_weight=1, n_estimators=2945, reg_alpha=0.021985432949321544, reg_lambda=1.761672643769806, scale_pos_weight=1.04381040288482, subsample=0.8388302343627552; total time=   6.7s\n",
      "[CV] END colsample_bylevel=0.8661310939812046, colsample_bynode=0.9248374424121059, colsample_bytree=0.6182014385847379, gamma=1.9761719269657005, learning_rate=0.09411510087112965, max_delta_step=1, max_depth=14, min_child_weight=12, n_estimators=1771, reg_alpha=2.895638504394922, reg_lambda=2.9811972953745274, scale_pos_weight=0.842780107626605, subsample=0.9474509448587037; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.8661310939812046, colsample_bynode=0.9248374424121059, colsample_bytree=0.6182014385847379, gamma=1.9761719269657005, learning_rate=0.09411510087112965, max_delta_step=1, max_depth=14, min_child_weight=12, n_estimators=1771, reg_alpha=2.895638504394922, reg_lambda=2.9811972953745274, scale_pos_weight=0.842780107626605, subsample=0.9474509448587037; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.9602838031640679, colsample_bynode=0.7394758886143243, colsample_bytree=0.7813523799480191, gamma=1.8332809334917124, learning_rate=0.09433159317817344, max_delta_step=4, max_depth=15, min_child_weight=10, n_estimators=2672, reg_alpha=2.6938234418268565, reg_lambda=1.9784042824977464, scale_pos_weight=1.0756371423363167, subsample=0.9713700153976069; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.00394789976347214, max_delta_step=6, max_depth=4, min_child_weight=9, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.2516616629187012, scale_pos_weight=0.8, subsample=1.0; total time=   5.8s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.9614612931359314, colsample_bytree=0.6, gamma=0.9204768055736312, learning_rate=0.004030678769699066, max_delta_step=10, max_depth=4, min_child_weight=8, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   6.3s\n",
      "[CV] END colsample_bylevel=0.6901971182437642, colsample_bynode=0.824853365329119, colsample_bytree=0.7391895749087618, gamma=1.9667205660355251, learning_rate=0.0010176050220125474, max_delta_step=8, max_depth=15, min_child_weight=8, n_estimators=1476, reg_alpha=0.17272008389022558, reg_lambda=2.7884529304862076, scale_pos_weight=1.110766797966305, subsample=0.8535943916445419; total time=   8.2s\n",
      "[CV] END colsample_bylevel=0.6901971182437642, colsample_bynode=0.824853365329119, colsample_bytree=0.7391895749087618, gamma=1.9667205660355251, learning_rate=0.0010176050220125474, max_delta_step=8, max_depth=15, min_child_weight=8, n_estimators=1476, reg_alpha=0.17272008389022558, reg_lambda=2.7884529304862076, scale_pos_weight=1.110766797966305, subsample=0.8535943916445419; total time=   8.1s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7050182232229448, colsample_bytree=0.6, gamma=2.0, learning_rate=0.009686747314976062, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=1354, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.0183581848280083, subsample=0.7; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.6068361029872763, colsample_bynode=0.8198508237347564, colsample_bytree=0.9554580396281735, gamma=0.03851030135886125, learning_rate=0.006668339641989962, max_delta_step=1, max_depth=4, min_child_weight=15, n_estimators=2820, reg_alpha=2.6082480057681563, reg_lambda=0.6985656288359039, scale_pos_weight=1.178337224596226, subsample=0.7082207942075341; total time=   6.8s\n",
      "[CV] END colsample_bylevel=0.7076754763140614, colsample_bynode=0.8868433174003499, colsample_bytree=0.9941587532954389, gamma=1.866879730280912, learning_rate=0.029597300454890195, max_delta_step=4, max_depth=15, min_child_weight=14, n_estimators=1965, reg_alpha=2.857977428294917, reg_lambda=1.4237062587232279, scale_pos_weight=0.9308546516702704, subsample=0.8935365269250675; total time=   4.0s\n",
      "[CV] END colsample_bylevel=0.7076754763140614, colsample_bynode=0.8868433174003499, colsample_bytree=0.9941587532954389, gamma=1.866879730280912, learning_rate=0.029597300454890195, max_delta_step=4, max_depth=15, min_child_weight=14, n_estimators=1965, reg_alpha=2.857977428294917, reg_lambda=1.4237062587232279, scale_pos_weight=0.9308546516702704, subsample=0.8935365269250675; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.78607317324341, colsample_bynode=0.9119086035548003, colsample_bytree=0.611745424403072, gamma=0.7428288265747619, learning_rate=0.0034038781147346536, max_delta_step=3, max_depth=15, min_child_weight=12, n_estimators=680, reg_alpha=2.875051550347724, reg_lambda=1.1212600237731027, scale_pos_weight=0.8009300345203847, subsample=0.7187348425454448; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.6675000313433527, colsample_bynode=0.9008421695284963, colsample_bytree=0.60561552067792, gamma=0.15802806306265296, learning_rate=0.03656649954192327, max_delta_step=4, max_depth=4, min_child_weight=6, n_estimators=564, reg_alpha=2.9784841695406126, reg_lambda=2.2523170716204346, scale_pos_weight=1.1550409969712567, subsample=0.8225880058928153; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.7281538580252533, colsample_bynode=0.6805558296769407, colsample_bytree=0.9353515839436878, gamma=1.1136248221318752, learning_rate=0.005817697013060812, max_delta_step=10, max_depth=6, min_child_weight=12, n_estimators=522, reg_alpha=2.8053757478891264, reg_lambda=1.211241563805959, scale_pos_weight=1.051817148643392, subsample=0.7567233571429313; total time=   2.6s\n",
      "[CV] END colsample_bylevel=0.7281538580252533, colsample_bynode=0.6805558296769407, colsample_bytree=0.9353515839436878, gamma=1.1136248221318752, learning_rate=0.005817697013060812, max_delta_step=10, max_depth=6, min_child_weight=12, n_estimators=522, reg_alpha=2.8053757478891264, reg_lambda=1.211241563805959, scale_pos_weight=1.051817148643392, subsample=0.7567233571429313; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.8396228324365845, colsample_bynode=0.6388173948126993, colsample_bytree=0.7081449018709958, gamma=1.98381584140394, learning_rate=0.006658985448726347, max_delta_step=2, max_depth=14, min_child_weight=12, n_estimators=682, reg_alpha=0.02804951915936727, reg_lambda=2.4167686314224746, scale_pos_weight=0.8101078196910982, subsample=0.8905399700512685; total time=   2.7s\n",
      "[CV] END colsample_bylevel=0.7603737077398374, colsample_bynode=1.0, colsample_bytree=0.6, gamma=1.713397583364906, learning_rate=0.02045131518705028, max_delta_step=2, max_depth=4, min_child_weight=9, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bylevel=0.7603737077398374, colsample_bynode=1.0, colsample_bytree=0.6, gamma=1.713397583364906, learning_rate=0.02045131518705028, max_delta_step=2, max_depth=4, min_child_weight=9, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   5.3s\n",
      "[CV] END colsample_bylevel=0.6010300856271814, colsample_bynode=0.8965573748092919, colsample_bytree=0.9154200469404541, gamma=0.12112769121585235, learning_rate=0.0010271523932214696, max_delta_step=7, max_depth=7, min_child_weight=2, n_estimators=2976, reg_alpha=0.40395565723104887, reg_lambda=0.643016424477618, scale_pos_weight=1.181343972105119, subsample=0.8730904028252356; total time=  21.7s\n",
      "[CV] END colsample_bylevel=0.6010300856271814, colsample_bynode=0.8965573748092919, colsample_bytree=0.9154200469404541, gamma=0.12112769121585235, learning_rate=0.0010271523932214696, max_delta_step=7, max_depth=7, min_child_weight=2, n_estimators=2976, reg_alpha=0.40395565723104887, reg_lambda=0.643016424477618, scale_pos_weight=1.181343972105119, subsample=0.8730904028252356; total time=  20.8s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.0, learning_rate=0.001, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=0.7; total time=   5.8s\n",
      "[CV] END colsample_bylevel=0.6249101981366861, colsample_bynode=0.6417499979095366, colsample_bytree=0.9905276020613366, gamma=1.9677435539271961, learning_rate=0.035638260559013986, max_delta_step=1, max_depth=15, min_child_weight=1, n_estimators=2945, reg_alpha=0.021985432949321544, reg_lambda=1.761672643769806, scale_pos_weight=1.04381040288482, subsample=0.8388302343627552; total time=   6.6s\n",
      "[CV] END colsample_bylevel=0.8661310939812046, colsample_bynode=0.9248374424121059, colsample_bytree=0.6182014385847379, gamma=1.9761719269657005, learning_rate=0.09411510087112965, max_delta_step=1, max_depth=14, min_child_weight=12, n_estimators=1771, reg_alpha=2.895638504394922, reg_lambda=2.9811972953745274, scale_pos_weight=0.842780107626605, subsample=0.9474509448587037; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.8661310939812046, colsample_bynode=0.9248374424121059, colsample_bytree=0.6182014385847379, gamma=1.9761719269657005, learning_rate=0.09411510087112965, max_delta_step=1, max_depth=14, min_child_weight=12, n_estimators=1771, reg_alpha=2.895638504394922, reg_lambda=2.9811972953745274, scale_pos_weight=0.842780107626605, subsample=0.9474509448587037; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.9602838031640679, colsample_bynode=0.7394758886143243, colsample_bytree=0.7813523799480191, gamma=1.8332809334917124, learning_rate=0.09433159317817344, max_delta_step=4, max_depth=15, min_child_weight=10, n_estimators=2672, reg_alpha=2.6938234418268565, reg_lambda=1.9784042824977464, scale_pos_weight=1.0756371423363167, subsample=0.9713700153976069; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.00394789976347214, max_delta_step=6, max_depth=4, min_child_weight=9, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.2516616629187012, scale_pos_weight=0.8, subsample=1.0; total time=   5.9s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.9614612931359314, colsample_bytree=0.6, gamma=0.9204768055736312, learning_rate=0.004030678769699066, max_delta_step=10, max_depth=4, min_child_weight=8, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   6.5s\n",
      "[CV] END colsample_bylevel=0.6901971182437642, colsample_bynode=0.824853365329119, colsample_bytree=0.7391895749087618, gamma=1.9667205660355251, learning_rate=0.0010176050220125474, max_delta_step=8, max_depth=15, min_child_weight=8, n_estimators=1476, reg_alpha=0.17272008389022558, reg_lambda=2.7884529304862076, scale_pos_weight=1.110766797966305, subsample=0.8535943916445419; total time=   8.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7050182232229448, colsample_bytree=0.6, gamma=2.0, learning_rate=0.009686747314976062, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=1354, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.0183581848280083, subsample=0.7; total time=   3.1s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7050182232229448, colsample_bytree=0.6, gamma=2.0, learning_rate=0.009686747314976062, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=1354, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.0183581848280083, subsample=0.7; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.6068361029872763, colsample_bynode=0.8198508237347564, colsample_bytree=0.9554580396281735, gamma=0.03851030135886125, learning_rate=0.006668339641989962, max_delta_step=1, max_depth=4, min_child_weight=15, n_estimators=2820, reg_alpha=2.6082480057681563, reg_lambda=0.6985656288359039, scale_pos_weight=1.178337224596226, subsample=0.7082207942075341; total time=   7.1s\n",
      "[CV] END colsample_bylevel=0.7076754763140614, colsample_bynode=0.8868433174003499, colsample_bytree=0.9941587532954389, gamma=1.866879730280912, learning_rate=0.029597300454890195, max_delta_step=4, max_depth=15, min_child_weight=14, n_estimators=1965, reg_alpha=2.857977428294917, reg_lambda=1.4237062587232279, scale_pos_weight=0.9308546516702704, subsample=0.8935365269250675; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.78607317324341, colsample_bynode=0.9119086035548003, colsample_bytree=0.611745424403072, gamma=0.7428288265747619, learning_rate=0.0034038781147346536, max_delta_step=3, max_depth=15, min_child_weight=12, n_estimators=680, reg_alpha=2.875051550347724, reg_lambda=1.1212600237731027, scale_pos_weight=0.8009300345203847, subsample=0.7187348425454448; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.78607317324341, colsample_bynode=0.9119086035548003, colsample_bytree=0.611745424403072, gamma=0.7428288265747619, learning_rate=0.0034038781147346536, max_delta_step=3, max_depth=15, min_child_weight=12, n_estimators=680, reg_alpha=2.875051550347724, reg_lambda=1.1212600237731027, scale_pos_weight=0.8009300345203847, subsample=0.7187348425454448; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.7281538580252533, colsample_bynode=0.6805558296769407, colsample_bytree=0.9353515839436878, gamma=1.1136248221318752, learning_rate=0.005817697013060812, max_delta_step=10, max_depth=6, min_child_weight=12, n_estimators=522, reg_alpha=2.8053757478891264, reg_lambda=1.211241563805959, scale_pos_weight=1.051817148643392, subsample=0.7567233571429313; total time=   2.6s\n",
      "[CV] END colsample_bylevel=0.8396228324365845, colsample_bynode=0.6388173948126993, colsample_bytree=0.7081449018709958, gamma=1.98381584140394, learning_rate=0.006658985448726347, max_delta_step=2, max_depth=14, min_child_weight=12, n_estimators=682, reg_alpha=0.02804951915936727, reg_lambda=2.4167686314224746, scale_pos_weight=0.8101078196910982, subsample=0.8905399700512685; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.7603737077398374, colsample_bynode=1.0, colsample_bytree=0.6, gamma=1.713397583364906, learning_rate=0.02045131518705028, max_delta_step=2, max_depth=4, min_child_weight=9, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   5.0s\n",
      "[CV] END colsample_bylevel=0.9131257619095126, colsample_bynode=0.6341249216690007, colsample_bytree=0.9936675155445983, gamma=0.0857942676485748, learning_rate=0.09481663486224755, max_delta_step=7, max_depth=15, min_child_weight=3, n_estimators=548, reg_alpha=2.4610959455164734, reg_lambda=2.6124094668159477, scale_pos_weight=1.0940675942646385, subsample=0.8595823133915781; total time=   5.3s\n",
      "[CV] END colsample_bylevel=0.9496495710520071, colsample_bynode=0.7297548347921033, colsample_bytree=0.6729551572186834, gamma=0.35894132306677556, learning_rate=0.008217533888141244, max_delta_step=7, max_depth=15, min_child_weight=9, n_estimators=2956, reg_alpha=2.9634734275917465, reg_lambda=0.9536283864182313, scale_pos_weight=0.8133759404527321, subsample=0.7208362598703725; total time=  14.4s\n",
      "[CV] END colsample_bylevel=0.9496495710520071, colsample_bynode=0.7297548347921033, colsample_bytree=0.6729551572186834, gamma=0.35894132306677556, learning_rate=0.008217533888141244, max_delta_step=7, max_depth=15, min_child_weight=9, n_estimators=2956, reg_alpha=2.9634734275917465, reg_lambda=0.9536283864182313, scale_pos_weight=0.8133759404527321, subsample=0.7208362598703725; total time=  15.7s\n",
      "[CV] END colsample_bylevel=0.6010300856271814, colsample_bynode=0.8965573748092919, colsample_bytree=0.9154200469404541, gamma=0.12112769121585235, learning_rate=0.0010271523932214696, max_delta_step=7, max_depth=7, min_child_weight=2, n_estimators=2976, reg_alpha=0.40395565723104887, reg_lambda=0.643016424477618, scale_pos_weight=1.181343972105119, subsample=0.8730904028252356; total time=  21.0s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.0, learning_rate=0.001, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=0.7; total time=   5.8s\n",
      "[CV] END colsample_bylevel=0.6249101981366861, colsample_bynode=0.6417499979095366, colsample_bytree=0.9905276020613366, gamma=1.9677435539271961, learning_rate=0.035638260559013986, max_delta_step=1, max_depth=15, min_child_weight=1, n_estimators=2945, reg_alpha=0.021985432949321544, reg_lambda=1.761672643769806, scale_pos_weight=1.04381040288482, subsample=0.8388302343627552; total time=   6.7s\n",
      "[CV] END colsample_bylevel=0.8661310939812046, colsample_bynode=0.9248374424121059, colsample_bytree=0.6182014385847379, gamma=1.9761719269657005, learning_rate=0.09411510087112965, max_delta_step=1, max_depth=14, min_child_weight=12, n_estimators=1771, reg_alpha=2.895638504394922, reg_lambda=2.9811972953745274, scale_pos_weight=0.842780107626605, subsample=0.9474509448587037; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.8661310939812046, colsample_bynode=0.9248374424121059, colsample_bytree=0.6182014385847379, gamma=1.9761719269657005, learning_rate=0.09411510087112965, max_delta_step=1, max_depth=14, min_child_weight=12, n_estimators=1771, reg_alpha=2.895638504394922, reg_lambda=2.9811972953745274, scale_pos_weight=0.842780107626605, subsample=0.9474509448587037; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.9602838031640679, colsample_bynode=0.7394758886143243, colsample_bytree=0.7813523799480191, gamma=1.8332809334917124, learning_rate=0.09433159317817344, max_delta_step=4, max_depth=15, min_child_weight=10, n_estimators=2672, reg_alpha=2.6938234418268565, reg_lambda=1.9784042824977464, scale_pos_weight=1.0756371423363167, subsample=0.9713700153976069; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.00394789976347214, max_delta_step=6, max_depth=4, min_child_weight=9, n_estimators=3000, reg_alpha=0.0, reg_lambda=0.2516616629187012, scale_pos_weight=0.8, subsample=1.0; total time=   5.9s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.9614612931359314, colsample_bytree=0.6, gamma=0.9204768055736312, learning_rate=0.004030678769699066, max_delta_step=10, max_depth=4, min_child_weight=8, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   6.3s\n",
      "[CV] END colsample_bylevel=0.6901971182437642, colsample_bynode=0.824853365329119, colsample_bytree=0.7391895749087618, gamma=1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".9667205660355251, learning_rate=0.0010176050220125474, max_delta_step=8, max_depth=15, min_child_weight=8, n_estimators=1476, reg_alpha=0.17272008389022558, reg_lambda=2.7884529304862076, scale_pos_weight=1.110766797966305, subsample=0.8535943916445419; total time=   8.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7050182232229448, colsample_bytree=0.6, gamma=2.0, learning_rate=0.009686747314976062, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=1354, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.0183581848280083, subsample=0.7; total time=   3.1s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7050182232229448, colsample_bytree=0.6, gamma=2.0, learning_rate=0.009686747314976062, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=1354, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.0183581848280083, subsample=0.7; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.6068361029872763, colsample_bynode=0.8198508237347564, colsample_bytree=0.9554580396281735, gamma=0.03851030135886125, learning_rate=0.006668339641989962, max_delta_step=1, max_depth=4, min_child_weight=15, n_estimators=2820, reg_alpha=2.6082480057681563, reg_lambda=0.6985656288359039, scale_pos_weight=1.178337224596226, subsample=0.7082207942075341; total time=   7.1s\n",
      "[CV] END colsample_bylevel=0.7076754763140614, colsample_bynode=0.8868433174003499, colsample_bytree=0.9941587532954389, gamma=1.866879730280912, learning_rate=0.029597300454890195, max_delta_step=4, max_depth=15, min_child_weight=14, n_estimators=1965, reg_alpha=2.857977428294917, reg_lambda=1.4237062587232279, scale_pos_weight=0.9308546516702704, subsample=0.8935365269250675; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.78607317324341, colsample_bynode=0.9119086035548003, colsample_bytree=0.611745424403072, gamma=0.7428288265747619, learning_rate=0.0034038781147346536, max_delta_step=3, max_depth=15, min_child_weight=12, n_estimators=680, reg_alpha=2.875051550347724, reg_lambda=1.1212600237731027, scale_pos_weight=0.8009300345203847, subsample=0.7187348425454448; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.6675000313433527, colsample_bynode=0.9008421695284963, colsample_bytree=0.60561552067792, gamma=0.15802806306265296, learning_rate=0.03656649954192327, max_delta_step=4, max_depth=4, min_child_weight=6, n_estimators=564, reg_alpha=2.9784841695406126, reg_lambda=2.2523170716204346, scale_pos_weight=1.1550409969712567, subsample=0.8225880058928153; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.6675000313433527, colsample_bynode=0.9008421695284963, colsample_bytree=0.60561552067792, gamma=0.15802806306265296, learning_rate=0.03656649954192327, max_delta_step=4, max_depth=4, min_child_weight=6, n_estimators=564, reg_alpha=2.9784841695406126, reg_lambda=2.2523170716204346, scale_pos_weight=1.1550409969712567, subsample=0.8225880058928153; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.7281538580252533, colsample_bynode=0.6805558296769407, colsample_bytree=0.9353515839436878, gamma=1.1136248221318752, learning_rate=0.005817697013060812, max_delta_step=10, max_depth=6, min_child_weight=12, n_estimators=522, reg_alpha=2.8053757478891264, reg_lambda=1.211241563805959, scale_pos_weight=1.051817148643392, subsample=0.7567233571429313; total time=   2.7s\n",
      "[CV] END colsample_bylevel=0.8396228324365845, colsample_bynode=0.6388173948126993, colsample_bytree=0.7081449018709958, gamma=1.98381584140394, learning_rate=0.006658985448726347, max_delta_step=2, max_depth=14, min_child_weight=12, n_estimators=682, reg_alpha=0.02804951915936727, reg_lambda=2.4167686314224746, scale_pos_weight=0.8101078196910982, subsample=0.8905399700512685; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.7603737077398374, colsample_bynode=1.0, colsample_bytree=0.6, gamma=1.713397583364906, learning_rate=0.02045131518705028, max_delta_step=2, max_depth=4, min_child_weight=9, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bylevel=0.7603737077398374, colsample_bynode=1.0, colsample_bytree=0.6, gamma=1.713397583364906, learning_rate=0.02045131518705028, max_delta_step=2, max_depth=4, min_child_weight=9, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   5.4s\n",
      "[CV] END colsample_bylevel=0.9131257619095126, colsample_bynode=0.6341249216690007, colsample_bytree=0.9936675155445983, gamma=0.0857942676485748, learning_rate=0.09481663486224755, max_delta_step=7, max_depth=15, min_child_weight=3, n_estimators=548, reg_alpha=2.4610959455164734, reg_lambda=2.6124094668159477, scale_pos_weight=1.0940675942646385, subsample=0.8595823133915781; total time=   3.4s\n",
      "[CV] END colsample_bylevel=0.9496495710520071, colsample_bynode=0.7297548347921033, colsample_bytree=0.6729551572186834, gamma=0.35894132306677556, learning_rate=0.008217533888141244, max_delta_step=7, max_depth=15, min_child_weight=9, n_estimators=2956, reg_alpha=2.9634734275917465, reg_lambda=0.9536283864182313, scale_pos_weight=0.8133759404527321, subsample=0.7208362598703725; total time=  14.6s\n",
      "[CV] END colsample_bylevel=0.6810608926563045, colsample_bynode=0.8568745137018805, colsample_bytree=0.7863911877086216, gamma=0.6615107559360499, learning_rate=0.003943650747126641, max_delta_step=8, max_depth=15, min_child_weight=8, n_estimators=2723, reg_alpha=0.033491545664107954, reg_lambda=0.9762164505337632, scale_pos_weight=1.0664026110064593, subsample=0.9347156859224584; total time=  16.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:53:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:54:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:55:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.6675000313433527, colsample_bynode=0.9008421695284963, colsample_bytree=0.60561552067792, gamma=0.15802806306265296, learning_rate=0.03656649954192327, max_delta_step=4, max_depth=4, min_child_weight=6, n_estimators=564, reg_alpha=2.9784841695406126, reg_lambda=2.2523170716204346, scale_pos_weight=1.1550409969712567, subsample=0.8225880058928153; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.6675000313433527, colsample_bynode=0.9008421695284963, colsample_bytree=0.60561552067792, gamma=0.15802806306265296, learning_rate=0.03656649954192327, max_delta_step=4, max_depth=4, min_child_weight=6, n_estimators=564, reg_alpha=2.9784841695406126, reg_lambda=2.2523170716204346, scale_pos_weight=1.1550409969712567, subsample=0.8225880058928153; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.7281538580252533, colsample_bynode=0.6805558296769407, colsample_bytree=0.9353515839436878, gamma=1.1136248221318752, learning_rate=0.005817697013060812, max_delta_step=10, max_depth=6, min_child_weight=12, n_estimators=522, reg_alpha=2.8053757478891264, reg_lambda=1.211241563805959, scale_pos_weight=1.051817148643392, subsample=0.7567233571429313; total time=   2.7s\n",
      "[CV] END colsample_bylevel=0.8396228324365845, colsample_bynode=0.6388173948126993, colsample_bytree=0.7081449018709958, gamma=1.98381584140394, learning_rate=0.006658985448726347, max_delta_step=2, max_depth=14, min_child_weight=12, n_estimators=682, reg_alpha=0.02804951915936727, reg_lambda=2.4167686314224746, scale_pos_weight=0.8101078196910982, subsample=0.8905399700512685; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.7603737077398374, colsample_bynode=1.0, colsample_bytree=0.6, gamma=1.713397583364906, learning_rate=0.02045131518705028, max_delta_step=2, max_depth=4, min_child_weight=9, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bylevel=0.9131257619095126, colsample_bynode=0.6341249216690007, colsample_bytree=0.9936675155445983, gamma=0.0857942676485748, learning_rate=0.09481663486224755, max_delta_step=7, max_depth=15, min_child_weight=3, n_estimators=548, reg_alpha=2.4610959455164734, reg_lambda=2.6124094668159477, scale_pos_weight=1.0940675942646385, subsample=0.8595823133915781; total time=   5.4s\n",
      "[CV] END colsample_bylevel=0.9131257619095126, colsample_bynode=0.6341249216690007, colsample_bytree=0.9936675155445983, gamma=0.0857942676485748, learning_rate=0.09481663486224755, max_delta_step=7, max_depth=15, min_child_weight=3, n_estimators=548, reg_alpha=2.4610959455164734, reg_lambda=2.6124094668159477, scale_pos_weight=1.0940675942646385, subsample=0.8595823133915781; total time=   3.4s\n",
      "[CV] END colsample_bylevel=0.9496495710520071, colsample_bynode=0.7297548347921033, colsample_bytree=0.6729551572186834, gamma=0.35894132306677556, learning_rate=0.008217533888141244, max_delta_step=7, max_depth=15, min_child_weight=9, n_estimators=2956, reg_alpha=2.9634734275917465, reg_lambda=0.9536283864182313, scale_pos_weight=0.8133759404527321, subsample=0.7208362598703725; total time=  14.8s\n",
      "[CV] END colsample_bylevel=0.6810608926563045, colsample_bynode=0.8568745137018805, colsample_bytree=0.7863911877086216, gamma=0.6615107559360499, learning_rate=0.003943650747126641, max_delta_step=8, max_depth=15, min_child_weight=8, n_estimators=2723, reg_alpha=0.033491545664107954, reg_lambda=0.9762164505337632, scale_pos_weight=1.0664026110064593, subsample=0.9347156859224584; total time=  16.6s\n",
      "[CV] END colsample_bylevel=0.8700495242781614, colsample_bynode=0.9741069403804136, colsample_bytree=0.62958717036796, gamma=0.07206843180361024, learning_rate=0.004575142131563671, max_delta_step=7, max_depth=15, min_child_weight=11, n_estimators=2889, reg_alpha=0.45340026405866274, reg_lambda=2.3568033515980917, scale_pos_weight=1.0876294750664361, subsample=0.9829278377772181; total time=  18.7s\n",
      "[CV] END colsample_bylevel=0.8700495242781614, colsample_bynode=0.9741069403804136, colsample_bytree=0.62958717036796, gamma=0.07206843180361024, learning_rate=0.004575142131563671, max_delta_step=7, max_depth=15, min_child_weight=11, n_estimators=2889, reg_alpha=0.45340026405866274, reg_lambda=2.3568033515980917, scale_pos_weight=1.0876294750664361, subsample=0.9829278377772181; total time=  13.7s\n",
      "[CV] END colsample_bylevel=0.9371253734625461, colsample_bynode=0.7882829953738026, colsample_bytree=0.8801698866610705, gamma=1.441658192209363, learning_rate=0.09890276655435588, max_delta_step=2, max_depth=14, min_child_weight=4, n_estimators=531, reg_alpha=0.16743579376618728, reg_lambda=1.4716116897426033, scale_pos_weight=0.8806736880089954, subsample=0.8078323550245288; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.6555948393906834, colsample_bynode=0.779127897071196, colsample_bytree=0.8843646418013996, gamma=0.7771406615207754, learning_rate=0.0010371750670406712, max_delta_step=9, max_depth=4, min_child_weight=3, n_estimators=895, reg_alpha=1.7163498690255783, reg_lambda=1.6920753989674546, scale_pos_weight=1.0074249300479703, subsample=0.9041284057602071; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.9866994616453865, gamma=0.7171575435473898, learning_rate=0.001, max_delta_step=1, max_depth=4, min_child_weight=1, n_estimators=1676, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=1.0975676556865281, subsample=0.8905984149471087; total time=   4.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.9866994616453865, gamma=0.7171575435473898, learning_rate=0.001, max_delta_step=1, max_depth=4, min_child_weight=1, n_estimators=1676, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=1.0975676556865281, subsample=0.8905984149471087; total time=   3.1s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7513703676532686, colsample_bytree=0.8416195781917156, gamma=0.0, learning_rate=0.0039432254340619555, max_delta_step=1, max_depth=4, min_child_weight=15, n_estimators=2035, reg_alpha=3.0, reg_lambda=0.24425098596191985, scale_pos_weight=0.896285636936831, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.9421811010359487, colsample_bynode=0.7271963836450162, colsample_bytree=0.7068356488970613, gamma=1.943450135251715, learning_rate=0.008054540143887817, max_delta_step=9, max_depth=4, min_child_weight=5, n_estimators=686, reg_alpha=0.04894963511345664, reg_lambda=0.9027847872438328, scale_pos_weight=0.843160163085181, subsample=0.7224624787282491; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.9586493830484578, colsample_bynode=0.9278296072652311, colsample_bytree=0.8780925342447243, gamma=0.12382855459709166, learning_rate=0.0034551379742941125, max_delta_step=4, max_depth=15, min_child_weight=5, n_estimators=515, reg_alpha=0.45713254706048245, reg_lambda=0.026067252142143345, scale_pos_weight=0.8604125211847513, subsample=0.8527339081796862; total time=   7.5s\n",
      "[CV] END colsample_bylevel=0.9586493830484578, colsample_bynode=0.9278296072652311, colsample_bytree=0.8780925342447243, gamma=0.12382855459709166, learning_rate=0.0034551379742941125, max_delta_step=4, max_depth=15, min_child_weight=5, n_estimators=515, reg_alpha=0.45713254706048245, reg_lambda=0.026067252142143345, scale_pos_weight=0.8604125211847513, subsample=0.8527339081796862; total time=   4.4s\n",
      "[CV] END colsample_bylevel=0.6052444905383665, colsample_bynode=1.0, colsample_bytree=0.6, gamma=0.0, learning_rate=0.016499149107402907, max_delta_step=10, max_depth=4, min_child_weight=13, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.0788031614100677, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.7310356044247226, colsample_bynode=0.8819640306581151, colsample_bytree=0.7508921358405333, gamma=1.9572085629164693, learning_rate=0.0024088747151639737, max_delta_step=9, max_depth=15, min_child_weight=11, n_estimators=2952, reg_alpha=1.8243000016355744, reg_lambda=2.4269789081386235, scale_pos_weight=1.1966076052914254, subsample=0.9277926671066168; total time=  13.4s\n",
      "[CV] END colsample_bylevel=0.7125696251276914, colsample_bynode=0.9936842903272232, colsample_bytree=0.868783415330656, gamma=1.987391204062766, learning_rate=0.001651191832630541, max_delta_step=9, max_depth=4, min_child_weight=4, n_estimators=2948, reg_alpha=0.8992020411205937, reg_lambda=2.3030921920862792, scale_pos_weight=1.1933230309329774, subsample=0.9122306976646831; total time=   7.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.7281538580252533, colsample_bynode=0.6805558296769407, colsample_bytree=0.9353515839436878, gamma=1.1136248221318752, learning_rate=0.005817697013060812, max_delta_step=10, max_depth=6, min_child_weight=12, n_estimators=522, reg_alpha=2.8053757478891264, reg_lambda=1.211241563805959, scale_pos_weight=1.051817148643392, subsample=0.7567233571429313; total time=   2.5s\n",
      "[CV] END colsample_bylevel=0.7281538580252533, colsample_bynode=0.6805558296769407, colsample_bytree=0.9353515839436878, gamma=1.1136248221318752, learning_rate=0.005817697013060812, max_delta_step=10, max_depth=6, min_child_weight=12, n_estimators=522, reg_alpha=2.8053757478891264, reg_lambda=1.211241563805959, scale_pos_weight=1.051817148643392, subsample=0.7567233571429313; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.8396228324365845, colsample_bynode=0.6388173948126993, colsample_bytree=0.7081449018709958, gamma=1.98381584140394, learning_rate=0.006658985448726347, max_delta_step=2, max_depth=14, min_child_weight=12, n_estimators=682, reg_alpha=0.02804951915936727, reg_lambda=2.4167686314224746, scale_pos_weight=0.8101078196910982, subsample=0.8905399700512685; total time=   2.7s\n",
      "[CV] END colsample_bylevel=0.8396228324365845, colsample_bynode=0.6388173948126993, colsample_bytree=0.7081449018709958, gamma=1.98381584140394, learning_rate=0.006658985448726347, max_delta_step=2, max_depth=14, min_child_weight=12, n_estimators=682, reg_alpha=0.02804951915936727, reg_lambda=2.4167686314224746, scale_pos_weight=0.8101078196910982, subsample=0.8905399700512685; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.7603737077398374, colsample_bynode=1.0, colsample_bytree=0.6, gamma=1.713397583364906, learning_rate=0.02045131518705028, max_delta_step=2, max_depth=4, min_child_weight=9, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   5.6s\n",
      "[CV] END colsample_bylevel=0.9131257619095126, colsample_bynode=0.6341249216690007, colsample_bytree=0.9936675155445983, gamma=0.0857942676485748, learning_rate=0.09481663486224755, max_delta_step=7, max_depth=15, min_child_weight=3, n_estimators=548, reg_alpha=2.4610959455164734, reg_lambda=2.6124094668159477, scale_pos_weight=1.0940675942646385, subsample=0.8595823133915781; total time=   4.0s\n",
      "[CV] END colsample_bylevel=0.9496495710520071, colsample_bynode=0.7297548347921033, colsample_bytree=0.6729551572186834, gamma=0.35894132306677556, learning_rate=0.008217533888141244, max_delta_step=7, max_depth=15, min_child_weight=9, n_estimators=2956, reg_alpha=2.9634734275917465, reg_lambda=0.9536283864182313, scale_pos_weight=0.8133759404527321, subsample=0.7208362598703725; total time=  14.5s\n",
      "[CV] END colsample_bylevel=0.6810608926563045, colsample_bynode=0.8568745137018805, colsample_bytree=0.7863911877086216, gamma=0.6615107559360499, learning_rate=0.003943650747126641, max_delta_step=8, max_depth=15, min_child_weight=8, n_estimators=2723, reg_alpha=0.033491545664107954, reg_lambda=0.9762164505337632, scale_pos_weight=1.0664026110064593, subsample=0.9347156859224584; total time=  16.6s\n",
      "[CV] END colsample_bylevel=0.6810608926563045, colsample_bynode=0.8568745137018805, colsample_bytree=0.7863911877086216, gamma=0.6615107559360499, learning_rate=0.003943650747126641, max_delta_step=8, max_depth=15, min_child_weight=8, n_estimators=2723, reg_alpha=0.033491545664107954, reg_lambda=0.9762164505337632, scale_pos_weight=1.0664026110064593, subsample=0.9347156859224584; total time=  17.1s\n",
      "[CV] END colsample_bylevel=0.8700495242781614, colsample_bynode=0.9741069403804136, colsample_bytree=0.62958717036796, gamma=0.07206843180361024, learning_rate=0.004575142131563671, max_delta_step=7, max_depth=15, min_child_weight=11, n_estimators=2889, reg_alpha=0.45340026405866274, reg_lambda=2.3568033515980917, scale_pos_weight=1.0876294750664361, subsample=0.9829278377772181; total time=  14.9s\n",
      "[CV] END colsample_bylevel=0.9371253734625461, colsample_bynode=0.7882829953738026, colsample_bytree=0.8801698866610705, gamma=1.441658192209363, learning_rate=0.09890276655435588, max_delta_step=2, max_depth=14, min_child_weight=4, n_estimators=531, reg_alpha=0.16743579376618728, reg_lambda=1.4716116897426033, scale_pos_weight=0.8806736880089954, subsample=0.8078323550245288; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.9371253734625461, colsample_bynode=0.7882829953738026, colsample_bytree=0.8801698866610705, gamma=1.441658192209363, learning_rate=0.09890276655435588, max_delta_step=2, max_depth=14, min_child_weight=4, n_estimators=531, reg_alpha=0.16743579376618728, reg_lambda=1.4716116897426033, scale_pos_weight=0.8806736880089954, subsample=0.8078323550245288; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.6555948393906834, colsample_bynode=0.779127897071196, colsample_bytree=0.8843646418013996, gamma=0.7771406615207754, learning_rate=0.0010371750670406712, max_delta_step=9, max_depth=4, min_child_weight=3, n_estimators=895, reg_alpha=1.7163498690255783, reg_lambda=1.6920753989674546, scale_pos_weight=1.0074249300479703, subsample=0.9041284057602071; total time=   2.1s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.9866994616453865, gamma=0.7171575435473898, learning_rate=0.001, max_delta_step=1, max_depth=4, min_child_weight=1, n_estimators=1676, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=1.0975676556865281, subsample=0.8905984149471087; total time=   4.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7513703676532686, colsample_bytree=0.8416195781917156, gamma=0.0, learning_rate=0.0039432254340619555, max_delta_step=1, max_depth=4, min_child_weight=15, n_estimators=2035, reg_alpha=3.0, reg_lambda=0.24425098596191985, scale_pos_weight=0.896285636936831, subsample=1.0; total time=   4.8s\n",
      "[CV] END colsample_bylevel=0.9421811010359487, colsample_bynode=0.7271963836450162, colsample_bytree=0.7068356488970613, gamma=1.943450135251715, learning_rate=0.008054540143887817, max_delta_step=9, max_depth=4, min_child_weight=5, n_estimators=686, reg_alpha=0.04894963511345664, reg_lambda=0.9027847872438328, scale_pos_weight=0.843160163085181, subsample=0.7224624787282491; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.9421811010359487, colsample_bynode=0.7271963836450162, colsample_bytree=0.7068356488970613, gamma=1.943450135251715, learning_rate=0.008054540143887817, max_delta_step=9, max_depth=4, min_child_weight=5, n_estimators=686, reg_alpha=0.04894963511345664, reg_lambda=0.9027847872438328, scale_pos_weight=0.843160163085181, subsample=0.7224624787282491; total time=   1.8s\n",
      "[CV] END colsample_bylevel=0.9586493830484578, colsample_bynode=0.9278296072652311, colsample_bytree=0.8780925342447243, gamma=0.12382855459709166, learning_rate=0.0034551379742941125, max_delta_step=4, max_depth=15, min_child_weight=5, n_estimators=515, reg_alpha=0.45713254706048245, reg_lambda=0.026067252142143345, scale_pos_weight=0.8604125211847513, subsample=0.8527339081796862; total time=   7.6s\n",
      "[CV] END colsample_bylevel=0.6052444905383665, colsample_bynode=1.0, colsample_bytree=0.6, gamma=0.0, learning_rate=0.016499149107402907, max_delta_step=10, max_depth=4, min_child_weight=13, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.0788031614100677, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.6052444905383665, colsample_bynode=1.0, colsample_bytree=0.6, gamma=0.0, learning_rate=0.016499149107402907, max_delta_step=10, max_depth=4, min_child_weight=13, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.0788031614100677, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.7310356044247226, colsample_bynode=0.8819640306581151, colsample_bytree=0.7508921358405333, gamma=1.9572085629164693, learning_rate=0.0024088747151639737, max_delta_step=9, max_depth=15, min_child_weight=11, n_estimators=2952, reg_alpha=1.8243000016355744, reg_lambda=2.4269789081386235, scale_pos_weight=1.1966076052914254, subsample=0.9277926671066168; total time=  13.0s\n",
      "[CV] END colsample_bylevel=0.7125696251276914, colsample_bynode=0.9936842903272232, colsample_bytree=0.868783415330656, gamma=1.987391204062766, learning_rate=0.001651191832630541, max_delta_step=9, max_depth=4, min_child_weight=4, n_estimators=2948, reg_alpha=0.8992020411205937, reg_lambda=2.3030921920862792, scale_pos_weight=1.1933230309329774, subsample=0.9122306976646831; total time=   7.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.8396228324365845, colsample_bynode=0.6388173948126993, colsample_bytree=0.7081449018709958, gamma=1.98381584140394, learning_rate=0.006658985448726347, max_delta_step=2, max_depth=14, min_child_weight=12, n_estimators=682, reg_alpha=0.02804951915936727, reg_lambda=2.4167686314224746, scale_pos_weight=0.8101078196910982, subsample=0.8905399700512685; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.7603737077398374, colsample_bynode=1.0, colsample_bytree=0.6, gamma=1.713397583364906, learning_rate=0.02045131518705028, max_delta_step=2, max_depth=4, min_child_weight=9, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bylevel=0.9131257619095126, colsample_bynode=0.6341249216690007, colsample_bytree=0.9936675155445983, gamma=0.0857942676485748, learning_rate=0.09481663486224755, max_delta_step=7, max_depth=15, min_child_weight=3, n_estimators=548, reg_alpha=2.4610959455164734, reg_lambda=2.6124094668159477, scale_pos_weight=1.0940675942646385, subsample=0.8595823133915781; total time=   5.5s\n",
      "[CV] END colsample_bylevel=0.9131257619095126, colsample_bynode=0.6341249216690007, colsample_bytree=0.9936675155445983, gamma=0.0857942676485748, learning_rate=0.09481663486224755, max_delta_step=7, max_depth=15, min_child_weight=3, n_estimators=548, reg_alpha=2.4610959455164734, reg_lambda=2.6124094668159477, scale_pos_weight=1.0940675942646385, subsample=0.8595823133915781; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.9496495710520071, colsample_bynode=0.7297548347921033, colsample_bytree=0.6729551572186834, gamma=0.35894132306677556, learning_rate=0.008217533888141244, max_delta_step=7, max_depth=15, min_child_weight=9, n_estimators=2956, reg_alpha=2.9634734275917465, reg_lambda=0.9536283864182313, scale_pos_weight=0.8133759404527321, subsample=0.7208362598703725; total time=  14.6s\n",
      "[CV] END colsample_bylevel=0.6810608926563045, colsample_bynode=0.8568745137018805, colsample_bytree=0.7863911877086216, gamma=0.6615107559360499, learning_rate=0.003943650747126641, max_delta_step=8, max_depth=15, min_child_weight=8, n_estimators=2723, reg_alpha=0.033491545664107954, reg_lambda=0.9762164505337632, scale_pos_weight=1.0664026110064593, subsample=0.9347156859224584; total time=  16.6s\n",
      "[CV] END colsample_bylevel=0.6810608926563045, colsample_bynode=0.8568745137018805, colsample_bytree=0.7863911877086216, gamma=0.6615107559360499, learning_rate=0.003943650747126641, max_delta_step=8, max_depth=15, min_child_weight=8, n_estimators=2723, reg_alpha=0.033491545664107954, reg_lambda=0.9762164505337632, scale_pos_weight=1.0664026110064593, subsample=0.9347156859224584; total time=  17.6s\n",
      "[CV] END colsample_bylevel=0.8700495242781614, colsample_bynode=0.9741069403804136, colsample_bytree=0.62958717036796, gamma=0.07206843180361024, learning_rate=0.004575142131563671, max_delta_step=7, max_depth=15, min_child_weight=11, n_estimators=2889, reg_alpha=0.45340026405866274, reg_lambda=2.3568033515980917, scale_pos_weight=1.0876294750664361, subsample=0.9829278377772181; total time=  14.5s\n",
      "[CV] END colsample_bylevel=0.9371253734625461, colsample_bynode=0.7882829953738026, colsample_bytree=0.8801698866610705, gamma=1.441658192209363, learning_rate=0.09890276655435588, max_delta_step=2, max_depth=14, min_child_weight=4, n_estimators=531, reg_alpha=0.16743579376618728, reg_lambda=1.4716116897426033, scale_pos_weight=0.8806736880089954, subsample=0.8078323550245288; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.6555948393906834, colsample_bynode=0.779127897071196, colsample_bytree=0.8843646418013996, gamma=0.7771406615207754, learning_rate=0.0010371750670406712, max_delta_step=9, max_depth=4, min_child_weight=3, n_estimators=895, reg_alpha=1.7163498690255783, reg_lambda=1.6920753989674546, scale_pos_weight=1.0074249300479703, subsample=0.9041284057602071; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.9866994616453865, gamma=0.7171575435473898, learning_rate=0.001, max_delta_step=1, max_depth=4, min_child_weight=1, n_estimators=1676, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=1.0975676556865281, subsample=0.8905984149471087; total time=   4.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7513703676532686, colsample_bytree=0.8416195781917156, gamma=0.0, learning_rate=0.0039432254340619555, max_delta_step=1, max_depth=4, min_child_weight=15, n_estimators=2035, reg_alpha=3.0, reg_lambda=0.24425098596191985, scale_pos_weight=0.896285636936831, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7513703676532686, colsample_bytree=0.8416195781917156, gamma=0.0, learning_rate=0.0039432254340619555, max_delta_step=1, max_depth=4, min_child_weight=15, n_estimators=2035, reg_alpha=3.0, reg_lambda=0.24425098596191985, scale_pos_weight=0.896285636936831, subsample=1.0; total time=   5.0s\n",
      "[CV] END colsample_bylevel=0.9586493830484578, colsample_bynode=0.9278296072652311, colsample_bytree=0.8780925342447243, gamma=0.12382855459709166, learning_rate=0.0034551379742941125, max_delta_step=4, max_depth=15, min_child_weight=5, n_estimators=515, reg_alpha=0.45713254706048245, reg_lambda=0.026067252142143345, scale_pos_weight=0.8604125211847513, subsample=0.8527339081796862; total time=   7.5s\n",
      "[CV] END colsample_bylevel=0.6052444905383665, colsample_bynode=1.0, colsample_bytree=0.6, gamma=0.0, learning_rate=0.016499149107402907, max_delta_step=10, max_depth=4, min_child_weight=13, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.0788031614100677, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.7310356044247226, colsample_bynode=0.8819640306581151, colsample_bytree=0.7508921358405333, gamma=1.9572085629164693, learning_rate=0.0024088747151639737, max_delta_step=9, max_depth=15, min_child_weight=11, n_estimators=2952, reg_alpha=1.8243000016355744, reg_lambda=2.4269789081386235, scale_pos_weight=1.1966076052914254, subsample=0.9277926671066168; total time=  13.0s\n",
      "[CV] END colsample_bylevel=0.7310356044247226, colsample_bynode=0.8819640306581151, colsample_bytree=0.7508921358405333, gamma=1.9572085629164693, learning_rate=0.0024088747151639737, max_delta_step=9, max_depth=15, min_child_weight=11, n_estimators=2952, reg_alpha=1.8243000016355744, reg_lambda=2.4269789081386235, scale_pos_weight=1.1966076052914254, subsample=0.9277926671066168; total time=  11.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=1.040463659958357, learning_rate=0.005952096969175991, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=1763, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=0.8440318924367449, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bylevel=0.8462933638642077, colsample_bynode=0.9057498977948752, colsample_bytree=0.8563062368406351, gamma=0.0, learning_rate=0.0026574184389436335, max_delta_step=1, max_depth=4, min_child_weight=6, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.8833628534088293, scale_pos_weight=1.2, subsample=0.7; total time=   7.9s\n",
      "[CV] END colsample_bylevel=0.6102413718196124, colsample_bynode=0.7440242316803746, colsample_bytree=0.6341335220211852, gamma=0.7700278424471481, learning_rate=0.05143879552988949, max_delta_step=7, max_depth=4, min_child_weight=7, n_estimators=500, reg_alpha=3.0, reg_lambda=1.7837126368580276, scale_pos_weight=1.1849679837912286, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.6102413718196124, colsample_bynode=0.7440242316803746, colsample_bytree=0.6341335220211852, gamma=0.7700278424471481, learning_rate=0.05143879552988949, max_delta_step=7, max_depth=4, min_child_weight=7, n_estimators=500, reg_alpha=3.0, reg_lambda=1.7837126368580276, scale_pos_weight=1.1849679837912286, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.8677291073484901, colsample_bynode=0.603736117594583, colsample_bytree=0.8884344512621404, gamma=1.9885386884664678, learning_rate=0.002274213099941156, max_delta_step=3, max_depth=10, min_child_weight=1, n_estimators=2226, reg_alpha=0.09028258368517209, reg_lambda=1.8428916074222934, scale_pos_weight=0.94000857652063, subsample=0.7686470875919859; total time=  12.8s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.8700495242781614, colsample_bynode=0.9741069403804136, colsample_bytree=0.62958717036796, gamma=0.07206843180361024, learning_rate=0.004575142131563671, max_delta_step=7, max_depth=15, min_child_weight=11, n_estimators=2889, reg_alpha=0.45340026405866274, reg_lambda=2.3568033515980917, scale_pos_weight=1.0876294750664361, subsample=0.9829278377772181; total time=  18.7s\n",
      "[CV] END colsample_bylevel=0.8700495242781614, colsample_bynode=0.9741069403804136, colsample_bytree=0.62958717036796, gamma=0.07206843180361024, learning_rate=0.004575142131563671, max_delta_step=7, max_depth=15, min_child_weight=11, n_estimators=2889, reg_alpha=0.45340026405866274, reg_lambda=2.3568033515980917, scale_pos_weight=1.0876294750664361, subsample=0.9829278377772181; total time=  13.8s\n",
      "[CV] END colsample_bylevel=0.9371253734625461, colsample_bynode=0.7882829953738026, colsample_bytree=0.8801698866610705, gamma=1.441658192209363, learning_rate=0.09890276655435588, max_delta_step=2, max_depth=14, min_child_weight=4, n_estimators=531, reg_alpha=0.16743579376618728, reg_lambda=1.4716116897426033, scale_pos_weight=0.8806736880089954, subsample=0.8078323550245288; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.6555948393906834, colsample_bynode=0.779127897071196, colsample_bytree=0.8843646418013996, gamma=0.7771406615207754, learning_rate=0.0010371750670406712, max_delta_step=9, max_depth=4, min_child_weight=3, n_estimators=895, reg_alpha=1.7163498690255783, reg_lambda=1.6920753989674546, scale_pos_weight=1.0074249300479703, subsample=0.9041284057602071; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.6555948393906834, colsample_bynode=0.779127897071196, colsample_bytree=0.8843646418013996, gamma=0.7771406615207754, learning_rate=0.0010371750670406712, max_delta_step=9, max_depth=4, min_child_weight=3, n_estimators=895, reg_alpha=1.7163498690255783, reg_lambda=1.6920753989674546, scale_pos_weight=1.0074249300479703, subsample=0.9041284057602071; total time=   2.1s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.9866994616453865, gamma=0.7171575435473898, learning_rate=0.001, max_delta_step=1, max_depth=4, min_child_weight=1, n_estimators=1676, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=1.0975676556865281, subsample=0.8905984149471087; total time=   4.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7513703676532686, colsample_bytree=0.8416195781917156, gamma=0.0, learning_rate=0.0039432254340619555, max_delta_step=1, max_depth=4, min_child_weight=15, n_estimators=2035, reg_alpha=3.0, reg_lambda=0.24425098596191985, scale_pos_weight=0.896285636936831, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.9421811010359487, colsample_bynode=0.7271963836450162, colsample_bytree=0.7068356488970613, gamma=1.943450135251715, learning_rate=0.008054540143887817, max_delta_step=9, max_depth=4, min_child_weight=5, n_estimators=686, reg_alpha=0.04894963511345664, reg_lambda=0.9027847872438328, scale_pos_weight=0.843160163085181, subsample=0.7224624787282491; total time=   2.0s\n",
      "[CV] END colsample_bylevel=0.9421811010359487, colsample_bynode=0.7271963836450162, colsample_bytree=0.7068356488970613, gamma=1.943450135251715, learning_rate=0.008054540143887817, max_delta_step=9, max_depth=4, min_child_weight=5, n_estimators=686, reg_alpha=0.04894963511345664, reg_lambda=0.9027847872438328, scale_pos_weight=0.843160163085181, subsample=0.7224624787282491; total time=   1.8s\n",
      "[CV] END colsample_bylevel=0.9586493830484578, colsample_bynode=0.9278296072652311, colsample_bytree=0.8780925342447243, gamma=0.12382855459709166, learning_rate=0.0034551379742941125, max_delta_step=4, max_depth=15, min_child_weight=5, n_estimators=515, reg_alpha=0.45713254706048245, reg_lambda=0.026067252142143345, scale_pos_weight=0.8604125211847513, subsample=0.8527339081796862; total time=   7.7s\n",
      "[CV] END colsample_bylevel=0.6052444905383665, colsample_bynode=1.0, colsample_bytree=0.6, gamma=0.0, learning_rate=0.016499149107402907, max_delta_step=10, max_depth=4, min_child_weight=13, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.0788031614100677, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.7310356044247226, colsample_bynode=0.8819640306581151, colsample_bytree=0.7508921358405333, gamma=1.9572085629164693, learning_rate=0.0024088747151639737, max_delta_step=9, max_depth=15, min_child_weight=11, n_estimators=2952, reg_alpha=1.8243000016355744, reg_lambda=2.4269789081386235, scale_pos_weight=1.1966076052914254, subsample=0.9277926671066168; total time=  13.1s\n",
      "[CV] END colsample_bylevel=0.7125696251276914, colsample_bynode=0.9936842903272232, colsample_bytree=0.868783415330656, gamma=1.987391204062766, learning_rate=0.001651191832630541, max_delta_step=9, max_depth=4, min_child_weight=4, n_estimators=2948, reg_alpha=0.8992020411205937, reg_lambda=2.3030921920862792, scale_pos_weight=1.1933230309329774, subsample=0.9122306976646831; total time=   7.6s\n",
      "[CV] END colsample_bylevel=0.7125696251276914, colsample_bynode=0.9936842903272232, colsample_bytree=0.868783415330656, gamma=1.987391204062766, learning_rate=0.001651191832630541, max_delta_step=9, max_depth=4, min_child_weight=4, n_estimators=2948, reg_alpha=0.8992020411205937, reg_lambda=2.3030921920862792, scale_pos_weight=1.1933230309329774, subsample=0.9122306976646831; total time=   5.9s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=1.040463659958357, learning_rate=0.005952096969175991, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=1763, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=0.8440318924367449, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=1.040463659958357, learning_rate=0.005952096969175991, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=1763, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=0.8440318924367449, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bylevel=0.8462933638642077, colsample_bynode=0.9057498977948752, colsample_bytree=0.8563062368406351, gamma=0.0, learning_rate=0.0026574184389436335, max_delta_step=1, max_depth=4, min_child_weight=6, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.8833628534088293, scale_pos_weight=1.2, subsample=0.7; total time=   7.3s\n",
      "[CV] END colsample_bylevel=0.8677291073484901, colsample_bynode=0.603736117594583, colsample_bytree=0.8884344512621404, gamma=1.9885386884664678, learning_rate=0.002274213099941156, max_delta_step=3, max_depth=10, min_child_weight=1, n_estimators=2226, reg_alpha=0.09028258368517209, reg_lambda=1.8428916074222934, scale_pos_weight=0.94000857652063, subsample=0.7686470875919859; total time=  12.9s\n",
      "[CV] END colsample_bylevel=0.7416301492048569, colsample_bynode=0.6957232814153148, colsample_bytree=0.9694523589326586, gamma=1.94441477286735, learning_rate=0.023388688062623314, max_delta_step=1, max_depth=14, min_child_weight=2, n_estimators=992, reg_alpha=0.0035444383065781357, reg_lambda=2.477159647203251, scale_pos_weight=0.8411469986804891, subsample=0.9921939358957043; total time=   2.6s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6377265116705637, colsample_bytree=0.6, gamma=2.0, learning_rate=0.01256672201636577, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=2.671764211510077, scale_pos_weight=1.1436985440474707, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6377265116705637, colsample_bytree=0.6, gamma=2.0, learning_rate=0.01256672201636577, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=2.671764211510077, scale_pos_weight=1.1436985440474707, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6377265116705637, colsample_bytree=0.6, gamma=2.0, learning_rate=0.01256672201636577, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=2.671764211510077, scale_pos_weight=1.1436985440474707, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.9493023530310418, colsample_bynode=0.6610466329638184, colsample_bytree=0.7304013206396551, gamma=1.9601273812033466, learning_rate=0.002200463303514099, max_delta_step=8, max_depth=15, min_child_weight=5, n_estimators=546, reg_alpha=2.997333316676403, reg_lambda=1.1063705708931721, scale_pos_weight=1.1895179376375697, subsample=0.9739004829076016; total time=   4.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.6810608926563045, colsample_bynode=0.8568745137018805, colsample_bytree=0.7863911877086216, gamma=0.6615107559360499, learning_rate=0.003943650747126641, max_delta_step=8, max_depth=15, min_child_weight=8, n_estimators=2723, reg_alpha=0.033491545664107954, reg_lambda=0.9762164505337632, scale_pos_weight=1.0664026110064593, subsample=0.9347156859224584; total time=  16.6s\n",
      "[CV] END colsample_bylevel=0.8700495242781614, colsample_bynode=0.9741069403804136, colsample_bytree=0.62958717036796, gamma=0.07206843180361024, learning_rate=0.004575142131563671, max_delta_step=7, max_depth=15, min_child_weight=11, n_estimators=2889, reg_alpha=0.45340026405866274, reg_lambda=2.3568033515980917, scale_pos_weight=1.0876294750664361, subsample=0.9829278377772181; total time=  18.9s\n",
      "[CV] END colsample_bylevel=0.9371253734625461, colsample_bynode=0.7882829953738026, colsample_bytree=0.8801698866610705, gamma=1.441658192209363, learning_rate=0.09890276655435588, max_delta_step=2, max_depth=14, min_child_weight=4, n_estimators=531, reg_alpha=0.16743579376618728, reg_lambda=1.4716116897426033, scale_pos_weight=0.8806736880089954, subsample=0.8078323550245288; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.9371253734625461, colsample_bynode=0.7882829953738026, colsample_bytree=0.8801698866610705, gamma=1.441658192209363, learning_rate=0.09890276655435588, max_delta_step=2, max_depth=14, min_child_weight=4, n_estimators=531, reg_alpha=0.16743579376618728, reg_lambda=1.4716116897426033, scale_pos_weight=0.8806736880089954, subsample=0.8078323550245288; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.6555948393906834, colsample_bynode=0.779127897071196, colsample_bytree=0.8843646418013996, gamma=0.7771406615207754, learning_rate=0.0010371750670406712, max_delta_step=9, max_depth=4, min_child_weight=3, n_estimators=895, reg_alpha=1.7163498690255783, reg_lambda=1.6920753989674546, scale_pos_weight=1.0074249300479703, subsample=0.9041284057602071; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.9866994616453865, gamma=0.7171575435473898, learning_rate=0.001, max_delta_step=1, max_depth=4, min_child_weight=1, n_estimators=1676, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=1.0975676556865281, subsample=0.8905984149471087; total time=   4.6s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7513703676532686, colsample_bytree=0.8416195781917156, gamma=0.0, learning_rate=0.0039432254340619555, max_delta_step=1, max_depth=4, min_child_weight=15, n_estimators=2035, reg_alpha=3.0, reg_lambda=0.24425098596191985, scale_pos_weight=0.896285636936831, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.9421811010359487, colsample_bynode=0.7271963836450162, colsample_bytree=0.7068356488970613, gamma=1.943450135251715, learning_rate=0.008054540143887817, max_delta_step=9, max_depth=4, min_child_weight=5, n_estimators=686, reg_alpha=0.04894963511345664, reg_lambda=0.9027847872438328, scale_pos_weight=0.843160163085181, subsample=0.7224624787282491; total time=   2.0s\n",
      "[CV] END colsample_bylevel=0.9586493830484578, colsample_bynode=0.9278296072652311, colsample_bytree=0.8780925342447243, gamma=0.12382855459709166, learning_rate=0.0034551379742941125, max_delta_step=4, max_depth=15, min_child_weight=5, n_estimators=515, reg_alpha=0.45713254706048245, reg_lambda=0.026067252142143345, scale_pos_weight=0.8604125211847513, subsample=0.8527339081796862; total time=   7.4s\n",
      "[CV] END colsample_bylevel=0.9586493830484578, colsample_bynode=0.9278296072652311, colsample_bytree=0.8780925342447243, gamma=0.12382855459709166, learning_rate=0.0034551379742941125, max_delta_step=4, max_depth=15, min_child_weight=5, n_estimators=515, reg_alpha=0.45713254706048245, reg_lambda=0.026067252142143345, scale_pos_weight=0.8604125211847513, subsample=0.8527339081796862; total time=   4.5s\n",
      "[CV] END colsample_bylevel=0.6052444905383665, colsample_bynode=1.0, colsample_bytree=0.6, gamma=0.0, learning_rate=0.016499149107402907, max_delta_step=10, max_depth=4, min_child_weight=13, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.0788031614100677, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.7310356044247226, colsample_bynode=0.8819640306581151, colsample_bytree=0.7508921358405333, gamma=1.9572085629164693, learning_rate=0.0024088747151639737, max_delta_step=9, max_depth=15, min_child_weight=11, n_estimators=2952, reg_alpha=1.8243000016355744, reg_lambda=2.4269789081386235, scale_pos_weight=1.1966076052914254, subsample=0.9277926671066168; total time=  13.0s\n",
      "[CV] END colsample_bylevel=0.7310356044247226, colsample_bynode=0.8819640306581151, colsample_bytree=0.7508921358405333, gamma=1.9572085629164693, learning_rate=0.0024088747151639737, max_delta_step=9, max_depth=15, min_child_weight=11, n_estimators=2952, reg_alpha=1.8243000016355744, reg_lambda=2.4269789081386235, scale_pos_weight=1.1966076052914254, subsample=0.9277926671066168; total time=  11.6s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=1.040463659958357, learning_rate=0.005952096969175991, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=1763, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=0.8440318924367449, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bylevel=0.8462933638642077, colsample_bynode=0.9057498977948752, colsample_bytree=0.8563062368406351, gamma=0.0, learning_rate=0.0026574184389436335, max_delta_step=1, max_depth=4, min_child_weight=6, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.8833628534088293, scale_pos_weight=1.2, subsample=0.7; total time=   8.1s\n",
      "[CV] END colsample_bylevel=0.6102413718196124, colsample_bynode=0.7440242316803746, colsample_bytree=0.6341335220211852, gamma=0.7700278424471481, learning_rate=0.05143879552988949, max_delta_step=7, max_depth=4, min_child_weight=7, n_estimators=500, reg_alpha=3.0, reg_lambda=1.7837126368580276, scale_pos_weight=1.1849679837912286, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.6102413718196124, colsample_bynode=0.7440242316803746, colsample_bytree=0.6341335220211852, gamma=0.7700278424471481, learning_rate=0.05143879552988949, max_delta_step=7, max_depth=4, min_child_weight=7, n_estimators=500, reg_alpha=3.0, reg_lambda=1.7837126368580276, scale_pos_weight=1.1849679837912286, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.6102413718196124, colsample_bynode=0.7440242316803746, colsample_bytree=0.6341335220211852, gamma=0.7700278424471481, learning_rate=0.05143879552988949, max_delta_step=7, max_depth=4, min_child_weight=7, n_estimators=500, reg_alpha=3.0, reg_lambda=1.7837126368580276, scale_pos_weight=1.1849679837912286, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bylevel=0.8677291073484901, colsample_bynode=0.603736117594583, colsample_bytree=0.8884344512621404, gamma=1.9885386884664678, learning_rate=0.002274213099941156, max_delta_step=3, max_depth=10, min_child_weight=1, n_estimators=2226, reg_alpha=0.09028258368517209, reg_lambda=1.8428916074222934, scale_pos_weight=0.94000857652063, subsample=0.7686470875919859; total time=  13.0s\n",
      "[CV] END colsample_bylevel=0.7416301492048569, colsample_bynode=0.6957232814153148, colsample_bytree=0.9694523589326586, gamma=1.94441477286735, learning_rate=0.023388688062623314, max_delta_step=1, max_depth=14, min_child_weight=2, n_estimators=992, reg_alpha=0.0035444383065781357, reg_lambda=2.477159647203251, scale_pos_weight=0.8411469986804891, subsample=0.9921939358957043; total time=   2.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6377265116705637, colsample_bytree=0.6, gamma=2.0, learning_rate=0.01256672201636577, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=2.671764211510077, scale_pos_weight=1.1436985440474707, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6377265116705637, colsample_bytree=0.6, gamma=2.0, learning_rate=0.01256672201636577, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=2.671764211510077, scale_pos_weight=1.1436985440474707, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.6810608926563045, colsample_bynode=0.8568745137018805, colsample_bytree=0.7863911877086216, gamma=0.6615107559360499, learning_rate=0.003943650747126641, max_delta_step=8, max_depth=15, min_child_weight=8, n_estimators=2723, reg_alpha=0.033491545664107954, reg_lambda=0.9762164505337632, scale_pos_weight=1.0664026110064593, subsample=0.9347156859224584; total time=  17.5s\n",
      "[CV] END colsample_bylevel=0.8700495242781614, colsample_bynode=0.9741069403804136, colsample_bytree=0.62958717036796, gamma=0.07206843180361024, learning_rate=0.004575142131563671, max_delta_step=7, max_depth=15, min_child_weight=11, n_estimators=2889, reg_alpha=0.45340026405866274, reg_lambda=2.3568033515980917, scale_pos_weight=1.0876294750664361, subsample=0.9829278377772181; total time=  14.9s\n",
      "[CV] END colsample_bylevel=0.9371253734625461, colsample_bynode=0.7882829953738026, colsample_bytree=0.8801698866610705, gamma=1.441658192209363, learning_rate=0.09890276655435588, max_delta_step=2, max_depth=14, min_child_weight=4, n_estimators=531, reg_alpha=0.16743579376618728, reg_lambda=1.4716116897426033, scale_pos_weight=0.8806736880089954, subsample=0.8078323550245288; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.6555948393906834, colsample_bynode=0.779127897071196, colsample_bytree=0.8843646418013996, gamma=0.7771406615207754, learning_rate=0.0010371750670406712, max_delta_step=9, max_depth=4, min_child_weight=3, n_estimators=895, reg_alpha=1.7163498690255783, reg_lambda=1.6920753989674546, scale_pos_weight=1.0074249300479703, subsample=0.9041284057602071; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.9866994616453865, gamma=0.7171575435473898, learning_rate=0.001, max_delta_step=1, max_depth=4, min_child_weight=1, n_estimators=1676, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=1.0975676556865281, subsample=0.8905984149471087; total time=   4.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7513703676532686, colsample_bytree=0.8416195781917156, gamma=0.0, learning_rate=0.0039432254340619555, max_delta_step=1, max_depth=4, min_child_weight=15, n_estimators=2035, reg_alpha=3.0, reg_lambda=0.24425098596191985, scale_pos_weight=0.896285636936831, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.9421811010359487, colsample_bynode=0.7271963836450162, colsample_bytree=0.7068356488970613, gamma=1.943450135251715, learning_rate=0.008054540143887817, max_delta_step=9, max_depth=4, min_child_weight=5, n_estimators=686, reg_alpha=0.04894963511345664, reg_lambda=0.9027847872438328, scale_pos_weight=0.843160163085181, subsample=0.7224624787282491; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.9421811010359487, colsample_bynode=0.7271963836450162, colsample_bytree=0.7068356488970613, gamma=1.943450135251715, learning_rate=0.008054540143887817, max_delta_step=9, max_depth=4, min_child_weight=5, n_estimators=686, reg_alpha=0.04894963511345664, reg_lambda=0.9027847872438328, scale_pos_weight=0.843160163085181, subsample=0.7224624787282491; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.9586493830484578, colsample_bynode=0.9278296072652311, colsample_bytree=0.8780925342447243, gamma=0.12382855459709166, learning_rate=0.0034551379742941125, max_delta_step=4, max_depth=15, min_child_weight=5, n_estimators=515, reg_alpha=0.45713254706048245, reg_lambda=0.026067252142143345, scale_pos_weight=0.8604125211847513, subsample=0.8527339081796862; total time=   7.8s\n",
      "[CV] END colsample_bylevel=0.6052444905383665, colsample_bynode=1.0, colsample_bytree=0.6, gamma=0.0, learning_rate=0.016499149107402907, max_delta_step=10, max_depth=4, min_child_weight=13, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.0788031614100677, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.7310356044247226, colsample_bynode=0.8819640306581151, colsample_bytree=0.7508921358405333, gamma=1.9572085629164693, learning_rate=0.0024088747151639737, max_delta_step=9, max_depth=15, min_child_weight=11, n_estimators=2952, reg_alpha=1.8243000016355744, reg_lambda=2.4269789081386235, scale_pos_weight=1.1966076052914254, subsample=0.9277926671066168; total time=  13.1s\n",
      "[CV] END colsample_bylevel=0.7125696251276914, colsample_bynode=0.9936842903272232, colsample_bytree=0.868783415330656, gamma=1.987391204062766, learning_rate=0.001651191832630541, max_delta_step=9, max_depth=4, min_child_weight=4, n_estimators=2948, reg_alpha=0.8992020411205937, reg_lambda=2.3030921920862792, scale_pos_weight=1.1933230309329774, subsample=0.9122306976646831; total time=   7.6s\n",
      "[CV] END colsample_bylevel=0.7125696251276914, colsample_bynode=0.9936842903272232, colsample_bytree=0.868783415330656, gamma=1.987391204062766, learning_rate=0.001651191832630541, max_delta_step=9, max_depth=4, min_child_weight=4, n_estimators=2948, reg_alpha=0.8992020411205937, reg_lambda=2.3030921920862792, scale_pos_weight=1.1933230309329774, subsample=0.9122306976646831; total time=   5.9s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=1.040463659958357, learning_rate=0.005952096969175991, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=1763, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=0.8440318924367449, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bylevel=0.8462933638642077, colsample_bynode=0.9057498977948752, colsample_bytree=0.8563062368406351, gamma=0.0, learning_rate=0.0026574184389436335, max_delta_step=1, max_depth=4, min_child_weight=6, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.8833628534088293, scale_pos_weight=1.2, subsample=0.7; total time=   8.0s\n",
      "[CV] END colsample_bylevel=0.6102413718196124, colsample_bynode=0.7440242316803746, colsample_bytree=0.6341335220211852, gamma=0.7700278424471481, learning_rate=0.05143879552988949, max_delta_step=7, max_depth=4, min_child_weight=7, n_estimators=500, reg_alpha=3.0, reg_lambda=1.7837126368580276, scale_pos_weight=1.1849679837912286, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bylevel=0.6102413718196124, colsample_bynode=0.7440242316803746, colsample_bytree=0.6341335220211852, gamma=0.7700278424471481, learning_rate=0.05143879552988949, max_delta_step=7, max_depth=4, min_child_weight=7, n_estimators=500, reg_alpha=3.0, reg_lambda=1.7837126368580276, scale_pos_weight=1.1849679837912286, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.8677291073484901, colsample_bynode=0.603736117594583, colsample_bytree=0.8884344512621404, gamma=1.9885386884664678, learning_rate=0.002274213099941156, max_delta_step=3, max_depth=10, min_child_weight=1, n_estimators=2226, reg_alpha=0.09028258368517209, reg_lambda=1.8428916074222934, scale_pos_weight=0.94000857652063, subsample=0.7686470875919859; total time=  12.7s\n",
      "[CV] END colsample_bylevel=0.7416301492048569, colsample_bynode=0.6957232814153148, colsample_bytree=0.9694523589326586, gamma=1.94441477286735, learning_rate=0.023388688062623314, max_delta_step=1, max_depth=14, min_child_weight=2, n_estimators=992, reg_alpha=0.0035444383065781357, reg_lambda=2.477159647203251, scale_pos_weight=0.8411469986804891, subsample=0.9921939358957043; total time=   2.6s\n",
      "[CV] END colsample_bylevel=0.7416301492048569, colsample_bynode=0.6957232814153148, colsample_bytree=0.9694523589326586, gamma=1.94441477286735, learning_rate=0.023388688062623314, max_delta_step=1, max_depth=14, min_child_weight=2, n_estimators=992, reg_alpha=0.0035444383065781357, reg_lambda=2.477159647203251, scale_pos_weight=0.8411469986804891, subsample=0.9921939358957043; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6377265116705637, colsample_bytree=0.6, gamma=2.0, learning_rate=0.01256672201636577, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=2.671764211510077, scale_pos_weight=1.1436985440474707, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.9493023530310418, colsample_bynode=0.6610466329638184, colsample_bytree=0.7304013206396551, gamma=1.9601273812033466, learning_rate=0.002200463303514099, max_delta_step=8, max_depth=15, min_child_weight=5, n_estimators=546, reg_alpha=2.997333316676403, reg_lambda=1.1063705708931721, scale_pos_weight=1.1895179376375697, subsample=0.9739004829076016; total time=   4.2sFitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:56:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.9131257619095126, colsample_bynode=0.6341249216690007, colsample_bytree=0.9936675155445983, gamma=0.0857942676485748, learning_rate=0.09481663486224755, max_delta_step=7, max_depth=15, min_child_weight=3, n_estimators=548, reg_alpha=2.4610959455164734, reg_lambda=2.6124094668159477, scale_pos_weight=1.0940675942646385, subsample=0.8595823133915781; total time=   3.4s\n",
      "[CV] END colsample_bylevel=0.9496495710520071, colsample_bynode=0.7297548347921033, colsample_bytree=0.6729551572186834, gamma=0.35894132306677556, learning_rate=0.008217533888141244, max_delta_step=7, max_depth=15, min_child_weight=9, n_estimators=2956, reg_alpha=2.9634734275917465, reg_lambda=0.9536283864182313, scale_pos_weight=0.8133759404527321, subsample=0.7208362598703725; total time=  14.7s\n",
      "[CV] END colsample_bylevel=0.6810608926563045, colsample_bynode=0.8568745137018805, colsample_bytree=0.7863911877086216, gamma=0.6615107559360499, learning_rate=0.003943650747126641, max_delta_step=8, max_depth=15, min_child_weight=8, n_estimators=2723, reg_alpha=0.033491545664107954, reg_lambda=0.9762164505337632, scale_pos_weight=1.0664026110064593, subsample=0.9347156859224584; total time=  16.6s\n",
      "[CV] END colsample_bylevel=0.8700495242781614, colsample_bynode=0.9741069403804136, colsample_bytree=0.62958717036796, gamma=0.07206843180361024, learning_rate=0.004575142131563671, max_delta_step=7, max_depth=15, min_child_weight=11, n_estimators=2889, reg_alpha=0.45340026405866274, reg_lambda=2.3568033515980917, scale_pos_weight=1.0876294750664361, subsample=0.9829278377772181; total time=  19.1s\n",
      "[CV] END colsample_bylevel=0.9371253734625461, colsample_bynode=0.7882829953738026, colsample_bytree=0.8801698866610705, gamma=1.441658192209363, learning_rate=0.09890276655435588, max_delta_step=2, max_depth=14, min_child_weight=4, n_estimators=531, reg_alpha=0.16743579376618728, reg_lambda=1.4716116897426033, scale_pos_weight=0.8806736880089954, subsample=0.8078323550245288; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.6555948393906834, colsample_bynode=0.779127897071196, colsample_bytree=0.8843646418013996, gamma=0.7771406615207754, learning_rate=0.0010371750670406712, max_delta_step=9, max_depth=4, min_child_weight=3, n_estimators=895, reg_alpha=1.7163498690255783, reg_lambda=1.6920753989674546, scale_pos_weight=1.0074249300479703, subsample=0.9041284057602071; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.6555948393906834, colsample_bynode=0.779127897071196, colsample_bytree=0.8843646418013996, gamma=0.7771406615207754, learning_rate=0.0010371750670406712, max_delta_step=9, max_depth=4, min_child_weight=3, n_estimators=895, reg_alpha=1.7163498690255783, reg_lambda=1.6920753989674546, scale_pos_weight=1.0074249300479703, subsample=0.9041284057602071; total time=   2.1s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.9866994616453865, gamma=0.7171575435473898, learning_rate=0.001, max_delta_step=1, max_depth=4, min_child_weight=1, n_estimators=1676, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=1.0975676556865281, subsample=0.8905984149471087; total time=   4.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7513703676532686, colsample_bytree=0.8416195781917156, gamma=0.0, learning_rate=0.0039432254340619555, max_delta_step=1, max_depth=4, min_child_weight=15, n_estimators=2035, reg_alpha=3.0, reg_lambda=0.24425098596191985, scale_pos_weight=0.896285636936831, subsample=1.0; total time=   4.8s\n",
      "[CV] END colsample_bylevel=0.9421811010359487, colsample_bynode=0.7271963836450162, colsample_bytree=0.7068356488970613, gamma=1.943450135251715, learning_rate=0.008054540143887817, max_delta_step=9, max_depth=4, min_child_weight=5, n_estimators=686, reg_alpha=0.04894963511345664, reg_lambda=0.9027847872438328, scale_pos_weight=0.843160163085181, subsample=0.7224624787282491; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.9421811010359487, colsample_bynode=0.7271963836450162, colsample_bytree=0.7068356488970613, gamma=1.943450135251715, learning_rate=0.008054540143887817, max_delta_step=9, max_depth=4, min_child_weight=5, n_estimators=686, reg_alpha=0.04894963511345664, reg_lambda=0.9027847872438328, scale_pos_weight=0.843160163085181, subsample=0.7224624787282491; total time=   1.8s\n",
      "[CV] END colsample_bylevel=0.9586493830484578, colsample_bynode=0.9278296072652311, colsample_bytree=0.8780925342447243, gamma=0.12382855459709166, learning_rate=0.0034551379742941125, max_delta_step=4, max_depth=15, min_child_weight=5, n_estimators=515, reg_alpha=0.45713254706048245, reg_lambda=0.026067252142143345, scale_pos_weight=0.8604125211847513, subsample=0.8527339081796862; total time=   7.8s\n",
      "[CV] END colsample_bylevel=0.6052444905383665, colsample_bynode=1.0, colsample_bytree=0.6, gamma=0.0, learning_rate=0.016499149107402907, max_delta_step=10, max_depth=4, min_child_weight=13, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.0788031614100677, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.6052444905383665, colsample_bynode=1.0, colsample_bytree=0.6, gamma=0.0, learning_rate=0.016499149107402907, max_delta_step=10, max_depth=4, min_child_weight=13, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.0788031614100677, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.7310356044247226, colsample_bynode=0.8819640306581151, colsample_bytree=0.7508921358405333, gamma=1.9572085629164693, learning_rate=0.0024088747151639737, max_delta_step=9, max_depth=15, min_child_weight=11, n_estimators=2952, reg_alpha=1.8243000016355744, reg_lambda=2.4269789081386235, scale_pos_weight=1.1966076052914254, subsample=0.9277926671066168; total time=  12.9s\n",
      "[CV] END colsample_bylevel=0.7125696251276914, colsample_bynode=0.9936842903272232, colsample_bytree=0.868783415330656, gamma=1.987391204062766, learning_rate=0.001651191832630541, max_delta_step=9, max_depth=4, min_child_weight=4, n_estimators=2948, reg_alpha=0.8992020411205937, reg_lambda=2.3030921920862792, scale_pos_weight=1.1933230309329774, subsample=0.9122306976646831; total time=   7.7s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=1.040463659958357, learning_rate=0.005952096969175991, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=1763, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=0.8440318924367449, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=1.040463659958357, learning_rate=0.005952096969175991, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=1763, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=0.8440318924367449, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bylevel=0.8462933638642077, colsample_bynode=0.9057498977948752, colsample_bytree=0.8563062368406351, gamma=0.0, learning_rate=0.0026574184389436335, max_delta_step=1, max_depth=4, min_child_weight=6, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.8833628534088293, scale_pos_weight=1.2, subsample=0.7; total time=   7.3s\n",
      "[CV] END colsample_bylevel=0.8677291073484901, colsample_bynode=0.603736117594583, colsample_bytree=0.8884344512621404, gamma=1.9885386884664678, learning_rate=0.002274213099941156, max_delta_step=3, max_depth=10, min_child_weight=1, n_estimators=2226, reg_alpha=0.09028258368517209, reg_lambda=1.8428916074222934, scale_pos_weight=0.94000857652063, subsample=0.7686470875919859; total time=  12.7s\n",
      "[CV] END colsample_bylevel=0.8677291073484901, colsample_bynode=0.603736117594583, colsample_bytree=0.8884344512621404, gamma=1.9885386884664678, learning_rate=0.002274213099941156, max_delta_step=3, max_depth=10, min_child_weight=1, n_estimators=2226, reg_alpha=0.09028258368517209, reg_lambda=1.8428916074222934, scale_pos_weight=0.94000857652063, subsample=0.7686470875919859; total time=   9.5s\n",
      "[CV] END colsample_bylevel=0.9493023530310418, colsample_bynode=0.6610466329638184, colsample_bytree=0.7304013206396551, gamma=1.9601273812033466, learning_rate=0.002200463303514099, max_delta_step=8, max_depth=15, min_child_weight=5, n_estimators=546, reg_alpha=2.997333316676403, reg_lambda=1.1063705708931721, scale_pos_weight=1.1895179376375697, subsample=0.9739004829076016; total time=   4.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.6810608926563045, colsample_bynode=0.8568745137018805, colsample_bytree=0.7863911877086216, gamma=0.6615107559360499, learning_rate=0.003943650747126641, max_delta_step=8, max_depth=15, min_child_weight=8, n_estimators=2723, reg_alpha=0.033491545664107954, reg_lambda=0.9762164505337632, scale_pos_weight=1.0664026110064593, subsample=0.9347156859224584; total time=  17.5s\n",
      "[CV] END colsample_bylevel=0.8700495242781614, colsample_bynode=0.9741069403804136, colsample_bytree=0.62958717036796, gamma=0.07206843180361024, learning_rate=0.004575142131563671, max_delta_step=7, max_depth=15, min_child_weight=11, n_estimators=2889, reg_alpha=0.45340026405866274, reg_lambda=2.3568033515980917, scale_pos_weight=1.0876294750664361, subsample=0.9829278377772181; total time=  15.2s\n",
      "[CV] END colsample_bylevel=0.9371253734625461, colsample_bynode=0.7882829953738026, colsample_bytree=0.8801698866610705, gamma=1.441658192209363, learning_rate=0.09890276655435588, max_delta_step=2, max_depth=14, min_child_weight=4, n_estimators=531, reg_alpha=0.16743579376618728, reg_lambda=1.4716116897426033, scale_pos_weight=0.8806736880089954, subsample=0.8078323550245288; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.6555948393906834, colsample_bynode=0.779127897071196, colsample_bytree=0.8843646418013996, gamma=0.7771406615207754, learning_rate=0.0010371750670406712, max_delta_step=9, max_depth=4, min_child_weight=3, n_estimators=895, reg_alpha=1.7163498690255783, reg_lambda=1.6920753989674546, scale_pos_weight=1.0074249300479703, subsample=0.9041284057602071; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.9866994616453865, gamma=0.7171575435473898, learning_rate=0.001, max_delta_step=1, max_depth=4, min_child_weight=1, n_estimators=1676, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=1.0975676556865281, subsample=0.8905984149471087; total time=   4.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.9866994616453865, gamma=0.7171575435473898, learning_rate=0.001, max_delta_step=1, max_depth=4, min_child_weight=1, n_estimators=1676, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=1.0975676556865281, subsample=0.8905984149471087; total time=   3.1s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7513703676532686, colsample_bytree=0.8416195781917156, gamma=0.0, learning_rate=0.0039432254340619555, max_delta_step=1, max_depth=4, min_child_weight=15, n_estimators=2035, reg_alpha=3.0, reg_lambda=0.24425098596191985, scale_pos_weight=0.896285636936831, subsample=1.0; total time=   4.8s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7513703676532686, colsample_bytree=0.8416195781917156, gamma=0.0, learning_rate=0.0039432254340619555, max_delta_step=1, max_depth=4, min_child_weight=15, n_estimators=2035, reg_alpha=3.0, reg_lambda=0.24425098596191985, scale_pos_weight=0.896285636936831, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bylevel=0.9586493830484578, colsample_bynode=0.9278296072652311, colsample_bytree=0.8780925342447243, gamma=0.12382855459709166, learning_rate=0.0034551379742941125, max_delta_step=4, max_depth=15, min_child_weight=5, n_estimators=515, reg_alpha=0.45713254706048245, reg_lambda=0.026067252142143345, scale_pos_weight=0.8604125211847513, subsample=0.8527339081796862; total time=   7.5s\n",
      "[CV] END colsample_bylevel=0.6052444905383665, colsample_bynode=1.0, colsample_bytree=0.6, gamma=0.0, learning_rate=0.016499149107402907, max_delta_step=10, max_depth=4, min_child_weight=13, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.0788031614100677, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.7310356044247226, colsample_bynode=0.8819640306581151, colsample_bytree=0.7508921358405333, gamma=1.9572085629164693, learning_rate=0.0024088747151639737, max_delta_step=9, max_depth=15, min_child_weight=11, n_estimators=2952, reg_alpha=1.8243000016355744, reg_lambda=2.4269789081386235, scale_pos_weight=1.1966076052914254, subsample=0.9277926671066168; total time=  13.1s\n",
      "[CV] END colsample_bylevel=0.7125696251276914, colsample_bynode=0.9936842903272232, colsample_bytree=0.868783415330656, gamma=1.987391204062766, learning_rate=0.001651191832630541, max_delta_step=9, max_depth=4, min_child_weight=4, n_estimators=2948, reg_alpha=0.8992020411205937, reg_lambda=2.3030921920862792, scale_pos_weight=1.1933230309329774, subsample=0.9122306976646831; total time=   7.7s\n",
      "[CV] END colsample_bylevel=0.7125696251276914, colsample_bynode=0.9936842903272232, colsample_bytree=0.868783415330656, gamma=1.987391204062766, learning_rate=0.001651191832630541, max_delta_step=9, max_depth=4, min_child_weight=4, n_estimators=2948, reg_alpha=0.8992020411205937, reg_lambda=2.3030921920862792, scale_pos_weight=1.1933230309329774, subsample=0.9122306976646831; total time=   5.8s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=1.040463659958357, learning_rate=0.005952096969175991, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=1763, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=0.8440318924367449, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bylevel=0.8462933638642077, colsample_bynode=0.9057498977948752, colsample_bytree=0.8563062368406351, gamma=0.0, learning_rate=0.0026574184389436335, max_delta_step=1, max_depth=4, min_child_weight=6, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.8833628534088293, scale_pos_weight=1.2, subsample=0.7; total time=   8.1s\n",
      "[CV] END colsample_bylevel=0.6102413718196124, colsample_bynode=0.7440242316803746, colsample_bytree=0.6341335220211852, gamma=0.7700278424471481, learning_rate=0.05143879552988949, max_delta_step=7, max_depth=4, min_child_weight=7, n_estimators=500, reg_alpha=3.0, reg_lambda=1.7837126368580276, scale_pos_weight=1.1849679837912286, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.6102413718196124, colsample_bynode=0.7440242316803746, colsample_bytree=0.6341335220211852, gamma=0.7700278424471481, learning_rate=0.05143879552988949, max_delta_step=7, max_depth=4, min_child_weight=7, n_estimators=500, reg_alpha=3.0, reg_lambda=1.7837126368580276, scale_pos_weight=1.1849679837912286, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.6102413718196124, colsample_bynode=0.7440242316803746, colsample_bytree=0.6341335220211852, gamma=0.7700278424471481, learning_rate=0.05143879552988949, max_delta_step=7, max_depth=4, min_child_weight=7, n_estimators=500, reg_alpha=3.0, reg_lambda=1.7837126368580276, scale_pos_weight=1.1849679837912286, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bylevel=0.8677291073484901, colsample_bynode=0.603736117594583, colsample_bytree=0.8884344512621404, gamma=1.9885386884664678, learning_rate=0.002274213099941156, max_delta_step=3, max_depth=10, min_child_weight=1, n_estimators=2226, reg_alpha=0.09028258368517209, reg_lambda=1.8428916074222934, scale_pos_weight=0.94000857652063, subsample=0.7686470875919859; total time=  12.7s\n",
      "[CV] END colsample_bylevel=0.7416301492048569, colsample_bynode=0.6957232814153148, colsample_bytree=0.9694523589326586, gamma=1.94441477286735, learning_rate=0.023388688062623314, max_delta_step=1, max_depth=14, min_child_weight=2, n_estimators=992, reg_alpha=0.0035444383065781357, reg_lambda=2.477159647203251, scale_pos_weight=0.8411469986804891, subsample=0.9921939358957043; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.7416301492048569, colsample_bynode=0.6957232814153148, colsample_bytree=0.9694523589326586, gamma=1.94441477286735, learning_rate=0.023388688062623314, max_delta_step=1, max_depth=14, min_child_weight=2, n_estimators=992, reg_alpha=0.0035444383065781357, reg_lambda=2.477159647203251, scale_pos_weight=0.8411469986804891, subsample=0.9921939358957043; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6377265116705637, colsample_bytree=0.6, gamma=2.0, learning_rate=0.01256672201636577, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=2.671764211510077, scale_pos_weight=1.1436985440474707, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.9493023530310418, colsample_bynode=0.6610466329638184, colsample_bytree=0.7304013206396551, gamma=1.9601273812033466, learning_rate=0.002200463303514099, max_delta_step=8, max_depth=15, min_child_weight=5, n_estimators=546, reg_alpha=2.997333316676403, reg_lambda=1.1063705708931721, scale_pos_weight=1.1895179376375697, subsample=0.9739004829076016; total time=   4.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:57:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:58:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.7125696251276914, colsample_bynode=0.9936842903272232, colsample_bytree=0.868783415330656, gamma=1.987391204062766, learning_rate=0.001651191832630541, max_delta_step=9, max_depth=4, min_child_weight=4, n_estimators=2948, reg_alpha=0.8992020411205937, reg_lambda=2.3030921920862792, scale_pos_weight=1.1933230309329774, subsample=0.9122306976646831; total time=   5.8s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=1.040463659958357, learning_rate=0.005952096969175991, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=1763, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=0.8440318924367449, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bylevel=0.8462933638642077, colsample_bynode=0.9057498977948752, colsample_bytree=0.8563062368406351, gamma=0.0, learning_rate=0.0026574184389436335, max_delta_step=1, max_depth=4, min_child_weight=6, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.8833628534088293, scale_pos_weight=1.2, subsample=0.7; total time=   7.9s\n",
      "[CV] END colsample_bylevel=0.8462933638642077, colsample_bynode=0.9057498977948752, colsample_bytree=0.8563062368406351, gamma=0.0, learning_rate=0.0026574184389436335, max_delta_step=1, max_depth=4, min_child_weight=6, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.8833628534088293, scale_pos_weight=1.2, subsample=0.7; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.8677291073484901, colsample_bynode=0.603736117594583, colsample_bytree=0.8884344512621404, gamma=1.9885386884664678, learning_rate=0.002274213099941156, max_delta_step=3, max_depth=10, min_child_weight=1, n_estimators=2226, reg_alpha=0.09028258368517209, reg_lambda=1.8428916074222934, scale_pos_weight=0.94000857652063, subsample=0.7686470875919859; total time=  12.8s\n",
      "[CV] END colsample_bylevel=0.7416301492048569, colsample_bynode=0.6957232814153148, colsample_bytree=0.9694523589326586, gamma=1.94441477286735, learning_rate=0.023388688062623314, max_delta_step=1, max_depth=14, min_child_weight=2, n_estimators=992, reg_alpha=0.0035444383065781357, reg_lambda=2.477159647203251, scale_pos_weight=0.8411469986804891, subsample=0.9921939358957043; total time=   2.6s\n",
      "[CV] END colsample_bylevel=0.7416301492048569, colsample_bynode=0.6957232814153148, colsample_bytree=0.9694523589326586, gamma=1.94441477286735, learning_rate=0.023388688062623314, max_delta_step=1, max_depth=14, min_child_weight=2, n_estimators=992, reg_alpha=0.0035444383065781357, reg_lambda=2.477159647203251, scale_pos_weight=0.8411469986804891, subsample=0.9921939358957043; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6377265116705637, colsample_bytree=0.6, gamma=2.0, learning_rate=0.01256672201636577, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=2.671764211510077, scale_pos_weight=1.1436985440474707, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.9493023530310418, colsample_bynode=0.6610466329638184, colsample_bytree=0.7304013206396551, gamma=1.9601273812033466, learning_rate=0.002200463303514099, max_delta_step=8, max_depth=15, min_child_weight=5, n_estimators=546, reg_alpha=2.997333316676403, reg_lambda=1.1063705708931721, scale_pos_weight=1.1895179376375697, subsample=0.9739004829076016; total time=   4.2s\n",
      "[CV] END colsample_bylevel=0.889444317748177, colsample_bynode=0.9632852894539913, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0038399496169913712, max_delta_step=10, max_depth=15, min_child_weight=15, n_estimators=500, reg_alpha=3.0, reg_lambda=0.3245518781282676, scale_pos_weight=1.0898856810581208, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bylevel=0.760739815416911, colsample_bynode=0.6965978775619123, colsample_bytree=0.643103288277387, gamma=1.981261082729455, learning_rate=0.03801484633656405, max_delta_step=10, max_depth=13, min_child_weight=14, n_estimators=2563, reg_alpha=2.995039345603483, reg_lambda=1.668131373501017, scale_pos_weight=1.022822618643537, subsample=0.7282281969859727; total time=   4.2s\n",
      "[CV] END colsample_bylevel=0.760739815416911, colsample_bynode=0.6965978775619123, colsample_bytree=0.643103288277387, gamma=1.981261082729455, learning_rate=0.03801484633656405, max_delta_step=10, max_depth=13, min_child_weight=14, n_estimators=2563, reg_alpha=2.995039345603483, reg_lambda=1.668131373501017, scale_pos_weight=1.022822618643537, subsample=0.7282281969859727; total time=   2.7s\n",
      "[CV] END colsample_bylevel=0.7375696727549332, colsample_bynode=0.7172005254059629, colsample_bytree=0.9980094723756316, gamma=1.44058157247619, learning_rate=0.05130843060698508, max_delta_step=4, max_depth=4, min_child_weight=2, n_estimators=543, reg_alpha=0.9814038478707849, reg_lambda=0.44490777634084167, scale_pos_weight=0.8666825787955377, subsample=0.9944640935395834; total time=   0.9s\n",
      "[CV] END colsample_bylevel=0.6381911354633409, colsample_bynode=0.7558470768527286, colsample_bytree=1.0, gamma=2.0, learning_rate=0.02176906485152723, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.9173505583786554, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.8503088411476036, colsample_bytree=0.6, gamma=0.0, learning_rate=0.003536883706397804, max_delta_step=4, max_depth=4, min_child_weight=15, n_estimators=2016, reg_alpha=3.0, reg_lambda=2.955282252477477, scale_pos_weight=0.8311283665694816, subsample=0.7; total time=   4.6s\n",
      "[CV] END colsample_bylevel=0.8702090810131375, colsample_bynode=0.6443354469097116, colsample_bytree=0.6350662211937494, gamma=0.9748442169902163, learning_rate=0.0010319684768327765, max_delta_step=7, max_depth=4, min_child_weight=14, n_estimators=2956, reg_alpha=1.5416262092798108, reg_lambda=0.5030060267921187, scale_pos_weight=0.8058215403596982, subsample=0.9381862420831204; total time=   7.4s\n",
      "[CV] END colsample_bylevel=0.8702090810131375, colsample_bynode=0.6443354469097116, colsample_bytree=0.6350662211937494, gamma=0.9748442169902163, learning_rate=0.0010319684768327765, max_delta_step=7, max_depth=4, min_child_weight=14, n_estimators=2956, reg_alpha=1.5416262092798108, reg_lambda=0.5030060267921187, scale_pos_weight=0.8058215403596982, subsample=0.9381862420831204; total time=   7.7s\n",
      "[CV] END colsample_bylevel=0.6049567208587082, colsample_bynode=0.8557669501289338, colsample_bytree=0.959519931692477, gamma=1.9853985559277496, learning_rate=0.004965175001673573, max_delta_step=3, max_depth=5, min_child_weight=1, n_estimators=947, reg_alpha=2.4689457315652916, reg_lambda=2.644198865966077, scale_pos_weight=0.8127549740051957, subsample=0.9303680677901948; total time=   4.7s\n",
      "[CV] END colsample_bylevel=0.6867009957086144, colsample_bynode=0.784970535052957, colsample_bytree=0.6271192334619813, gamma=1.9933397152942278, learning_rate=0.006715806589102056, max_delta_step=4, max_depth=14, min_child_weight=5, n_estimators=2803, reg_alpha=2.5734096374298105, reg_lambda=2.08584050106726, scale_pos_weight=1.0848653924111393, subsample=0.9445509295345054; total time=   8.7s\n",
      "[CV] END colsample_bylevel=0.8838794733924132, colsample_bynode=0.9050827638194778, colsample_bytree=0.6516107125324359, gamma=0.741466794976711, learning_rate=0.0013223969686197703, max_delta_step=4, max_depth=15, min_child_weight=13, n_estimators=2252, reg_alpha=2.849649290158395, reg_lambda=1.8307429739399375, scale_pos_weight=1.1420158966067704, subsample=0.7180831601617286; total time=  12.9s\n",
      "[CV] END colsample_bylevel=0.8838794733924132, colsample_bynode=0.9050827638194778, colsample_bytree=0.6516107125324359, gamma=0.741466794976711, learning_rate=0.0013223969686197703, max_delta_step=4, max_depth=15, min_child_weight=13, n_estimators=2252, reg_alpha=2.849649290158395, reg_lambda=1.8307429739399375, scale_pos_weight=1.1420158966067704, subsample=0.7180831601617286; total time=   9.2s\n",
      "[CV] END colsample_bylevel=0.8602283618562678, colsample_bynode=0.6167691173468559, colsample_bytree=0.9051490839774217, gamma=0.05969754835323983, learning_rate=0.0015383346552878614, max_delta_step=7, max_depth=15, min_child_weight=4, n_estimators=1569, reg_alpha=2.9453527456506645, reg_lambda=2.036573063729082, scale_pos_weight=1.0538783400036813, subsample=0.9865224350464125; total time=  19.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=1.040463659958357, learning_rate=0.005952096969175991, max_delta_step=10, max_depth=4, min_child_weight=15, n_estimators=1763, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=0.8440318924367449, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bylevel=0.8462933638642077, colsample_bynode=0.9057498977948752, colsample_bytree=0.8563062368406351, gamma=0.0, learning_rate=0.0026574184389436335, max_delta_step=1, max_depth=4, min_child_weight=6, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.8833628534088293, scale_pos_weight=1.2, subsample=0.7; total time=   8.0s\n",
      "[CV] END colsample_bylevel=0.8462933638642077, colsample_bynode=0.9057498977948752, colsample_bytree=0.8563062368406351, gamma=0.0, learning_rate=0.0026574184389436335, max_delta_step=1, max_depth=4, min_child_weight=6, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.8833628534088293, scale_pos_weight=1.2, subsample=0.7; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.8677291073484901, colsample_bynode=0.603736117594583, colsample_bytree=0.8884344512621404, gamma=1.9885386884664678, learning_rate=0.002274213099941156, max_delta_step=3, max_depth=10, min_child_weight=1, n_estimators=2226, reg_alpha=0.09028258368517209, reg_lambda=1.8428916074222934, scale_pos_weight=0.94000857652063, subsample=0.7686470875919859; total time=  12.5s\n",
      "[CV] END colsample_bylevel=0.8677291073484901, colsample_bynode=0.603736117594583, colsample_bytree=0.8884344512621404, gamma=1.9885386884664678, learning_rate=0.002274213099941156, max_delta_step=3, max_depth=10, min_child_weight=1, n_estimators=2226, reg_alpha=0.09028258368517209, reg_lambda=1.8428916074222934, scale_pos_weight=0.94000857652063, subsample=0.7686470875919859; total time=   9.4s\n",
      "[CV] END colsample_bylevel=0.9493023530310418, colsample_bynode=0.6610466329638184, colsample_bytree=0.7304013206396551, gamma=1.9601273812033466, learning_rate=0.002200463303514099, max_delta_step=8, max_depth=15, min_child_weight=5, n_estimators=546, reg_alpha=2.997333316676403, reg_lambda=1.1063705708931721, scale_pos_weight=1.1895179376375697, subsample=0.9739004829076016; total time=   4.1s\n",
      "[CV] END colsample_bylevel=0.9493023530310418, colsample_bynode=0.6610466329638184, colsample_bytree=0.7304013206396551, gamma=1.9601273812033466, learning_rate=0.002200463303514099, max_delta_step=8, max_depth=15, min_child_weight=5, n_estimators=546, reg_alpha=2.997333316676403, reg_lambda=1.1063705708931721, scale_pos_weight=1.1895179376375697, subsample=0.9739004829076016; total time=   3.6s\n",
      "[CV] END colsample_bylevel=0.760739815416911, colsample_bynode=0.6965978775619123, colsample_bytree=0.643103288277387, gamma=1.981261082729455, learning_rate=0.03801484633656405, max_delta_step=10, max_depth=13, min_child_weight=14, n_estimators=2563, reg_alpha=2.995039345603483, reg_lambda=1.668131373501017, scale_pos_weight=1.022822618643537, subsample=0.7282281969859727; total time=   4.1s\n",
      "[CV] END colsample_bylevel=0.7375696727549332, colsample_bynode=0.7172005254059629, colsample_bytree=0.9980094723756316, gamma=1.44058157247619, learning_rate=0.05130843060698508, max_delta_step=4, max_depth=4, min_child_weight=2, n_estimators=543, reg_alpha=0.9814038478707849, reg_lambda=0.44490777634084167, scale_pos_weight=0.8666825787955377, subsample=0.9944640935395834; total time=   0.9s\n",
      "[CV] END colsample_bylevel=0.7375696727549332, colsample_bynode=0.7172005254059629, colsample_bytree=0.9980094723756316, gamma=1.44058157247619, learning_rate=0.05130843060698508, max_delta_step=4, max_depth=4, min_child_weight=2, n_estimators=543, reg_alpha=0.9814038478707849, reg_lambda=0.44490777634084167, scale_pos_weight=0.8666825787955377, subsample=0.9944640935395834; total time=   0.9s\n",
      "[CV] END colsample_bylevel=0.6381911354633409, colsample_bynode=0.7558470768527286, colsample_bytree=1.0, gamma=2.0, learning_rate=0.02176906485152723, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.9173505583786554, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.8503088411476036, colsample_bytree=0.6, gamma=0.0, learning_rate=0.003536883706397804, max_delta_step=4, max_depth=4, min_child_weight=15, n_estimators=2016, reg_alpha=3.0, reg_lambda=2.955282252477477, scale_pos_weight=0.8311283665694816, subsample=0.7; total time=   4.5s\n",
      "[CV] END colsample_bylevel=0.8702090810131375, colsample_bynode=0.6443354469097116, colsample_bytree=0.6350662211937494, gamma=0.9748442169902163, learning_rate=0.0010319684768327765, max_delta_step=7, max_depth=4, min_child_weight=14, n_estimators=2956, reg_alpha=1.5416262092798108, reg_lambda=0.5030060267921187, scale_pos_weight=0.8058215403596982, subsample=0.9381862420831204; total time=   7.4s\n",
      "[CV] END colsample_bylevel=0.9351246966903117, colsample_bynode=0.9854611863029131, colsample_bytree=0.9716049880497319, gamma=1.8591335968415852, learning_rate=0.0396596424565272, max_delta_step=8, max_depth=4, min_child_weight=10, n_estimators=2745, reg_alpha=0.4968230328509552, reg_lambda=2.5736435123657606, scale_pos_weight=1.184849173566848, subsample=0.8317612535057759; total time=   4.8s\n",
      "[CV] END colsample_bylevel=0.9351246966903117, colsample_bynode=0.9854611863029131, colsample_bytree=0.9716049880497319, gamma=1.8591335968415852, learning_rate=0.0396596424565272, max_delta_step=8, max_depth=4, min_child_weight=10, n_estimators=2745, reg_alpha=0.4968230328509552, reg_lambda=2.5736435123657606, scale_pos_weight=1.184849173566848, subsample=0.8317612535057759; total time=   6.0s\n",
      "[CV] END colsample_bylevel=0.6049567208587082, colsample_bynode=0.8557669501289338, colsample_bytree=0.959519931692477, gamma=1.9853985559277496, learning_rate=0.004965175001673573, max_delta_step=3, max_depth=5, min_child_weight=1, n_estimators=947, reg_alpha=2.4689457315652916, reg_lambda=2.644198865966077, scale_pos_weight=0.8127549740051957, subsample=0.9303680677901948; total time=   3.4s\n",
      "[CV] END colsample_bylevel=0.6867009957086144, colsample_bynode=0.784970535052957, colsample_bytree=0.6271192334619813, gamma=1.9933397152942278, learning_rate=0.006715806589102056, max_delta_step=4, max_depth=14, min_child_weight=5, n_estimators=2803, reg_alpha=2.5734096374298105, reg_lambda=2.08584050106726, scale_pos_weight=1.0848653924111393, subsample=0.9445509295345054; total time=   8.7s\n",
      "[CV] END colsample_bylevel=0.8838794733924132, colsample_bynode=0.9050827638194778, colsample_bytree=0.6516107125324359, gamma=0.741466794976711, learning_rate=0.0013223969686197703, max_delta_step=4, max_depth=15, min_child_weight=13, n_estimators=2252, reg_alpha=2.849649290158395, reg_lambda=1.8307429739399375, scale_pos_weight=1.1420158966067704, subsample=0.7180831601617286; total time=  13.0s\n",
      "[CV] END colsample_bylevel=0.8814068818406465, colsample_bynode=0.7197753845009405, colsample_bytree=1.0, gamma=0.0, learning_rate=0.00862812314063869, max_delta_step=6, max_depth=4, min_child_weight=15, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=0.7; total time=   1.8s\n",
      "[CV] END colsample_bylevel=0.8814068818406465, colsample_bynode=0.7197753845009405, colsample_bytree=1.0, gamma=0.0, learning_rate=0.00862812314063869, max_delta_step=6, max_depth=4, min_child_weight=15, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=0.7; total time=   1.8s\n",
      "[CV] END colsample_bylevel=0.8814068818406465, colsample_bynode=0.7197753845009405, colsample_bytree=1.0, gamma=0.0, learning_rate=0.00862812314063869, max_delta_step=6, max_depth=4, min_child_weight=15, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=0.7; total time=   1.7s\n",
      "[CV] END colsample_bylevel=0.8602283618562678, colsample_bynode=0.6167691173468559, colsample_bytree=0.9051490839774217, gamma=0.05969754835323983, learning_rate=0.0015383346552878614, max_delta_step=7, max_depth=15, min_child_weight=4, n_estimators=1569, reg_alpha=2.9453527456506645, reg_lambda=2.036573063729082, scale_pos_weight=1.0538783400036813, subsample=0.9865224350464125; total time=  19.8s\n",
      "[CV] END colsample_bylevel=0.9533923554263655, colsample_bynode=0.7698742853954607, colsample_bytree=0.7455511442221807, gamma=1.9791800808553475, learning_rate=0.08620622105880298, max_delta_step=6, max_depth=4, min_child_weight=6, n_estimators=1654, reg_alpha=2.4578329293588403, reg_lambda=2.3003373083809695, scale_pos_weight=1.1575520841344622, subsample=0.8414805196611954; total time=   2.9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:59:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.889444317748177, colsample_bynode=0.9632852894539913, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0038399496169913712, max_delta_step=10, max_depth=15, min_child_weight=15, n_estimators=500, reg_alpha=3.0, reg_lambda=0.3245518781282676, scale_pos_weight=1.0898856810581208, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bylevel=0.760739815416911, colsample_bynode=0.6965978775619123, colsample_bytree=0.643103288277387, gamma=1.981261082729455, learning_rate=0.03801484633656405, max_delta_step=10, max_depth=13, min_child_weight=14, n_estimators=2563, reg_alpha=2.995039345603483, reg_lambda=1.668131373501017, scale_pos_weight=1.022822618643537, subsample=0.7282281969859727; total time=   4.1s\n",
      "[CV] END colsample_bylevel=0.760739815416911, colsample_bynode=0.6965978775619123, colsample_bytree=0.643103288277387, gamma=1.981261082729455, learning_rate=0.03801484633656405, max_delta_step=10, max_depth=13, min_child_weight=14, n_estimators=2563, reg_alpha=2.995039345603483, reg_lambda=1.668131373501017, scale_pos_weight=1.022822618643537, subsample=0.7282281969859727; total time=   2.7s\n",
      "[CV] END colsample_bylevel=0.7375696727549332, colsample_bynode=0.7172005254059629, colsample_bytree=0.9980094723756316, gamma=1.44058157247619, learning_rate=0.05130843060698508, max_delta_step=4, max_depth=4, min_child_weight=2, n_estimators=543, reg_alpha=0.9814038478707849, reg_lambda=0.44490777634084167, scale_pos_weight=0.8666825787955377, subsample=0.9944640935395834; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.6381911354633409, colsample_bynode=0.7558470768527286, colsample_bytree=1.0, gamma=2.0, learning_rate=0.02176906485152723, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.9173505583786554, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.6381911354633409, colsample_bynode=0.7558470768527286, colsample_bytree=1.0, gamma=2.0, learning_rate=0.02176906485152723, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.9173505583786554, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.8503088411476036, colsample_bytree=0.6, gamma=0.0, learning_rate=0.003536883706397804, max_delta_step=4, max_depth=4, min_child_weight=15, n_estimators=2016, reg_alpha=3.0, reg_lambda=2.955282252477477, scale_pos_weight=0.8311283665694816, subsample=0.7; total time=   4.3s\n",
      "[CV] END colsample_bylevel=0.8702090810131375, colsample_bynode=0.6443354469097116, colsample_bytree=0.6350662211937494, gamma=0.9748442169902163, learning_rate=0.0010319684768327765, max_delta_step=7, max_depth=4, min_child_weight=14, n_estimators=2956, reg_alpha=1.5416262092798108, reg_lambda=0.5030060267921187, scale_pos_weight=0.8058215403596982, subsample=0.9381862420831204; total time=   7.5s\n",
      "[CV] END colsample_bylevel=0.9351246966903117, colsample_bynode=0.9854611863029131, colsample_bytree=0.9716049880497319, gamma=1.8591335968415852, learning_rate=0.0396596424565272, max_delta_step=8, max_depth=4, min_child_weight=10, n_estimators=2745, reg_alpha=0.4968230328509552, reg_lambda=2.5736435123657606, scale_pos_weight=1.184849173566848, subsample=0.8317612535057759; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.6049567208587082, colsample_bynode=0.8557669501289338, colsample_bytree=0.959519931692477, gamma=1.9853985559277496, learning_rate=0.004965175001673573, max_delta_step=3, max_depth=5, min_child_weight=1, n_estimators=947, reg_alpha=2.4689457315652916, reg_lambda=2.644198865966077, scale_pos_weight=0.8127549740051957, subsample=0.9303680677901948; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.6049567208587082, colsample_bynode=0.8557669501289338, colsample_bytree=0.959519931692477, gamma=1.9853985559277496, learning_rate=0.004965175001673573, max_delta_step=3, max_depth=5, min_child_weight=1, n_estimators=947, reg_alpha=2.4689457315652916, reg_lambda=2.644198865966077, scale_pos_weight=0.8127549740051957, subsample=0.9303680677901948; total time=   4.6s\n",
      "[CV] END colsample_bylevel=0.6867009957086144, colsample_bynode=0.784970535052957, colsample_bytree=0.6271192334619813, gamma=1.9933397152942278, learning_rate=0.006715806589102056, max_delta_step=4, max_depth=14, min_child_weight=5, n_estimators=2803, reg_alpha=2.5734096374298105, reg_lambda=2.08584050106726, scale_pos_weight=1.0848653924111393, subsample=0.9445509295345054; total time=   8.6s\n",
      "[CV] END colsample_bylevel=0.8838794733924132, colsample_bynode=0.9050827638194778, colsample_bytree=0.6516107125324359, gamma=0.741466794976711, learning_rate=0.0013223969686197703, max_delta_step=4, max_depth=15, min_child_weight=13, n_estimators=2252, reg_alpha=2.849649290158395, reg_lambda=1.8307429739399375, scale_pos_weight=1.1420158966067704, subsample=0.7180831601617286; total time=  13.0s\n",
      "[CV] END colsample_bylevel=0.8814068818406465, colsample_bynode=0.7197753845009405, colsample_bytree=1.0, gamma=0.0, learning_rate=0.00862812314063869, max_delta_step=6, max_depth=4, min_child_weight=15, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=0.7; total time=   1.8s\n",
      "[CV] END colsample_bylevel=0.8814068818406465, colsample_bynode=0.7197753845009405, colsample_bytree=1.0, gamma=0.0, learning_rate=0.00862812314063869, max_delta_step=6, max_depth=4, min_child_weight=15, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=0.7; total time=   1.8s\n",
      "[CV] END colsample_bylevel=0.8814068818406465, colsample_bynode=0.7197753845009405, colsample_bytree=1.0, gamma=0.0, learning_rate=0.00862812314063869, max_delta_step=6, max_depth=4, min_child_weight=15, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bylevel=0.8602283618562678, colsample_bynode=0.6167691173468559, colsample_bytree=0.9051490839774217, gamma=0.05969754835323983, learning_rate=0.0015383346552878614, max_delta_step=7, max_depth=15, min_child_weight=4, n_estimators=1569, reg_alpha=2.9453527456506645, reg_lambda=2.036573063729082, scale_pos_weight=1.0538783400036813, subsample=0.9865224350464125; total time=  19.4s\n",
      "[CV] END colsample_bylevel=0.9533923554263655, colsample_bynode=0.7698742853954607, colsample_bytree=0.7455511442221807, gamma=1.9791800808553475, learning_rate=0.08620622105880298, max_delta_step=6, max_depth=4, min_child_weight=6, n_estimators=1654, reg_alpha=2.4578329293588403, reg_lambda=2.3003373083809695, scale_pos_weight=1.1575520841344622, subsample=0.8414805196611954; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.9533923554263655, colsample_bynode=0.7698742853954607, colsample_bytree=0.7455511442221807, gamma=1.9791800808553475, learning_rate=0.08620622105880298, max_delta_step=6, max_depth=4, min_child_weight=6, n_estimators=1654, reg_alpha=2.4578329293588403, reg_lambda=2.3003373083809695, scale_pos_weight=1.1575520841344622, subsample=0.8414805196611954; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.6649962364931218, colsample_bynode=0.8847755784481242, colsample_bytree=0.7226827705501258, gamma=1.96975292470343, learning_rate=0.00849747157126491, max_delta_step=1, max_depth=15, min_child_weight=6, n_estimators=1663, reg_alpha=0.18734316004947443, reg_lambda=0.4048307065571941, scale_pos_weight=0.9346324108458257, subsample=0.9269603092966929; total time=   6.4s\n",
      "[CV] END colsample_bylevel=0.6649962364931218, colsample_bynode=0.8847755784481242, colsample_bytree=0.7226827705501258, gamma=1.96975292470343, learning_rate=0.00849747157126491, max_delta_step=1, max_depth=15, min_child_weight=6, n_estimators=1663, reg_alpha=0.18734316004947443, reg_lambda=0.4048307065571941, scale_pos_weight=0.9346324108458257, subsample=0.9269603092966929; total time=   4.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.01022295162190459, max_delta_step=0, max_depth=4, min_child_weight=15, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.9598781727284172, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.7767955244290717, colsample_bynode=0.6960142338918816, colsample_bytree=0.838194951900167, gamma=0.21722093722218166, learning_rate=0.0135257233226764, max_delta_step=1, max_depth=4, min_child_weight=5, n_estimators=576, reg_alpha=0.1898130813241477, reg_lambda=0.5717877557819098, scale_pos_weight=1.1057117475115867, subsample=0.9583901382776849; total time=   1.7s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.7416301492048569, colsample_bynode=0.6957232814153148, colsample_bytree=0.9694523589326586, gamma=1.94441477286735, learning_rate=0.023388688062623314, max_delta_step=1, max_depth=14, min_child_weight=2, n_estimators=992, reg_alpha=0.0035444383065781357, reg_lambda=2.477159647203251, scale_pos_weight=0.8411469986804891, subsample=0.9921939358957043; total time=   2.6s\n",
      "[CV] END colsample_bylevel=0.7416301492048569, colsample_bynode=0.6957232814153148, colsample_bytree=0.9694523589326586, gamma=1.94441477286735, learning_rate=0.023388688062623314, max_delta_step=1, max_depth=14, min_child_weight=2, n_estimators=992, reg_alpha=0.0035444383065781357, reg_lambda=2.477159647203251, scale_pos_weight=0.8411469986804891, subsample=0.9921939358957043; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6377265116705637, colsample_bytree=0.6, gamma=2.0, learning_rate=0.01256672201636577, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=2.671764211510077, scale_pos_weight=1.1436985440474707, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.9493023530310418, colsample_bynode=0.6610466329638184, colsample_bytree=0.7304013206396551, gamma=1.9601273812033466, learning_rate=0.002200463303514099, max_delta_step=8, max_depth=15, min_child_weight=5, n_estimators=546, reg_alpha=2.997333316676403, reg_lambda=1.1063705708931721, scale_pos_weight=1.1895179376375697, subsample=0.9739004829076016; total time=   4.0s\n",
      "[CV] END colsample_bylevel=0.9493023530310418, colsample_bynode=0.6610466329638184, colsample_bytree=0.7304013206396551, gamma=1.9601273812033466, learning_rate=0.002200463303514099, max_delta_step=8, max_depth=15, min_child_weight=5, n_estimators=546, reg_alpha=2.997333316676403, reg_lambda=1.1063705708931721, scale_pos_weight=1.1895179376375697, subsample=0.9739004829076016; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.760739815416911, colsample_bynode=0.6965978775619123, colsample_bytree=0.643103288277387, gamma=1.981261082729455, learning_rate=0.03801484633656405, max_delta_step=10, max_depth=13, min_child_weight=14, n_estimators=2563, reg_alpha=2.995039345603483, reg_lambda=1.668131373501017, scale_pos_weight=1.022822618643537, subsample=0.7282281969859727; total time=   4.1s\n",
      "[CV] END colsample_bylevel=0.7375696727549332, colsample_bynode=0.7172005254059629, colsample_bytree=0.9980094723756316, gamma=1.44058157247619, learning_rate=0.05130843060698508, max_delta_step=4, max_depth=4, min_child_weight=2, n_estimators=543, reg_alpha=0.9814038478707849, reg_lambda=0.44490777634084167, scale_pos_weight=0.8666825787955377, subsample=0.9944640935395834; total time=   0.9s\n",
      "[CV] END colsample_bylevel=0.6381911354633409, colsample_bynode=0.7558470768527286, colsample_bytree=1.0, gamma=2.0, learning_rate=0.02176906485152723, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.9173505583786554, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.6381911354633409, colsample_bynode=0.7558470768527286, colsample_bytree=1.0, gamma=2.0, learning_rate=0.02176906485152723, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.9173505583786554, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.8503088411476036, colsample_bytree=0.6, gamma=0.0, learning_rate=0.003536883706397804, max_delta_step=4, max_depth=4, min_child_weight=15, n_estimators=2016, reg_alpha=3.0, reg_lambda=2.955282252477477, scale_pos_weight=0.8311283665694816, subsample=0.7; total time=   4.3s\n",
      "[CV] END colsample_bylevel=0.8702090810131375, colsample_bynode=0.6443354469097116, colsample_bytree=0.6350662211937494, gamma=0.9748442169902163, learning_rate=0.0010319684768327765, max_delta_step=7, max_depth=4, min_child_weight=14, n_estimators=2956, reg_alpha=1.5416262092798108, reg_lambda=0.5030060267921187, scale_pos_weight=0.8058215403596982, subsample=0.9381862420831204; total time=   7.5s\n",
      "[CV] END colsample_bylevel=0.9351246966903117, colsample_bynode=0.9854611863029131, colsample_bytree=0.9716049880497319, gamma=1.8591335968415852, learning_rate=0.0396596424565272, max_delta_step=8, max_depth=4, min_child_weight=10, n_estimators=2745, reg_alpha=0.4968230328509552, reg_lambda=2.5736435123657606, scale_pos_weight=1.184849173566848, subsample=0.8317612535057759; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.9351246966903117, colsample_bynode=0.9854611863029131, colsample_bytree=0.9716049880497319, gamma=1.8591335968415852, learning_rate=0.0396596424565272, max_delta_step=8, max_depth=4, min_child_weight=10, n_estimators=2745, reg_alpha=0.4968230328509552, reg_lambda=2.5736435123657606, scale_pos_weight=1.184849173566848, subsample=0.8317612535057759; total time=   6.2s\n",
      "[CV] END colsample_bylevel=0.6049567208587082, colsample_bynode=0.8557669501289338, colsample_bytree=0.959519931692477, gamma=1.9853985559277496, learning_rate=0.004965175001673573, max_delta_step=3, max_depth=5, min_child_weight=1, n_estimators=947, reg_alpha=2.4689457315652916, reg_lambda=2.644198865966077, scale_pos_weight=0.8127549740051957, subsample=0.9303680677901948; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.6867009957086144, colsample_bynode=0.784970535052957, colsample_bytree=0.6271192334619813, gamma=1.9933397152942278, learning_rate=0.006715806589102056, max_delta_step=4, max_depth=14, min_child_weight=5, n_estimators=2803, reg_alpha=2.5734096374298105, reg_lambda=2.08584050106726, scale_pos_weight=1.0848653924111393, subsample=0.9445509295345054; total time=   8.7s\n",
      "[CV] END colsample_bylevel=0.8838794733924132, colsample_bynode=0.9050827638194778, colsample_bytree=0.6516107125324359, gamma=0.741466794976711, learning_rate=0.0013223969686197703, max_delta_step=4, max_depth=15, min_child_weight=13, n_estimators=2252, reg_alpha=2.849649290158395, reg_lambda=1.8307429739399375, scale_pos_weight=1.1420158966067704, subsample=0.7180831601617286; total time=  13.0s\n",
      "[CV] END colsample_bylevel=0.8814068818406465, colsample_bynode=0.7197753845009405, colsample_bytree=1.0, gamma=0.0, learning_rate=0.00862812314063869, max_delta_step=6, max_depth=4, min_child_weight=15, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=0.7; total time=   1.7s\n",
      "[CV] END colsample_bylevel=0.8814068818406465, colsample_bynode=0.7197753845009405, colsample_bytree=1.0, gamma=0.0, learning_rate=0.00862812314063869, max_delta_step=6, max_depth=4, min_child_weight=15, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=0.7; total time=   1.8s\n",
      "[CV] END colsample_bylevel=0.8602283618562678, colsample_bynode=0.6167691173468559, colsample_bytree=0.9051490839774217, gamma=0.05969754835323983, learning_rate=0.0015383346552878614, max_delta_step=7, max_depth=15, min_child_weight=4, n_estimators=1569, reg_alpha=2.9453527456506645, reg_lambda=2.036573063729082, scale_pos_weight=1.0538783400036813, subsample=0.9865224350464125; total time=  19.5s\n",
      "[CV] END colsample_bylevel=0.9533923554263655, colsample_bynode=0.7698742853954607, colsample_bytree=0.7455511442221807, gamma=1.9791800808553475, learning_rate=0.08620622105880298, max_delta_step=6, max_depth=4, min_child_weight=6, n_estimators=1654, reg_alpha=2.4578329293588403, reg_lambda=2.3003373083809695, scale_pos_weight=1.1575520841344622, subsample=0.8414805196611954; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.9533923554263655, colsample_bynode=0.7698742853954607, colsample_bytree=0.7455511442221807, gamma=1.9791800808553475, learning_rate=0.08620622105880298, max_delta_step=6, max_depth=4, min_child_weight=6, n_estimators=1654, reg_alpha=2.4578329293588403, reg_lambda=2.3003373083809695, scale_pos_weight=1.1575520841344622, subsample=0.8414805196611954; total time=   3.1s\n",
      "[CV] END colsample_bylevel=0.6649962364931218, colsample_bynode=0.8847755784481242, colsample_bytree=0.7226827705501258, gamma=1.96975292470343, learning_rate=0.00849747157126491, max_delta_step=1, max_depth=15, min_child_weight=6, n_estimators=1663, reg_alpha=0.18734316004947443, reg_lambda=0.4048307065571941, scale_pos_weight=0.9346324108458257, subsample=0.9269603092966929; total time=   6.8s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.6377265116705637, colsample_bytree=0.6, gamma=2.0, learning_rate=0.01256672201636577, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=2.671764211510077, scale_pos_weight=1.1436985440474707, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.9493023530310418, colsample_bynode=0.6610466329638184, colsample_bytree=0.7304013206396551, gamma=1.9601273812033466, learning_rate=0.002200463303514099, max_delta_step=8, max_depth=15, min_child_weight=5, n_estimators=546, reg_alpha=2.997333316676403, reg_lambda=1.1063705708931721, scale_pos_weight=1.1895179376375697, subsample=0.9739004829076016; total time=   4.3s\n",
      "[CV] END colsample_bylevel=0.889444317748177, colsample_bynode=0.9632852894539913, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0038399496169913712, max_delta_step=10, max_depth=15, min_child_weight=15, n_estimators=500, reg_alpha=3.0, reg_lambda=0.3245518781282676, scale_pos_weight=1.0898856810581208, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bylevel=0.889444317748177, colsample_bynode=0.9632852894539913, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0038399496169913712, max_delta_step=10, max_depth=15, min_child_weight=15, n_estimators=500, reg_alpha=3.0, reg_lambda=0.3245518781282676, scale_pos_weight=1.0898856810581208, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bylevel=0.760739815416911, colsample_bynode=0.6965978775619123, colsample_bytree=0.643103288277387, gamma=1.981261082729455, learning_rate=0.03801484633656405, max_delta_step=10, max_depth=13, min_child_weight=14, n_estimators=2563, reg_alpha=2.995039345603483, reg_lambda=1.668131373501017, scale_pos_weight=1.022822618643537, subsample=0.7282281969859727; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.7375696727549332, colsample_bynode=0.7172005254059629, colsample_bytree=0.9980094723756316, gamma=1.44058157247619, learning_rate=0.05130843060698508, max_delta_step=4, max_depth=4, min_child_weight=2, n_estimators=543, reg_alpha=0.9814038478707849, reg_lambda=0.44490777634084167, scale_pos_weight=0.8666825787955377, subsample=0.9944640935395834; total time=   0.9s\n",
      "[CV] END colsample_bylevel=0.6381911354633409, colsample_bynode=0.7558470768527286, colsample_bytree=1.0, gamma=2.0, learning_rate=0.02176906485152723, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.9173505583786554, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.8503088411476036, colsample_bytree=0.6, gamma=0.0, learning_rate=0.003536883706397804, max_delta_step=4, max_depth=4, min_child_weight=15, n_estimators=2016, reg_alpha=3.0, reg_lambda=2.955282252477477, scale_pos_weight=0.8311283665694816, subsample=0.7; total time=   4.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.8503088411476036, colsample_bytree=0.6, gamma=0.0, learning_rate=0.003536883706397804, max_delta_step=4, max_depth=4, min_child_weight=15, n_estimators=2016, reg_alpha=3.0, reg_lambda=2.955282252477477, scale_pos_weight=0.8311283665694816, subsample=0.7; total time=   2.4s\n",
      "[CV] END colsample_bylevel=0.8702090810131375, colsample_bynode=0.6443354469097116, colsample_bytree=0.6350662211937494, gamma=0.9748442169902163, learning_rate=0.0010319684768327765, max_delta_step=7, max_depth=4, min_child_weight=14, n_estimators=2956, reg_alpha=1.5416262092798108, reg_lambda=0.5030060267921187, scale_pos_weight=0.8058215403596982, subsample=0.9381862420831204; total time=   7.4s\n",
      "[CV] END colsample_bylevel=0.9351246966903117, colsample_bynode=0.9854611863029131, colsample_bytree=0.9716049880497319, gamma=1.8591335968415852, learning_rate=0.0396596424565272, max_delta_step=8, max_depth=4, min_child_weight=10, n_estimators=2745, reg_alpha=0.4968230328509552, reg_lambda=2.5736435123657606, scale_pos_weight=1.184849173566848, subsample=0.8317612535057759; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.9351246966903117, colsample_bynode=0.9854611863029131, colsample_bytree=0.9716049880497319, gamma=1.8591335968415852, learning_rate=0.0396596424565272, max_delta_step=8, max_depth=4, min_child_weight=10, n_estimators=2745, reg_alpha=0.4968230328509552, reg_lambda=2.5736435123657606, scale_pos_weight=1.184849173566848, subsample=0.8317612535057759; total time=   6.1s\n",
      "[CV] END colsample_bylevel=0.6049567208587082, colsample_bynode=0.8557669501289338, colsample_bytree=0.959519931692477, gamma=1.9853985559277496, learning_rate=0.004965175001673573, max_delta_step=3, max_depth=5, min_child_weight=1, n_estimators=947, reg_alpha=2.4689457315652916, reg_lambda=2.644198865966077, scale_pos_weight=0.8127549740051957, subsample=0.9303680677901948; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.6867009957086144, colsample_bynode=0.784970535052957, colsample_bytree=0.6271192334619813, gamma=1.9933397152942278, learning_rate=0.006715806589102056, max_delta_step=4, max_depth=14, min_child_weight=5, n_estimators=2803, reg_alpha=2.5734096374298105, reg_lambda=2.08584050106726, scale_pos_weight=1.0848653924111393, subsample=0.9445509295345054; total time=   8.6s\n",
      "[CV] END colsample_bylevel=0.6867009957086144, colsample_bynode=0.784970535052957, colsample_bytree=0.6271192334619813, gamma=1.9933397152942278, learning_rate=0.006715806589102056, max_delta_step=4, max_depth=14, min_child_weight=5, n_estimators=2803, reg_alpha=2.5734096374298105, reg_lambda=2.08584050106726, scale_pos_weight=1.0848653924111393, subsample=0.9445509295345054; total time=   7.4s\n",
      "[CV] END colsample_bylevel=0.8838794733924132, colsample_bynode=0.9050827638194778, colsample_bytree=0.6516107125324359, gamma=0.741466794976711, learning_rate=0.0013223969686197703, max_delta_step=4, max_depth=15, min_child_weight=13, n_estimators=2252, reg_alpha=2.849649290158395, reg_lambda=1.8307429739399375, scale_pos_weight=1.1420158966067704, subsample=0.7180831601617286; total time=  12.5s\n",
      "[CV] END colsample_bylevel=0.8602283618562678, colsample_bynode=0.6167691173468559, colsample_bytree=0.9051490839774217, gamma=0.05969754835323983, learning_rate=0.0015383346552878614, max_delta_step=7, max_depth=15, min_child_weight=4, n_estimators=1569, reg_alpha=2.9453527456506645, reg_lambda=2.036573063729082, scale_pos_weight=1.0538783400036813, subsample=0.9865224350464125; total time=  19.0s\n",
      "[CV] END colsample_bylevel=0.8602283618562678, colsample_bynode=0.6167691173468559, colsample_bytree=0.9051490839774217, gamma=0.05969754835323983, learning_rate=0.0015383346552878614, max_delta_step=7, max_depth=15, min_child_weight=4, n_estimators=1569, reg_alpha=2.9453527456506645, reg_lambda=2.036573063729082, scale_pos_weight=1.0538783400036813, subsample=0.9865224350464125; total time=  16.6s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.01022295162190459, max_delta_step=0, max_depth=4, min_child_weight=15, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.9598781727284172, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.7767955244290717, colsample_bynode=0.6960142338918816, colsample_bytree=0.838194951900167, gamma=0.21722093722218166, learning_rate=0.0135257233226764, max_delta_step=1, max_depth=4, min_child_weight=5, n_estimators=576, reg_alpha=0.1898130813241477, reg_lambda=0.5717877557819098, scale_pos_weight=1.1057117475115867, subsample=0.9583901382776849; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.7767955244290717, colsample_bynode=0.6960142338918816, colsample_bytree=0.838194951900167, gamma=0.21722093722218166, learning_rate=0.0135257233226764, max_delta_step=1, max_depth=4, min_child_weight=5, n_estimators=576, reg_alpha=0.1898130813241477, reg_lambda=0.5717877557819098, scale_pos_weight=1.1057117475115867, subsample=0.9583901382776849; total time=   1.6s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.796031218457304, colsample_bytree=0.6, gamma=0.36781805718101357, learning_rate=0.018908377529571776, max_delta_step=0, max_depth=4, min_child_weight=14, n_estimators=500, reg_alpha=3.0, reg_lambda=0.3644045001537639, scale_pos_weight=0.8153144476093589, subsample=1.0; total time=   1.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.889444317748177, colsample_bynode=0.9632852894539913, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0038399496169913712, max_delta_step=10, max_depth=15, min_child_weight=15, n_estimators=500, reg_alpha=3.0, reg_lambda=0.3245518781282676, scale_pos_weight=1.0898856810581208, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bylevel=0.889444317748177, colsample_bynode=0.9632852894539913, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0038399496169913712, max_delta_step=10, max_depth=15, min_child_weight=15, n_estimators=500, reg_alpha=3.0, reg_lambda=0.3245518781282676, scale_pos_weight=1.0898856810581208, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bylevel=0.760739815416911, colsample_bynode=0.6965978775619123, colsample_bytree=0.643103288277387, gamma=1.981261082729455, learning_rate=0.03801484633656405, max_delta_step=10, max_depth=13, min_child_weight=14, n_estimators=2563, reg_alpha=2.995039345603483, reg_lambda=1.668131373501017, scale_pos_weight=1.022822618643537, subsample=0.7282281969859727; total time=   3.6s\n",
      "[CV] END colsample_bylevel=0.7375696727549332, colsample_bynode=0.7172005254059629, colsample_bytree=0.9980094723756316, gamma=1.44058157247619, learning_rate=0.05130843060698508, max_delta_step=4, max_depth=4, min_child_weight=2, n_estimators=543, reg_alpha=0.9814038478707849, reg_lambda=0.44490777634084167, scale_pos_weight=0.8666825787955377, subsample=0.9944640935395834; total time=   0.9s\n",
      "[CV] END colsample_bylevel=0.6381911354633409, colsample_bynode=0.7558470768527286, colsample_bytree=1.0, gamma=2.0, learning_rate=0.02176906485152723, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.9173505583786554, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.8503088411476036, colsample_bytree=0.6, gamma=0.0, learning_rate=0.003536883706397804, max_delta_step=4, max_depth=4, min_child_weight=15, n_estimators=2016, reg_alpha=3.0, reg_lambda=2.955282252477477, scale_pos_weight=0.8311283665694816, subsample=0.7; total time=   4.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.8503088411476036, colsample_bytree=0.6, gamma=0.0, learning_rate=0.003536883706397804, max_delta_step=4, max_depth=4, min_child_weight=15, n_estimators=2016, reg_alpha=3.0, reg_lambda=2.955282252477477, scale_pos_weight=0.8311283665694816, subsample=0.7; total time=   2.4s\n",
      "[CV] END colsample_bylevel=0.8702090810131375, colsample_bynode=0.6443354469097116, colsample_bytree=0.6350662211937494, gamma=0.9748442169902163, learning_rate=0.0010319684768327765, max_delta_step=7, max_depth=4, min_child_weight=14, n_estimators=2956, reg_alpha=1.5416262092798108, reg_lambda=0.5030060267921187, scale_pos_weight=0.8058215403596982, subsample=0.9381862420831204; total time=   7.5s\n",
      "[CV] END colsample_bylevel=0.9351246966903117, colsample_bynode=0.9854611863029131, colsample_bytree=0.9716049880497319, gamma=1.8591335968415852, learning_rate=0.0396596424565272, max_delta_step=8, max_depth=4, min_child_weight=10, n_estimators=2745, reg_alpha=0.4968230328509552, reg_lambda=2.5736435123657606, scale_pos_weight=1.184849173566848, subsample=0.8317612535057759; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.6049567208587082, colsample_bynode=0.8557669501289338, colsample_bytree=0.959519931692477, gamma=1.9853985559277496, learning_rate=0.004965175001673573, max_delta_step=3, max_depth=5, min_child_weight=1, n_estimators=947, reg_alpha=2.4689457315652916, reg_lambda=2.644198865966077, scale_pos_weight=0.8127549740051957, subsample=0.9303680677901948; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.6049567208587082, colsample_bynode=0.8557669501289338, colsample_bytree=0.959519931692477, gamma=1.9853985559277496, learning_rate=0.004965175001673573, max_delta_step=3, max_depth=5, min_child_weight=1, n_estimators=947, reg_alpha=2.4689457315652916, reg_lambda=2.644198865966077, scale_pos_weight=0.8127549740051957, subsample=0.9303680677901948; total time=   4.6s\n",
      "[CV] END colsample_bylevel=0.6867009957086144, colsample_bynode=0.784970535052957, colsample_bytree=0.6271192334619813, gamma=1.9933397152942278, learning_rate=0.006715806589102056, max_delta_step=4, max_depth=14, min_child_weight=5, n_estimators=2803, reg_alpha=2.5734096374298105, reg_lambda=2.08584050106726, scale_pos_weight=1.0848653924111393, subsample=0.9445509295345054; total time=   8.8s\n",
      "[CV] END colsample_bylevel=0.8838794733924132, colsample_bynode=0.9050827638194778, colsample_bytree=0.6516107125324359, gamma=0.741466794976711, learning_rate=0.0013223969686197703, max_delta_step=4, max_depth=15, min_child_weight=13, n_estimators=2252, reg_alpha=2.849649290158395, reg_lambda=1.8307429739399375, scale_pos_weight=1.1420158966067704, subsample=0.7180831601617286; total time=  12.8s\n",
      "[CV] END colsample_bylevel=0.8814068818406465, colsample_bynode=0.7197753845009405, colsample_bytree=1.0, gamma=0.0, learning_rate=0.00862812314063869, max_delta_step=6, max_depth=4, min_child_weight=15, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=0.7; total time=   1.8s\n",
      "[CV] END colsample_bylevel=0.8814068818406465, colsample_bynode=0.7197753845009405, colsample_bytree=1.0, gamma=0.0, learning_rate=0.00862812314063869, max_delta_step=6, max_depth=4, min_child_weight=15, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.2, subsample=0.7; total time=   1.8s\n",
      "[CV] END colsample_bylevel=0.8602283618562678, colsample_bynode=0.6167691173468559, colsample_bytree=0.9051490839774217, gamma=0.05969754835323983, learning_rate=0.0015383346552878614, max_delta_step=7, max_depth=15, min_child_weight=4, n_estimators=1569, reg_alpha=2.9453527456506645, reg_lambda=2.036573063729082, scale_pos_weight=1.0538783400036813, subsample=0.9865224350464125; total time=  19.2s\n",
      "[CV] END colsample_bylevel=0.8602283618562678, colsample_bynode=0.6167691173468559, colsample_bytree=0.9051490839774217, gamma=0.05969754835323983, learning_rate=0.0015383346552878614, max_delta_step=7, max_depth=15, min_child_weight=4, n_estimators=1569, reg_alpha=2.9453527456506645, reg_lambda=2.036573063729082, scale_pos_weight=1.0538783400036813, subsample=0.9865224350464125; total time=  16.7s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.01022295162190459, max_delta_step=0, max_depth=4, min_child_weight=15, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.9598781727284172, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.7767955244290717, colsample_bynode=0.6960142338918816, colsample_bytree=0.838194951900167, gamma=0.21722093722218166, learning_rate=0.0135257233226764, max_delta_step=1, max_depth=4, min_child_weight=5, n_estimators=576, reg_alpha=0.1898130813241477, reg_lambda=0.5717877557819098, scale_pos_weight=1.1057117475115867, subsample=0.9583901382776849; total time=   1.8s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.796031218457304, colsample_bytree=0.6, gamma=0.36781805718101357, learning_rate=0.018908377529571776, max_delta_step=0, max_depth=4, min_child_weight=14, n_estimators=500, reg_alpha=3.0, reg_lambda=0.3644045001537639, scale_pos_weight=0.8153144476093589, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.796031218457304, colsample_bytree=0.6, gamma=0.36781805718101357, learning_rate=0.018908377529571776, max_delta_step=0, max_depth=4, min_child_weight=14, n_estimators=500, reg_alpha=3.0, reg_lambda=0.3644045001537639, scale_pos_weight=0.8153144476093589, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.796031218457304, colsample_bytree=0.6, gamma=0.36781805718101357, learning_rate=0.018908377529571776, max_delta_step=0, max_depth=4, min_child_weight=14, n_estimators=500, reg_alpha=3.0, reg_lambda=0.3644045001537639, scale_pos_weight=0.8153144476093589, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bylevel=0.8049790884946122, colsample_bynode=0.958267187155686, colsample_bytree=0.8592699958135106, gamma=1.8798111344072106, learning_rate=0.09811076108892733, max_delta_step=9, max_depth=15, min_child_weight=15, n_estimators=600, reg_alpha=1.4395413174242633, reg_lambda=1.0292008334139462, scale_pos_weight=1.1279868608711727, subsample=0.8689249096774724; total time=   1.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:00:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.889444317748177, colsample_bynode=0.9632852894539913, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0038399496169913712, max_delta_step=10, max_depth=15, min_child_weight=15, n_estimators=500, reg_alpha=3.0, reg_lambda=0.3245518781282676, scale_pos_weight=1.0898856810581208, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bylevel=0.889444317748177, colsample_bynode=0.9632852894539913, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0038399496169913712, max_delta_step=10, max_depth=15, min_child_weight=15, n_estimators=500, reg_alpha=3.0, reg_lambda=0.3245518781282676, scale_pos_weight=1.0898856810581208, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bylevel=0.760739815416911, colsample_bynode=0.6965978775619123, colsample_bytree=0.643103288277387, gamma=1.981261082729455, learning_rate=0.03801484633656405, max_delta_step=10, max_depth=13, min_child_weight=14, n_estimators=2563, reg_alpha=2.995039345603483, reg_lambda=1.668131373501017, scale_pos_weight=1.022822618643537, subsample=0.7282281969859727; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.7375696727549332, colsample_bynode=0.7172005254059629, colsample_bytree=0.9980094723756316, gamma=1.44058157247619, learning_rate=0.05130843060698508, max_delta_step=4, max_depth=4, min_child_weight=2, n_estimators=543, reg_alpha=0.9814038478707849, reg_lambda=0.44490777634084167, scale_pos_weight=0.8666825787955377, subsample=0.9944640935395834; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.7375696727549332, colsample_bynode=0.7172005254059629, colsample_bytree=0.9980094723756316, gamma=1.44058157247619, learning_rate=0.05130843060698508, max_delta_step=4, max_depth=4, min_child_weight=2, n_estimators=543, reg_alpha=0.9814038478707849, reg_lambda=0.44490777634084167, scale_pos_weight=0.8666825787955377, subsample=0.9944640935395834; total time=   0.9s\n",
      "[CV] END colsample_bylevel=0.6381911354633409, colsample_bynode=0.7558470768527286, colsample_bytree=1.0, gamma=2.0, learning_rate=0.02176906485152723, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.9173505583786554, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.8503088411476036, colsample_bytree=0.6, gamma=0.0, learning_rate=0.003536883706397804, max_delta_step=4, max_depth=4, min_child_weight=15, n_estimators=2016, reg_alpha=3.0, reg_lambda=2.955282252477477, scale_pos_weight=0.8311283665694816, subsample=0.7; total time=   4.5s\n",
      "[CV] END colsample_bylevel=0.8702090810131375, colsample_bynode=0.6443354469097116, colsample_bytree=0.6350662211937494, gamma=0.9748442169902163, learning_rate=0.0010319684768327765, max_delta_step=7, max_depth=4, min_child_weight=14, n_estimators=2956, reg_alpha=1.5416262092798108, reg_lambda=0.5030060267921187, scale_pos_weight=0.8058215403596982, subsample=0.9381862420831204; total time=   7.4s\n",
      "[CV] END colsample_bylevel=0.9351246966903117, colsample_bynode=0.9854611863029131, colsample_bytree=0.9716049880497319, gamma=1.8591335968415852, learning_rate=0.0396596424565272, max_delta_step=8, max_depth=4, min_child_weight=10, n_estimators=2745, reg_alpha=0.4968230328509552, reg_lambda=2.5736435123657606, scale_pos_weight=1.184849173566848, subsample=0.8317612535057759; total time=   4.8s\n",
      "[CV] END colsample_bylevel=0.9351246966903117, colsample_bynode=0.9854611863029131, colsample_bytree=0.9716049880497319, gamma=1.8591335968415852, learning_rate=0.0396596424565272, max_delta_step=8, max_depth=4, min_child_weight=10, n_estimators=2745, reg_alpha=0.4968230328509552, reg_lambda=2.5736435123657606, scale_pos_weight=1.184849173566848, subsample=0.8317612535057759; total time=   6.3s\n",
      "[CV] END colsample_bylevel=0.6049567208587082, colsample_bynode=0.8557669501289338, colsample_bytree=0.959519931692477, gamma=1.9853985559277496, learning_rate=0.004965175001673573, max_delta_step=3, max_depth=5, min_child_weight=1, n_estimators=947, reg_alpha=2.4689457315652916, reg_lambda=2.644198865966077, scale_pos_weight=0.8127549740051957, subsample=0.9303680677901948; total time=   3.1s\n",
      "[CV] END colsample_bylevel=0.6867009957086144, colsample_bynode=0.784970535052957, colsample_bytree=0.6271192334619813, gamma=1.9933397152942278, learning_rate=0.006715806589102056, max_delta_step=4, max_depth=14, min_child_weight=5, n_estimators=2803, reg_alpha=2.5734096374298105, reg_lambda=2.08584050106726, scale_pos_weight=1.0848653924111393, subsample=0.9445509295345054; total time=   8.6s\n",
      "[CV] END colsample_bylevel=0.8838794733924132, colsample_bynode=0.9050827638194778, colsample_bytree=0.6516107125324359, gamma=0.741466794976711, learning_rate=0.0013223969686197703, max_delta_step=4, max_depth=15, min_child_weight=13, n_estimators=2252, reg_alpha=2.849649290158395, reg_lambda=1.8307429739399375, scale_pos_weight=1.1420158966067704, subsample=0.7180831601617286; total time=  12.9s\n",
      "[CV] END colsample_bylevel=0.8838794733924132, colsample_bynode=0.9050827638194778, colsample_bytree=0.6516107125324359, gamma=0.741466794976711, learning_rate=0.0013223969686197703, max_delta_step=4, max_depth=15, min_child_weight=13, n_estimators=2252, reg_alpha=2.849649290158395, reg_lambda=1.8307429739399375, scale_pos_weight=1.1420158966067704, subsample=0.7180831601617286; total time=   9.3s\n",
      "[CV] END colsample_bylevel=0.8602283618562678, colsample_bynode=0.6167691173468559, colsample_bytree=0.9051490839774217, gamma=0.05969754835323983, learning_rate=0.0015383346552878614, max_delta_step=7, max_depth=15, min_child_weight=4, n_estimators=1569, reg_alpha=2.9453527456506645, reg_lambda=2.036573063729082, scale_pos_weight=1.0538783400036813, subsample=0.9865224350464125; total time=  19.8s\n",
      "[CV] END colsample_bylevel=0.9533923554263655, colsample_bynode=0.7698742853954607, colsample_bytree=0.7455511442221807, gamma=1.9791800808553475, learning_rate=0.08620622105880298, max_delta_step=6, max_depth=4, min_child_weight=6, n_estimators=1654, reg_alpha=2.4578329293588403, reg_lambda=2.3003373083809695, scale_pos_weight=1.1575520841344622, subsample=0.8414805196611954; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.9533923554263655, colsample_bynode=0.7698742853954607, colsample_bytree=0.7455511442221807, gamma=1.9791800808553475, learning_rate=0.08620622105880298, max_delta_step=6, max_depth=4, min_child_weight=6, n_estimators=1654, reg_alpha=2.4578329293588403, reg_lambda=2.3003373083809695, scale_pos_weight=1.1575520841344622, subsample=0.8414805196611954; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.6649962364931218, colsample_bynode=0.8847755784481242, colsample_bytree=0.7226827705501258, gamma=1.96975292470343, learning_rate=0.00849747157126491, max_delta_step=1, max_depth=15, min_child_weight=6, n_estimators=1663, reg_alpha=0.18734316004947443, reg_lambda=0.4048307065571941, scale_pos_weight=0.9346324108458257, subsample=0.9269603092966929; total time=   6.6s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.01022295162190459, max_delta_step=0, max_depth=4, min_child_weight=15, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.9598781727284172, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.7767955244290717, colsample_bynode=0.6960142338918816, colsample_bytree=0.838194951900167, gamma=0.21722093722218166, learning_rate=0.0135257233226764, max_delta_step=1, max_depth=4, min_child_weight=5, n_estimators=576, reg_alpha=0.1898130813241477, reg_lambda=0.5717877557819098, scale_pos_weight=1.1057117475115867, subsample=0.9583901382776849; total time=   1.7s\n",
      "[CV] END colsample_bylevel=0.7767955244290717, colsample_bynode=0.6960142338918816, colsample_bytree=0.838194951900167, gamma=0.21722093722218166, learning_rate=0.0135257233226764, max_delta_step=1, max_depth=4, min_child_weight=5, n_estimators=576, reg_alpha=0.1898130813241477, reg_lambda=0.5717877557819098, scale_pos_weight=1.1057117475115867, subsample=0.9583901382776849; total time=   1.7s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.796031218457304, colsample_bytree=0.6, gamma=0.36781805718101357, learning_rate=0.018908377529571776, max_delta_step=0, max_depth=4, min_child_weight=14, n_estimators=500, reg_alpha=3.0, reg_lambda=0.3644045001537639, scale_pos_weight=0.8153144476093589, subsample=1.0; total time=   1.3sFitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.889444317748177, colsample_bynode=0.9632852894539913, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0038399496169913712, max_delta_step=10, max_depth=15, min_child_weight=15, n_estimators=500, reg_alpha=3.0, reg_lambda=0.3245518781282676, scale_pos_weight=1.0898856810581208, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bylevel=0.889444317748177, colsample_bynode=0.9632852894539913, colsample_bytree=0.6, gamma=2.0, learning_rate=0.0038399496169913712, max_delta_step=10, max_depth=15, min_child_weight=15, n_estimators=500, reg_alpha=3.0, reg_lambda=0.3245518781282676, scale_pos_weight=1.0898856810581208, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bylevel=0.760739815416911, colsample_bynode=0.6965978775619123, colsample_bytree=0.643103288277387, gamma=1.981261082729455, learning_rate=0.03801484633656405, max_delta_step=10, max_depth=13, min_child_weight=14, n_estimators=2563, reg_alpha=2.995039345603483, reg_lambda=1.668131373501017, scale_pos_weight=1.022822618643537, subsample=0.7282281969859727; total time=   3.6s\n",
      "[CV] END colsample_bylevel=0.7375696727549332, colsample_bynode=0.7172005254059629, colsample_bytree=0.9980094723756316, gamma=1.44058157247619, learning_rate=0.05130843060698508, max_delta_step=4, max_depth=4, min_child_weight=2, n_estimators=543, reg_alpha=0.9814038478707849, reg_lambda=0.44490777634084167, scale_pos_weight=0.8666825787955377, subsample=0.9944640935395834; total time=   0.9s\n",
      "[CV] END colsample_bylevel=0.6381911354633409, colsample_bynode=0.7558470768527286, colsample_bytree=1.0, gamma=2.0, learning_rate=0.02176906485152723, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.9173505583786554, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.8503088411476036, colsample_bytree=0.6, gamma=0.0, learning_rate=0.003536883706397804, max_delta_step=4, max_depth=4, min_child_weight=15, n_estimators=2016, reg_alpha=3.0, reg_lambda=2.955282252477477, scale_pos_weight=0.8311283665694816, subsample=0.7; total time=   4.6s\n",
      "[CV] END colsample_bylevel=0.8702090810131375, colsample_bynode=0.6443354469097116, colsample_bytree=0.6350662211937494, gamma=0.9748442169902163, learning_rate=0.0010319684768327765, max_delta_step=7, max_depth=4, min_child_weight=14, n_estimators=2956, reg_alpha=1.5416262092798108, reg_lambda=0.5030060267921187, scale_pos_weight=0.8058215403596982, subsample=0.9381862420831204; total time=   7.4s\n",
      "[CV] END colsample_bylevel=0.8702090810131375, colsample_bynode=0.6443354469097116, colsample_bytree=0.6350662211937494, gamma=0.9748442169902163, learning_rate=0.0010319684768327765, max_delta_step=7, max_depth=4, min_child_weight=14, n_estimators=2956, reg_alpha=1.5416262092798108, reg_lambda=0.5030060267921187, scale_pos_weight=0.8058215403596982, subsample=0.9381862420831204; total time=   7.7s\n",
      "[CV] END colsample_bylevel=0.6049567208587082, colsample_bynode=0.8557669501289338, colsample_bytree=0.959519931692477, gamma=1.9853985559277496, learning_rate=0.004965175001673573, max_delta_step=3, max_depth=5, min_child_weight=1, n_estimators=947, reg_alpha=2.4689457315652916, reg_lambda=2.644198865966077, scale_pos_weight=0.8127549740051957, subsample=0.9303680677901948; total time=   4.6s\n",
      "[CV] END colsample_bylevel=0.6867009957086144, colsample_bynode=0.784970535052957, colsample_bytree=0.6271192334619813, gamma=1.9933397152942278, learning_rate=0.006715806589102056, max_delta_step=4, max_depth=14, min_child_weight=5, n_estimators=2803, reg_alpha=2.5734096374298105, reg_lambda=2.08584050106726, scale_pos_weight=1.0848653924111393, subsample=0.9445509295345054; total time=   8.5s\n",
      "[CV] END colsample_bylevel=0.6867009957086144, colsample_bynode=0.784970535052957, colsample_bytree=0.6271192334619813, gamma=1.9933397152942278, learning_rate=0.006715806589102056, max_delta_step=4, max_depth=14, min_child_weight=5, n_estimators=2803, reg_alpha=2.5734096374298105, reg_lambda=2.08584050106726, scale_pos_weight=1.0848653924111393, subsample=0.9445509295345054; total time=   7.4s\n",
      "[CV] END colsample_bylevel=0.8838794733924132, colsample_bynode=0.9050827638194778, colsample_bytree=0.6516107125324359, gamma=0.741466794976711, learning_rate=0.0013223969686197703, max_delta_step=4, max_depth=15, min_child_weight=13, n_estimators=2252, reg_alpha=2.849649290158395, reg_lambda=1.8307429739399375, scale_pos_weight=1.1420158966067704, subsample=0.7180831601617286; total time=  12.5s\n",
      "[CV] END colsample_bylevel=0.8602283618562678, colsample_bynode=0.6167691173468559, colsample_bytree=0.9051490839774217, gamma=0.05969754835323983, learning_rate=0.0015383346552878614, max_delta_step=7, max_depth=15, min_child_weight=4, n_estimators=1569, reg_alpha=2.9453527456506645, reg_lambda=2.036573063729082, scale_pos_weight=1.0538783400036813, subsample=0.9865224350464125; total time=  19.6s\n",
      "[CV] END colsample_bylevel=0.9533923554263655, colsample_bynode=0.7698742853954607, colsample_bytree=0.7455511442221807, gamma=1.9791800808553475, learning_rate=0.08620622105880298, max_delta_step=6, max_depth=4, min_child_weight=6, n_estimators=1654, reg_alpha=2.4578329293588403, reg_lambda=2.3003373083809695, scale_pos_weight=1.1575520841344622, subsample=0.8414805196611954; total time=   3.1s\n",
      "[CV] END colsample_bylevel=0.6649962364931218, colsample_bynode=0.8847755784481242, colsample_bytree=0.7226827705501258, gamma=1.96975292470343, learning_rate=0.00849747157126491, max_delta_step=1, max_depth=15, min_child_weight=6, n_estimators=1663, reg_alpha=0.18734316004947443, reg_lambda=0.4048307065571941, scale_pos_weight=0.9346324108458257, subsample=0.9269603092966929; total time=   6.5s\n",
      "[CV] END colsample_bylevel=0.6649962364931218, colsample_bynode=0.8847755784481242, colsample_bytree=0.7226827705501258, gamma=1.96975292470343, learning_rate=0.00849747157126491, max_delta_step=1, max_depth=15, min_child_weight=6, n_estimators=1663, reg_alpha=0.18734316004947443, reg_lambda=0.4048307065571941, scale_pos_weight=0.9346324108458257, subsample=0.9269603092966929; total time=   5.7s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.01022295162190459, max_delta_step=0, max_depth=4, min_child_weight=15, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.9598781727284172, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.7767955244290717, colsample_bynode=0.6960142338918816, colsample_bytree=0.838194951900167, gamma=0.21722093722218166, learning_rate=0.0135257233226764, max_delta_step=1, max_depth=4, min_child_weight=5, n_estimators=576, reg_alpha=0.1898130813241477, reg_lambda=0.5717877557819098, scale_pos_weight=1.1057117475115867, subsample=0.9583901382776849; total time=   1.7s\n",
      "[CV] END colsample_bylevel=0.7767955244290717, colsample_bynode=0.6960142338918816, colsample_bytree=0.838194951900167, gamma=0.21722093722218166, learning_rate=0.0135257233226764, max_delta_step=1, max_depth=4, min_child_weight=5, n_estimators=576, reg_alpha=0.1898130813241477, reg_lambda=0.5717877557819098, scale_pos_weight=1.1057117475115867, subsample=0.9583901382776849; total time=   1.8s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.796031218457304, colsample_bytree=0.6, gamma=0.36781805718101357, learning_rate=0.018908377529571776, max_delta_step=0, max_depth=4, min_child_weight=14, n_estimators=500, reg_alpha=3.0, reg_lambda=0.3644045001537639, scale_pos_weight=0.8153144476093589, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.8049790884946122, colsample_bynode=0.958267187155686, colsample_bytree=0.8592699958135106, gamma=1.8798111344072106, learning_rate=0.09811076108892733, max_delta_step=9, max_depth=15, min_child_weight=15, n_estimators=600, reg_alpha=1.4395413174242633, reg_lambda=1.0292008334139462, scale_pos_weight=1.1279868608711727, subsample=0.8689249096774724; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.6244917232814939, colsample_bynode=0.7500289333491468, colsample_bytree=0.9929819056662685, gamma=1.967710172445452, learning_rate=0.0023537342997263723, max_delta_step=1, max_depth=5, min_child_weight=13, n_estimators=1924, reg_alpha=0.39379578359099776, reg_lambda=2.545417450208824, scale_pos_weight=1.083007910106893, subsample=0.9444253706712565; total time=   8.2sFitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:01:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:02:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:02:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:02:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:02:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:02:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:02:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:02:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:02:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:02:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:02:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:02:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:02:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:02:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:02:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:02:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:02:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:02:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:02:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:02:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:02:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:02:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:02:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.8049790884946122, colsample_bynode=0.958267187155686, colsample_bytree=0.8592699958135106, gamma=1.8798111344072106, learning_rate=0.09811076108892733, max_delta_step=9, max_depth=15, min_child_weight=15, n_estimators=600, reg_alpha=1.4395413174242633, reg_lambda=1.0292008334139462, scale_pos_weight=1.1279868608711727, subsample=0.8689249096774724; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.6244917232814939, colsample_bynode=0.7500289333491468, colsample_bytree=0.9929819056662685, gamma=1.967710172445452, learning_rate=0.0023537342997263723, max_delta_step=1, max_depth=5, min_child_weight=13, n_estimators=1924, reg_alpha=0.39379578359099776, reg_lambda=2.545417450208824, scale_pos_weight=1.083007910106893, subsample=0.9444253706712565; total time=   8.3s\n",
      "[CV] END colsample_bylevel=0.8136493924008539, colsample_bynode=0.8663098031568854, colsample_bytree=0.838040662169969, gamma=1.953452213261073, learning_rate=0.0011142904405282083, max_delta_step=4, max_depth=4, min_child_weight=15, n_estimators=2373, reg_alpha=2.869584805083433, reg_lambda=1.613901303618288, scale_pos_weight=0.9847934487675435, subsample=0.7188325076490992; total time=   7.3s\n",
      "[CV] END colsample_bylevel=0.8136493924008539, colsample_bynode=0.8663098031568854, colsample_bytree=0.838040662169969, gamma=1.953452213261073, learning_rate=0.0011142904405282083, max_delta_step=4, max_depth=4, min_child_weight=15, n_estimators=2373, reg_alpha=2.869584805083433, reg_lambda=1.613901303618288, scale_pos_weight=0.9847934487675435, subsample=0.7188325076490992; total time=   5.0s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7214430854736362, colsample_bytree=0.9854627100473761, gamma=1.7541256265830654, learning_rate=0.031702865109362516, max_delta_step=0, max_depth=4, min_child_weight=8, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bylevel=0.8630729744826783, colsample_bynode=0.9935101903682826, colsample_bytree=0.7203975392263717, gamma=1.8837692803378632, learning_rate=0.07948851651358695, max_delta_step=7, max_depth=15, min_child_weight=2, n_estimators=2298, reg_alpha=2.9932596070657604, reg_lambda=2.6730734698731853, scale_pos_weight=1.092633397136379, subsample=0.9431362450708927; total time=   3.8s\n",
      "[CV] END colsample_bylevel=0.8630729744826783, colsample_bynode=0.9935101903682826, colsample_bytree=0.7203975392263717, gamma=1.8837692803378632, learning_rate=0.07948851651358695, max_delta_step=7, max_depth=15, min_child_weight=2, n_estimators=2298, reg_alpha=2.9932596070657604, reg_lambda=2.6730734698731853, scale_pos_weight=1.092633397136379, subsample=0.9431362450708927; total time=   3.4s\n",
      "[CV] END colsample_bylevel=0.8260935202425312, colsample_bynode=0.6780865147438422, colsample_bytree=0.6, gamma=2.0, learning_rate=0.001, max_delta_step=10, max_depth=7, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1789373395850282, subsample=1.0; total time=  17.5s\n",
      "[CV] END colsample_bylevel=0.7537074234765465, colsample_bynode=0.7568019971062518, colsample_bytree=0.7841057345600763, gamma=1.872329868172045, learning_rate=0.011230172421284015, max_delta_step=9, max_depth=15, min_child_weight=7, n_estimators=656, reg_alpha=1.6433824068842462, reg_lambda=1.132574999195819, scale_pos_weight=0.8078680817965324, subsample=0.7423322699968832; total time=   3.5s\n",
      "[CV] END colsample_bylevel=0.7537074234765465, colsample_bynode=0.7568019971062518, colsample_bytree=0.7841057345600763, gamma=1.872329868172045, learning_rate=0.011230172421284015, max_delta_step=9, max_depth=15, min_child_weight=7, n_estimators=656, reg_alpha=1.6433824068842462, reg_lambda=1.132574999195819, scale_pos_weight=0.8078680817965324, subsample=0.7423322699968832; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.7756554417203437, colsample_bynode=0.7300790056918609, colsample_bytree=0.6302819532608847, gamma=1.8822040489605418, learning_rate=0.015726551726098936, max_delta_step=5, max_depth=9, min_child_weight=10, n_estimators=510, reg_alpha=2.990826813391728, reg_lambda=2.586920238594296, scale_pos_weight=1.1553778481575212, subsample=0.7254234722479168; total time=   2.7s\n",
      "[CV] END colsample_bylevel=0.6323551844580703, colsample_bynode=0.6576387621119553, colsample_bytree=0.7696930725879388, gamma=1.8149348328567636, learning_rate=0.0029900207975659876, max_delta_step=2, max_depth=11, min_child_weight=14, n_estimators=633, reg_alpha=0.23627623487799537, reg_lambda=0.2662635764642302, scale_pos_weight=1.0909985768619666, subsample=0.7034909127232992; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.6323551844580703, colsample_bynode=0.6576387621119553, colsample_bytree=0.7696930725879388, gamma=1.8149348328567636, learning_rate=0.0029900207975659876, max_delta_step=2, max_depth=11, min_child_weight=14, n_estimators=633, reg_alpha=0.23627623487799537, reg_lambda=0.2662635764642302, scale_pos_weight=1.0909985768619666, subsample=0.7034909127232992; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.9601411196443507, colsample_bynode=0.7966212444192398, colsample_bytree=0.6930998860139954, gamma=1.6879589433889206, learning_rate=0.0010124414373235994, max_delta_step=4, max_depth=15, min_child_weight=9, n_estimators=2887, reg_alpha=0.8821168244039665, reg_lambda=1.2448000608298926, scale_pos_weight=0.8455428982527128, subsample=0.7239246089840329; total time=  15.9s\n",
      "[CV] END colsample_bylevel=0.803809687296255, colsample_bynode=0.6034225470031548, colsample_bytree=0.6317081700832806, gamma=1.98675328035122, learning_rate=0.07729121166073208, max_delta_step=9, max_depth=8, min_child_weight=8, n_estimators=2885, reg_alpha=1.2773213476401888, reg_lambda=2.4550946227862767, scale_pos_weight=1.070082578732788, subsample=0.9973180774279604; total time=   3.9s\n",
      "[CV] END colsample_bylevel=0.9975100458948011, colsample_bynode=0.6297336126549192, colsample_bytree=0.6002404174267807, gamma=1.9597971313266744, learning_rate=0.0012872094197615008, max_delta_step=8, max_depth=14, min_child_weight=14, n_estimators=1624, reg_alpha=2.8023628052524434, reg_lambda=0.45843710726537534, scale_pos_weight=0.8088497589455969, subsample=0.7034967719641311; total time=   7.4s\n",
      "[CV] END colsample_bylevel=0.9975100458948011, colsample_bynode=0.6297336126549192, colsample_bytree=0.6002404174267807, gamma=1.9597971313266744, learning_rate=0.0012872094197615008, max_delta_step=8, max_depth=14, min_child_weight=14, n_estimators=1624, reg_alpha=2.8023628052524434, reg_lambda=0.45843710726537534, scale_pos_weight=0.8088497589455969, subsample=0.7034967719641311; total time=   5.4s\n",
      "[CV] END colsample_bylevel=0.9234712046133574, colsample_bynode=0.9018987298009663, colsample_bytree=0.8125607387764793, gamma=0.1147992410458816, learning_rate=0.024373689671177427, max_delta_step=10, max_depth=15, min_child_weight=9, n_estimators=2947, reg_alpha=0.03037924928893921, reg_lambda=2.536307578124162, scale_pos_weight=1.0873206530460928, subsample=0.9982555882054965; total time=  18.4s\n",
      "[CV] END colsample_bylevel=0.7867581948991739, colsample_bynode=0.9303869073943833, colsample_bytree=0.7963902646747765, gamma=0.0317084602734703, learning_rate=0.020096856092047324, max_delta_step=9, max_depth=15, min_child_weight=11, n_estimators=2127, reg_alpha=2.8699654377992703, reg_lambda=0.23154048462970217, scale_pos_weight=0.9139109911644648, subsample=0.960118245497821; total time=  17.1s\n",
      "[CV] END colsample_bylevel=0.9067384536773431, colsample_bynode=0.6126748729398347, colsample_bytree=0.9819341977594845, gamma=0.8895356791966749, learning_rate=0.02284176200877286, max_delta_step=0, max_depth=15, min_child_weight=6, n_estimators=2621, reg_alpha=2.6931033263340423, reg_lambda=2.034918221054438, scale_pos_weight=0.9691367789834109, subsample=0.998020900102754; total time=   6.4s\n",
      "[CV] END colsample_bylevel=0.9067384536773431, colsample_bynode=0.6126748729398347, colsample_bytree=0.9819341977594845, gamma=0.8895356791966749, learning_rate=0.02284176200877286, max_delta_step=0, max_depth=15, min_child_weight=6, n_estimators=2621, reg_alpha=2.6931033263340423, reg_lambda=2.034918221054438, scale_pos_weight=0.9691367789834109, subsample=0.998020900102754; total time=   6.1s\n",
      "[CV] END colsample_bylevel=0.7745272342149911, colsample_bynode=0.8672356627721698, colsample_bytree=0.7881330533719713, gamma=1.0375505262740985, learning_rate=0.014272716330904232, max_delta_step=8, max_depth=4, min_child_weight=3, n_estimators=809, reg_alpha=0.10673541775704112, reg_lambda=0.3919322779266198, scale_pos_weight=1.0491838911999625, subsample=0.7266366377985876; total time=   2.5s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.7658651292754646, colsample_bytree=1.0, gamma=2.0, learning_rate=0.01345117921380264, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=1146, reg_alpha=0.0, reg_lambda=0.5872528988341121, scale_pos_weight=0.8615059429830153, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.6597322567913767, colsample_bynode=0.954146867216343, colsample_bytree=0.6424175497237475, gamma=0.047553879161059256, learning_rate=0.007440685591392875, max_delta_step=1, max_depth=4, min_child_weight=2, n_estimators=2989, reg_alpha=2.2851921100158643, reg_lambda=0.3485605035974515, scale_pos_weight=0.802746849920165, subsample=0.9790214738952016; total time=   8.4s\n",
      "[CV] END colsample_bylevel=0.6597322567913767, colsample_bynode=0.954146867216343, colsample_bytree=0.6424175497237475, gamma=0.047553879161059256, learning_rate=0.007440685591392875, max_delta_step=1, max_depth=4, min_child_weight=2, n_estimators=2989, reg_alpha=2.2851921100158643, reg_lambda=0.3485605035974515, scale_pos_weight=0.802746849920165, subsample=0.9790214738952016; total time=   5.4s\n",
      "[CV] END colsample_bylevel=0.9653116876268035, colsample_bynode=0.7624196130273131, colsample_bytree=0.6063157550834486, gamma=1.197442825229783, learning_rate=0.003184019752064612, max_delta_step=0, max_depth=15, min_child_weight=3, n_estimators=2938, reg_alpha=2.520382695710136, reg_lambda=0.3113786361921287, scale_pos_weight=1.1690756364866899, subsample=0.7334315239237805; total time=  17.8s\n",
      "[CV] END colsample_bylevel=0.9653116876268035, colsample_bynode=0.7624196130273131, colsample_bytree=0.6063157550834486, gamma=1.197442825229783, learning_rate=0.003184019752064612, max_delta_step=0, max_depth=15, min_child_weight=3, n_estimators=2938, reg_alpha=2.520382695710136, reg_lambda=0.3113786361921287, scale_pos_weight=1.1690756364866899, subsample=0.7334315239237805; total time=  16.3s\n",
      "[CV] END colsample_bylevel=0.8546625088429568, colsample_bynode=0.8249770025662069, colsample_bytree=0.9796944581148662, gamma=0.03852449315728613, learning_rate=0.0030284080004574724, max_delta_step=1, max_depth=15, min_child_weight=3, n_estimators=1455, reg_alpha=1.624639669766568, reg_lambda=0.16118396335612845, scale_pos_weight=1.1767119623134499, subsample=0.7069714046418374; total time=  21.7s\n",
      "\n",
      "[CV] END colsample_bylevel=0.8049790884946122, colsample_bynode=0.958267187155686, colsample_bytree=0.8592699958135106, gamma=1.8798111344072106, learning_rate=0.09811076108892733, max_delta_step=9, max_depth=15, min_child_weight=15, n_estimators=600, reg_alpha=1.4395413174242633, reg_lambda=1.0292008334139462, scale_pos_weight=1.1279868608711727, subsample=0.8689249096774724; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.8049790884946122, colsample_bynode=0.958267187155686, colsample_bytree=0.8592699958135106, gamma=1.8798111344072106, learning_rate=0.09811076108892733, max_delta_step=9, max_depth=15, min_child_weight=15, n_estimators=600, reg_alpha=1.4395413174242633, reg_lambda=1.0292008334139462, scale_pos_weight=1.1279868608711727, subsample=0.8689249096774724; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.6244917232814939, colsample_bynode=0.7500289333491468, colsample_bytree=0.9929819056662685, gamma=1.967710172445452, learning_rate=0.0023537342997263723, max_delta_step=1, max_depth=5, min_child_weight=13, n_estimators=1924, reg_alpha=0.39379578359099776, reg_lambda=2.545417450208824, scale_pos_weight=1.083007910106893, subsample=0.9444253706712565; total time=   8.0s\n",
      "[CV] END colsample_bylevel=0.8136493924008539, colsample_bynode=0.8663098031568854, colsample_bytree=0.838040662169969, gamma=1.953452213261073, learning_rate=0.0011142904405282083, max_delta_step=4, max_depth=4, min_child_weight=15, n_estimators=2373, reg_alpha=2.869584805083433, reg_lambda=1.613901303618288, scale_pos_weight=0.9847934487675435, subsample=0.7188325076490992; total time=   7.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7214430854736362, colsample_bytree=0.9854627100473761, gamma=1.7541256265830654, learning_rate=0.031702865109362516, max_delta_step=0, max_depth=4, min_child_weight=8, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7214430854736362, colsample_bytree=0.9854627100473761, gamma=1.7541256265830654, learning_rate=0.031702865109362516, max_delta_step=0, max_depth=4, min_child_weight=8, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.8630729744826783, colsample_bynode=0.9935101903682826, colsample_bytree=0.7203975392263717, gamma=1.8837692803378632, learning_rate=0.07948851651358695, max_delta_step=7, max_depth=15, min_child_weight=2, n_estimators=2298, reg_alpha=2.9932596070657604, reg_lambda=2.6730734698731853, scale_pos_weight=1.092633397136379, subsample=0.9431362450708927; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.8595290977953045, colsample_bynode=0.8372912774326707, colsample_bytree=1.0, gamma=0.0, learning_rate=0.015003275330162335, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=1.0925275286236853, scale_pos_weight=0.9532633020219079, subsample=0.9613565213259727; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.8260935202425312, colsample_bynode=0.6780865147438422, colsample_bytree=0.6, gamma=2.0, learning_rate=0.001, max_delta_step=10, max_depth=7, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1789373395850282, subsample=1.0; total time=  17.3s\n",
      "[CV] END colsample_bylevel=0.7537074234765465, colsample_bynode=0.7568019971062518, colsample_bytree=0.7841057345600763, gamma=1.872329868172045, learning_rate=0.011230172421284015, max_delta_step=9, max_depth=15, min_child_weight=7, n_estimators=656, reg_alpha=1.6433824068842462, reg_lambda=1.132574999195819, scale_pos_weight=0.8078680817965324, subsample=0.7423322699968832; total time=   3.6s\n",
      "[CV] END colsample_bylevel=0.7537074234765465, colsample_bynode=0.7568019971062518, colsample_bytree=0.7841057345600763, gamma=1.872329868172045, learning_rate=0.011230172421284015, max_delta_step=9, max_depth=15, min_child_weight=7, n_estimators=656, reg_alpha=1.6433824068842462, reg_lambda=1.132574999195819, scale_pos_weight=0.8078680817965324, subsample=0.7423322699968832; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.7756554417203437, colsample_bynode=0.7300790056918609, colsample_bytree=0.6302819532608847, gamma=1.8822040489605418, learning_rate=0.015726551726098936, max_delta_step=5, max_depth=9, min_child_weight=10, n_estimators=510, reg_alpha=2.990826813391728, reg_lambda=2.586920238594296, scale_pos_weight=1.1553778481575212, subsample=0.7254234722479168; total time=   2.6s\n",
      "[CV] END colsample_bylevel=0.6323551844580703, colsample_bynode=0.6576387621119553, colsample_bytree=0.7696930725879388, gamma=1.8149348328567636, learning_rate=0.0029900207975659876, max_delta_step=2, max_depth=11, min_child_weight=14, n_estimators=633, reg_alpha=0.23627623487799537, reg_lambda=0.2662635764642302, scale_pos_weight=1.0909985768619666, subsample=0.7034909127232992; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.9601411196443507, colsample_bynode=0.7966212444192398, colsample_bytree=0.6930998860139954, gamma=1.6879589433889206, learning_rate=0.0010124414373235994, max_delta_step=4, max_depth=15, min_child_weight=9, n_estimators=2887, reg_alpha=0.8821168244039665, reg_lambda=1.2448000608298926, scale_pos_weight=0.8455428982527128, subsample=0.7239246089840329; total time=  16.4s\n",
      "[CV] END colsample_bylevel=0.803809687296255, colsample_bynode=0.6034225470031548, colsample_bytree=0.6317081700832806, gamma=1.98675328035122, learning_rate=0.07729121166073208, max_delta_step=9, max_depth=8, min_child_weight=8, n_estimators=2885, reg_alpha=1.2773213476401888, reg_lambda=2.4550946227862767, scale_pos_weight=1.070082578732788, subsample=0.9973180774279604; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.803809687296255, colsample_bynode=0.6034225470031548, colsample_bytree=0.6317081700832806, gamma=1.98675328035122, learning_rate=0.07729121166073208, max_delta_step=9, max_depth=8, min_child_weight=8, n_estimators=2885, reg_alpha=1.2773213476401888, reg_lambda=2.4550946227862767, scale_pos_weight=1.070082578732788, subsample=0.9973180774279604; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.9975100458948011, colsample_bynode=0.6297336126549192, colsample_bytree=0.6002404174267807, gamma=1.9597971313266744, learning_rate=0.0012872094197615008, max_delta_step=8, max_depth=14, min_child_weight=14, n_estimators=1624, reg_alpha=2.8023628052524434, reg_lambda=0.45843710726537534, scale_pos_weight=0.8088497589455969, subsample=0.7034967719641311; total time=   7.6s\n",
      "[CV] END colsample_bylevel=0.9140441275632102, colsample_bynode=0.7792800689115179, colsample_bytree=0.6, gamma=2.0, learning_rate=0.1, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.9140441275632102, colsample_bynode=0.7792800689115179, colsample_bytree=0.6, gamma=2.0, learning_rate=0.1, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.6744062240881087, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.0, learning_rate=0.019890225694014878, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.002570548172429792, scale_pos_weight=1.2, subsample=0.9511129209230911; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.9234712046133574, colsample_bynode=0.9018987298009663, colsample_bytree=0.8125607387764793, gamma=0.1147992410458816, learning_rate=0.024373689671177427, max_delta_step=10, max_depth=15, min_child_weight=9, n_estimators=2947, reg_alpha=0.03037924928893921, reg_lambda=2.536307578124162, scale_pos_weight=1.0873206530460928, subsample=0.9982555882054965; total time=  18.1s\n",
      "[CV] END colsample_bylevel=0.7867581948991739, colsample_bynode=0.9303869073943833, colsample_bytree=0.7963902646747765, gamma=0.0317084602734703, learning_rate=0.020096856092047324, max_delta_step=9, max_depth=15, min_child_weight=11, n_estimators=2127, reg_alpha=2.8699654377992703, reg_lambda=0.23154048462970217, scale_pos_weight=0.9139109911644648, subsample=0.960118245497821; total time=  17.2s\n",
      "[CV] END colsample_bylevel=0.7867581948991739, colsample_bynode=0.9303869073943833, colsample_bytree=0.7963902646747765, gamma=0.0317084602734703, learning_rate=0.020096856092047324, max_delta_step=9, max_depth=15, min_child_weight=11, n_estimators=2127, reg_alpha=2.8699654377992703, reg_lambda=0.23154048462970217, scale_pos_weight=0.9139109911644648, subsample=0.960118245497821; total time=  14.9s\n",
      "[CV] END colsample_bylevel=0.7745272342149911, colsample_bynode=0.8672356627721698, colsample_bytree=0.7881330533719713, gamma=1.0375505262740985, learning_rate=0.014272716330904232, max_delta_step=8, max_depth=4, min_child_weight=3, n_estimators=809, reg_alpha=0.10673541775704112, reg_lambda=0.3919322779266198, scale_pos_weight=1.0491838911999625, subsample=0.7266366377985876; total time=   2.5s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.7658651292754646, colsample_bytree=1.0, gamma=2.0, learning_rate=0.01345117921380264, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=1146, reg_alpha=0.0, reg_lambda=0.5872528988341121, scale_pos_weight=0.8615059429830153, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.6597322567913767, colsample_bynode=0.954146867216343, colsample_bytree=0.6424175497237475, gamma=0.047553879161059256, learning_rate=0.007440685591392875, max_delta_step=1, max_depth=4, min_child_weight=2, n_estimators=2989, reg_alpha=2.2851921100158643, reg_lambda=0.3485605035974515, scale_pos_weight=0.802746849920165, subsample=0.9790214738952016; total time=   8.4s\n",
      "[CV] END colsample_bylevel=0.9653116876268035, colsample_bynode=0.7624196130273131, colsample_bytree=0.6063157550834486, gamma=1.197442825229783, learning_rate=0.003184019752064612, max_delta_step=0, max_depth=15, min_child_weight=3, n_estimators=2938, reg_alpha=2.520382695710136, reg_lambda=0.3113786361921287, scale_pos_weight=1.1690756364866899, subsample=0.7334315239237805; total time=  18.3s\n",
      "[CV] END colsample_bylevel=0.9007555565273145, colsample_bynode=0.7836190736171249, colsample_bytree=0.7006284799308222, gamma=1.9982460298595777, learning_rate=0.010428453093846449, max_delta_step=10, max_depth=15, min_child_weight=6, n_estimators=2992, reg_alpha=1.9291537997853434, reg_lambda=2.7330981930370646, scale_pos_weight=0.9291253397346689, subsample=0.7309685935907756; total time=   9.2s\n",
      "[CV] END colsample_bylevel=0.9007555565273145, colsample_bynode=0.7836190736171249, colsample_bytree=0.7006284799308222, gamma=1.9982460298595777, learning_rate=0.010428453093846449, max_delta_step=10, max_depth=15, min_child_weight=6, n_estimators=2992, reg_alpha=1.9291537997853434, reg_lambda=2.7330981930370646, scale_pos_weight=0.9291253397346689, subsample=0.7309685935907756; total time=   8.1s\n",
      "[CV] END colsample_bylevel=0.8546625088429568, colsample_bynode=0.8249770025662069, colsample_bytree=0.9796944581148662, gamma=0.03852449315728613, learning_rate=0.0030284080004574724, max_delta_step=1, max_depth=15, min_child_weight=3, n_estimators=1455, reg_alpha=1.624639669766568, reg_lambda=0.16118396335612845, scale_pos_weight=1.1767119623134499, subsample=0.7069714046418374; total time=  21.7s\n",
      "\n",
      "[CV] END colsample_bylevel=0.6649962364931218, colsample_bynode=0.8847755784481242, colsample_bytree=0.7226827705501258, gamma=1.96975292470343, learning_rate=0.00849747157126491, max_delta_step=1, max_depth=15, min_child_weight=6, n_estimators=1663, reg_alpha=0.18734316004947443, reg_lambda=0.4048307065571941, scale_pos_weight=0.9346324108458257, subsample=0.9269603092966929; total time=   3.9s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.01022295162190459, max_delta_step=0, max_depth=4, min_child_weight=15, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.9598781727284172, subsample=1.0; total time=   4.8s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.01022295162190459, max_delta_step=0, max_depth=4, min_child_weight=15, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.9598781727284172, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bylevel=0.8049790884946122, colsample_bynode=0.958267187155686, colsample_bytree=0.8592699958135106, gamma=1.8798111344072106, learning_rate=0.09811076108892733, max_delta_step=9, max_depth=15, min_child_weight=15, n_estimators=600, reg_alpha=1.4395413174242633, reg_lambda=1.0292008334139462, scale_pos_weight=1.1279868608711727, subsample=0.8689249096774724; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.8049790884946122, colsample_bynode=0.958267187155686, colsample_bytree=0.8592699958135106, gamma=1.8798111344072106, learning_rate=0.09811076108892733, max_delta_step=9, max_depth=15, min_child_weight=15, n_estimators=600, reg_alpha=1.4395413174242633, reg_lambda=1.0292008334139462, scale_pos_weight=1.1279868608711727, subsample=0.8689249096774724; total time=   1.7s\n",
      "[CV] END colsample_bylevel=0.6244917232814939, colsample_bynode=0.7500289333491468, colsample_bytree=0.9929819056662685, gamma=1.967710172445452, learning_rate=0.0023537342997263723, max_delta_step=1, max_depth=5, min_child_weight=13, n_estimators=1924, reg_alpha=0.39379578359099776, reg_lambda=2.545417450208824, scale_pos_weight=1.083007910106893, subsample=0.9444253706712565; total time=   8.2s\n",
      "[CV] END colsample_bylevel=0.8136493924008539, colsample_bynode=0.8663098031568854, colsample_bytree=0.838040662169969, gamma=1.953452213261073, learning_rate=0.0011142904405282083, max_delta_step=4, max_depth=4, min_child_weight=15, n_estimators=2373, reg_alpha=2.869584805083433, reg_lambda=1.613901303618288, scale_pos_weight=0.9847934487675435, subsample=0.7188325076490992; total time=   7.1s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7214430854736362, colsample_bytree=0.9854627100473761, gamma=1.7541256265830654, learning_rate=0.031702865109362516, max_delta_step=0, max_depth=4, min_child_weight=8, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bylevel=0.8630729744826783, colsample_bynode=0.9935101903682826, colsample_bytree=0.7203975392263717, gamma=1.8837692803378632, learning_rate=0.07948851651358695, max_delta_step=7, max_depth=15, min_child_weight=2, n_estimators=2298, reg_alpha=2.9932596070657604, reg_lambda=2.6730734698731853, scale_pos_weight=1.092633397136379, subsample=0.9431362450708927; total time=   3.8s\n",
      "[CV] END colsample_bylevel=0.8630729744826783, colsample_bynode=0.9935101903682826, colsample_bytree=0.7203975392263717, gamma=1.8837692803378632, learning_rate=0.07948851651358695, max_delta_step=7, max_depth=15, min_child_weight=2, n_estimators=2298, reg_alpha=2.9932596070657604, reg_lambda=2.6730734698731853, scale_pos_weight=1.092633397136379, subsample=0.9431362450708927; total time=   3.4s\n",
      "[CV] END colsample_bylevel=0.8260935202425312, colsample_bynode=0.6780865147438422, colsample_bytree=0.6, gamma=2.0, learning_rate=0.001, max_delta_step=10, max_depth=7, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1789373395850282, subsample=1.0; total time=  17.3s\n",
      "[CV] END colsample_bylevel=0.7537074234765465, colsample_bynode=0.7568019971062518, colsample_bytree=0.7841057345600763, gamma=1.872329868172045, learning_rate=0.011230172421284015, max_delta_step=9, max_depth=15, min_child_weight=7, n_estimators=656, reg_alpha=1.6433824068842462, reg_lambda=1.132574999195819, scale_pos_weight=0.8078680817965324, subsample=0.7423322699968832; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.7537074234765465, colsample_bynode=0.7568019971062518, colsample_bytree=0.7841057345600763, gamma=1.872329868172045, learning_rate=0.011230172421284015, max_delta_step=9, max_depth=15, min_child_weight=7, n_estimators=656, reg_alpha=1.6433824068842462, reg_lambda=1.132574999195819, scale_pos_weight=0.8078680817965324, subsample=0.7423322699968832; total time=   3.9s\n",
      "[CV] END colsample_bylevel=0.7756554417203437, colsample_bynode=0.7300790056918609, colsample_bytree=0.6302819532608847, gamma=1.8822040489605418, learning_rate=0.015726551726098936, max_delta_step=5, max_depth=9, min_child_weight=10, n_estimators=510, reg_alpha=2.990826813391728, reg_lambda=2.586920238594296, scale_pos_weight=1.1553778481575212, subsample=0.7254234722479168; total time=   2.7s\n",
      "[CV] END colsample_bylevel=0.6323551844580703, colsample_bynode=0.6576387621119553, colsample_bytree=0.7696930725879388, gamma=1.8149348328567636, learning_rate=0.0029900207975659876, max_delta_step=2, max_depth=11, min_child_weight=14, n_estimators=633, reg_alpha=0.23627623487799537, reg_lambda=0.2662635764642302, scale_pos_weight=1.0909985768619666, subsample=0.7034909127232992; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.9601411196443507, colsample_bynode=0.7966212444192398, colsample_bytree=0.6930998860139954, gamma=1.6879589433889206, learning_rate=0.0010124414373235994, max_delta_step=4, max_depth=15, min_child_weight=9, n_estimators=2887, reg_alpha=0.8821168244039665, reg_lambda=1.2448000608298926, scale_pos_weight=0.8455428982527128, subsample=0.7239246089840329; total time=  16.0s\n",
      "[CV] END colsample_bylevel=0.803809687296255, colsample_bynode=0.6034225470031548, colsample_bytree=0.6317081700832806, gamma=1.98675328035122, learning_rate=0.07729121166073208, max_delta_step=9, max_depth=8, min_child_weight=8, n_estimators=2885, reg_alpha=1.2773213476401888, reg_lambda=2.4550946227862767, scale_pos_weight=1.070082578732788, subsample=0.9973180774279604; total time=   3.8s\n",
      "[CV] END colsample_bylevel=0.803809687296255, colsample_bynode=0.6034225470031548, colsample_bytree=0.6317081700832806, gamma=1.98675328035122, learning_rate=0.07729121166073208, max_delta_step=9, max_depth=8, min_child_weight=8, n_estimators=2885, reg_alpha=1.2773213476401888, reg_lambda=2.4550946227862767, scale_pos_weight=1.070082578732788, subsample=0.9973180774279604; total time=   3.6s\n",
      "[CV] END colsample_bylevel=0.9975100458948011, colsample_bynode=0.6297336126549192, colsample_bytree=0.6002404174267807, gamma=1.9597971313266744, learning_rate=0.0012872094197615008, max_delta_step=8, max_depth=14, min_child_weight=14, n_estimators=1624, reg_alpha=2.8023628052524434, reg_lambda=0.45843710726537534, scale_pos_weight=0.8088497589455969, subsample=0.7034967719641311; total time=   7.6s\n",
      "[CV] END colsample_bylevel=0.9975100458948011, colsample_bynode=0.6297336126549192, colsample_bytree=0.6002404174267807, gamma=1.9597971313266744, learning_rate=0.0012872094197615008, max_delta_step=8, max_depth=14, min_child_weight=14, n_estimators=1624, reg_alpha=2.8023628052524434, reg_lambda=0.45843710726537534, scale_pos_weight=0.8088497589455969, subsample=0.7034967719641311; total time=   5.3s\n",
      "[CV] END colsample_bylevel=0.9234712046133574, colsample_bynode=0.9018987298009663, colsample_bytree=0.8125607387764793, gamma=0.1147992410458816, learning_rate=0.024373689671177427, max_delta_step=10, max_depth=15, min_child_weight=9, n_estimators=2947, reg_alpha=0.03037924928893921, reg_lambda=2.536307578124162, scale_pos_weight=1.0873206530460928, subsample=0.9982555882054965; total time=  18.0s\n",
      "[CV] END colsample_bylevel=0.7867581948991739, colsample_bynode=0.9303869073943833, colsample_bytree=0.7963902646747765, gamma=0.0317084602734703, learning_rate=0.020096856092047324, max_delta_step=9, max_depth=15, min_child_weight=11, n_estimators=2127, reg_alpha=2.8699654377992703, reg_lambda=0.23154048462970217, scale_pos_weight=0.9139109911644648, subsample=0.960118245497821; total time=  17.0s\n",
      "[CV] END colsample_bylevel=0.7867581948991739, colsample_bynode=0.9303869073943833, colsample_bytree=0.7963902646747765, gamma=0.0317084602734703, learning_rate=0.020096856092047324, max_delta_step=9, max_depth=15, min_child_weight=11, n_estimators=2127, reg_alpha=2.8699654377992703, reg_lambda=0.23154048462970217, scale_pos_weight=0.9139109911644648, subsample=0.960118245497821; total time=  15.1s\n",
      "[CV] END colsample_bylevel=0.7745272342149911, colsample_bynode=0.8672356627721698, colsample_bytree=0.7881330533719713, gamma=1.0375505262740985, learning_rate=0.014272716330904232, max_delta_step=8, max_depth=4, min_child_weight=3, n_estimators=809, reg_alpha=0.10673541775704112, reg_lambda=0.3919322779266198, scale_pos_weight=1.0491838911999625, subsample=0.7266366377985876; total time=   2.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.7658651292754646, colsample_bytree=1.0, gamma=2.0, learning_rate=0.01345117921380264, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=1146, reg_alpha=0.0, reg_lambda=0.5872528988341121, scale_pos_weight=0.8615059429830153, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.7658651292754646, colsample_bytree=1.0, gamma=2.0, learning_rate=0.01345117921380264, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=1146, reg_alpha=0.0, reg_lambda=0.5872528988341121, scale_pos_weight=0.8615059429830153, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.6597322567913767, colsample_bynode=0.954146867216343, colsample_bytree=0.6424175497237475, gamma=0.047553879161059256, learning_rate=0.007440685591392875, max_delta_step=1, max_depth=4, min_child_weight=2, n_estimators=2989, reg_alpha=2.2851921100158643, reg_lambda=0.3485605035974515, scale_pos_weight=0.802746849920165, subsample=0.9790214738952016; total time=   8.8s\n",
      "[CV] END colsample_bylevel=0.9653116876268035, colsample_bynode=0.7624196130273131, colsample_bytree=0.6063157550834486, gamma=1.197442825229783, learning_rate=0.003184019752064612, max_delta_step=0, max_depth=15, min_child_weight=3, n_estimators=2938, reg_alpha=2.520382695710136, reg_lambda=0.3113786361921287, scale_pos_weight=1.1690756364866899, subsample=0.7334315239237805; total time=  17.9s\n",
      "[CV] END colsample_bylevel=0.9007555565273145, colsample_bynode=0.7836190736171249, colsample_bytree=0.7006284799308222, gamma=1.9982460298595777, learning_rate=0.010428453093846449, max_delta_step=10, max_depth=15, min_child_weight=6, n_estimators=2992, reg_alpha=1.9291537997853434, reg_lambda=2.7330981930370646, scale_pos_weight=0.9291253397346689, subsample=0.7309685935907756; total time=   9.4s\n",
      "[CV] END colsample_bylevel=0.9007555565273145, colsample_bynode=0.7836190736171249, colsample_bytree=0.7006284799308222, gamma=1.9982460298595777, learning_rate=0.010428453093846449, max_delta_step=10, max_depth=15, min_child_weight=6, n_estimators=2992, reg_alpha=1.9291537997853434, reg_lambda=2.7330981930370646, scale_pos_weight=0.9291253397346689, subsample=0.7309685935907756; total time=   8.0s\n",
      "[CV] END colsample_bylevel=0.8546625088429568, colsample_bynode=0.8249770025662069, colsample_bytree=0.9796944581148662, gamma=0.03852449315728613, learning_rate=0.0030284080004574724, max_delta_step=1, max_depth=15, min_child_weight=3, n_estimators=1455, reg_alpha=1.624639669766568, reg_lambda=0.16118396335612845, scale_pos_weight=1.1767119623134499, subsample=0.7069714046418374; total time=  21.5s\n",
      "\n",
      "[CV] END colsample_bylevel=0.6244917232814939, colsample_bynode=0.7500289333491468, colsample_bytree=0.9929819056662685, gamma=1.967710172445452, learning_rate=0.0023537342997263723, max_delta_step=1, max_depth=5, min_child_weight=13, n_estimators=1924, reg_alpha=0.39379578359099776, reg_lambda=2.545417450208824, scale_pos_weight=1.083007910106893, subsample=0.9444253706712565; total time=   8.4s\n",
      "[CV] END colsample_bylevel=0.8136493924008539, colsample_bynode=0.8663098031568854, colsample_bytree=0.838040662169969, gamma=1.953452213261073, learning_rate=0.0011142904405282083, max_delta_step=4, max_depth=4, min_child_weight=15, n_estimators=2373, reg_alpha=2.869584805083433, reg_lambda=1.613901303618288, scale_pos_weight=0.9847934487675435, subsample=0.7188325076490992; total time=   7.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7214430854736362, colsample_bytree=0.9854627100473761, gamma=1.7541256265830654, learning_rate=0.031702865109362516, max_delta_step=0, max_depth=4, min_child_weight=8, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7214430854736362, colsample_bytree=0.9854627100473761, gamma=1.7541256265830654, learning_rate=0.031702865109362516, max_delta_step=0, max_depth=4, min_child_weight=8, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.8630729744826783, colsample_bynode=0.9935101903682826, colsample_bytree=0.7203975392263717, gamma=1.8837692803378632, learning_rate=0.07948851651358695, max_delta_step=7, max_depth=15, min_child_weight=2, n_estimators=2298, reg_alpha=2.9932596070657604, reg_lambda=2.6730734698731853, scale_pos_weight=1.092633397136379, subsample=0.9431362450708927; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.8595290977953045, colsample_bynode=0.8372912774326707, colsample_bytree=1.0, gamma=0.0, learning_rate=0.015003275330162335, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=1.0925275286236853, scale_pos_weight=0.9532633020219079, subsample=0.9613565213259727; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.8260935202425312, colsample_bynode=0.6780865147438422, colsample_bytree=0.6, gamma=2.0, learning_rate=0.001, max_delta_step=10, max_depth=7, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1789373395850282, subsample=1.0; total time=  17.3s\n",
      "[CV] END colsample_bylevel=0.7537074234765465, colsample_bynode=0.7568019971062518, colsample_bytree=0.7841057345600763, gamma=1.872329868172045, learning_rate=0.011230172421284015, max_delta_step=9, max_depth=15, min_child_weight=7, n_estimators=656, reg_alpha=1.6433824068842462, reg_lambda=1.132574999195819, scale_pos_weight=0.8078680817965324, subsample=0.7423322699968832; total time=   3.6s\n",
      "[CV] END colsample_bylevel=0.7756554417203437, colsample_bynode=0.7300790056918609, colsample_bytree=0.6302819532608847, gamma=1.8822040489605418, learning_rate=0.015726551726098936, max_delta_step=5, max_depth=9, min_child_weight=10, n_estimators=510, reg_alpha=2.990826813391728, reg_lambda=2.586920238594296, scale_pos_weight=1.1553778481575212, subsample=0.7254234722479168; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.7756554417203437, colsample_bynode=0.7300790056918609, colsample_bytree=0.6302819532608847, gamma=1.8822040489605418, learning_rate=0.015726551726098936, max_delta_step=5, max_depth=9, min_child_weight=10, n_estimators=510, reg_alpha=2.990826813391728, reg_lambda=2.586920238594296, scale_pos_weight=1.1553778481575212, subsample=0.7254234722479168; total time=   2.7s\n",
      "[CV] END colsample_bylevel=0.7756554417203437, colsample_bynode=0.7300790056918609, colsample_bytree=0.6302819532608847, gamma=1.8822040489605418, learning_rate=0.015726551726098936, max_delta_step=5, max_depth=9, min_child_weight=10, n_estimators=510, reg_alpha=2.990826813391728, reg_lambda=2.586920238594296, scale_pos_weight=1.1553778481575212, subsample=0.7254234722479168; total time=   1.7s\n",
      "[CV] END colsample_bylevel=0.6323551844580703, colsample_bynode=0.6576387621119553, colsample_bytree=0.7696930725879388, gamma=1.8149348328567636, learning_rate=0.0029900207975659876, max_delta_step=2, max_depth=11, min_child_weight=14, n_estimators=633, reg_alpha=0.23627623487799537, reg_lambda=0.2662635764642302, scale_pos_weight=1.0909985768619666, subsample=0.7034909127232992; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.9601411196443507, colsample_bynode=0.7966212444192398, colsample_bytree=0.6930998860139954, gamma=1.6879589433889206, learning_rate=0.0010124414373235994, max_delta_step=4, max_depth=15, min_child_weight=9, n_estimators=2887, reg_alpha=0.8821168244039665, reg_lambda=1.2448000608298926, scale_pos_weight=0.8455428982527128, subsample=0.7239246089840329; total time=  16.1s\n",
      "[CV] END colsample_bylevel=0.803809687296255, colsample_bynode=0.6034225470031548, colsample_bytree=0.6317081700832806, gamma=1.98675328035122, learning_rate=0.07729121166073208, max_delta_step=9, max_depth=8, min_child_weight=8, n_estimators=2885, reg_alpha=1.2773213476401888, reg_lambda=2.4550946227862767, scale_pos_weight=1.070082578732788, subsample=0.9973180774279604; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.803809687296255, colsample_bynode=0.6034225470031548, colsample_bytree=0.6317081700832806, gamma=1.98675328035122, learning_rate=0.07729121166073208, max_delta_step=9, max_depth=8, min_child_weight=8, n_estimators=2885, reg_alpha=1.2773213476401888, reg_lambda=2.4550946227862767, scale_pos_weight=1.070082578732788, subsample=0.9973180774279604; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.9975100458948011, colsample_bynode=0.6297336126549192, colsample_bytree=0.6002404174267807, gamma=1.9597971313266744, learning_rate=0.0012872094197615008, max_delta_step=8, max_depth=14, min_child_weight=14, n_estimators=1624, reg_alpha=2.8023628052524434, reg_lambda=0.45843710726537534, scale_pos_weight=0.8088497589455969, subsample=0.7034967719641311; total time=   7.9s\n",
      "[CV] END colsample_bylevel=0.9140441275632102, colsample_bynode=0.7792800689115179, colsample_bytree=0.6, gamma=2.0, learning_rate=0.1, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.6744062240881087, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.0, learning_rate=0.019890225694014878, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.002570548172429792, scale_pos_weight=1.2, subsample=0.9511129209230911; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.6744062240881087, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.0, learning_rate=0.019890225694014878, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.002570548172429792, scale_pos_weight=1.2, subsample=0.9511129209230911; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.9234712046133574, colsample_bynode=0.9018987298009663, colsample_bytree=0.8125607387764793, gamma=0.1147992410458816, learning_rate=0.024373689671177427, max_delta_step=10, max_depth=15, min_child_weight=9, n_estimators=2947, reg_alpha=0.03037924928893921, reg_lambda=2.536307578124162, scale_pos_weight=1.0873206530460928, subsample=0.9982555882054965; total time=  18.4s\n",
      "[CV] END colsample_bylevel=0.7867581948991739, colsample_bynode=0.9303869073943833, colsample_bytree=0.7963902646747765, gamma=0.0317084602734703, learning_rate=0.020096856092047324, max_delta_step=9, max_depth=15, min_child_weight=11, n_estimators=2127, reg_alpha=2.8699654377992703, reg_lambda=0.23154048462970217, scale_pos_weight=0.9139109911644648, subsample=0.960118245497821; total time=  17.4s\n",
      "[CV] END colsample_bylevel=0.9067384536773431, colsample_bynode=0.6126748729398347, colsample_bytree=0.9819341977594845, gamma=0.8895356791966749, learning_rate=0.02284176200877286, max_delta_step=0, max_depth=15, min_child_weight=6, n_estimators=2621, reg_alpha=2.6931033263340423, reg_lambda=2.034918221054438, scale_pos_weight=0.9691367789834109, subsample=0.998020900102754; total time=   6.1s\n",
      "[CV] END colsample_bylevel=0.9067384536773431, colsample_bynode=0.6126748729398347, colsample_bytree=0.9819341977594845, gamma=0.8895356791966749, learning_rate=0.02284176200877286, max_delta_step=0, max_depth=15, min_child_weight=6, n_estimators=2621, reg_alpha=2.6931033263340423, reg_lambda=2.034918221054438, scale_pos_weight=0.9691367789834109, subsample=0.998020900102754; total time=   6.3s\n",
      "[CV] END colsample_bylevel=0.9067384536773431, colsample_bynode=0.6126748729398347, colsample_bytree=0.9819341977594845, gamma=0.8895356791966749, learning_rate=0.02284176200877286, max_delta_step=0, max_depth=15, min_child_weight=6, n_estimators=2621, reg_alpha=2.6931033263340423, reg_lambda=2.034918221054438, scale_pos_weight=0.9691367789834109, subsample=0.998020900102754; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.7745272342149911, colsample_bynode=0.8672356627721698, colsample_bytree=0.7881330533719713, gamma=1.0375505262740985, learning_rate=0.014272716330904232, max_delta_step=8, max_depth=4, min_child_weight=3, n_estimators=809, reg_alpha=0.10673541775704112, reg_lambda=0.3919322779266198, scale_pos_weight=1.0491838911999625, subsample=0.7266366377985876; total time=   2.5s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.7658651292754646, colsample_bytree=1.0, gamma=2.0, learning_rate=0.01345117921380264, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=1146, reg_alpha=0.0, reg_lambda=0.5872528988341121, scale_pos_weight=0.8615059429830153, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.6597322567913767, colsample_bynode=0.954146867216343, colsample_bytree=0.6424175497237475, gamma=0.047553879161059256, learning_rate=0.007440685591392875, max_delta_step=1, max_depth=4, min_child_weight=2, n_estimators=2989, reg_alpha=2.2851921100158643, reg_lambda=0.3485605035974515, scale_pos_weight=0.802746849920165, subsample=0.9790214738952016; total time=   8.5s\n",
      "[CV] END colsample_bylevel=0.6597322567913767, colsample_bynode=0.954146867216343, colsample_bytree=0.6424175497237475, gamma=0.047553879161059256, learning_rate=0.007440685591392875, max_delta_step=1, max_depth=4, min_child_weight=2, n_estimators=2989, reg_alpha=2.2851921100158643, reg_lambda=0.3485605035974515, scale_pos_weight=0.802746849920165, subsample=0.9790214738952016; total time=   5.5s\n",
      "[CV] END colsample_bylevel=0.9653116876268035, colsample_bynode=0.7624196130273131, colsample_bytree=0.6063157550834486, gamma=1.197442825229783, learning_rate=0.003184019752064612, max_delta_step=0, max_depth=15, min_child_weight=3, n_estimators=2938, reg_alpha=2.520382695710136, reg_lambda=0.3113786361921287, scale_pos_weight=1.1690756364866899, subsample=0.7334315239237805; total time=  18.0s\n",
      "[CV] END colsample_bylevel=0.9007555565273145, colsample_bynode=0.7836190736171249, colsample_bytree=0.7006284799308222, gamma=1.9982460298595777, learning_rate=0.010428453093846449, max_delta_step=10, max_depth=15, min_child_weight=6, n_estimators=2992, reg_alpha=1.9291537997853434, reg_lambda=2.7330981930370646, scale_pos_weight=0.9291253397346689, subsample=0.7309685935907756; total time=   9.1s\n",
      "[CV] END colsample_bylevel=0.9007555565273145, colsample_bynode=0.7836190736171249, colsample_bytree=0.7006284799308222, gamma=1.9982460298595777, learning_rate=0.010428453093846449, max_delta_step=10, max_depth=15, min_child_weight=6, n_estimators=2992, reg_alpha=1.9291537997853434, reg_lambda=2.7330981930370646, scale_pos_weight=0.9291253397346689, subsample=0.7309685935907756; total time=   7.8s\n",
      "[CV] END colsample_bylevel=0.8546625088429568, colsample_bynode=0.8249770025662069, colsample_bytree=0.9796944581148662, gamma=0.03852449315728613, learning_rate=0.0030284080004574724, max_delta_step=1, max_depth=15, min_child_weight=3, n_estimators=1455, reg_alpha=1.624639669766568, reg_lambda=0.16118396335612845, scale_pos_weight=1.1767119623134499, subsample=0.7069714046418374; total time=  21.4s\n",
      "\n",
      "[CV] END colsample_bylevel=0.9533923554263655, colsample_bynode=0.7698742853954607, colsample_bytree=0.7455511442221807, gamma=1.9791800808553475, learning_rate=0.08620622105880298, max_delta_step=6, max_depth=4, min_child_weight=6, n_estimators=1654, reg_alpha=2.4578329293588403, reg_lambda=2.3003373083809695, scale_pos_weight=1.1575520841344622, subsample=0.8414805196611954; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.6649962364931218, colsample_bynode=0.8847755784481242, colsample_bytree=0.7226827705501258, gamma=1.96975292470343, learning_rate=0.00849747157126491, max_delta_step=1, max_depth=15, min_child_weight=6, n_estimators=1663, reg_alpha=0.18734316004947443, reg_lambda=0.4048307065571941, scale_pos_weight=0.9346324108458257, subsample=0.9269603092966929; total time=   6.7s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.01022295162190459, max_delta_step=0, max_depth=4, min_child_weight=15, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.9598781727284172, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.01022295162190459, max_delta_step=0, max_depth=4, min_child_weight=15, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.9598781727284172, subsample=1.0; total time=   4.8s\n",
      "[CV] END colsample_bylevel=0.8049790884946122, colsample_bynode=0.958267187155686, colsample_bytree=0.8592699958135106, gamma=1.8798111344072106, learning_rate=0.09811076108892733, max_delta_step=9, max_depth=15, min_child_weight=15, n_estimators=600, reg_alpha=1.4395413174242633, reg_lambda=1.0292008334139462, scale_pos_weight=1.1279868608711727, subsample=0.8689249096774724; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.6244917232814939, colsample_bynode=0.7500289333491468, colsample_bytree=0.9929819056662685, gamma=1.967710172445452, learning_rate=0.0023537342997263723, max_delta_step=1, max_depth=5, min_child_weight=13, n_estimators=1924, reg_alpha=0.39379578359099776, reg_lambda=2.545417450208824, scale_pos_weight=1.083007910106893, subsample=0.9444253706712565; total time=   8.5s\n",
      "[CV] END colsample_bylevel=0.8136493924008539, colsample_bynode=0.8663098031568854, colsample_bytree=0.838040662169969, gamma=1.953452213261073, learning_rate=0.0011142904405282083, max_delta_step=4, max_depth=4, min_child_weight=15, n_estimators=2373, reg_alpha=2.869584805083433, reg_lambda=1.613901303618288, scale_pos_weight=0.9847934487675435, subsample=0.7188325076490992; total time=   7.4s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7214430854736362, colsample_bytree=0.9854627100473761, gamma=1.7541256265830654, learning_rate=0.031702865109362516, max_delta_step=0, max_depth=4, min_child_weight=8, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bylevel=0.8630729744826783, colsample_bynode=0.9935101903682826, colsample_bytree=0.7203975392263717, gamma=1.8837692803378632, learning_rate=0.07948851651358695, max_delta_step=7, max_depth=15, min_child_weight=2, n_estimators=2298, reg_alpha=2.9932596070657604, reg_lambda=2.6730734698731853, scale_pos_weight=1.092633397136379, subsample=0.9431362450708927; total time=   3.8s\n",
      "[CV] END colsample_bylevel=0.8595290977953045, colsample_bynode=0.8372912774326707, colsample_bytree=1.0, gamma=0.0, learning_rate=0.015003275330162335, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=1.0925275286236853, scale_pos_weight=0.9532633020219079, subsample=0.9613565213259727; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.8595290977953045, colsample_bynode=0.8372912774326707, colsample_bytree=1.0, gamma=0.0, learning_rate=0.015003275330162335, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=1.0925275286236853, scale_pos_weight=0.9532633020219079, subsample=0.9613565213259727; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.8260935202425312, colsample_bynode=0.6780865147438422, colsample_bytree=0.6, gamma=2.0, learning_rate=0.001, max_delta_step=10, max_depth=7, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1789373395850282, subsample=1.0; total time=  17.5s\n",
      "[CV] END colsample_bylevel=0.7537074234765465, colsample_bynode=0.7568019971062518, colsample_bytree=0.7841057345600763, gamma=1.872329868172045, learning_rate=0.011230172421284015, max_delta_step=9, max_depth=15, min_child_weight=7, n_estimators=656, reg_alpha=1.6433824068842462, reg_lambda=1.132574999195819, scale_pos_weight=0.8078680817965324, subsample=0.7423322699968832; total time=   3.5s\n",
      "[CV] END colsample_bylevel=0.7756554417203437, colsample_bynode=0.7300790056918609, colsample_bytree=0.6302819532608847, gamma=1.8822040489605418, learning_rate=0.015726551726098936, max_delta_step=5, max_depth=9, min_child_weight=10, n_estimators=510, reg_alpha=2.990826813391728, reg_lambda=2.586920238594296, scale_pos_weight=1.1553778481575212, subsample=0.7254234722479168; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.7756554417203437, colsample_bynode=0.7300790056918609, colsample_bytree=0.6302819532608847, gamma=1.8822040489605418, learning_rate=0.015726551726098936, max_delta_step=5, max_depth=9, min_child_weight=10, n_estimators=510, reg_alpha=2.990826813391728, reg_lambda=2.586920238594296, scale_pos_weight=1.1553778481575212, subsample=0.7254234722479168; total time=   2.7s\n",
      "[CV] END colsample_bylevel=0.7756554417203437, colsample_bynode=0.7300790056918609, colsample_bytree=0.6302819532608847, gamma=1.8822040489605418, learning_rate=0.015726551726098936, max_delta_step=5, max_depth=9, min_child_weight=10, n_estimators=510, reg_alpha=2.990826813391728, reg_lambda=2.586920238594296, scale_pos_weight=1.1553778481575212, subsample=0.7254234722479168; total time=   1.6s\n",
      "[CV] END colsample_bylevel=0.6323551844580703, colsample_bynode=0.6576387621119553, colsample_bytree=0.7696930725879388, gamma=1.8149348328567636, learning_rate=0.0029900207975659876, max_delta_step=2, max_depth=11, min_child_weight=14, n_estimators=633, reg_alpha=0.23627623487799537, reg_lambda=0.2662635764642302, scale_pos_weight=1.0909985768619666, subsample=0.7034909127232992; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.9601411196443507, colsample_bynode=0.7966212444192398, colsample_bytree=0.6930998860139954, gamma=1.6879589433889206, learning_rate=0.0010124414373235994, max_delta_step=4, max_depth=15, min_child_weight=9, n_estimators=2887, reg_alpha=0.8821168244039665, reg_lambda=1.2448000608298926, scale_pos_weight=0.8455428982527128, subsample=0.7239246089840329; total time=  16.1s\n",
      "[CV] END colsample_bylevel=0.9601411196443507, colsample_bynode=0.7966212444192398, colsample_bytree=0.6930998860139954, gamma=1.6879589433889206, learning_rate=0.0010124414373235994, max_delta_step=4, max_depth=15, min_child_weight=9, n_estimators=2887, reg_alpha=0.8821168244039665, reg_lambda=1.2448000608298926, scale_pos_weight=0.8455428982527128, subsample=0.7239246089840329; total time=  10.3s\n",
      "[CV] END colsample_bylevel=0.9975100458948011, colsample_bynode=0.6297336126549192, colsample_bytree=0.6002404174267807, gamma=1.9597971313266744, learning_rate=0.0012872094197615008, max_delta_step=8, max_depth=14, min_child_weight=14, n_estimators=1624, reg_alpha=2.8023628052524434, reg_lambda=0.45843710726537534, scale_pos_weight=0.8088497589455969, subsample=0.7034967719641311; total time=   7.6s\n",
      "[CV] END colsample_bylevel=0.9140441275632102, colsample_bynode=0.7792800689115179, colsample_bytree=0.6, gamma=2.0, learning_rate=0.1, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.9140441275632102, colsample_bynode=0.7792800689115179, colsample_bytree=0.6, gamma=2.0, learning_rate=0.1, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.6744062240881087, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.0, learning_rate=0.019890225694014878, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.002570548172429792, scale_pos_weight=1.2, subsample=0.9511129209230911; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.6744062240881087, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.0, learning_rate=0.019890225694014878, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.002570548172429792, scale_pos_weight=1.2, subsample=0.9511129209230911; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.9234712046133574, colsample_bynode=0.9018987298009663, colsample_bytree=0.8125607387764793, gamma=0.1147992410458816, learning_rate=0.024373689671177427, max_delta_step=10, max_depth=15, min_child_weight=9, n_estimators=2947, reg_alpha=0.03037924928893921, reg_lambda=2.536307578124162, scale_pos_weight=1.0873206530460928, subsample=0.9982555882054965; total time=  17.9s\n",
      "[CV] END colsample_bylevel=0.7867581948991739, colsample_bynode=0.9303869073943833, colsample_bytree=0.7963902646747765, gamma=0.0317084602734703, learning_rate=0.020096856092047324, max_delta_step=9, max_depth=15, min_child_weight=11, n_estimators=2127, reg_alpha=2.8699654377992703, reg_lambda=0.23154048462970217, scale_pos_weight=0.9139109911644648, subsample=0.960118245497821; total time=  17.5s\n",
      "[CV] END colsample_bylevel=0.9067384536773431, colsample_bynode=0.6126748729398347, colsample_bytree=0.9819341977594845, gamma=0.8895356791966749, learning_rate=0.02284176200877286, max_delta_step=0, max_depth=15, min_child_weight=6, n_estimators=2621, reg_alpha=2.6931033263340423, reg_lambda=2.034918221054438, scale_pos_weight=0.9691367789834109, subsample=0.998020900102754; total time=   6.2s\n",
      "[CV] END colsample_bylevel=0.9067384536773431, colsample_bynode=0.6126748729398347, colsample_bytree=0.9819341977594845, gamma=0.8895356791966749, learning_rate=0.02284176200877286, max_delta_step=0, max_depth=15, min_child_weight=6, n_estimators=2621, reg_alpha=2.6931033263340423, reg_lambda=2.034918221054438, scale_pos_weight=0.9691367789834109, subsample=0.998020900102754; total time=   6.3s\n",
      "[CV] END colsample_bylevel=0.9067384536773431, colsample_bynode=0.6126748729398347, colsample_bytree=0.9819341977594845, gamma=0.8895356791966749, learning_rate=0.02284176200877286, max_delta_step=0, max_depth=15, min_child_weight=6, n_estimators=2621, reg_alpha=2.6931033263340423, reg_lambda=2.034918221054438, scale_pos_weight=0.9691367789834109, subsample=0.998020900102754; total time=   3.1s\n",
      "[CV] END colsample_bylevel=0.7745272342149911, colsample_bynode=0.8672356627721698, colsample_bytree=0.7881330533719713, gamma=1.0375505262740985, learning_rate=0.014272716330904232, max_delta_step=8, max_depth=4, min_child_weight=3, n_estimators=809, reg_alpha=0.10673541775704112, reg_lambda=0.3919322779266198, scale_pos_weight=1.0491838911999625, subsample=0.7266366377985876; total time=   2.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.7658651292754646, colsample_bytree=1.0, gamma=2.0, learning_rate=0.01345117921380264, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=1146, reg_alpha=0.0, reg_lambda=0.5872528988341121, scale_pos_weight=0.8615059429830153, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.7658651292754646, colsample_bytree=1.0, gamma=2.0, learning_rate=0.01345117921380264, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=1146, reg_alpha=0.0, reg_lambda=0.5872528988341121, scale_pos_weight=0.8615059429830153, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=0.6597322567913767, colsample_bynode=0.954146867216343, colsample_bytree=0.6424175497237475, gamma=0.047553879161059256, learning_rate=0.007440685591392875, max_delta_step=1, max_depth=4, min_child_weight=2, n_estimators=2989, reg_alpha=2.2851921100158643, reg_lambda=0.3485605035974515, scale_pos_weight=0.802746849920165, subsample=0.9790214738952016; total time=   8.6s\n",
      "[CV] END colsample_bylevel=0.9653116876268035, colsample_bynode=0.7624196130273131, colsample_bytree=0.6063157550834486, gamma=1.197442825229783, learning_rate=0.003184019752064612, max_delta_step=0, max_depth=15, min_child_weight=3, n_estimators=2938, reg_alpha=2.520382695710136, reg_lambda=0.3113786361921287, scale_pos_weight=1.1690756364866899, subsample=0.7334315239237805; total time=  18.2s\n",
      "[CV] END colsample_bylevel=0.9007555565273145, colsample_bynode=0.7836190736171249, colsample_bytree=0.7006284799308222, gamma=1.9982460298595777, learning_rate=0.010428453093846449, max_delta_step=10, max_depth=15, min_child_weight=6, n_estimators=2992, reg_alpha=1.9291537997853434, reg_lambda=2.7330981930370646, scale_pos_weight=0.9291253397346689, subsample=0.7309685935907756; total time=   9.0s\n",
      "[CV] END colsample_bylevel=0.9007555565273145, colsample_bynode=0.7836190736171249, colsample_bytree=0.7006284799308222, gamma=1.9982460298595777, learning_rate=0.010428453093846449, max_delta_step=10, max_depth=15, min_child_weight=6, n_estimators=2992, reg_alpha=1.9291537997853434, reg_lambda=2.7330981930370646, scale_pos_weight=0.9291253397346689, subsample=0.7309685935907756; total time=   7.6s\n",
      "[CV] END colsample_bylevel=0.8546625088429568, colsample_bynode=0.8249770025662069, colsample_bytree=0.9796944581148662, gamma=0.03852449315728613, learning_rate=0.0030284080004574724, max_delta_step=1, max_depth=15, min_child_weight=3, n_estimators=1455, reg_alpha=1.624639669766568, reg_lambda=0.16118396335612845, scale_pos_weight=1.1767119623134499, subsample=0.7069714046418374; total time=  21.4s\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:19:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:19:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:19:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:19:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:19:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:19:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:19:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:19:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:19:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:19:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:19:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:19:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:19:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:19:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:19:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:19:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:20:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.7767955244290717, colsample_bynode=0.6960142338918816, colsample_bytree=0.838194951900167, gamma=0.21722093722218166, learning_rate=0.0135257233226764, max_delta_step=1, max_depth=4, min_child_weight=5, n_estimators=576, reg_alpha=0.1898130813241477, reg_lambda=0.5717877557819098, scale_pos_weight=1.1057117475115867, subsample=0.9583901382776849; total time=   1.6s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.796031218457304, colsample_bytree=0.6, gamma=0.36781805718101357, learning_rate=0.018908377529571776, max_delta_step=0, max_depth=4, min_child_weight=14, n_estimators=500, reg_alpha=3.0, reg_lambda=0.3644045001537639, scale_pos_weight=0.8153144476093589, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.8049790884946122, colsample_bynode=0.958267187155686, colsample_bytree=0.8592699958135106, gamma=1.8798111344072106, learning_rate=0.09811076108892733, max_delta_step=9, max_depth=15, min_child_weight=15, n_estimators=600, reg_alpha=1.4395413174242633, reg_lambda=1.0292008334139462, scale_pos_weight=1.1279868608711727, subsample=0.8689249096774724; total time=   1.6s\n",
      "[CV] END colsample_bylevel=0.6244917232814939, colsample_bynode=0.7500289333491468, colsample_bytree=0.9929819056662685, gamma=1.967710172445452, learning_rate=0.0023537342997263723, max_delta_step=1, max_depth=5, min_child_weight=13, n_estimators=1924, reg_alpha=0.39379578359099776, reg_lambda=2.545417450208824, scale_pos_weight=1.083007910106893, subsample=0.9444253706712565; total time=   8.2s\n",
      "[CV] END colsample_bylevel=0.8136493924008539, colsample_bynode=0.8663098031568854, colsample_bytree=0.838040662169969, gamma=1.953452213261073, learning_rate=0.0011142904405282083, max_delta_step=4, max_depth=4, min_child_weight=15, n_estimators=2373, reg_alpha=2.869584805083433, reg_lambda=1.613901303618288, scale_pos_weight=0.9847934487675435, subsample=0.7188325076490992; total time=   7.3s\n",
      "[CV] END colsample_bylevel=0.8136493924008539, colsample_bynode=0.8663098031568854, colsample_bytree=0.838040662169969, gamma=1.953452213261073, learning_rate=0.0011142904405282083, max_delta_step=4, max_depth=4, min_child_weight=15, n_estimators=2373, reg_alpha=2.869584805083433, reg_lambda=1.613901303618288, scale_pos_weight=0.9847934487675435, subsample=0.7188325076490992; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7214430854736362, colsample_bytree=0.9854627100473761, gamma=1.7541256265830654, learning_rate=0.031702865109362516, max_delta_step=0, max_depth=4, min_child_weight=8, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bylevel=0.8630729744826783, colsample_bynode=0.9935101903682826, colsample_bytree=0.7203975392263717, gamma=1.8837692803378632, learning_rate=0.07948851651358695, max_delta_step=7, max_depth=15, min_child_weight=2, n_estimators=2298, reg_alpha=2.9932596070657604, reg_lambda=2.6730734698731853, scale_pos_weight=1.092633397136379, subsample=0.9431362450708927; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.8595290977953045, colsample_bynode=0.8372912774326707, colsample_bytree=1.0, gamma=0.0, learning_rate=0.015003275330162335, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=1.0925275286236853, scale_pos_weight=0.9532633020219079, subsample=0.9613565213259727; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.8595290977953045, colsample_bynode=0.8372912774326707, colsample_bytree=1.0, gamma=0.0, learning_rate=0.015003275330162335, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=1.0925275286236853, scale_pos_weight=0.9532633020219079, subsample=0.9613565213259727; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.8260935202425312, colsample_bynode=0.6780865147438422, colsample_bytree=0.6, gamma=2.0, learning_rate=0.001, max_delta_step=10, max_depth=7, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1789373395850282, subsample=1.0; total time=  17.6s\n",
      "[CV] END colsample_bylevel=0.7537074234765465, colsample_bynode=0.7568019971062518, colsample_bytree=0.7841057345600763, gamma=1.872329868172045, learning_rate=0.011230172421284015, max_delta_step=9, max_depth=15, min_child_weight=7, n_estimators=656, reg_alpha=1.6433824068842462, reg_lambda=1.132574999195819, scale_pos_weight=0.8078680817965324, subsample=0.7423322699968832; total time=   3.4s\n",
      "[CV] END colsample_bylevel=0.7537074234765465, colsample_bynode=0.7568019971062518, colsample_bytree=0.7841057345600763, gamma=1.872329868172045, learning_rate=0.011230172421284015, max_delta_step=9, max_depth=15, min_child_weight=7, n_estimators=656, reg_alpha=1.6433824068842462, reg_lambda=1.132574999195819, scale_pos_weight=0.8078680817965324, subsample=0.7423322699968832; total time=   3.5s\n",
      "[CV] END colsample_bylevel=0.7756554417203437, colsample_bynode=0.7300790056918609, colsample_bytree=0.6302819532608847, gamma=1.8822040489605418, learning_rate=0.015726551726098936, max_delta_step=5, max_depth=9, min_child_weight=10, n_estimators=510, reg_alpha=2.990826813391728, reg_lambda=2.586920238594296, scale_pos_weight=1.1553778481575212, subsample=0.7254234722479168; total time=   2.7s\n",
      "[CV] END colsample_bylevel=0.6323551844580703, colsample_bynode=0.6576387621119553, colsample_bytree=0.7696930725879388, gamma=1.8149348328567636, learning_rate=0.0029900207975659876, max_delta_step=2, max_depth=11, min_child_weight=14, n_estimators=633, reg_alpha=0.23627623487799537, reg_lambda=0.2662635764642302, scale_pos_weight=1.0909985768619666, subsample=0.7034909127232992; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.6323551844580703, colsample_bynode=0.6576387621119553, colsample_bytree=0.7696930725879388, gamma=1.8149348328567636, learning_rate=0.0029900207975659876, max_delta_step=2, max_depth=11, min_child_weight=14, n_estimators=633, reg_alpha=0.23627623487799537, reg_lambda=0.2662635764642302, scale_pos_weight=1.0909985768619666, subsample=0.7034909127232992; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.9601411196443507, colsample_bynode=0.7966212444192398, colsample_bytree=0.6930998860139954, gamma=1.6879589433889206, learning_rate=0.0010124414373235994, max_delta_step=4, max_depth=15, min_child_weight=9, n_estimators=2887, reg_alpha=0.8821168244039665, reg_lambda=1.2448000608298926, scale_pos_weight=0.8455428982527128, subsample=0.7239246089840329; total time=  16.0s\n",
      "[CV] END colsample_bylevel=0.803809687296255, colsample_bynode=0.6034225470031548, colsample_bytree=0.6317081700832806, gamma=1.98675328035122, learning_rate=0.07729121166073208, max_delta_step=9, max_depth=8, min_child_weight=8, n_estimators=2885, reg_alpha=1.2773213476401888, reg_lambda=2.4550946227862767, scale_pos_weight=1.070082578732788, subsample=0.9973180774279604; total time=   3.9s\n",
      "[CV] END colsample_bylevel=0.9975100458948011, colsample_bynode=0.6297336126549192, colsample_bytree=0.6002404174267807, gamma=1.9597971313266744, learning_rate=0.0012872094197615008, max_delta_step=8, max_depth=14, min_child_weight=14, n_estimators=1624, reg_alpha=2.8023628052524434, reg_lambda=0.45843710726537534, scale_pos_weight=0.8088497589455969, subsample=0.7034967719641311; total time=   7.5s\n",
      "[CV] END colsample_bylevel=0.9140441275632102, colsample_bynode=0.7792800689115179, colsample_bytree=0.6, gamma=2.0, learning_rate=0.1, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.9140441275632102, colsample_bynode=0.7792800689115179, colsample_bytree=0.6, gamma=2.0, learning_rate=0.1, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.6744062240881087, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.0, learning_rate=0.019890225694014878, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.002570548172429792, scale_pos_weight=1.2, subsample=0.9511129209230911; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.9234712046133574, colsample_bynode=0.9018987298009663, colsample_bytree=0.8125607387764793, gamma=0.1147992410458816, learning_rate=0.024373689671177427, max_delta_step=10, max_depth=15, min_child_weight=9, n_estimators=2947, reg_alpha=0.03037924928893921, reg_lambda=2.536307578124162, scale_pos_weight=1.0873206530460928, subsample=0.9982555882054965; total time=  17.7s\n",
      "[CV] END colsample_bylevel=0.9533923554263655, colsample_bynode=0.7698742853954607, colsample_bytree=0.7455511442221807, gamma=1.9791800808553475, learning_rate=0.08620622105880298, max_delta_step=6, max_depth=4, min_child_weight=6, n_estimators=1654, reg_alpha=2.4578329293588403, reg_lambda=2.3003373083809695, scale_pos_weight=1.1575520841344622, subsample=0.8414805196611954; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.6649962364931218, colsample_bynode=0.8847755784481242, colsample_bytree=0.7226827705501258, gamma=1.96975292470343, learning_rate=0.00849747157126491, max_delta_step=1, max_depth=15, min_child_weight=6, n_estimators=1663, reg_alpha=0.18734316004947443, reg_lambda=0.4048307065571941, scale_pos_weight=0.9346324108458257, subsample=0.9269603092966929; total time=   6.4s\n",
      "[CV] END colsample_bylevel=0.6649962364931218, colsample_bynode=0.8847755784481242, colsample_bytree=0.7226827705501258, gamma=1.96975292470343, learning_rate=0.00849747157126491, max_delta_step=1, max_depth=15, min_child_weight=6, n_estimators=1663, reg_alpha=0.18734316004947443, reg_lambda=0.4048307065571941, scale_pos_weight=0.9346324108458257, subsample=0.9269603092966929; total time=   5.7s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=2.0, learning_rate=0.01022295162190459, max_delta_step=0, max_depth=4, min_child_weight=15, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.9598781727284172, subsample=1.0; total time=   5.0s\n",
      "[CV] END colsample_bylevel=0.7767955244290717, colsample_bynode=0.6960142338918816, colsample_bytree=0.838194951900167, gamma=0.21722093722218166, learning_rate=0.0135257233226764, max_delta_step=1, max_depth=4, min_child_weight=5, n_estimators=576, reg_alpha=0.1898130813241477, reg_lambda=0.5717877557819098, scale_pos_weight=1.1057117475115867, subsample=0.9583901382776849; total time=   1.7s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.796031218457304, colsample_bytree=0.6, gamma=0.36781805718101357, learning_rate=0.018908377529571776, max_delta_step=0, max_depth=4, min_child_weight=14, n_estimators=500, reg_alpha=3.0, reg_lambda=0.3644045001537639, scale_pos_weight=0.8153144476093589, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.796031218457304, colsample_bytree=0.6, gamma=0.36781805718101357, learning_rate=0.018908377529571776, max_delta_step=0, max_depth=4, min_child_weight=14, n_estimators=500, reg_alpha=3.0, reg_lambda=0.3644045001537639, scale_pos_weight=0.8153144476093589, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.796031218457304, colsample_bytree=0.6, gamma=0.36781805718101357, learning_rate=0.018908377529571776, max_delta_step=0, max_depth=4, min_child_weight=14, n_estimators=500, reg_alpha=3.0, reg_lambda=0.3644045001537639, scale_pos_weight=0.8153144476093589, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.8049790884946122, colsample_bynode=0.958267187155686, colsample_bytree=0.8592699958135106, gamma=1.8798111344072106, learning_rate=0.09811076108892733, max_delta_step=9, max_depth=15, min_child_weight=15, n_estimators=600, reg_alpha=1.4395413174242633, reg_lambda=1.0292008334139462, scale_pos_weight=1.1279868608711727, subsample=0.8689249096774724; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.6244917232814939, colsample_bynode=0.7500289333491468, colsample_bytree=0.9929819056662685, gamma=1.967710172445452, learning_rate=0.0023537342997263723, max_delta_step=1, max_depth=5, min_child_weight=13, n_estimators=1924, reg_alpha=0.39379578359099776, reg_lambda=2.545417450208824, scale_pos_weight=1.083007910106893, subsample=0.9444253706712565; total time=   8.1s\n",
      "[CV] END colsample_bylevel=0.6244917232814939, colsample_bynode=0.7500289333491468, colsample_bytree=0.9929819056662685, gamma=1.967710172445452, learning_rate=0.0023537342997263723, max_delta_step=1, max_depth=5, min_child_weight=13, n_estimators=1924, reg_alpha=0.39379578359099776, reg_lambda=2.545417450208824, scale_pos_weight=1.083007910106893, subsample=0.9444253706712565; total time=   6.6s\n",
      "[CV] END colsample_bylevel=0.8136493924008539, colsample_bynode=0.8663098031568854, colsample_bytree=0.838040662169969, gamma=1.953452213261073, learning_rate=0.0011142904405282083, max_delta_step=4, max_depth=4, min_child_weight=15, n_estimators=2373, reg_alpha=2.869584805083433, reg_lambda=1.613901303618288, scale_pos_weight=0.9847934487675435, subsample=0.7188325076490992; total time=   5.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7214430854736362, colsample_bytree=0.9854627100473761, gamma=1.7541256265830654, learning_rate=0.031702865109362516, max_delta_step=0, max_depth=4, min_child_weight=8, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.8630729744826783, colsample_bynode=0.9935101903682826, colsample_bytree=0.7203975392263717, gamma=1.8837692803378632, learning_rate=0.07948851651358695, max_delta_step=7, max_depth=15, min_child_weight=2, n_estimators=2298, reg_alpha=2.9932596070657604, reg_lambda=2.6730734698731853, scale_pos_weight=1.092633397136379, subsample=0.9431362450708927; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.8595290977953045, colsample_bynode=0.8372912774326707, colsample_bytree=1.0, gamma=0.0, learning_rate=0.015003275330162335, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=1.0925275286236853, scale_pos_weight=0.9532633020219079, subsample=0.9613565213259727; total time=   1.6s\n",
      "[CV] END colsample_bylevel=0.8595290977953045, colsample_bynode=0.8372912774326707, colsample_bytree=1.0, gamma=0.0, learning_rate=0.015003275330162335, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=1.0925275286236853, scale_pos_weight=0.9532633020219079, subsample=0.9613565213259727; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.8260935202425312, colsample_bynode=0.6780865147438422, colsample_bytree=0.6, gamma=2.0, learning_rate=0.001, max_delta_step=10, max_depth=7, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1789373395850282, subsample=1.0; total time=  17.0s\n",
      "[CV] END colsample_bylevel=0.8260935202425312, colsample_bynode=0.6780865147438422, colsample_bytree=0.6, gamma=2.0, learning_rate=0.001, max_delta_step=10, max_depth=7, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1789373395850282, subsample=1.0; total time=  14.1s\n",
      "[CV] END colsample_bylevel=0.6323551844580703, colsample_bynode=0.6576387621119553, colsample_bytree=0.7696930725879388, gamma=1.8149348328567636, learning_rate=0.0029900207975659876, max_delta_step=2, max_depth=11, min_child_weight=14, n_estimators=633, reg_alpha=0.23627623487799537, reg_lambda=0.2662635764642302, scale_pos_weight=1.0909985768619666, subsample=0.7034909127232992; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.9601411196443507, colsample_bynode=0.7966212444192398, colsample_bytree=0.6930998860139954, gamma=1.6879589433889206, learning_rate=0.0010124414373235994, max_delta_step=4, max_depth=15, min_child_weight=9, n_estimators=2887, reg_alpha=0.8821168244039665, reg_lambda=1.2448000608298926, scale_pos_weight=0.8455428982527128, subsample=0.7239246089840329; total time=  16.0s\n",
      "[CV] END colsample_bylevel=0.9601411196443507, colsample_bynode=0.7966212444192398, colsample_bytree=0.6930998860139954, gamma=1.6879589433889206, learning_rate=0.0010124414373235994, max_delta_step=4, max_depth=15, min_child_weight=9, n_estimators=2887, reg_alpha=0.8821168244039665, reg_lambda=1.2448000608298926, scale_pos_weight=0.8455428982527128, subsample=0.7239246089840329; total time=  10.4s\n",
      "[CV] END colsample_bylevel=0.9975100458948011, colsample_bynode=0.6297336126549192, colsample_bytree=0.6002404174267807, gamma=1.9597971313266744, learning_rate=0.0012872094197615008, max_delta_step=8, max_depth=14, min_child_weight=14, n_estimators=1624, reg_alpha=2.8023628052524434, reg_lambda=0.45843710726537534, scale_pos_weight=0.8088497589455969, subsample=0.7034967719641311; total time=   7.7s\n",
      "[CV] END colsample_bylevel=0.9140441275632102, colsample_bynode=0.7792800689115179, colsample_bytree=0.6, gamma=2.0, learning_rate=0.1, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   0.8sFitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:21:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–õ—É—á—à–∏–π ROC-AUC –Ω–∞ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏: 0.9303\n",
      "–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
      "  colsample_bylevel: 0.6\n",
      "  colsample_bynode: 0.8250732258254885\n",
      "  colsample_bytree: 0.6\n",
      "  gamma: 2.0\n",
      "  learning_rate: 0.017997938375945485\n",
      "  max_delta_step: 10\n",
      "  max_depth: 4\n",
      "  min_child_weight: 1\n",
      "  n_estimators: 3000\n",
      "  reg_alpha: 0.0\n",
      "  reg_lambda: 0.0\n",
      "  scale_pos_weight: 1.2\n",
      "  subsample: 1.0\n",
      "\n",
      "–£–ª—É—á—à–µ–Ω–Ω—ã–π Bayesian XGBoost –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:\n",
      "ROC-AUC: 0.9254\n",
      "Accuracy: 0.8911\n",
      "\n",
      "–î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.95      0.93      1782\n",
      "         1.0       0.78      0.67      0.72       468\n",
      "\n",
      "    accuracy                           0.89      2250\n",
      "   macro avg       0.85      0.81      0.83      2250\n",
      "weighted avg       0.89      0.89      0.89      2250\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1693   89]\n",
      " [ 156  312]]\n",
      "\n",
      "–¢–æ–ø-10 —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\n",
      "                             feature  importance\n",
      "5                      NumOfProducts    0.114371\n",
      "2                                Age    0.102471\n",
      "12               CreditScore_per_Age    0.101681\n",
      "17                  Is_Senior_Client    0.083735\n",
      "13              Products_per_Balance    0.080744\n",
      "24  CreditScore_Products_Interaction    0.067014\n",
      "15                   Is_Young_Client    0.056845\n",
      "7                     IsActiveMember    0.045273\n",
      "9                  Geography_Germany    0.045195\n",
      "21            Is_Active_High_Balance    0.044887\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:22:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bylevel=0.6244917232814939, colsample_bynode=0.7500289333491468, colsample_bytree=0.9929819056662685, gamma=1.967710172445452, learning_rate=0.0023537342997263723, max_delta_step=1, max_depth=5, min_child_weight=13, n_estimators=1924, reg_alpha=0.39379578359099776, reg_lambda=2.545417450208824, scale_pos_weight=1.083007910106893, subsample=0.9444253706712565; total time=   6.5s\n",
      "[CV] END colsample_bylevel=0.8136493924008539, colsample_bynode=0.8663098031568854, colsample_bytree=0.838040662169969, gamma=1.953452213261073, learning_rate=0.0011142904405282083, max_delta_step=4, max_depth=4, min_child_weight=15, n_estimators=2373, reg_alpha=2.869584805083433, reg_lambda=1.613901303618288, scale_pos_weight=0.9847934487675435, subsample=0.7188325076490992; total time=   5.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=0.7214430854736362, colsample_bytree=0.9854627100473761, gamma=1.7541256265830654, learning_rate=0.031702865109362516, max_delta_step=0, max_depth=4, min_child_weight=8, n_estimators=500, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bylevel=0.8630729744826783, colsample_bynode=0.9935101903682826, colsample_bytree=0.7203975392263717, gamma=1.8837692803378632, learning_rate=0.07948851651358695, max_delta_step=7, max_depth=15, min_child_weight=2, n_estimators=2298, reg_alpha=2.9932596070657604, reg_lambda=2.6730734698731853, scale_pos_weight=1.092633397136379, subsample=0.9431362450708927; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.8595290977953045, colsample_bynode=0.8372912774326707, colsample_bytree=1.0, gamma=0.0, learning_rate=0.015003275330162335, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=1.0925275286236853, scale_pos_weight=0.9532633020219079, subsample=0.9613565213259727; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.8595290977953045, colsample_bynode=0.8372912774326707, colsample_bytree=1.0, gamma=0.0, learning_rate=0.015003275330162335, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=1.0925275286236853, scale_pos_weight=0.9532633020219079, subsample=0.9613565213259727; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.8260935202425312, colsample_bynode=0.6780865147438422, colsample_bytree=0.6, gamma=2.0, learning_rate=0.001, max_delta_step=10, max_depth=7, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1789373395850282, subsample=1.0; total time=  17.0s\n",
      "[CV] END colsample_bylevel=0.8260935202425312, colsample_bynode=0.6780865147438422, colsample_bytree=0.6, gamma=2.0, learning_rate=0.001, max_delta_step=10, max_depth=7, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=0.0, scale_pos_weight=1.1789373395850282, subsample=1.0; total time=  13.9s\n",
      "[CV] END colsample_bylevel=0.6323551844580703, colsample_bynode=0.6576387621119553, colsample_bytree=0.7696930725879388, gamma=1.8149348328567636, learning_rate=0.0029900207975659876, max_delta_step=2, max_depth=11, min_child_weight=14, n_estimators=633, reg_alpha=0.23627623487799537, reg_lambda=0.2662635764642302, scale_pos_weight=1.0909985768619666, subsample=0.7034909127232992; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.9601411196443507, colsample_bynode=0.7966212444192398, colsample_bytree=0.6930998860139954, gamma=1.6879589433889206, learning_rate=0.0010124414373235994, max_delta_step=4, max_depth=15, min_child_weight=9, n_estimators=2887, reg_alpha=0.8821168244039665, reg_lambda=1.2448000608298926, scale_pos_weight=0.8455428982527128, subsample=0.7239246089840329; total time=  16.3s\n",
      "[CV] END colsample_bylevel=0.803809687296255, colsample_bynode=0.6034225470031548, colsample_bytree=0.6317081700832806, gamma=1.98675328035122, learning_rate=0.07729121166073208, max_delta_step=9, max_depth=8, min_child_weight=8, n_estimators=2885, reg_alpha=1.2773213476401888, reg_lambda=2.4550946227862767, scale_pos_weight=1.070082578732788, subsample=0.9973180774279604; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.803809687296255, colsample_bynode=0.6034225470031548, colsample_bytree=0.6317081700832806, gamma=1.98675328035122, learning_rate=0.07729121166073208, max_delta_step=9, max_depth=8, min_child_weight=8, n_estimators=2885, reg_alpha=1.2773213476401888, reg_lambda=2.4550946227862767, scale_pos_weight=1.070082578732788, subsample=0.9973180774279604; total time=   3.6s\n",
      "[CV] END colsample_bylevel=0.9975100458948011, colsample_bynode=0.6297336126549192, colsample_bytree=0.6002404174267807, gamma=1.9597971313266744, learning_rate=0.0012872094197615008, max_delta_step=8, max_depth=14, min_child_weight=14, n_estimators=1624, reg_alpha=2.8023628052524434, reg_lambda=0.45843710726537534, scale_pos_weight=0.8088497589455969, subsample=0.7034967719641311; total time=   7.7s\n",
      "[CV] END colsample_bylevel=0.9140441275632102, colsample_bynode=0.7792800689115179, colsample_bytree=0.6, gamma=2.0, learning_rate=0.1, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.9140441275632102, colsample_bynode=0.7792800689115179, colsample_bytree=0.6, gamma=2.0, learning_rate=0.1, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=0.8, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bylevel=0.6744062240881087, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.0, learning_rate=0.019890225694014878, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.002570548172429792, scale_pos_weight=1.2, subsample=0.9511129209230911; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.6744062240881087, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.0, learning_rate=0.019890225694014878, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.002570548172429792, scale_pos_weight=1.2, subsample=0.9511129209230911; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.9234712046133574, colsample_bynode=0.9018987298009663, colsample_bytree=0.8125607387764793, gamma=0.1147992410458816, learning_rate=0.024373689671177427, max_delta_step=10, max_depth=15, min_child_weight=9, n_estimators=2947, reg_alpha=0.03037924928893921, reg_lambda=2.536307578124162, scale_pos_weight=1.0873206530460928, subsample=0.9982555882054965; total time=  17.6s\n",
      "[CV] END colsample_bylevel=0.9234712046133574, colsample_bynode=0.9018987298009663, colsample_bytree=0.8125607387764793, gamma=0.1147992410458816, learning_rate=0.024373689671177427, max_delta_step=10, max_depth=15, min_child_weight=9, n_estimators=2947, reg_alpha=0.03037924928893921, reg_lambda=2.536307578124162, scale_pos_weight=1.0873206530460928, subsample=0.9982555882054965; total time=  15.7s\n",
      "[CV] END colsample_bylevel=0.7867581948991739, colsample_bynode=0.9303869073943833, colsample_bytree=0.7963902646747765, gamma=0.0317084602734703, learning_rate=0.020096856092047324, max_delta_step=9, max_depth=15, min_child_weight=11, n_estimators=2127, reg_alpha=2.8699654377992703, reg_lambda=0.23154048462970217, scale_pos_weight=0.9139109911644648, subsample=0.960118245497821; total time=  16.0s\n",
      "[CV] END colsample_bylevel=0.7745272342149911, colsample_bynode=0.8672356627721698, colsample_bytree=0.7881330533719713, gamma=1.0375505262740985, learning_rate=0.014272716330904232, max_delta_step=8, max_depth=4, min_child_weight=3, n_estimators=809, reg_alpha=0.10673541775704112, reg_lambda=0.3919322779266198, scale_pos_weight=1.0491838911999625, subsample=0.7266366377985876; total time=   2.5s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.7658651292754646, colsample_bytree=1.0, gamma=2.0, learning_rate=0.01345117921380264, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=1146, reg_alpha=0.0, reg_lambda=0.5872528988341121, scale_pos_weight=0.8615059429830153, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.6597322567913767, colsample_bynode=0.954146867216343, colsample_bytree=0.6424175497237475, gamma=0.047553879161059256, learning_rate=0.007440685591392875, max_delta_step=1, max_depth=4, min_child_weight=2, n_estimators=2989, reg_alpha=2.2851921100158643, reg_lambda=0.3485605035974515, scale_pos_weight=0.802746849920165, subsample=0.9790214738952016; total time=   8.5s\n",
      "[CV] END colsample_bylevel=0.9653116876268035, colsample_bynode=0.7624196130273131, colsample_bytree=0.6063157550834486, gamma=1.197442825229783, learning_rate=0.003184019752064612, max_delta_step=0, max_depth=15, min_child_weight=3, n_estimators=2938, reg_alpha=2.520382695710136, reg_lambda=0.3113786361921287, scale_pos_weight=1.1690756364866899, subsample=0.7334315239237805; total time=  18.3s\n",
      "[CV] END colsample_bylevel=0.9007555565273145, colsample_bynode=0.7836190736171249, colsample_bytree=0.7006284799308222, gamma=1.9982460298595777, learning_rate=0.010428453093846449, max_delta_step=10, max_depth=15, min_child_weight=6, n_estimators=2992, reg_alpha=1.9291537997853434, reg_lambda=2.7330981930370646, scale_pos_weight=0.9291253397346689, subsample=0.7309685935907756; total time=   9.3s\n",
      "[CV] END colsample_bylevel=0.8546625088429568, colsample_bynode=0.8249770025662069, colsample_bytree=0.9796944581148662, gamma=0.03852449315728613, learning_rate=0.0030284080004574724, max_delta_step=1, max_depth=15, min_child_weight=3, n_estimators=1455, reg_alpha=1.624639669766568, reg_lambda=0.16118396335612845, scale_pos_weight=1.1767119623134499, subsample=0.7069714046418374; total time=  21.0s\n",
      "[CV] END colsample_bylevel=0.8546625088429568, colsample_bynode=0.8249770025662069, colsample_bytree=0.9796944581148662, gamma=0.03852449315728613, learning_rate=0.0030284080004574724, max_delta_step=1, max_depth=15, min_child_weight=3, n_estimators=1455, reg_alpha=1.624639669766568, reg_lambda=0.16118396335612845, scale_pos_weight=1.1767119623134499, subsample=0.7069714046418374; total time=16.4min\n",
      "[CV] END colsample_bylevel=0.7205924091292311, colsample_bynode=0.7538825598628269, colsample_bytree=0.6256527488612251, gamma=0.058445520437185886, learning_rate=0.0010230160650187292, max_delta_step=4, max_depth=12, min_child_weight=3, n_estimators=2854, reg_alpha=0.6816657648500135, reg_lambda=2.8777976082912597, scale_pos_weight=1.1580817065698183, subsample=0.7061622549984752; total time=  25.9s\n",
      "[CV] END colsample_bylevel=0.7205924091292311, colsample_bynode=0.7538825598628269, colsample_bytree=0.6256527488612251, gamma=0.058445520437185886, learning_rate=0.0010230160650187292, max_delta_step=4, max_depth=12, min_child_weight=3, n_estimators=2854, reg_alpha=0.6816657648500135, reg_lambda=2.8777976082912597, scale_pos_weight=1.1580817065698183, subsample=0.7061622549984752; total time=  26.0s\n",
      "[CV] END colsample_bylevel=0.9679101553147511, colsample_bynode=0.7535071394925625, colsample_bytree=0.99638272105358, gamma=1.681979709004854, learning_rate=0.0010176958502207448, max_delta_step=10, max_depth=8, min_child_weight=7, n_estimators=508, reg_alpha=2.8693004904206676, reg_lambda=1.588107350864381, scale_pos_weight=1.106616075664961, subsample=0.7101869645854496; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.8569962307940416, colsample_bynode=0.9862199517927497, colsample_bytree=0.923006263140393, gamma=0.1005751074993129, learning_rate=0.00392410799950455, max_delta_step=9, max_depth=4, min_child_weight=5, n_estimators=2916, reg_alpha=0.07713944520334617, reg_lambda=2.7718694964431596, scale_pos_weight=0.9886267032691654, subsample=0.9769145941982649; total time=   6.9s\n",
      "[CV] END colsample_bylevel=0.8569962307940416, colsample_bynode=0.9862199517927497, colsample_bytree=0.923006263140393, gamma=0.1005751074993129, learning_rate=0.00392410799950455, max_delta_step=9, max_depth=4, min_child_weight=5, n_estimators=2916, reg_alpha=0.07713944520334617, reg_lambda=2.7718694964431596, scale_pos_weight=0.9886267032691654, subsample=0.9769145941982649; total time=   7.0s\n",
      "[CV] END colsample_bylevel=0.8301313283219944, colsample_bynode=0.680160222105382, colsample_bytree=0.7882403662787804, gamma=0.5869767833282243, learning_rate=0.0010456444067817427, max_delta_step=10, max_depth=15, min_child_weight=7, n_estimators=518, reg_alpha=1.0814095343565013, reg_lambda=1.0430250769227085, scale_pos_weight=1.1445212326010408, subsample=0.7644498891871443; total time=   3.9s\n",
      "[CV] END colsample_bylevel=0.6770229510061877, colsample_bynode=0.7286682999943922, colsample_bytree=0.6274346266519762, gamma=1.9453460560848872, learning_rate=0.0011739381069326327, max_delta_step=0, max_depth=5, min_child_weight=12, n_estimators=2855, reg_alpha=2.161909828353458, reg_lambda=0.35317818386819744, scale_pos_weight=0.9066121961527045, subsample=0.9935421822173636; total time=   8.0s\n",
      "[CV] END colsample_bylevel=0.6770229510061877, colsample_bynode=0.7286682999943922, colsample_bytree=0.6274346266519762, gamma=1.9453460560848872, learning_rate=0.0011739381069326327, max_delta_step=0, max_depth=5, min_child_weight=12, n_estimators=2855, reg_alpha=2.161909828353458, reg_lambda=0.35317818386819744, scale_pos_weight=0.9066121961527045, subsample=0.9935421822173636; total time=   6.0s\n",
      "[CV] END colsample_bylevel=0.8343769227678106, colsample_bynode=0.9336809203107367, colsample_bytree=0.6208823029790741, gamma=1.1680246349978256, learning_rate=0.03701912540916061, max_delta_step=10, max_depth=14, min_child_weight=13, n_estimators=504, reg_alpha=0.46671049498692085, reg_lambda=2.791335439864069, scale_pos_weight=1.1587280854407362, subsample=0.9809711325681316; total time=   1.7s\n",
      "[CV] END colsample_bylevel=0.7809462954223588, colsample_bynode=0.6309085186749382, colsample_bytree=0.6, gamma=1.4613468265875142, learning_rate=0.05012224930540062, max_delta_step=10, max_depth=9, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=0.8, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.6440280332895054, colsample_bynode=0.7910605592178892, colsample_bytree=0.6557345613086555, gamma=0.9367916630594701, learning_rate=0.02431792943797359, max_delta_step=1, max_depth=4, min_child_weight=7, n_estimators=2452, reg_alpha=1.2647041706170272, reg_lambda=0.42033828809105744, scale_pos_weight=0.8563723648647037, subsample=0.9928340657181653; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.6440280332895054, colsample_bynode=0.7910605592178892, colsample_bytree=0.6557345613086555, gamma=0.9367916630594701, learning_rate=0.02431792943797359, max_delta_step=1, max_depth=4, min_child_weight=7, n_estimators=2452, reg_alpha=1.2647041706170272, reg_lambda=0.42033828809105744, scale_pos_weight=0.8563723648647037, subsample=0.9928340657181653; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.713647445242851, colsample_bynode=0.9233622952313745, colsample_bytree=0.7019239328950171, gamma=0.6849967422481907, learning_rate=0.007762522556681685, max_delta_step=9, max_depth=5, min_child_weight=6, n_estimators=2901, reg_alpha=2.492030588019343, reg_lambda=2.2047614829712723, scale_pos_weight=1.0059635874476003, subsample=0.7038933936922651; total time=   7.4s\n",
      "[CV] END colsample_bylevel=0.713647445242851, colsample_bynode=0.9233622952313745, colsample_bytree=0.7019239328950171, gamma=0.6849967422481907, learning_rate=0.007762522556681685, max_delta_step=9, max_depth=5, min_child_weight=6, n_estimators=2901, reg_alpha=2.492030588019343, reg_lambda=2.2047614829712723, scale_pos_weight=1.0059635874476003, subsample=0.7038933936922651; total time=   7.6s\n",
      "[CV] END colsample_bylevel=0.8858114288816348, colsample_bynode=0.7357605197816451, colsample_bytree=0.6776097798659215, gamma=1.9004423520625127, learning_rate=0.08514911120439839, max_delta_step=0, max_depth=4, min_child_weight=2, n_estimators=2654, reg_alpha=2.354117758124679, reg_lambda=2.6323166290111413, scale_pos_weight=0.8100871732231256, subsample=0.9903560584075802; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.8858114288816348, colsample_bynode=0.7357605197816451, colsample_bytree=0.6776097798659215, gamma=1.9004423520625127, learning_rate=0.08514911120439839, max_delta_step=0, max_depth=4, min_child_weight=2, n_estimators=2654, reg_alpha=2.354117758124679, reg_lambda=2.6323166290111413, scale_pos_weight=0.8100871732231256, subsample=0.9903560584075802; total time=   3.0s\n",
      "\n",
      "–ê–Ω—Å–∞–º–±–ª—å –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:\n",
      "ROC-AUC: 0.9020\n",
      "Accuracy: 0.8702\n",
      "\n",
      "–°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô:\n",
      "Bayesian XGBoost ROC-AUC: 0.9254\n",
      "–ê–Ω—Å–∞–º–±–ª—å ROC-AUC: 0.9020\n",
      "\n",
      "–õ–£–ß–®–ê–Ø –ú–û–î–ï–õ–¨:\n",
      "ROC-AUC: 0.9254\n",
      "\n",
      "–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –î–ê–õ–¨–ù–ï–ô–®–ï–ì–û –£–õ–£–ß–®–ï–ù–ò–Ø:\n",
      "1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤\n",
      "2. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—ã–±—Ä–æ—Å—ã –≤ –¥–∞–Ω–Ω—ã—Ö\n",
      "3. –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã feature engineering\n",
      "4. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –∏–ª–∏ –¥—Ä—É–≥–∏–µ —Å–ª–æ–∂–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã\n",
      "5. –£–≤–µ–ª–∏—á–∏—Ç—å –æ–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –ø—Ä–∏–º–µ–Ω–∏—Ç—å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ X_advanced_clean –∏ y —É–∂–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã\n",
    "X_final = X_advanced_clean\n",
    "y_final = y\n",
    "\n",
    "print(f\"X_final shape: {X_final.shape}\")\n",
    "print(f\"y_final length: {len(y_final)}\")\n",
    "\n",
    "# –†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏\n",
    "param_space = {\n",
    "    'n_estimators': Integer(500, 3000),\n",
    "    'max_depth': Integer(4, 15),\n",
    "    'learning_rate': Real(0.001, 0.1, prior='log-uniform'),\n",
    "    'subsample': Real(0.7, 1.0),\n",
    "    'colsample_bytree': Real(0.6, 1.0),\n",
    "    'colsample_bylevel': Real(0.6, 1.0),\n",
    "    'colsample_bynode': Real(0.6, 1.0),\n",
    "    'reg_alpha': Real(0, 3),\n",
    "    'reg_lambda': Real(0, 3),\n",
    "    'gamma': Real(0, 2),\n",
    "    'min_child_weight': Integer(1, 15),\n",
    "    'max_delta_step': Integer(0, 10),\n",
    "    'scale_pos_weight': Real(0.8, 1.2)  # –î–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –∫–ª–∞—Å—Å–æ–≤\n",
    "}\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å XGBoost —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏\n",
    "xgb = XGBClassifier(\n",
    "    random_state=42, \n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    "    tree_method='hist',  # –ë–æ–ª–µ–µ –±—ã—Å—Ç—Ä—ã–π –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥\n",
    "    predictor='auto'\n",
    ")\n",
    "\n",
    "# –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π –∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª—å—à–µ —Ñ–æ–ª–¥–æ–≤\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=xgb,\n",
    "    search_spaces=param_space,\n",
    "    n_iter=165,  # –£–≤–µ–ª–∏—á–∏–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π\n",
    "    cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42),  # –ë–æ–ª—å—à–µ —Ñ–æ–ª–¥–æ–≤\n",
    "    scoring='roc_auc',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,  # –ë–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥\n",
    "    n_points=3  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏\n",
    ")\n",
    "\n",
    "print(f\"–ë—É–¥–µ—Ç –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ {bayes_search.n_iter} –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\")\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–æ –æ–±—É—á–µ–Ω–∏—è, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å data leakage\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_final, y_final, \n",
    "    test_size=0.15, \n",
    "    random_state=42,\n",
    "    stratify=y_final\n",
    ")\n",
    "\n",
    "# –û–±—É—á–∞–µ–º –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "bayes_search.fit(X_train, y_train)\n",
    "\n",
    "# –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "print(f\"–õ—É—á—à–∏–π ROC-AUC –Ω–∞ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏: {bayes_search.best_score_:.4f}\")\n",
    "print(f\"–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\")\n",
    "for param, value in bayes_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "best_bayes_model = bayes_search.best_estimator_\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "y_pred_bayes = best_bayes_model.predict(X_test)\n",
    "y_pred_proba_bayes = best_bayes_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "roc_auc_bayes = roc_auc_score(y_test, y_pred_proba_bayes)\n",
    "accuracy_bayes = accuracy_score(y_test, y_pred_bayes)\n",
    "\n",
    "print(f\"\\n–£–ª—É—á—à–µ–Ω–Ω—ã–π Bayesian XGBoost –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "print(f\"ROC-AUC: {roc_auc_bayes:.4f}\")\n",
    "print(f\"Accuracy: {accuracy_bayes:.4f}\")\n",
    "\n",
    "# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"\\n–î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏:\")\n",
    "print(classification_report(y_test, y_pred_bayes))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_bayes))\n",
    "\n",
    "# –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "feature_importance = best_bayes_model.feature_importances_\n",
    "features = pd.DataFrame({\n",
    "    'feature': X_final.columns if hasattr(X_final, 'columns') else [f'feature_{i}' for i in range(X_final.shape[1])],\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n–¢–æ–ø-10 —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\")\n",
    "print(features.head(10))\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(features['feature'].head(15)[::-1], features['importance'].head(15)[::-1])\n",
    "plt.xlabel('–í–∞–∂–Ω–æ—Å—Ç—å')\n",
    "plt.title('–¢–æ–ø-15 —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤—Å–µ –µ—â–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ö–æ—Ä–æ—à, –ø–æ–ø—Ä–æ–±—É–µ–º –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –∞–Ω—Å–∞–º–±–ª—å –º–æ–¥–µ–ª–µ–π\n",
    "estimators = [\n",
    "    ('xgb', best_bayes_model),\n",
    "    ('logreg', LogisticRegression(C=0.1, random_state=42, max_iter=1000)),\n",
    "    ('svc', SVC(probability=True, random_state=42, kernel='rbf', C=1.0))\n",
    "]\n",
    "\n",
    "ensemble = VotingClassifier(estimators=estimators, voting='soft', n_jobs=-1)\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "y_pred_ensemble = ensemble.predict(X_test)\n",
    "y_pred_proba_ensemble = ensemble.predict_proba(X_test)[:, 1]\n",
    "\n",
    "roc_auc_ensemble = roc_auc_score(y_test, y_pred_proba_ensemble)\n",
    "accuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
    "\n",
    "print(f\"\\n–ê–Ω—Å–∞–º–±–ª—å –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "print(f\"ROC-AUC: {roc_auc_ensemble:.4f}\")\n",
    "print(f\"Accuracy: {accuracy_ensemble:.4f}\")\n",
    "\n",
    "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π\n",
    "print(f\"\\n–°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô:\")\n",
    "print(f\"Bayesian XGBoost ROC-AUC: {roc_auc_bayes:.4f}\")\n",
    "print(f\"–ê–Ω—Å–∞–º–±–ª—å ROC-AUC: {roc_auc_ensemble:.4f}\")\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å\n",
    "if roc_auc_ensemble > roc_auc_bayes:\n",
    "    best_model = ensemble\n",
    "    best_roc_auc = roc_auc_ensemble\n",
    "else:\n",
    "    best_model = best_bayes_model\n",
    "    best_roc_auc = roc_auc_bayes\n",
    "\n",
    "print(f\"\\n–õ–£–ß–®–ê–Ø –ú–û–î–ï–õ–¨:\")\n",
    "print(f\"ROC-AUC: {best_roc_auc:.4f}\")\n",
    "\n",
    "# –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ –¥–æ—Å—Ç–∏–≥–ª–∏ 0.97, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "if best_roc_auc < 0.97:\n",
    "    print(\"\\n–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –î–ê–õ–¨–ù–ï–ô–®–ï–ì–û –£–õ–£–ß–®–ï–ù–ò–Ø:\")\n",
    "    print(\"1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤\")\n",
    "    print(\"2. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—ã–±—Ä–æ—Å—ã –≤ –¥–∞–Ω–Ω—ã—Ö\")\n",
    "    print(\"3. –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã feature engineering\")\n",
    "    print(\"4. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –∏–ª–∏ –¥—Ä—É–≥–∏–µ —Å–ª–æ–∂–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã\")\n",
    "    print(\"5. –£–≤–µ–ª–∏—á–∏—Ç—å –æ–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –ø—Ä–∏–º–µ–Ω–∏—Ç—å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d88e13ab-793a-473a-a236-1e3b668e9c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.7205924091292311, colsample_bynode=0.7538825598628269, colsample_bytree=0.6256527488612251, gamma=0.058445520437185886, learning_rate=0.0010230160650187292, max_delta_step=4, max_depth=12, min_child_weight=3, n_estimators=2854, reg_alpha=0.6816657648500135, reg_lambda=2.8777976082912597, scale_pos_weight=1.1580817065698183, subsample=0.7061622549984752; total time=  26.5s\n",
      "[CV] END colsample_bylevel=0.6984601194313953, colsample_bynode=0.8944850111984711, colsample_bytree=1.0, gamma=0.6757498341962027, learning_rate=0.00473222978018942, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.2, subsample=1.0; total time=   9.2s\n",
      "[CV] END colsample_bylevel=0.6912564180595353, colsample_bynode=0.9801589742001154, colsample_bytree=0.6408245829556941, gamma=1.8743026566860703, learning_rate=0.006776236493718202, max_delta_step=9, max_depth=10, min_child_weight=4, n_estimators=1567, reg_alpha=0.12382233138019408, reg_lambda=1.3002371771559078, scale_pos_weight=0.8344337316271376, subsample=0.951719490368345; total time=   6.0s\n",
      "[CV] END colsample_bylevel=0.6912564180595353, colsample_bynode=0.9801589742001154, colsample_bytree=0.6408245829556941, gamma=1.8743026566860703, learning_rate=0.006776236493718202, max_delta_step=9, max_depth=10, min_child_weight=4, n_estimators=1567, reg_alpha=0.12382233138019408, reg_lambda=1.3002371771559078, scale_pos_weight=0.8344337316271376, subsample=0.951719490368345; total time=   5.9s\n",
      "[CV] END colsample_bylevel=0.9679101553147511, colsample_bynode=0.7535071394925625, colsample_bytree=0.99638272105358, gamma=1.681979709004854, learning_rate=0.0010176958502207448, max_delta_step=10, max_depth=8, min_child_weight=7, n_estimators=508, reg_alpha=2.8693004904206676, reg_lambda=1.588107350864381, scale_pos_weight=1.106616075664961, subsample=0.7101869645854496; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.9679101553147511, colsample_bynode=0.7535071394925625, colsample_bytree=0.99638272105358, gamma=1.681979709004854, learning_rate=0.0010176958502207448, max_delta_step=10, max_depth=8, min_child_weight=7, n_estimators=508, reg_alpha=2.8693004904206676, reg_lambda=1.588107350864381, scale_pos_weight=1.106616075664961, subsample=0.7101869645854496; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.8569962307940416, colsample_bynode=0.9862199517927497, colsample_bytree=0.923006263140393, gamma=0.1005751074993129, learning_rate=0.00392410799950455, max_delta_step=9, max_depth=4, min_child_weight=5, n_estimators=2916, reg_alpha=0.07713944520334617, reg_lambda=2.7718694964431596, scale_pos_weight=0.9886267032691654, subsample=0.9769145941982649; total time=   7.0s\n",
      "[CV] END colsample_bylevel=0.855727669436894, colsample_bynode=0.8893722348022144, colsample_bytree=0.6469317674481467, gamma=1.7966034612386077, learning_rate=0.04448267762598664, max_delta_step=10, max_depth=15, min_child_weight=1, n_estimators=2910, reg_alpha=0.6813653536040802, reg_lambda=2.873856441379481, scale_pos_weight=0.8406197620531091, subsample=0.9909911302206835; total time=   3.8s\n",
      "[CV] END colsample_bylevel=0.8301313283219944, colsample_bynode=0.680160222105382, colsample_bytree=0.7882403662787804, gamma=0.5869767833282243, learning_rate=0.0010456444067817427, max_delta_step=10, max_depth=15, min_child_weight=7, n_estimators=518, reg_alpha=1.0814095343565013, reg_lambda=1.0430250769227085, scale_pos_weight=1.1445212326010408, subsample=0.7644498891871443; total time=   3.8s\n",
      "[CV] END colsample_bylevel=0.6770229510061877, colsample_bynode=0.7286682999943922, colsample_bytree=0.6274346266519762, gamma=1.9453460560848872, learning_rate=0.0011739381069326327, max_delta_step=0, max_depth=5, min_child_weight=12, n_estimators=2855, reg_alpha=2.161909828353458, reg_lambda=0.35317818386819744, scale_pos_weight=0.9066121961527045, subsample=0.9935421822173636; total time=   8.3s\n",
      "[CV] END colsample_bylevel=0.7507044205387277, colsample_bynode=0.7049424715681426, colsample_bytree=0.6479129327126751, gamma=1.860066167554181, learning_rate=0.04792656203245692, max_delta_step=0, max_depth=12, min_child_weight=7, n_estimators=584, reg_alpha=2.9217822405302307, reg_lambda=0.8423298528076069, scale_pos_weight=0.9452430152931751, subsample=0.9916724464551119; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.7507044205387277, colsample_bynode=0.7049424715681426, colsample_bytree=0.6479129327126751, gamma=1.860066167554181, learning_rate=0.04792656203245692, max_delta_step=0, max_depth=12, min_child_weight=7, n_estimators=584, reg_alpha=2.9217822405302307, reg_lambda=0.8423298528076069, scale_pos_weight=0.9452430152931751, subsample=0.9916724464551119; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.8343769227678106, colsample_bynode=0.9336809203107367, colsample_bytree=0.6208823029790741, gamma=1.1680246349978256, learning_rate=0.03701912540916061, max_delta_step=10, max_depth=14, min_child_weight=13, n_estimators=504, reg_alpha=0.46671049498692085, reg_lambda=2.791335439864069, scale_pos_weight=1.1587280854407362, subsample=0.9809711325681316; total time=   1.6s\n",
      "[CV] END colsample_bylevel=0.7809462954223588, colsample_bynode=0.6309085186749382, colsample_bytree=0.6, gamma=1.4613468265875142, learning_rate=0.05012224930540062, max_delta_step=10, max_depth=9, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=0.8, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.6440280332895054, colsample_bynode=0.7910605592178892, colsample_bytree=0.6557345613086555, gamma=0.9367916630594701, learning_rate=0.02431792943797359, max_delta_step=1, max_depth=4, min_child_weight=7, n_estimators=2452, reg_alpha=1.2647041706170272, reg_lambda=0.42033828809105744, scale_pos_weight=0.8563723648647037, subsample=0.9928340657181653; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.6440280332895054, colsample_bynode=0.7910605592178892, colsample_bytree=0.6557345613086555, gamma=0.9367916630594701, learning_rate=0.02431792943797359, max_delta_step=1, max_depth=4, min_child_weight=7, n_estimators=2452, reg_alpha=1.2647041706170272, reg_lambda=0.42033828809105744, scale_pos_weight=0.8563723648647037, subsample=0.9928340657181653; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.713647445242851, colsample_bynode=0.9233622952313745, colsample_bytree=0.7019239328950171, gamma=0.6849967422481907, learning_rate=0.007762522556681685, max_delta_step=9, max_depth=5, min_child_weight=6, n_estimators=2901, reg_alpha=2.492030588019343, reg_lambda=2.2047614829712723, scale_pos_weight=1.0059635874476003, subsample=0.7038933936922651; total time=   7.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=0.7135702127651323, learning_rate=0.0038527355554399483, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=1.589238012344313, scale_pos_weight=0.8, subsample=0.7; total time=   6.7s\n",
      "[CV] END colsample_bylevel=0.8858114288816348, colsample_bynode=0.7357605197816451, colsample_bytree=0.6776097798659215, gamma=1.9004423520625127, learning_rate=0.08514911120439839, max_delta_step=0, max_depth=4, min_child_weight=2, n_estimators=2654, reg_alpha=2.354117758124679, reg_lambda=2.6323166290111413, scale_pos_weight=0.8100871732231256, subsample=0.9903560584075802; total time=   3.1s\n",
      "[CV] END colsample_bylevel=0.8858114288816348, colsample_bynode=0.7357605197816451, colsample_bytree=0.6776097798659215, gamma=1.9004423520625127, learning_rate=0.08514911120439839, max_delta_step=0, max_depth=4, min_child_weight=2, n_estimators=2654, reg_alpha=2.354117758124679, reg_lambda=2.6323166290111413, scale_pos_weight=0.8100871732231256, subsample=0.9903560584075802; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.8858114288816348, colsample_bynode=0.7357605197816451, colsample_bytree=0.6776097798659215, gamma=1.9004423520625127, learning_rate=0.08514911120439839, max_delta_step=0, max_depth=4, min_child_weight=2, n_estimators=2654, reg_alpha=2.354117758124679, reg_lambda=2.6323166290111413, scale_pos_weight=0.8100871732231256, subsample=0.9903560584075802; total time=   1.7s\n",
      "[CV] END colsample_bylevel=0.7205924091292311, colsample_bynode=0.7538825598628269, colsample_bytree=0.6256527488612251, gamma=0.058445520437185886, learning_rate=0.0010230160650187292, max_delta_step=4, max_depth=12, min_child_weight=3, n_estimators=2854, reg_alpha=0.6816657648500135, reg_lambda=2.8777976082912597, scale_pos_weight=1.1580817065698183, subsample=0.7061622549984752; total time=  26.3s\n",
      "[CV] END colsample_bylevel=0.6984601194313953, colsample_bynode=0.8944850111984711, colsample_bytree=1.0, gamma=0.6757498341962027, learning_rate=0.00473222978018942, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.2, subsample=1.0; total time=   8.5s\n",
      "[CV] END colsample_bylevel=0.6984601194313953, colsample_bynode=0.8944850111984711, colsample_bytree=1.0, gamma=0.6757498341962027, learning_rate=0.00473222978018942, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.2, subsample=1.0; total time=   8.5s\n",
      "[CV] END colsample_bylevel=0.6912564180595353, colsample_bynode=0.9801589742001154, colsample_bytree=0.6408245829556941, gamma=1.8743026566860703, learning_rate=0.006776236493718202, max_delta_step=9, max_depth=10, min_child_weight=4, n_estimators=1567, reg_alpha=0.12382233138019408, reg_lambda=1.3002371771559078, scale_pos_weight=0.8344337316271376, subsample=0.951719490368345; total time=   5.8s\n",
      "[CV] END colsample_bylevel=0.9679101553147511, colsample_bynode=0.7535071394925625, colsample_bytree=0.99638272105358, gamma=1.681979709004854, learning_rate=0.0010176958502207448, max_delta_step=10, max_depth=8, min_child_weight=7, n_estimators=508, reg_alpha=2.8693004904206676, reg_lambda=1.588107350864381, scale_pos_weight=1.106616075664961, subsample=0.7101869645854496; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.8569962307940416, colsample_bynode=0.9862199517927497, colsample_bytree=0.923006263140393, gamma=0.1005751074993129, learning_rate=0.00392410799950455, max_delta_step=9, max_depth=4, min_child_weight=5, n_estimators=2916, reg_alpha=0.07713944520334617, reg_lambda=2.7718694964431596, scale_pos_weight=0.9886267032691654, subsample=0.9769145941982649; total time=   7.0s\n",
      "[CV] END colsample_bylevel=0.8569962307940416, colsample_bynode=0.9862199517927497, colsample_bytree=0.923006263140393, gamma=0.1005751074993129, learning_rate=0.00392410799950455, max_delta_step=9, max_depth=4, min_child_weight=5, n_estimators=2916, reg_alpha=0.07713944520334617, reg_lambda=2.7718694964431596, scale_pos_weight=0.9886267032691654, subsample=0.9769145941982649; total time=   7.0s\n",
      "[CV] END colsample_bylevel=0.8301313283219944, colsample_bynode=0.680160222105382, colsample_bytree=0.7882403662787804, gamma=0.5869767833282243, learning_rate=0.0010456444067817427, max_delta_step=10, max_depth=15, min_child_weight=7, n_estimators=518, reg_alpha=1.0814095343565013, reg_lambda=1.0430250769227085, scale_pos_weight=1.1445212326010408, subsample=0.7644498891871443; total time=   3.8s\n",
      "[CV] END colsample_bylevel=0.6770229510061877, colsample_bynode=0.7286682999943922, colsample_bytree=0.6274346266519762, gamma=1.9453460560848872, learning_rate=0.0011739381069326327, max_delta_step=0, max_depth=5, min_child_weight=12, n_estimators=2855, reg_alpha=2.161909828353458, reg_lambda=0.35317818386819744, scale_pos_weight=0.9066121961527045, subsample=0.9935421822173636; total time=   8.1s\n",
      "[CV] END colsample_bylevel=0.7507044205387277, colsample_bynode=0.7049424715681426, colsample_bytree=0.6479129327126751, gamma=1.860066167554181, learning_rate=0.04792656203245692, max_delta_step=0, max_depth=12, min_child_weight=7, n_estimators=584, reg_alpha=2.9217822405302307, reg_lambda=0.8423298528076069, scale_pos_weight=0.9452430152931751, subsample=0.9916724464551119; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.7507044205387277, colsample_bynode=0.7049424715681426, colsample_bytree=0.6479129327126751, gamma=1.860066167554181, learning_rate=0.04792656203245692, max_delta_step=0, max_depth=12, min_child_weight=7, n_estimators=584, reg_alpha=2.9217822405302307, reg_lambda=0.8423298528076069, scale_pos_weight=0.9452430152931751, subsample=0.9916724464551119; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.8343769227678106, colsample_bynode=0.9336809203107367, colsample_bytree=0.6208823029790741, gamma=1.1680246349978256, learning_rate=0.03701912540916061, max_delta_step=10, max_depth=14, min_child_weight=13, n_estimators=504, reg_alpha=0.46671049498692085, reg_lambda=2.791335439864069, scale_pos_weight=1.1587280854407362, subsample=0.9809711325681316; total time=   1.6s\n",
      "[CV] END colsample_bylevel=0.8343769227678106, colsample_bynode=0.9336809203107367, colsample_bytree=0.6208823029790741, gamma=1.1680246349978256, learning_rate=0.03701912540916061, max_delta_step=10, max_depth=14, min_child_weight=13, n_estimators=504, reg_alpha=0.46671049498692085, reg_lambda=2.791335439864069, scale_pos_weight=1.1587280854407362, subsample=0.9809711325681316; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.6440280332895054, colsample_bynode=0.7910605592178892, colsample_bytree=0.6557345613086555, gamma=0.9367916630594701, learning_rate=0.02431792943797359, max_delta_step=1, max_depth=4, min_child_weight=7, n_estimators=2452, reg_alpha=1.2647041706170272, reg_lambda=0.42033828809105744, scale_pos_weight=0.8563723648647037, subsample=0.9928340657181653; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.713647445242851, colsample_bynode=0.9233622952313745, colsample_bytree=0.7019239328950171, gamma=0.6849967422481907, learning_rate=0.007762522556681685, max_delta_step=9, max_depth=5, min_child_weight=6, n_estimators=2901, reg_alpha=2.492030588019343, reg_lambda=2.2047614829712723, scale_pos_weight=1.0059635874476003, subsample=0.7038933936922651; total time=   7.4s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=0.7135702127651323, learning_rate=0.0038527355554399483, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=1.589238012344313, scale_pos_weight=0.8, subsample=0.7; total time=   6.6s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=0.7135702127651323, learning_rate=0.0038527355554399483, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=1.589238012344313, scale_pos_weight=0.8, subsample=0.7; total time=   6.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "–õ—É—á—à–∏–π ROC-AUC: 0.9306\n",
      "–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
      "  bagging_temperature: 0.886391376887529\n",
      "  border_count: 163\n",
      "  depth: 3\n",
      "  iterations: 2980\n",
      "  l2_leaf_reg: 6.051071442283133\n",
      "  learning_rate: 0.004350896577755755\n",
      "  random_strength: 0.13340593896720732\n",
      "\n",
      "CatBoost —Å Bayesian optimization –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:\n",
      "ROC-AUC: 0.9298\n",
      "Accuracy: 0.8960\n",
      "\n",
      "–°–†–ê–í–ù–ï–ù–ò–ï –° RANDOM FOREST:\n",
      "Random Forest ROC-AUC: 0.9203\n",
      "CatBoost ROC-AUC: 0.9298\n",
      "–£–ª—É—á—à–µ–Ω–∏–µ: 0.0095\n",
      "\n",
      "[CV] END colsample_bylevel=0.9234712046133574, colsample_bynode=0.9018987298009663, colsample_bytree=0.8125607387764793, gamma=0.1147992410458816, learning_rate=0.024373689671177427, max_delta_step=10, max_depth=15, min_child_weight=9, n_estimators=2947, reg_alpha=0.03037924928893921, reg_lambda=2.536307578124162, scale_pos_weight=1.0873206530460928, subsample=0.9982555882054965; total time=  15.8s\n",
      "[CV] END colsample_bylevel=0.7867581948991739, colsample_bynode=0.9303869073943833, colsample_bytree=0.7963902646747765, gamma=0.0317084602734703, learning_rate=0.020096856092047324, max_delta_step=9, max_depth=15, min_child_weight=11, n_estimators=2127, reg_alpha=2.8699654377992703, reg_lambda=0.23154048462970217, scale_pos_weight=0.9139109911644648, subsample=0.960118245497821; total time=  15.7s\n",
      "[CV] END colsample_bylevel=0.7745272342149911, colsample_bynode=0.8672356627721698, colsample_bytree=0.7881330533719713, gamma=1.0375505262740985, learning_rate=0.014272716330904232, max_delta_step=8, max_depth=4, min_child_weight=3, n_estimators=809, reg_alpha=0.10673541775704112, reg_lambda=0.3919322779266198, scale_pos_weight=1.0491838911999625, subsample=0.7266366377985876; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.7745272342149911, colsample_bynode=0.8672356627721698, colsample_bytree=0.7881330533719713, gamma=1.0375505262740985, learning_rate=0.014272716330904232, max_delta_step=8, max_depth=4, min_child_weight=3, n_estimators=809, reg_alpha=0.10673541775704112, reg_lambda=0.3919322779266198, scale_pos_weight=1.0491838911999625, subsample=0.7266366377985876; total time=   2.8s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.7658651292754646, colsample_bytree=1.0, gamma=2.0, learning_rate=0.01345117921380264, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=1146, reg_alpha=0.0, reg_lambda=0.5872528988341121, scale_pos_weight=0.8615059429830153, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.6597322567913767, colsample_bynode=0.954146867216343, colsample_bytree=0.6424175497237475, gamma=0.047553879161059256, learning_rate=0.007440685591392875, max_delta_step=1, max_depth=4, min_child_weight=2, n_estimators=2989, reg_alpha=2.2851921100158643, reg_lambda=0.3485605035974515, scale_pos_weight=0.802746849920165, subsample=0.9790214738952016; total time=   8.8s\n",
      "[CV] END colsample_bylevel=0.9653116876268035, colsample_bynode=0.7624196130273131, colsample_bytree=0.6063157550834486, gamma=1.197442825229783, learning_rate=0.003184019752064612, max_delta_step=0, max_depth=15, min_child_weight=3, n_estimators=2938, reg_alpha=2.520382695710136, reg_lambda=0.3113786361921287, scale_pos_weight=1.1690756364866899, subsample=0.7334315239237805; total time=  18.1s\n",
      "[CV] END colsample_bylevel=0.9007555565273145, colsample_bynode=0.7836190736171249, colsample_bytree=0.7006284799308222, gamma=1.9982460298595777, learning_rate=0.010428453093846449, max_delta_step=10, max_depth=15, min_child_weight=6, n_estimators=2992, reg_alpha=1.9291537997853434, reg_lambda=2.7330981930370646, scale_pos_weight=0.9291253397346689, subsample=0.7309685935907756; total time=   9.3s\n",
      "[CV] END colsample_bylevel=0.8546625088429568, colsample_bynode=0.8249770025662069, colsample_bytree=0.9796944581148662, gamma=0.03852449315728613, learning_rate=0.0030284080004574724, max_delta_step=1, max_depth=15, min_child_weight=3, n_estimators=1455, reg_alpha=1.624639669766568, reg_lambda=0.16118396335612845, scale_pos_weight=1.1767119623134499, subsample=0.7069714046418374; total time=  20.5s\n",
      "[CV] END colsample_bylevel=0.8546625088429568, colsample_bynode=0.8249770025662069, colsample_bytree=0.9796944581148662, gamma=0.03852449315728613, learning_rate=0.0030284080004574724, max_delta_step=1, max_depth=15, min_child_weight=3, n_estimators=1455, reg_alpha=1.624639669766568, reg_lambda=0.16118396335612845, scale_pos_weight=1.1767119623134499, subsample=0.7069714046418374; total time=16.5min\n",
      "[CV] END colsample_bylevel=0.7205924091292311, colsample_bynode=0.7538825598628269, colsample_bytree=0.6256527488612251, gamma=0.058445520437185886, learning_rate=0.0010230160650187292, max_delta_step=4, max_depth=12, min_child_weight=3, n_estimators=2854, reg_alpha=0.6816657648500135, reg_lambda=2.8777976082912597, scale_pos_weight=1.1580817065698183, subsample=0.7061622549984752; total time=  26.1s\n",
      "[CV] END colsample_bylevel=0.6984601194313953, colsample_bynode=0.8944850111984711, colsample_bytree=1.0, gamma=0.6757498341962027, learning_rate=0.00473222978018942, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.2, subsample=1.0; total time=   8.6s\n",
      "[CV] END colsample_bylevel=0.6984601194313953, colsample_bynode=0.8944850111984711, colsample_bytree=1.0, gamma=0.6757498341962027, learning_rate=0.00473222978018942, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.2, subsample=1.0; total time=   9.0s\n",
      "[CV] END colsample_bylevel=0.6912564180595353, colsample_bynode=0.9801589742001154, colsample_bytree=0.6408245829556941, gamma=1.8743026566860703, learning_rate=0.006776236493718202, max_delta_step=9, max_depth=10, min_child_weight=4, n_estimators=1567, reg_alpha=0.12382233138019408, reg_lambda=1.3002371771559078, scale_pos_weight=0.8344337316271376, subsample=0.951719490368345; total time=   5.9s\n",
      "[CV] END colsample_bylevel=0.6912564180595353, colsample_bynode=0.9801589742001154, colsample_bytree=0.6408245829556941, gamma=1.8743026566860703, learning_rate=0.006776236493718202, max_delta_step=9, max_depth=10, min_child_weight=4, n_estimators=1567, reg_alpha=0.12382233138019408, reg_lambda=1.3002371771559078, scale_pos_weight=0.8344337316271376, subsample=0.951719490368345; total time=   3.9s\n",
      "[CV] END colsample_bylevel=0.9679101553147511, colsample_bynode=0.7535071394925625, colsample_bytree=0.99638272105358, gamma=1.681979709004854, learning_rate=0.0010176958502207448, max_delta_step=10, max_depth=8, min_child_weight=7, n_estimators=508, reg_alpha=2.8693004904206676, reg_lambda=1.588107350864381, scale_pos_weight=1.106616075664961, subsample=0.7101869645854496; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.9679101553147511, colsample_bynode=0.7535071394925625, colsample_bytree=0.99638272105358, gamma=1.681979709004854, learning_rate=0.0010176958502207448, max_delta_step=10, max_depth=8, min_child_weight=7, n_estimators=508, reg_alpha=2.8693004904206676, reg_lambda=1.588107350864381, scale_pos_weight=1.106616075664961, subsample=0.7101869645854496; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.8569962307940416, colsample_bynode=0.9862199517927497, colsample_bytree=0.923006263140393, gamma=0.1005751074993129, learning_rate=0.00392410799950455, max_delta_step=9, max_depth=4, min_child_weight=5, n_estimators=2916, reg_alpha=0.07713944520334617, reg_lambda=2.7718694964431596, scale_pos_weight=0.9886267032691654, subsample=0.9769145941982649; total time=   7.0s\n",
      "[CV] END colsample_bylevel=0.855727669436894, colsample_bynode=0.8893722348022144, colsample_bytree=0.6469317674481467, gamma=1.7966034612386077, learning_rate=0.04448267762598664, max_delta_step=10, max_depth=15, min_child_weight=1, n_estimators=2910, reg_alpha=0.6813653536040802, reg_lambda=2.873856441379481, scale_pos_weight=0.8406197620531091, subsample=0.9909911302206835; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.8301313283219944, colsample_bynode=0.680160222105382, colsample_bytree=0.7882403662787804, gamma=0.5869767833282243, learning_rate=0.0010456444067817427, max_delta_step=10, max_depth=15, min_child_weight=7, n_estimators=518, reg_alpha=1.0814095343565013, reg_lambda=1.0430250769227085, scale_pos_weight=1.1445212326010408, subsample=0.7644498891871443; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.8301313283219944, colsample_bynode=0.680160222105382, colsample_bytree=0.7882403662787804, gamma=0.5869767833282243, learning_rate=0.0010456444067817427, max_delta_step=10, max_depth=15, min_child_weight=7, n_estimators=518, reg_alpha=1.0814095343565013, reg_lambda=1.0430250769227085, scale_pos_weight=1.1445212326010408, subsample=0.7644498891871443; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.6770229510061877, colsample_bynode=0.7286682999943922, colsample_bytree=0.6274346266519762, gamma=1.9453460560848872, learning_rate=0.0011739381069326327, max_delta_step=0, max_depth=5, min_child_weight=12, n_estimators=2855, reg_alpha=2.161909828353458, reg_lambda=0.35317818386819744, scale_pos_weight=0.9066121961527045, subsample=0.9935421822173636; total time=   7.8s\n",
      "[CV] END colsample_bylevel=0.8343769227678106, colsample_bynode=0.9336809203107367, colsample_bytree=0.6208823029790741, gamma=1.1680246349978256, learning_rate=0.03701912540916061, max_delta_step=10, max_depth=14, min_child_weight=13, n_estimators=504, reg_alpha=0.46671049498692085, reg_lambda=2.791335439864069, scale_pos_weight=1.1587280854407362, subsample=0.9809711325681316; total time=   1.6s\n",
      "[CV] END colsample_bylevel=0.7809462954223588, colsample_bynode=0.6309085186749382, colsample_bytree=0.6, gamma=1.4613468265875142, learning_rate=0.05012224930540062, max_delta_step=10, max_depth=9, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=0.8, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.7809462954223588, colsample_bynode=0.6309085186749382, colsample_bytree=0.6, gamma=1.4613468265875142, learning_rate=0.05012224930540062, max_delta_step=10, max_depth=9, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=0.8, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.6440280332895054, colsample_bynode=0.7910605592178892, colsample_bytree=0.6557345613086555, gamma=0.9367916630594701, learning_rate=0.02431792943797359, max_delta_step=1, max_depth=4, min_child_weight=7, n_estimators=2452, reg_alpha=1.2647041706170272, reg_lambda=0.42033828809105744, scale_pos_weight=0.8563723648647037, subsample=0.9928340657181653; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.713647445242851, colsample_bynode=0.9233622952313745, colsample_bytree=0.7019239328950171, gamma=0.6849967422481907, learning_rate=0.007762522556681685, max_delta_step=9, max_depth=5, min_child_weight=6, n_estimators=2901, reg_alpha=2.492030588019343, reg_lambda=2.2047614829712723, scale_pos_weight=1.0059635874476003, subsample=0.7038933936922651; total time=   7.4s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=0.7135702127651323, learning_rate=0.0038527355554399483, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=1.589238012344313, scale_pos_weight=0.8, subsample=0.7; total time=   6.8s\n",
      "[CV] END colsample_bylevel=0.8858114288816348, colsample_bynode=0.7357605197816451, colsample_bytree=0.6776097798659215, gamma=1.9004423520625127, learning_rate=0.08514911120439839, max_delta_step=0, max_depth=4, min_child_weight=2, n_estimators=2654, reg_alpha=2.354117758124679, reg_lambda=2.6323166290111413, scale_pos_weight=0.8100871732231256, subsample=0.9903560584075802; total time=   3.1s\n",
      "[CV] END colsample_bylevel=0.8858114288816348, colsample_bynode=0.7357605197816451, colsample_bytree=0.6776097798659215, gamma=1.9004423520625127, learning_rate=0.08514911120439839, max_delta_step=0, max_depth=4, min_child_weight=2, n_estimators=2654, reg_alpha=2.354117758124679, reg_lambda=2.6323166290111413, scale_pos_weight=0.8100871732231256, subsample=0.9903560584075802; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.8858114288816348, colsample_bynode=0.7357605197816451, colsample_bytree=0.6776097798659215, gamma=1.9004423520625127, learning_rate=0.08514911120439839, max_delta_step=0, max_depth=4, min_child_weight=2, n_estimators=2654, reg_alpha=2.354117758124679, reg_lambda=2.6323166290111413, scale_pos_weight=0.8100871732231256, subsample=0.9903560584075802; total time=   1.7s\n",
      "\n",
      "[CV] END colsample_bylevel=0.6744062240881087, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.0, learning_rate=0.019890225694014878, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.002570548172429792, scale_pos_weight=1.2, subsample=0.9511129209230911; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.6744062240881087, colsample_bynode=0.6, colsample_bytree=0.6, gamma=0.0, learning_rate=0.019890225694014878, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=0.002570548172429792, scale_pos_weight=1.2, subsample=0.9511129209230911; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.9234712046133574, colsample_bynode=0.9018987298009663, colsample_bytree=0.8125607387764793, gamma=0.1147992410458816, learning_rate=0.024373689671177427, max_delta_step=10, max_depth=15, min_child_weight=9, n_estimators=2947, reg_alpha=0.03037924928893921, reg_lambda=2.536307578124162, scale_pos_weight=1.0873206530460928, subsample=0.9982555882054965; total time=  18.4s\n",
      "[CV] END colsample_bylevel=0.7867581948991739, colsample_bynode=0.9303869073943833, colsample_bytree=0.7963902646747765, gamma=0.0317084602734703, learning_rate=0.020096856092047324, max_delta_step=9, max_depth=15, min_child_weight=11, n_estimators=2127, reg_alpha=2.8699654377992703, reg_lambda=0.23154048462970217, scale_pos_weight=0.9139109911644648, subsample=0.960118245497821; total time=  17.2s\n",
      "[CV] END colsample_bylevel=0.9067384536773431, colsample_bynode=0.6126748729398347, colsample_bytree=0.9819341977594845, gamma=0.8895356791966749, learning_rate=0.02284176200877286, max_delta_step=0, max_depth=15, min_child_weight=6, n_estimators=2621, reg_alpha=2.6931033263340423, reg_lambda=2.034918221054438, scale_pos_weight=0.9691367789834109, subsample=0.998020900102754; total time=   6.4s\n",
      "[CV] END colsample_bylevel=0.9067384536773431, colsample_bynode=0.6126748729398347, colsample_bytree=0.9819341977594845, gamma=0.8895356791966749, learning_rate=0.02284176200877286, max_delta_step=0, max_depth=15, min_child_weight=6, n_estimators=2621, reg_alpha=2.6931033263340423, reg_lambda=2.034918221054438, scale_pos_weight=0.9691367789834109, subsample=0.998020900102754; total time=   6.4s\n",
      "[CV] END colsample_bylevel=0.7745272342149911, colsample_bynode=0.8672356627721698, colsample_bytree=0.7881330533719713, gamma=1.0375505262740985, learning_rate=0.014272716330904232, max_delta_step=8, max_depth=4, min_child_weight=3, n_estimators=809, reg_alpha=0.10673541775704112, reg_lambda=0.3919322779266198, scale_pos_weight=1.0491838911999625, subsample=0.7266366377985876; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.7745272342149911, colsample_bynode=0.8672356627721698, colsample_bytree=0.7881330533719713, gamma=1.0375505262740985, learning_rate=0.014272716330904232, max_delta_step=8, max_depth=4, min_child_weight=3, n_estimators=809, reg_alpha=0.10673541775704112, reg_lambda=0.3919322779266198, scale_pos_weight=1.0491838911999625, subsample=0.7266366377985876; total time=   2.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.7658651292754646, colsample_bytree=1.0, gamma=2.0, learning_rate=0.01345117921380264, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=1146, reg_alpha=0.0, reg_lambda=0.5872528988341121, scale_pos_weight=0.8615059429830153, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=0.6597322567913767, colsample_bynode=0.954146867216343, colsample_bytree=0.6424175497237475, gamma=0.047553879161059256, learning_rate=0.007440685591392875, max_delta_step=1, max_depth=4, min_child_weight=2, n_estimators=2989, reg_alpha=2.2851921100158643, reg_lambda=0.3485605035974515, scale_pos_weight=0.802746849920165, subsample=0.9790214738952016; total time=   8.8s\n",
      "[CV] END colsample_bylevel=0.9653116876268035, colsample_bynode=0.7624196130273131, colsample_bytree=0.6063157550834486, gamma=1.197442825229783, learning_rate=0.003184019752064612, max_delta_step=0, max_depth=15, min_child_weight=3, n_estimators=2938, reg_alpha=2.520382695710136, reg_lambda=0.3113786361921287, scale_pos_weight=1.1690756364866899, subsample=0.7334315239237805; total time=  17.8s\n",
      "[CV] END colsample_bylevel=0.9653116876268035, colsample_bynode=0.7624196130273131, colsample_bytree=0.6063157550834486, gamma=1.197442825229783, learning_rate=0.003184019752064612, max_delta_step=0, max_depth=15, min_child_weight=3, n_estimators=2938, reg_alpha=2.520382695710136, reg_lambda=0.3113786361921287, scale_pos_weight=1.1690756364866899, subsample=0.7334315239237805; total time=  16.0s\n",
      "[CV] END colsample_bylevel=0.8546625088429568, colsample_bynode=0.8249770025662069, colsample_bytree=0.9796944581148662, gamma=0.03852449315728613, learning_rate=0.0030284080004574724, max_delta_step=1, max_depth=15, min_child_weight=3, n_estimators=1455, reg_alpha=1.624639669766568, reg_lambda=0.16118396335612845, scale_pos_weight=1.1767119623134499, subsample=0.7069714046418374; total time=  21.4s\n",
      "[CV] END colsample_bylevel=0.7205924091292311, colsample_bynode=0.7538825598628269, colsample_bytree=0.6256527488612251, gamma=0.058445520437185886, learning_rate=0.0010230160650187292, max_delta_step=4, max_depth=12, min_child_weight=3, n_estimators=2854, reg_alpha=0.6816657648500135, reg_lambda=2.8777976082912597, scale_pos_weight=1.1580817065698183, subsample=0.7061622549984752; total time=  25.7s\n",
      "[CV] END colsample_bylevel=0.7205924091292311, colsample_bynode=0.7538825598628269, colsample_bytree=0.6256527488612251, gamma=0.058445520437185886, learning_rate=0.0010230160650187292, max_delta_step=4, max_depth=12, min_child_weight=3, n_estimators=2854, reg_alpha=0.6816657648500135, reg_lambda=2.8777976082912597, scale_pos_weight=1.1580817065698183, subsample=0.7061622549984752; total time=  26.1s\n",
      "[CV] END colsample_bylevel=0.9679101553147511, colsample_bynode=0.7535071394925625, colsample_bytree=0.99638272105358, gamma=1.681979709004854, learning_rate=0.0010176958502207448, max_delta_step=10, max_depth=8, min_child_weight=7, n_estimators=508, reg_alpha=2.8693004904206676, reg_lambda=1.588107350864381, scale_pos_weight=1.106616075664961, subsample=0.7101869645854496; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.8569962307940416, colsample_bynode=0.9862199517927497, colsample_bytree=0.923006263140393, gamma=0.1005751074993129, learning_rate=0.00392410799950455, max_delta_step=9, max_depth=4, min_child_weight=5, n_estimators=2916, reg_alpha=0.07713944520334617, reg_lambda=2.7718694964431596, scale_pos_weight=0.9886267032691654, subsample=0.9769145941982649; total time=   7.0s\n",
      "[CV] END colsample_bylevel=0.855727669436894, colsample_bynode=0.8893722348022144, colsample_bytree=0.6469317674481467, gamma=1.7966034612386077, learning_rate=0.04448267762598664, max_delta_step=10, max_depth=15, min_child_weight=1, n_estimators=2910, reg_alpha=0.6813653536040802, reg_lambda=2.873856441379481, scale_pos_weight=0.8406197620531091, subsample=0.9909911302206835; total time=   3.8s\n",
      "[CV] END colsample_bylevel=0.855727669436894, colsample_bynode=0.8893722348022144, colsample_bytree=0.6469317674481467, gamma=1.7966034612386077, learning_rate=0.04448267762598664, max_delta_step=10, max_depth=15, min_child_weight=1, n_estimators=2910, reg_alpha=0.6813653536040802, reg_lambda=2.873856441379481, scale_pos_weight=0.8406197620531091, subsample=0.9909911302206835; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.8301313283219944, colsample_bynode=0.680160222105382, colsample_bytree=0.7882403662787804, gamma=0.5869767833282243, learning_rate=0.0010456444067817427, max_delta_step=10, max_depth=15, min_child_weight=7, n_estimators=518, reg_alpha=1.0814095343565013, reg_lambda=1.0430250769227085, scale_pos_weight=1.1445212326010408, subsample=0.7644498891871443; total time=   3.8s\n",
      "[CV] END colsample_bylevel=0.6770229510061877, colsample_bynode=0.7286682999943922, colsample_bytree=0.6274346266519762, gamma=1.9453460560848872, learning_rate=0.0011739381069326327, max_delta_step=0, max_depth=5, min_child_weight=12, n_estimators=2855, reg_alpha=2.161909828353458, reg_lambda=0.35317818386819744, scale_pos_weight=0.9066121961527045, subsample=0.9935421822173636; total time=   8.0s\n",
      "[CV] END colsample_bylevel=0.6770229510061877, colsample_bynode=0.7286682999943922, colsample_bytree=0.6274346266519762, gamma=1.9453460560848872, learning_rate=0.0011739381069326327, max_delta_step=0, max_depth=5, min_child_weight=12, n_estimators=2855, reg_alpha=2.161909828353458, reg_lambda=0.35317818386819744, scale_pos_weight=0.9066121961527045, subsample=0.9935421822173636; total time=   6.0s\n",
      "[CV] END colsample_bylevel=0.8343769227678106, colsample_bynode=0.9336809203107367, colsample_bytree=0.6208823029790741, gamma=1.1680246349978256, learning_rate=0.03701912540916061, max_delta_step=10, max_depth=14, min_child_weight=13, n_estimators=504, reg_alpha=0.46671049498692085, reg_lambda=2.791335439864069, scale_pos_weight=1.1587280854407362, subsample=0.9809711325681316; total time=   1.7s\n",
      "[CV] END colsample_bylevel=0.7809462954223588, colsample_bynode=0.6309085186749382, colsample_bytree=0.6, gamma=1.4613468265875142, learning_rate=0.05012224930540062, max_delta_step=10, max_depth=9, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=0.8, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.7809462954223588, colsample_bynode=0.6309085186749382, colsample_bytree=0.6, gamma=1.4613468265875142, learning_rate=0.05012224930540062, max_delta_step=10, max_depth=9, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=0.8, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.6440280332895054, colsample_bynode=0.7910605592178892, colsample_bytree=0.6557345613086555, gamma=0.9367916630594701, learning_rate=0.02431792943797359, max_delta_step=1, max_depth=4, min_child_weight=7, n_estimators=2452, reg_alpha=1.2647041706170272, reg_lambda=0.42033828809105744, scale_pos_weight=0.8563723648647037, subsample=0.9928340657181653; total time=   3.1s\n",
      "[CV] END colsample_bylevel=0.713647445242851, colsample_bynode=0.9233622952313745, colsample_bytree=0.7019239328950171, gamma=0.6849967422481907, learning_rate=0.007762522556681685, max_delta_step=9, max_depth=5, min_child_weight=6, n_estimators=2901, reg_alpha=2.492030588019343, reg_lambda=2.2047614829712723, scale_pos_weight=1.0059635874476003, subsample=0.7038933936922651; total time=   7.3s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=0.7135702127651323, learning_rate=0.0038527355554399483, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=1.589238012344313, scale_pos_weight=0.8, subsample=0.7; total time=   6.7s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=0.7135702127651323, learning_rate=0.0038527355554399483, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=1.589238012344313, scale_pos_weight=0.8, subsample=0.7; total time=   6.8s\n",
      "[CV] END colsample_bylevel=0.7205924091292311, colsample_bynode=0.7538825598628269, colsample_bytree=0.6256527488612251, gamma=0.058445520437185886, learning_rate=0.0010230160650187292, max_delta_step=4, max_depth=12, min_child_weight=3, n_estimators=2854, reg_alpha=0.6816657648500135, reg_lambda=2.8777976082912597, scale_pos_weight=1.1580817065698183, subsample=0.7061622549984752; total time=  26.2s\n",
      "[CV] END colsample_bylevel=0.6984601194313953, colsample_bynode=0.8944850111984711, colsample_bytree=1.0, gamma=0.6757498341962027, learning_rate=0.00473222978018942, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.2, subsample=1.0; total time=   8.7s\n",
      "[CV] END colsample_bylevel=0.6984601194313953, colsample_bynode=0.8944850111984711, colsample_bytree=1.0, gamma=0.6757498341962027, learning_rate=0.00473222978018942, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.2, subsample=1.0; total time=   8.3s\n",
      "[CV] END colsample_bylevel=0.6912564180595353, colsample_bynode=0.9801589742001154, colsample_bytree=0.6408245829556941, gamma=1.8743026566860703, learning_rate=0.006776236493718202, max_delta_step=9, max_depth=10, min_child_weight=4, n_estimators=1567, reg_alpha=0.12382233138019408, reg_lambda=1.3002371771559078, scale_pos_weight=0.8344337316271376, subsample=0.951719490368345; total time=   5.8s\n",
      "[CV] END colsample_bylevel=0.9679101553147511, colsample_bynode=0.7535071394925625, colsample_bytree=0.99638272105358, gamma=1.681979709004854, learning_rate=0.0010176958502207448, max_delta_step=10, max_depth=8, min_child_weight=7, n_estimators=508, reg_alpha=2.8693004904206676, reg_lambda=1.588107350864381, scale_pos_weight=1.106616075664961, subsample=0.7101869645854496; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.8569962307940416, colsample_bynode=0.9862199517927497, colsample_bytree=0.923006263140393, gamma=0.1005751074993129, learning_rate=0.00392410799950455, max_delta_step=9, max_depth=4, min_child_weight=5, n_estimators=2916, reg_alpha=0.07713944520334617, reg_lambda=2.7718694964431596, scale_pos_weight=0.9886267032691654, subsample=0.9769145941982649; total time=   7.1s\n",
      "[CV] END colsample_bylevel=0.855727669436894, colsample_bynode=0.8893722348022144, colsample_bytree=0.6469317674481467, gamma=1.7966034612386077, learning_rate=0.04448267762598664, max_delta_step=10, max_depth=15, min_child_weight=1, n_estimators=2910, reg_alpha=0.6813653536040802, reg_lambda=2.873856441379481, scale_pos_weight=0.8406197620531091, subsample=0.9909911302206835; total time=   3.8s\n",
      "[CV] END colsample_bylevel=0.855727669436894, colsample_bynode=0.8893722348022144, colsample_bytree=0.6469317674481467, gamma=1.7966034612386077, learning_rate=0.04448267762598664, max_delta_step=10, max_depth=15, min_child_weight=1, n_estimators=2910, reg_alpha=0.6813653536040802, reg_lambda=2.873856441379481, scale_pos_weight=0.8406197620531091, subsample=0.9909911302206835; total time=   3.6s\n",
      "[CV] END colsample_bylevel=0.8301313283219944, colsample_bynode=0.680160222105382, colsample_bytree=0.7882403662787804, gamma=0.5869767833282243, learning_rate=0.0010456444067817427, max_delta_step=10, max_depth=15, min_child_weight=7, n_estimators=518, reg_alpha=1.0814095343565013, reg_lambda=1.0430250769227085, scale_pos_weight=1.1445212326010408, subsample=0.7644498891871443; total time=   3.8s\n",
      "[CV] END colsample_bylevel=0.6770229510061877, colsample_bynode=0.7286682999943922, colsample_bytree=0.6274346266519762, gamma=1.9453460560848872, learning_rate=0.0011739381069326327, max_delta_step=0, max_depth=5, min_child_weight=12, n_estimators=2855, reg_alpha=2.161909828353458, reg_lambda=0.35317818386819744, scale_pos_weight=0.9066121961527045, subsample=0.9935421822173636; total time=   8.2s\n",
      "[CV] END colsample_bylevel=0.7507044205387277, colsample_bynode=0.7049424715681426, colsample_bytree=0.6479129327126751, gamma=1.860066167554181, learning_rate=0.04792656203245692, max_delta_step=0, max_depth=12, min_child_weight=7, n_estimators=584, reg_alpha=2.9217822405302307, reg_lambda=0.8423298528076069, scale_pos_weight=0.9452430152931751, subsample=0.9916724464551119; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.7507044205387277, colsample_bynode=0.7049424715681426, colsample_bytree=0.6479129327126751, gamma=1.860066167554181, learning_rate=0.04792656203245692, max_delta_step=0, max_depth=12, min_child_weight=7, n_estimators=584, reg_alpha=2.9217822405302307, reg_lambda=0.8423298528076069, scale_pos_weight=0.9452430152931751, subsample=0.9916724464551119; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.7507044205387277, colsample_bynode=0.7049424715681426, colsample_bytree=0.6479129327126751, gamma=1.860066167554181, learning_rate=0.04792656203245692, max_delta_step=0, max_depth=12, min_child_weight=7, n_estimators=584, reg_alpha=2.9217822405302307, reg_lambda=0.8423298528076069, scale_pos_weight=0.9452430152931751, subsample=0.9916724464551119; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.8343769227678106, colsample_bynode=0.9336809203107367, colsample_bytree=0.6208823029790741, gamma=1.1680246349978256, learning_rate=0.03701912540916061, max_delta_step=10, max_depth=14, min_child_weight=13, n_estimators=504, reg_alpha=0.46671049498692085, reg_lambda=2.791335439864069, scale_pos_weight=1.1587280854407362, subsample=0.9809711325681316; total time=   1.6s\n",
      "[CV] END colsample_bylevel=0.7809462954223588, colsample_bynode=0.6309085186749382, colsample_bytree=0.6, gamma=1.4613468265875142, learning_rate=0.05012224930540062, max_delta_step=10, max_depth=9, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=0.8, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.7809462954223588, colsample_bynode=0.6309085186749382, colsample_bytree=0.6, gamma=1.4613468265875142, learning_rate=0.05012224930540062, max_delta_step=10, max_depth=9, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=0.8, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.6440280332895054, colsample_bynode=0.7910605592178892, colsample_bytree=0.6557345613086555, gamma=0.9367916630594701, learning_rate=0.02431792943797359, max_delta_step=1, max_depth=4, min_child_weight=7, n_estimators=2452, reg_alpha=1.2647041706170272, reg_lambda=0.42033828809105744, scale_pos_weight=0.8563723648647037, subsample=0.9928340657181653; total time=   3.1s\n",
      "[CV] END colsample_bylevel=0.713647445242851, colsample_bynode=0.9233622952313745, colsample_bytree=0.7019239328950171, gamma=0.6849967422481907, learning_rate=0.007762522556681685, max_delta_step=9, max_depth=5, min_child_weight=6, n_estimators=2901, reg_alpha=2.492030588019343, reg_lambda=2.2047614829712723, scale_pos_weight=1.0059635874476003, subsample=0.7038933936922651; total time=   7.3s\n",
      "[CV] END colsample_bylevel=0.713647445242851, colsample_bynode=0.9233622952313745, colsample_bytree=0.7019239328950171, gamma=0.6849967422481907, learning_rate=0.007762522556681685, max_delta_step=9, max_depth=5, min_child_weight=6, n_estimators=2901, reg_alpha=2.492030588019343, reg_lambda=2.2047614829712723, scale_pos_weight=1.0059635874476003, subsample=0.7038933936922651; total time=   7.5s\n",
      "[CV] END colsample_bylevel=0.8858114288816348, colsample_bynode=0.7357605197816451, colsample_bytree=0.6776097798659215, gamma=1.9004423520625127, learning_rate=0.08514911120439839, max_delta_step=0, max_depth=4, min_child_weight=2, n_estimators=2654, reg_alpha=2.354117758124679, reg_lambda=2.6323166290111413, scale_pos_weight=0.8100871732231256, subsample=0.9903560584075802; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.8858114288816348, colsample_bynode=0.7357605197816451, colsample_bytree=0.6776097798659215, gamma=1.9004423520625127, learning_rate=0.08514911120439839, max_delta_step=0, max_depth=4, min_child_weight=2, n_estimators=2654, reg_alpha=2.354117758124679, reg_lambda=2.6323166290111413, scale_pos_weight=0.8100871732231256, subsample=0.9903560584075802; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.7205924091292311, colsample_bynode=0.7538825598628269, colsample_bytree=0.6256527488612251, gamma=0.058445520437185886, learning_rate=0.0010230160650187292, max_delta_step=4, max_depth=12, min_child_weight=3, n_estimators=2854, reg_alpha=0.6816657648500135, reg_lambda=2.8777976082912597, scale_pos_weight=1.1580817065698183, subsample=0.7061622549984752; total time=  26.5s\n",
      "[CV] END colsample_bylevel=0.6984601194313953, colsample_bynode=0.8944850111984711, colsample_bytree=1.0, gamma=0.6757498341962027, learning_rate=0.00473222978018942, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.2, subsample=1.0; total time=   9.3s\n",
      "[CV] END colsample_bylevel=0.6912564180595353, colsample_bynode=0.9801589742001154, colsample_bytree=0.6408245829556941, gamma=1.8743026566860703, learning_rate=0.006776236493718202, max_delta_step=9, max_depth=10, min_child_weight=4, n_estimators=1567, reg_alpha=0.12382233138019408, reg_lambda=1.3002371771559078, scale_pos_weight=0.8344337316271376, subsample=0.951719490368345; total time=   5.8s\n",
      "[CV] END colsample_bylevel=0.6912564180595353, colsample_bynode=0.9801589742001154, colsample_bytree=0.6408245829556941, gamma=1.8743026566860703, learning_rate=0.006776236493718202, max_delta_step=9, max_depth=10, min_child_weight=4, n_estimators=1567, reg_alpha=0.12382233138019408, reg_lambda=1.3002371771559078, scale_pos_weight=0.8344337316271376, subsample=0.951719490368345; total time=   6.0s\n",
      "[CV] END colsample_bylevel=0.6912564180595353, colsample_bynode=0.9801589742001154, colsample_bytree=0.6408245829556941, gamma=1.8743026566860703, learning_rate=0.006776236493718202, max_delta_step=9, max_depth=10, min_child_weight=4, n_estimators=1567, reg_alpha=0.12382233138019408, reg_lambda=1.3002371771559078, scale_pos_weight=0.8344337316271376, subsample=0.951719490368345; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.9679101553147511, colsample_bynode=0.7535071394925625, colsample_bytree=0.99638272105358, gamma=1.681979709004854, learning_rate=0.0010176958502207448, max_delta_step=10, max_depth=8, min_child_weight=7, n_estimators=508, reg_alpha=2.8693004904206676, reg_lambda=1.588107350864381, scale_pos_weight=1.106616075664961, subsample=0.7101869645854496; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.8569962307940416, colsample_bynode=0.9862199517927497, colsample_bytree=0.923006263140393, gamma=0.1005751074993129, learning_rate=0.00392410799950455, max_delta_step=9, max_depth=4, min_child_weight=5, n_estimators=2916, reg_alpha=0.07713944520334617, reg_lambda=2.7718694964431596, scale_pos_weight=0.9886267032691654, subsample=0.9769145941982649; total time=   7.0s\n",
      "[CV] END colsample_bylevel=0.855727669436894, colsample_bynode=0.8893722348022144, colsample_bytree=0.6469317674481467, gamma=1.7966034612386077, learning_rate=0.04448267762598664, max_delta_step=10, max_depth=15, min_child_weight=1, n_estimators=2910, reg_alpha=0.6813653536040802, reg_lambda=2.873856441379481, scale_pos_weight=0.8406197620531091, subsample=0.9909911302206835; total time=   3.9s\n",
      "[CV] END colsample_bylevel=0.855727669436894, colsample_bynode=0.8893722348022144, colsample_bytree=0.6469317674481467, gamma=1.7966034612386077, learning_rate=0.04448267762598664, max_delta_step=10, max_depth=15, min_child_weight=1, n_estimators=2910, reg_alpha=0.6813653536040802, reg_lambda=2.873856441379481, scale_pos_weight=0.8406197620531091, subsample=0.9909911302206835; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.8301313283219944, colsample_bynode=0.680160222105382, colsample_bytree=0.7882403662787804, gamma=0.5869767833282243, learning_rate=0.0010456444067817427, max_delta_step=10, max_depth=15, min_child_weight=7, n_estimators=518, reg_alpha=1.0814095343565013, reg_lambda=1.0430250769227085, scale_pos_weight=1.1445212326010408, subsample=0.7644498891871443; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.8301313283219944, colsample_bynode=0.680160222105382, colsample_bytree=0.7882403662787804, gamma=0.5869767833282243, learning_rate=0.0010456444067817427, max_delta_step=10, max_depth=15, min_child_weight=7, n_estimators=518, reg_alpha=1.0814095343565013, reg_lambda=1.0430250769227085, scale_pos_weight=1.1445212326010408, subsample=0.7644498891871443; total time=   3.5s\n",
      "[CV] END colsample_bylevel=0.6770229510061877, colsample_bynode=0.7286682999943922, colsample_bytree=0.6274346266519762, gamma=1.9453460560848872, learning_rate=0.0011739381069326327, max_delta_step=0, max_depth=5, min_child_weight=12, n_estimators=2855, reg_alpha=2.161909828353458, reg_lambda=0.35317818386819744, scale_pos_weight=0.9066121961527045, subsample=0.9935421822173636; total time=   7.7s\n",
      "[CV] END colsample_bylevel=0.8343769227678106, colsample_bynode=0.9336809203107367, colsample_bytree=0.6208823029790741, gamma=1.1680246349978256, learning_rate=0.03701912540916061, max_delta_step=10, max_depth=14, min_child_weight=13, n_estimators=504, reg_alpha=0.46671049498692085, reg_lambda=2.791335439864069, scale_pos_weight=1.1587280854407362, subsample=0.9809711325681316; total time=   1.6s\n",
      "[CV] END colsample_bylevel=0.7809462954223588, colsample_bynode=0.6309085186749382, colsample_bytree=0.6, gamma=1.4613468265875142, learning_rate=0.05012224930540062, max_delta_step=10, max_depth=9, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=0.8, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bylevel=0.7809462954223588, colsample_bynode=0.6309085186749382, colsample_bytree=0.6, gamma=1.4613468265875142, learning_rate=0.05012224930540062, max_delta_step=10, max_depth=9, min_child_weight=1, n_estimators=500, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=0.8, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.6440280332895054, colsample_bynode=0.7910605592178892, colsample_bytree=0.6557345613086555, gamma=0.9367916630594701, learning_rate=0.02431792943797359, max_delta_step=1, max_depth=4, min_child_weight=7, n_estimators=2452, reg_alpha=1.2647041706170272, reg_lambda=0.42033828809105744, scale_pos_weight=0.8563723648647037, subsample=0.9928340657181653; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.713647445242851, colsample_bynode=0.9233622952313745, colsample_bytree=0.7019239328950171, gamma=0.6849967422481907, learning_rate=0.007762522556681685, max_delta_step=9, max_depth=5, min_child_weight=6, n_estimators=2901, reg_alpha=2.492030588019343, reg_lambda=2.2047614829712723, scale_pos_weight=1.0059635874476003, subsample=0.7038933936922651; total time=   7.4s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=0.7135702127651323, learning_rate=0.0038527355554399483, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=1.589238012344313, scale_pos_weight=0.8, subsample=0.7; total time=   6.6s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=0.7135702127651323, learning_rate=0.0038527355554399483, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=1.589238012344313, scale_pos_weight=0.8, subsample=0.7; total time=   6.8s\n",
      "[CV] END colsample_bylevel=0.7205924091292311, colsample_bynode=0.7538825598628269, colsample_bytree=0.6256527488612251, gamma=0.058445520437185886, learning_rate=0.0010230160650187292, max_delta_step=4, max_depth=12, min_child_weight=3, n_estimators=2854, reg_alpha=0.6816657648500135, reg_lambda=2.8777976082912597, scale_pos_weight=1.1580817065698183, subsample=0.7061622549984752; total time=  26.4s\n",
      "[CV] END colsample_bylevel=0.6984601194313953, colsample_bynode=0.8944850111984711, colsample_bytree=1.0, gamma=0.6757498341962027, learning_rate=0.00473222978018942, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.2, subsample=1.0; total time=   8.9s\n",
      "[CV] END colsample_bylevel=0.6984601194313953, colsample_bynode=0.8944850111984711, colsample_bytree=1.0, gamma=0.6757498341962027, learning_rate=0.00473222978018942, max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=3.0, scale_pos_weight=1.2, subsample=1.0; total time=   8.1s\n",
      "[CV] END colsample_bylevel=0.6912564180595353, colsample_bynode=0.9801589742001154, colsample_bytree=0.6408245829556941, gamma=1.8743026566860703, learning_rate=0.006776236493718202, max_delta_step=9, max_depth=10, min_child_weight=4, n_estimators=1567, reg_alpha=0.12382233138019408, reg_lambda=1.3002371771559078, scale_pos_weight=0.8344337316271376, subsample=0.951719490368345; total time=   5.5s\n",
      "[CV] END colsample_bylevel=0.9679101553147511, colsample_bynode=0.7535071394925625, colsample_bytree=0.99638272105358, gamma=1.681979709004854, learning_rate=0.0010176958502207448, max_delta_step=10, max_depth=8, min_child_weight=7, n_estimators=508, reg_alpha=2.8693004904206676, reg_lambda=1.588107350864381, scale_pos_weight=1.106616075664961, subsample=0.7101869645854496; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.8569962307940416, colsample_bynode=0.9862199517927497, colsample_bytree=0.923006263140393, gamma=0.1005751074993129, learning_rate=0.00392410799950455, max_delta_step=9, max_depth=4, min_child_weight=5, n_estimators=2916, reg_alpha=0.07713944520334617, reg_lambda=2.7718694964431596, scale_pos_weight=0.9886267032691654, subsample=0.9769145941982649; total time=   7.1s\n",
      "[CV] END colsample_bylevel=0.855727669436894, colsample_bynode=0.8893722348022144, colsample_bytree=0.6469317674481467, gamma=1.7966034612386077, learning_rate=0.04448267762598664, max_delta_step=10, max_depth=15, min_child_weight=1, n_estimators=2910, reg_alpha=0.6813653536040802, reg_lambda=2.873856441379481, scale_pos_weight=0.8406197620531091, subsample=0.9909911302206835; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.855727669436894, colsample_bynode=0.8893722348022144, colsample_bytree=0.6469317674481467, gamma=1.7966034612386077, learning_rate=0.04448267762598664, max_delta_step=10, max_depth=15, min_child_weight=1, n_estimators=2910, reg_alpha=0.6813653536040802, reg_lambda=2.873856441379481, scale_pos_weight=0.8406197620531091, subsample=0.9909911302206835; total time=   3.6s\n",
      "[CV] END colsample_bylevel=0.8301313283219944, colsample_bynode=0.680160222105382, colsample_bytree=0.7882403662787804, gamma=0.5869767833282243, learning_rate=0.0010456444067817427, max_delta_step=10, max_depth=15, min_child_weight=7, n_estimators=518, reg_alpha=1.0814095343565013, reg_lambda=1.0430250769227085, scale_pos_weight=1.1445212326010408, subsample=0.7644498891871443; total time=   3.8s\n",
      "[CV] END colsample_bylevel=0.6770229510061877, colsample_bynode=0.7286682999943922, colsample_bytree=0.6274346266519762, gamma=1.9453460560848872, learning_rate=0.0011739381069326327, max_delta_step=0, max_depth=5, min_child_weight=12, n_estimators=2855, reg_alpha=2.161909828353458, reg_lambda=0.35317818386819744, scale_pos_weight=0.9066121961527045, subsample=0.9935421822173636; total time=   8.1s\n",
      "[CV] END colsample_bylevel=0.7507044205387277, colsample_bynode=0.7049424715681426, colsample_bytree=0.6479129327126751, gamma=1.860066167554181, learning_rate=0.04792656203245692, max_delta_step=0, max_depth=12, min_child_weight=7, n_estimators=584, reg_alpha=2.9217822405302307, reg_lambda=0.8423298528076069, scale_pos_weight=0.9452430152931751, subsample=0.9916724464551119; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.7507044205387277, colsample_bynode=0.7049424715681426, colsample_bytree=0.6479129327126751, gamma=1.860066167554181, learning_rate=0.04792656203245692, max_delta_step=0, max_depth=12, min_child_weight=7, n_estimators=584, reg_alpha=2.9217822405302307, reg_lambda=0.8423298528076069, scale_pos_weight=0.9452430152931751, subsample=0.9916724464551119; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.7507044205387277, colsample_bynode=0.7049424715681426, colsample_bytree=0.6479129327126751, gamma=1.860066167554181, learning_rate=0.04792656203245692, max_delta_step=0, max_depth=12, min_child_weight=7, n_estimators=584, reg_alpha=2.9217822405302307, reg_lambda=0.8423298528076069, scale_pos_weight=0.9452430152931751, subsample=0.9916724464551119; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.8343769227678106, colsample_bynode=0.9336809203107367, colsample_bytree=0.6208823029790741, gamma=1.1680246349978256, learning_rate=0.03701912540916061, max_delta_step=10, max_depth=14, min_child_weight=13, n_estimators=504, reg_alpha=0.46671049498692085, reg_lambda=2.791335439864069, scale_pos_weight=1.1587280854407362, subsample=0.9809711325681316; total time=   1.6s\n",
      "[CV] END colsample_bylevel=0.8343769227678106, colsample_bynode=0.9336809203107367, colsample_bytree=0.6208823029790741, gamma=1.1680246349978256, learning_rate=0.03701912540916061, max_delta_step=10, max_depth=14, min_child_weight=13, n_estimators=504, reg_alpha=0.46671049498692085, reg_lambda=2.791335439864069, scale_pos_weight=1.1587280854407362, subsample=0.9809711325681316; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.6440280332895054, colsample_bynode=0.7910605592178892, colsample_bytree=0.6557345613086555, gamma=0.9367916630594701, learning_rate=0.02431792943797359, max_delta_step=1, max_depth=4, min_child_weight=7, n_estimators=2452, reg_alpha=1.2647041706170272, reg_lambda=0.42033828809105744, scale_pos_weight=0.8563723648647037, subsample=0.9928340657181653; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.713647445242851, colsample_bynode=0.9233622952313745, colsample_bytree=0.7019239328950171, gamma=0.6849967422481907, learning_rate=0.007762522556681685, max_delta_step=9, max_depth=5, min_child_weight=6, n_estimators=2901, reg_alpha=2.492030588019343, reg_lambda=2.2047614829712723, scale_pos_weight=1.0059635874476003, subsample=0.7038933936922651; total time=   7.5s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=0.7135702127651323, learning_rate=0.0038527355554399483, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=1.589238012344313, scale_pos_weight=0.8, subsample=0.7; total time=   6.7s\n",
      "[CV] END colsample_bylevel=0.6, colsample_bynode=1.0, colsample_bytree=0.6, gamma=0.7135702127651323, learning_rate=0.0038527355554399483, max_delta_step=10, max_depth=4, min_child_weight=1, n_estimators=3000, reg_alpha=3.0, reg_lambda=1.589238012344313, scale_pos_weight=0.8, subsample=0.7; total time=   6.8s\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è CatBoost\n",
    "param_space = {\n",
    "    'iterations': Integer(100, 3000),\n",
    "    'depth': Integer(3, 10),\n",
    "    'learning_rate': Real(0.001, 0.3, prior='log-uniform'),\n",
    "    'l2_leaf_reg': Real(0, 10),\n",
    "    'random_strength': Real(0, 10),\n",
    "    'bagging_temperature': Real(0, 1),\n",
    "    'border_count': Integer(32, 255),\n",
    "}\n",
    "\n",
    "catboost = CatBoostClassifier(random_state=42, verbose=False)\n",
    "\n",
    "bayes_search_cat = BayesSearchCV(\n",
    "    estimator=catboost,\n",
    "    search_spaces=param_space,\n",
    "    n_iter=50,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='roc_auc',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "bayes_search_cat.fit(X_train, y_train)\n",
    "\n",
    "# –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "print(f\"–õ—É—á—à–∏–π ROC-AUC: {bayes_search_cat.best_score_:.4f}\")\n",
    "print(f\"–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\")\n",
    "for param, value in bayes_search_cat.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "best_cat_model = bayes_search_cat.best_estimator_\n",
    "\n",
    "y_pred_cat = best_cat_model.predict(X_val)\n",
    "y_pred_proba_cat = best_cat_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "roc_auc_cat = roc_auc_score(y_val, y_pred_proba_cat)\n",
    "accuracy_cat = accuracy_score(y_val, y_pred_cat)\n",
    "\n",
    "print(f\"\\nCatBoost —Å Bayesian optimization –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:\")\n",
    "print(f\"ROC-AUC: {roc_auc_cat:.4f}\")\n",
    "print(f\"Accuracy: {accuracy_cat:.4f}\")\n",
    "\n",
    "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ\n",
    "print(f\"\\n–°–†–ê–í–ù–ï–ù–ò–ï –° RANDOM FOREST:\")\n",
    "print(f\"Random Forest ROC-AUC: {roc_auc:.4f}\")\n",
    "print(f\"CatBoost ROC-AUC: {roc_auc_cat:.4f}\")\n",
    "print(f\"–£–ª—É—á—à–µ–Ω–∏–µ: {roc_auc_cat - roc_auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
